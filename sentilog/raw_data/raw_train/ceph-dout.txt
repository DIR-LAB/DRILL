./rbd_replay/Replayer.cc:  dout(THREAD_LEVEL) << "Worker thread started" << dendl;
./rbd_replay/Replayer.cc:	dout(THREAD_LEVEL) << "Worker thread trying to stop, still waiting for " << m_pending_ios.size() << " pending IOs to complete:" << dendl;
./rbd_replay/Replayer.cc:	  dout(THREAD_LEVEL) << "> " << p.first << dendl;
./rbd_replay/Replayer.cc:  dout(THREAD_LEVEL) << "Worker thread stopped" << dendl;
./rbd_replay/Replayer.cc:      dout(THREAD_LEVEL) << "Waiting for workers to die" << dendl;
./rbd_replay/Replayer.cc:  dout(DEPGRAPH_LEVEL) << "ActionTracker::set_complete(" << id << ")" << dendl;
./rbd_replay/Replayer.cc:    dout(DEPGRAPH_LEVEL) << "Waiting for " << dep.id << dendl;
./rbd_replay/Replayer.cc:	dout(DEPGRAPH_LEVEL) << "Still waiting for " << dep.id << dendl;
./rbd_replay/Replayer.cc:    dout(DEPGRAPH_LEVEL) << "Finished waiting for " << dep.id << " after " << micros << " microseconds" << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/actions.cc:  dout(ACTION_LEVEL) << "Performing " << *this << dendl;
./rbd_replay/PendingIO.cc:  dout(ACTION_LEVEL) << "Completed pending IO #" << m_id << dendl;
./auth/none/AuthNoneAuthorizeHandler.cc:    ldout(cct, 0) << "AuthNoneAuthorizeHandle::verify_authorizer() failed to decode" << dendl;
./auth/AuthMethodList.cc:    ldout(cct, 5) << "adding auth protocol: " << *iter << dendl;
./auth/AuthRegistry.cc:    ldout(cct, 5) << "adding auth protocol: " << i << dendl;
./auth/AuthRegistry.cc:  ldout(cct,20) << __func__ << " " << s << " -> " << *v << dendl;
./auth/AuthRegistry.cc:    ldout(cct, 5) << "adding con mode: " << i << dendl;
./auth/AuthRegistry.cc:  ldout(cct,20) << __func__ << " " << s << " -> " << *v << dendl;
./auth/KeyRing.cc:  ldout(cct, 2) << "KeyRing::load: loaded key file " << filename << dendl;
./auth/KeyRing.cc:    ldout(cct, 10) << " importing " << p->first << dendl;
./auth/KeyRing.cc:    ldout(cct, 30) << "    " << p->second << dendl;
./auth/cephx/CephxClientHandler.cc:  ldout(cct,10) << __func__ << dendl;
./auth/cephx/CephxClientHandler.cc:  ldout(cct, 10) << "build_request" << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 20) << "no secret found for entity: " << cct->_conf->name << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 20) << "secret for entity " << cct->_conf->name << " is invalid" << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 20) << "cephx_calc_client_server_challenge error: " << error << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 20) << "old ticket len=" << req.old_ticket.blob.length() << dendl;
./auth/cephx/CephxClientHandler.cc:    ldout(cct, 10) << "get service keys: want=" << want << " need=" << need << " have=" << have << dendl;
./auth/cephx/CephxClientHandler.cc:  ldout(cct, 10) << this << " handle_response ret = " << ret << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 10) << " get_auth_session_key" << dendl;
./auth/cephx/CephxClientHandler.cc:	ldout(cct, 0) << "key not found for " << cct->_conf->name << dendl;
./auth/cephx/CephxClientHandler.cc:	ldout(cct, 0) << "could not verify service_ticket reply" << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 10) << " want=" << want << " need=" << need << " have=" << have << dendl;
./auth/cephx/CephxClientHandler.cc:	      ldout(cct, 10) << " got extra service_tickets" << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 10) << " get_principal_session_key session_key " << ticket_handler.session_key << dendl;
./auth/cephx/CephxClientHandler.cc:        ldout(cct, 0) << "could not verify service_ticket reply" << dendl;
./auth/cephx/CephxClientHandler.cc:      ldout(cct, 10) << " get_rotating_key" << dendl;
./auth/cephx/CephxClientHandler.cc:          ldout(cct, 0) << "key not found for " << cct->_conf->name << dendl;
./auth/cephx/CephxClientHandler.cc:   ldout(cct, 0) << " unknown request_type " << header.request_type << dendl;
./auth/cephx/CephxClientHandler.cc:  ldout(cct, 10) << "build_authorizer for service " << ceph_entity_type_name(service_id) << dendl;
./auth/cephx/CephxClientHandler.cc:  ldout(cct, 10) << "build_rotating_request" << dendl;
./auth/cephx/CephxAuthorizeHandler.cc:    ldout(cct, 1) << "verify authorizer, authorizer_data.length()=0" << dendl;
./auth/cephx/CephxServiceHandler.cc:        ldout(cct, 0) << "couldn't find entity name: " << entity_name << dendl;
./auth/cephx/CephxServiceHandler.cc:	ldout(cct, 0) << " cephx_calc_client_server_challenge error: " << error << dendl;
./auth/cephx/CephxServiceHandler.cc:        ldout(cct, 0) << " could not get service secret for auth subsystem" << dendl;
./auth/cephx/CephxServiceHandler.cc:        ldout(cct, 0) << " could not get mon caps for " << entity_name << dendl;
./auth/cephx/CephxServiceHandler.cc:          ldout(cct,0) << "mon caps null for " << entity_name << dendl;
./auth/cephx/CephxServiceHandler.cc:      ldout(cct, 10) << "handle_request get_principal_session_key" << dendl;
./auth/cephx/CephxServiceHandler.cc:      ldout(cct, 10) << " ticket_req.keys = " << ticket_req.keys << dendl;
./auth/cephx/CephxServiceHandler.cc:	ldout(cct, 10) << __func__ << " did not find any service keys" << dendl;
./auth/cephx/CephxServiceHandler.cc:    ldout(cct, 10) << "handle_request unknown op " << cephx_header.request_type << dendl;
./auth/cephx/CephxProtocol.cc:      ldout(cct, -1) << "error encoding encrypted: " << error << dendl;
./auth/cephx/CephxProtocol.cc:	ldout(cct, -1) << "error encoding encrypted ticket: " << error << dendl;
./auth/cephx/CephxProtocol.cc:      ldout(cct, 10) << __func__ << " got encrypted ticket" << dendl;
./auth/cephx/CephxProtocol.cc:    ldout(cct, 1) << __func__ << " decode error: " << e.what() << dendl;
./auth/cephx/CephxProtocol.cc:  ldout(cct, 10) << "verify_service_ticket_reply got " << num << " keys" << dendl;
./auth/cephx/CephxProtocol.cc:    ldout(cct, 10) << "got key for service_id " << ceph_entity_type_name(type) << dendl;
./auth/cephx/CephxProtocol.cc:    ldout(cct, 0) << "failed to encrypt authorizer: " << error << dendl;
./auth/cephx/CephxProtocol.cc:  ldout(cct, 10) << "verify_authorizer global_id=" << global_id << dendl;
./auth/cephx/CephxProtocol.cc:	ldout(cct, 10) << "verify_authorizer: encode_encrypt error: " << error << dendl;
./auth/cephx/CephxProtocol.cc:    ldout(cct, 10) << "verify_authorizer: encode_encrypt error: " << error << dendl;
./auth/cephx/CephxProtocol.cc:      ldout(cct, 0) << "verify_reply couldn't decrypt with error: " << error << dendl;
./auth/cephx/CephxProtocol.cc:    ldout(cct, 0) << __func__ << " failed to encrypt authorizer: " << error << dendl;
./auth/cephx/CephxKeyServer.cc:    ldout(cct, 10) << "get_service_secret service " << ceph_entity_type_name(service_id) << " not found " << dendl;
./auth/cephx/CephxKeyServer.cc:    ldout(cct, 30) << " I have:" << dendl;
./auth/cephx/CephxKeyServer.cc:      ldout(cct, 30) << " id " << iter->first << " " << iter->second << dendl;
./auth/cephx/CephxKeyServer.cc:  ldout(cct, 10) << "get_caps: name=" << name.to_str() << dendl;
./auth/cephx/CephxKeyServer.cc:    ldout(cct, 10) << "get_secret: num of caps=" << iter->second.caps.size() << dendl;
./auth/cephx/CephxKeyServer.cc:  ldout(cct, 10) << "_check_rotating_secrets" << dendl;
./auth/cephx/CephxKeyServer.cc:    ldout(cct, 10) << __func__ << " added " << added << dendl;
./auth/cephx/CephxKeyServer.cc:  ldout(cct, 30) << "_dump_rotating_secrets" << dendl;
./auth/cephx/CephxKeyServer.cc:    ldout(cct, 10) << "_rotate_secret adding " << ceph_entity_type_name(service_id) << dendl;
./auth/cephx/CephxSessionHandler.cc:      ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << " Sender did not set CEPH_MSG_FOOTER_SIGNED." << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << " Message signature does not match contents." << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << "Signature on message:" << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << "    sig: " << m->get_footer().sig << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << "Locally calculated signature:" << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "SIGN: MSG " << m->get_seq() << "    sig_check:" << sig << dendl;
./auth/cephx/CephxSessionHandler.cc:    ldout(cct, 0) << "Signature failed." << dendl;
./auth/AuthSessionHandler.cc:  ldout(cct,10) << "In get_auth_session_handler for protocol " << protocol << dendl;
./auth/RotatingKeyRing.cc:  ldout(cct, 10) << "dump_rotating:" << dendl;
./auth/RotatingKeyRing.cc:    ldout(cct, 10) << " id " << iter->first << " " << iter->second << dendl;
./auth/RotatingKeyRing.cc:    ldout(cct, 0) << "could not find secret_id=" << secret_id << dendl;
./neorados/cls/fifo.cc:    ldout(r->cct(), 0) << __func__ << "(): Raced locally!" << dendl;
./neorados/cls/fifo.cc:    ldout(r->cct(), 0) << __func__ << "(): ERROR: " << err << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ceph_mount: " << (c_root ? c_root : "<NULL>") << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ceph_mount: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ceph_unmount enter" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ceph_unmount exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ceph_release called" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: conf_set: opt " << c_opt << " val " << c_val << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: conf_set: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: conf_get: opt " << c_opt << " len " << buflen << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: conf_get: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: conf_read_file: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: conf_read_file: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: statfs: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: statfs: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: getcwd: enter" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: getcwd: exit ret " << c_cwd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: chdir: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: chdir: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: listdir: opendir: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: listdir: opendir: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: listdir: getdnames: enter" << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: listdir: getdnames: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:				ldout(cct, 20) << "jni: listdir: take path " << *ent << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: link: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: unlink: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: unlink: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: rename: from " << c_from << " to " << c_to << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: rename: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: mkdir: path " << c_path << " mode " << (int)j_mode << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: mkdir: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: mkdirs: path " << c_path << " mode " << (int)j_mode << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: mkdirs: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: rmdir: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: rmdir: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: readlink: lstatx " << c_path << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: readlink: lstat exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: readlink: size " << stx.stx_size << " path " << c_path << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: readlink: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: symlink: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lstat: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lstat exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: stat: path " << c_path << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: stat exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: setattr: path " << c_path << " mask " << mask << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: setattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: chmod: path " << c_path << " mode " << (int)j_mode << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: chmod: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: fchmod: fd " << (int)j_fd << " mode " << (int)j_mode << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: fchmod: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: truncate: path " << c_path << " size " << (loff_t)j_size << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: truncate: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: open: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: open_layout: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: close: fd " << (int)j_fd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: close: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lseek: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: read: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: write: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: ftruncate: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: fsync: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: flock: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: fstat: fd " << (int)j_fd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: fstat exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: sync_fs: enter" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: sync_fs: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: getxattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lgetxattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: listxattr: path " << c_path << " len " << buflen << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: listxattr: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:		ldout(cct, 10) << "jni: llistxattr: path " << c_path << " len " << buflen << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: llistxattr: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: removexattr: path " << c_path << " name " << c_name << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: removexattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lremovexattr: path " << c_path << " name " << c_name << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lremovexattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: setxattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: lsetxattr: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_stripe_unit: fd " << (int)j_fd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_stripe_unit: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_replication: fd " << (int)j_fd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_replication: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_pool_name: fd " << (int)j_fd << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_pool_name: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_default_data_pool_name" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_default_data_pool_name: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: localize_reads: val " << val << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: localize_reads: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_stripe_unit_granularity" << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_stripe_unit_granularity: exit ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_pool_id: name " << c_name << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_pool_id: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_pool_replication: poolid " << jpoolid << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_pool_replication: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_extent_osds: fd " << fd << " off " << off << dendl;
./java/native/libcephfs_jni.cc:	ldout(cct, 10) << "jni: get_file_extent_osds: ret " << ret << dendl;
./java/native/libcephfs_jni.cc:  ldout(cct, 10) << "jni: osd loc: osd " << osdid << dendl;
./java/native/libcephfs_jni.cc:  ldout(cct, 10) << "jni: osd loc: osd " << osdid << " ret " << ret << dendl;
./java/native/libcephfs_jni.cc:  ldout(cct, 10) << "jni: get_osd_addr: osd " << osd << dendl;
./java/native/libcephfs_jni.cc:  ldout(cct, 10) << "jni: get_osd_addr: ret " << ret << dendl;
./crypto/qat/qcccrypto.cc:    dout(10) << "Init sequence already called. Skipping duplicate call" << dendl;
./crypto/qat/qcccrypto.cc:  dout(15) << "First init for QAT" << dendl;
./crypto/qat/qcccrypto.cc:  dout(10) << "Init complete" << dendl;
./crypto/qat/qcccrypto.cc:    dout(15) << "QAT not initialized here. Nothing to do" << dendl;
./crypto/qat/qcccrypto.cc:    dout(5) << "QAT is still busy and cannot free resources yet" << dendl;
./crypto/qat/qcccrypto.cc:  dout(10) << "Destroying QAT crypto & related memory" << dendl;
./crypto/qat/qcccrypto.cc:    dout(10) << "QAT not intialized yet. Initializing now..." << dendl;
./crypto/qat/qcccrypto.cc:    dout(10) << "QAT not initialized in this instance or init failed with possible error " << (int)init_stat << dendl;
./crypto/qat/qcccrypto.cc:  dout(15) << "Using inst " << avail_inst << dendl;
./crypto/qat/qcccrypto.cc:      dout(15) << "Completed task under " << avail_inst << dendl;
./crypto/qat/qcccrypto.cc:    dout(15) << "Instantiation complete for " << avail_inst << dendl;
./osd/PG.cc:  dout(0) << "\t" << __func__ << ": " << info.pgid << " live ids:" << dendl;
./osd/PG.cc:    dout(0) << "\t\tid: " << *i << dendl;
./osd/PG.cc:  dout(0) << "\t" << __func__ << ": " << info.pgid << " live tags:" << dendl;
./osd/PG.cc:    dout(0) << "\t\tid: " << *i << dendl;
./osd/PG.cc:  dout(30) << "lock" << dendl;
./osd/PG.cc:  //generic_dout(0) << this << " " << info.pgid << " unlock" << dendl;
./osd/PG.cc:  dout(20) << __func__ << dendl;
./osd/PG.cc:    dout(0) << "op_has_sufficient_caps: no session for op " << *req << dendl;
./osd/PG.cc:    dout(10) << "queue_recovery -- not primary or not peered " << dendl;
./osd/PG.cc:    dout(10) << "queue_recovery -- already queued" << dendl;
./osd/PG.cc:    dout(10) << "queue_recovery -- queuing" << dendl;
./osd/PG.cc:  dout(10) << __func__ << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": scrubbing already" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": already queued" << dendl;
./osd/PG.cc:  dout(15) << __func__ << ": queueing" << dendl;
./osd/PG.cc:  dout(10) << "finish_recovery" << dendl;
./osd/PG.cc:    dout(10) << __func__ << " raced with delete or repair" << dendl;
./osd/PG.cc:    dout(15) << __func__ << " scrub_after_recovery? " << scrub_after_recovery << dendl;
./osd/PG.cc:      dout(10) << "_finish_recovery requeueing for scrub" << dendl;
./osd/PG.cc:    dout(10) << "_finish_recovery -- stale" << dendl;
./osd/PG.cc:  dout(10) << __func__ << " session " << s << " added " << *b << dendl;
./osd/PG.cc:  dout(10) << __func__ << " [" << begin << "," << end << ")" << dendl;
./osd/PG.cc:	dout(20) << __func__ << " checking  " << *q << dendl;
./osd/PG.cc:    dout(10) << __func__ << " " << *b << dendl;
./osd/PG.cc:  dout(10) << __func__ << " " << dendl;
./osd/PG.cc:      dout(10) << __func__ << " " << *b << dendl;
./osd/PG.cc:  dout(10) << __func__ << " " << *b << dendl;
./osd/PG.cc:  dout(10) << "clear_recovery_state" << dendl;
./osd/PG.cc:  dout(10) << "cancel_recovery" << dendl;
./osd/PG.cc:    dout(10) << "update_heartbeat_peers " << heartbeat_peers << " unchanged" << dendl;
./osd/PG.cc:    dout(10) << "update_heartbeat_peers " << heartbeat_peers << " -> " << new_peers << dendl;
./osd/PG.cc:  dout(15) << "clear_stats" << dendl;
./osd/PG.cc:    dout(0) << "strftime failed" << dendl;
./osd/PG.cc:	dout(10) << "filter_snapc filtering " << snaps << dendl;
./osd/PG.cc:      dout(20) << "filter_snapc  removing trimq|purged snap " << *p << dendl;
./osd/PG.cc:    dout(10) << "filter_snapc  result " << snaps << dendl;
./osd/PG.cc:    dout(20) << __func__ << " " << op << dendl;
./osd/PG.cc:      dout(20) << __func__ << " " << p->first << " " << p->second << dendl;
./osd/PG.cc:  dout(20) << __func__ << " must_scrub? " << (m_planned_scrub.must_scrub ? "true" : "false") << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": already queued" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": failed to initiate a scrub" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": failed to reserve locally" << dendl;
./osd/PG.cc:  dout(10) << __func__ << ": queueing" << dendl;
./osd/PG.cc:  dout(10) << __func__ << ": need_auto?" << planned.need_auto << " allow_deep_scrub? " << allow_deep_scrub << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": need repair after scrub errors" << dendl;
./osd/PG.cc:	dout(20) << __func__ << ": auto repair with deep scrubbing" << dendl;
./osd/PG.cc:  dout(10) << __func__ << " processing pg " << info.pgid << dendl;
./osd/PG.cc:    dout(20) << __func__ << ": scrubbing prevented during recovery" << dendl;
./osd/PG.cc:  dout(20) << __func__ << " scrub_queued was " << scrub_queued << " flags: " << m_planned_scrub << dendl;
./osd/PG.cc:    dout(10) << "Active: kicking snap trim" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": primary = " << get_primary() << dendl;
./osd/PG.cc:  dout(20) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " (op)" << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(10) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(15) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(15) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(15) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(15) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:  dout(15) << __func__ << " queued at: " << epoch_queued << dendl;
./osd/PG.cc:    dout(20) << " discard " << *m << dendl;
./osd/PG.cc:    dout(20) << " " << __func__ << " dead for nextmap is down " << from << dendl;
./osd/PG.cc:    dout(20) << " " << __func__ << " dead for 'get_down_at' " << from << dendl;
./osd/PG.cc:    dout(10) << " got old scan, ignoring" << dendl;
./osd/PG.cc:    dout(10) << " got old backfill, ignoring" << dendl;
./osd/PG.cc:  dout(10) << __func__ << ": " << evt->get_desc() << dendl;
./osd/PG.cc:    dout(10) << "discard old " << evt->get_desc() << dendl;
./osd/PG.cc:  dout(10) << "null" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": no luck, giving up on this pg for now (" << action << ")" << dendl;
./osd/PG.cc:    dout(10) << __func__ << ": no luck, giving up on this pg for now (queue_recovery)" << dendl;
./osd/PG.cc:  dout(10) << __func__ << ": " << osdmap->get_epoch() << dendl;
./osd/PG.cc:  dout(10) << __func__ << dendl;
./osd/PG.cc:  dout(10) << "handle_query_state" << dendl;
./osd/PG.cc:  dout(10) << __func__ << dendl;
./osd/PG.cc:      dout(20) << __func__ << " Delete scheduled at " << delete_schedule_time << dendl;
./osd/PG.cc:  dout(20) << __func__ << " " << olist << dendl;
./osd/PG.cc:    dout(20) << __func__ << " deleting " << num << " objects" << dendl;
./osd/PG.cc:      dout(1) << __func__ << " raced with merge, reinstantiating" << dendl;
./osd/PG.cc:    dout(20) << __func__ << " After kb_used " << new_stat.statfs.kb_used() << "KiB" << dendl;
./osd/OSDMap.cc:      ldout(cct, 30) << "containing_subtree_is_down(" << id << ") = false" << dendl;
./osd/OSDMap.cc:      ldout(cct, 30) << "containing_subtree_is_down(" << id << ") = true ... " << type << " >= " << subtree_type << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << __func__ << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << __func__ << dendl;
./osd/OSDMap.cc:    ldout(cct, 10) << " adding osd." << o << " at " << loc << dendl;
./osd/OSDMap.cc:    ldout(cct, 5) << " adding osd." << o << " at " << loc << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << __func__ << " pools " << only_pools << dendl;
./osd/OSDMap.cc:      ldout(cct, 20) << __func__ << " " << pg << " up " << up << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << " osd_weight_total " << osd_weight_total << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << " pgs_per_weight " << pgs_per_weight << dendl;
./osd/OSDMap.cc:  ldout(cct, 20) << " stdev " << stddev << " max_deviation " << cur_max_deviation << dendl;
./osd/OSDMap.cc:    ldout(cct, 30) << "Top of loop #" << max+1 << dendl;
./osd/OSDMap.cc:        ldout(cct, 30) << " check " << i->first << " <= " << max_deviation << dendl;
./osd/OSDMap.cc:	  ldout(cct, 30) << " add overfull osd." << i->second << dendl;
./osd/OSDMap.cc:        ldout(cct, 30) << " check " << i->first << " >= " << -(int)max_deviation << dendl;
./osd/OSDMap.cc:	  ldout(cct, 30) << " add underfull osd." << i->second << dendl;
./osd/OSDMap.cc:      ldout(cct, 20) << __func__ << " failed to build overfull and underfull" << dendl;
./osd/OSDMap.cc:      ldout(cct, 20) << __func__ << " Using more_overfull since we still have underfull" << dendl;
./osd/OSDMap.cc:        ldout(cct, 10) << " skipping overfull " << dendl;
./osd/OSDMap.cc:	ldout(cct, 10) << " trying " << pg << dendl;
./osd/OSDMap.cc:	ldout(cct, 10) << " " << pg << " " << orig << " -> " << out << dendl;
./osd/OSDMap.cc:	    ldout(cct, 30) << "Max osd." << orig[i] << " pos " << i << " dev " << osd_deviation[orig[i]] << dendl;
./osd/OSDMap.cc:      ldout(cct, 10) << " break due to aggressive mode not enabled" << dendl;
./osd/OSDMap.cc:    ldout(cct, 10) << " stddev " << stddev << " -> " << new_stddev << dendl;
./osd/OSDMap.cc:      ldout(cct, 10) << " unmap pg " << i << dendl;
./osd/OSDMap.cc:    ldout(cct, 20) << " stdev " << stddev << " max_deviation " << cur_max_deviation << dendl;
./osd/OSDMap.cc:  ldout(cct, 10) << " num_changed = " << num_changed << dendl;
./osd/MissingLoc.cc:  ldout(cct, 10) << __func__ << ": locs:" << locs << dendl;
./osd/MissingLoc.cc:    ldout(cct, 10) << __func__ << " source osd." << *p << " now down" << dendl;
./osd/MissingLoc.cc:    ldout(cct, 10) << __func__ << " no source osds (" << missing_loc_sources << ") went down" << dendl;
./osd/MissingLoc.cc:  ldout(cct, 10) << __func__ << " remove osd " << stray << " from missing_loc" << dendl;
./osd/MissingLoc.cc:    ldout(cct, 10) << __func__ << " remove osd" << stray << " from missing_loc_sources" << dendl;
./osd/Watch.cc:  dout(10) << "timeout" << dendl;
./osd/Watch.cc:  dout(10) << "start_watcher" << dendl;
./osd/Watch.cc:  dout(10) << "complete_watcher" << dendl;
./osd/Watch.cc:  dout(10) << __func__ << dendl;
./osd/Watch.cc:    ldout(osd->cct, 10) << "HandleWatchTimeout" << dendl;
./osd/Watch.cc:    dout(10) << "HandleWatchTimeoutDelayed" << dendl;
./osd/Watch.cc:  dout(10) << "Watch()" << dendl;
./osd/Watch.cc:  dout(10) << "~Watch" << dendl;
./osd/Watch.cc:    dout(15) << "re-registering callback, timeout: " << timeout << dendl;
./osd/Watch.cc:    dout(15) << "registering callback, timeout: " << timeout << dendl;
./osd/Watch.cc:  dout(15) << "unregister_cb" << dendl;
./osd/Watch.cc:  dout(15) << "actually registered, cancelling" << dendl;
./osd/Watch.cc:    dout(10) << __func__ << " con " << con << " - already connected" << dendl;
./osd/Watch.cc:  dout(10) << __func__ << " con " << con << dendl;
./osd/Watch.cc:  dout(10) << "disconnect (con was " << conn << ")" << dendl;
./osd/Watch.cc:  dout(10) << "discard" << dendl;
./osd/Watch.cc:  dout(10) << "remove" << dendl;
./osd/Watch.cc:  dout(10) << "start_notify " << notif->notify_id << dendl;
./osd/Watch.cc:  dout(10) << "cancel_notify " << notif->notify_id << dendl;
./osd/Watch.cc:  dout(10) << "send_notify" << dendl;
./osd/Watch.cc:  dout(10) << "notify_ack" << dendl;
./osd/PeeringState.cc:      psdout(10) << "peer_log_requested removing " << *i << dendl;
./osd/PeeringState.cc:      psdout(10) << "peer_missing_requested removing " << *i << dendl;
./osd/PeeringState.cc:    psdout(20) << __func__ << " advanced history from " << new_history << dendl;
./osd/PeeringState.cc:      psdout(20) << __func__ << " clearing past_intervals" << dendl;
./osd/PeeringState.cc:  psdout(10) << "purge_strays " << stray_set << dendl;
./osd/PeeringState.cc:      psdout(10) << "sending PGRemove to osd." << *p << dendl;
./osd/PeeringState.cc:      psdout(10) << "not sending PGRemove to down osd." << *p << dendl;
./osd/PeeringState.cc:  psdout(20) << "Enter PeeringState common QueryUnfound" << dendl;
./osd/PeeringState.cc:  psdout(20) << "Exit PeeringState common QueryUnfound" << dendl;
./osd/PeeringState.cc:  psdout(10) << " got osd." << from << " " << oinfo << dendl;
./osd/PeeringState.cc:    psdout(10) << " osd." << from << " has stray content: " << oinfo << dendl;
./osd/PeeringState.cc:      psdout(10) << " dropping down osd." << p->first << " info " << p->second << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << dendl;
./osd/PeeringState.cc:  psdout(20) << "set_last_peering_reset " << get_osdmap_epoch() << dendl;
./osd/PeeringState.cc:    psdout(10) << "Clearing blocked outgoing recovery messages" << dendl;
./osd/PeeringState.cc:      psdout(10) << "Beginning to block outgoing recovery messages" << dendl;
./osd/PeeringState.cc:      psdout(10) << "Not blocking outgoing recovery messages" << dendl;
./osd/PeeringState.cc:      psdout(10) << " pool was marked full in " << osdmap->get_epoch() << dendl;
./osd/PeeringState.cc:    psdout(10) << " no lastmap" << dendl;
./osd/PeeringState.cc:	psdout(10) << " map gap, clearing past_intervals and faking" << dendl;
./osd/PeeringState.cc:	psdout(10) << " noting past " << past_intervals << dendl;
./osd/PeeringState.cc:    psdout(10) << " acting empty, but i am up[0], clearing pg_temp" << dendl;
./osd/PeeringState.cc:  dout(20) << __func__ << dendl;
./osd/PeeringState.cc:  dout(10) << __func__ << " now " << hb_stamps << dendl;
./osd/PeeringState.cc:  psdout(10) << "clear_primary_state" << dendl;
./osd/PeeringState.cc:  psdout(20) << __func__ << " recovery priority is " << ret << dendl;
./osd/PeeringState.cc:  psdout(20) << __func__ << " backfill priority is " << ret << dendl;
./osd/PeeringState.cc:      psdout(20) << __func__ << " set" << dendl;
./osd/PeeringState.cc:    psdout(20) << __func__ << " clear" << dendl;
./osd/PeeringState.cc:      psdout(10) << __func__ << " set" << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << " clear" << dendl;
./osd/PeeringState.cc:    psdout(20) << __func__ << " no-op, !nonprimary" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " " << l << dendl;
./osd/PeeringState.cc:    psdout(20) << __func__ << " readable_until now " << readable_until << dendl;
./osd/PeeringState.cc:    psdout(20) << " no peer_clock_delta_lb -> ruub " << ruub << dendl;
./osd/PeeringState.cc:    psdout(10) << " empty prior_readable_down_osds, clearing ub" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " is recovered" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " does not need backfill" << dendl;
./osd/PeeringState.cc:      psdout(10) << __func__ << " failed, recovery below min size not enabled" << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << " failed, not recoverable " << dendl;
./osd/PeeringState.cc:      psdout(10) << __func__ << " failed" << dendl;
./osd/PeeringState.cc:  psdout(10) << ss.str() << dendl;
./osd/PeeringState.cc:      psdout(20) << __func__ << " skipping down osd." << peer << dendl;
./osd/PeeringState.cc:      psdout(20) << __func__ << " skipping purged osd." << peer << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << dendl;
./osd/PeeringState.cc:  psdout(15) << __func__ << ": built " << might_have_unfound << dendl;
./osd/PeeringState.cc:    psdout(10) << "activate - not complete, " << missing << dendl;
./osd/PeeringState.cc:      psdout(10) << "activate peer osd." << peer << " " << pi << dendl;
./osd/PeeringState.cc:	  psdout(10) << __func__ << ": adding " << *i << " as a source" << dendl;
./osd/PeeringState.cc:  psdout(10) << "share_pg_info" << dendl;
./osd/PeeringState.cc:  psdout(10) << "sending info" << dendl;
./osd/PeeringState.cc:  psdout(10) << "log request from " << from << dendl;
./osd/PeeringState.cc:    psdout(10) << " sending info+missing+full log" << dendl;
./osd/PeeringState.cc:  psdout(10) << " sending " << mlog->log << " " << mlog->missing << dendl;
./osd/PeeringState.cc:	  psdout(10) << "ready to merge (target)" << dendl;
./osd/PeeringState.cc:	  psdout(10) << "ready to merge (source)" << dendl;
./osd/PeeringState.cc:      psdout(10) << "not clean, not ready to merge" << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << " target incomplete" << dendl;
./osd/PeeringState.cc:      psdout(10) << __func__ << " source " << i.first << " missing" << dendl;
./osd/PeeringState.cc:      psdout(10) << __func__ << " taking source's past_intervals" << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << ": Setting backfill" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " " << entries << dendl;
./osd/PeeringState.cc:  psdout(10) << "add_log_entry " << e << dendl;
./osd/PeeringState.cc:  psdout(10) << "append_log " << pg_log.get_log() << " " << logv << dendl;
./osd/PeeringState.cc:  psdout(10) << "got missing " << oid << " v " << v << dendl;
./osd/PeeringState.cc:        psdout(10) << "calc_trim_to trimming to min_last_complete_ondisk" << dendl;
./osd/PeeringState.cc:    psdout(10) << "calc_trim_to " << pg_trim_to << " -> " << new_trim_to << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " limit = " << limit << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << " num_to_trim =  " << num_to_trim << dendl;
./osd/PeeringState.cc:    psdout(10) << __func__ << " pg_trim_to now " << pg_trim_to << dendl;
./osd/PeeringState.cc:  psdout(10) << "Ending blocked outgoing recovery messages" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Started advmap" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Ending blocked outgoing recovery messages" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Reset advmap" << dendl;
./osd/PeeringState.cc:    psdout(1) << "transitioning to Primary" << dendl;
./osd/PeeringState.cc:    psdout(1) << "transitioning to Stray" << dendl;
./osd/PeeringState.cc:  psdout(7) << "handle_pg_notify from osd." << notevt.from << dendl;
./osd/PeeringState.cc:  psdout(7) << "handle ActMap primary" << dendl;
./osd/PeeringState.cc:    psdout(10) << "marking for scrub" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Peering advmap" << dendl;
./osd/PeeringState.cc:    psdout(1) << "Peering, affected_by_map, going to Reset" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Leaving Peering" << dendl;
./osd/PeeringState.cc:  psdout(10) << "defer backfill, retry delay " << c.delay << dendl;
./osd/PeeringState.cc:  psdout(10) << "backfill has unfound, can't continue" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " num_bytes " << num_bytes << dendl;
./osd/PeeringState.cc:    psdout(10) << "got defer recovery but not recovering" << dendl;
./osd/PeeringState.cc:  psdout(10) << "defer recovery, retry delay " << evt.delay << dendl;
./osd/PeeringState.cc:  psdout(10) << "recovery has unfound, can't continue" << dendl;
./osd/PeeringState.cc:  psdout(10) << "In Active, about to call activate" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Activate Finished" << dendl;
./osd/PeeringState.cc:    psdout(10) << "Active advmap interval change, fast return" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Active advmap" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Active: handling ActMap" << dendl;
./osd/PeeringState.cc:  ldout(ps->cct,10) << " replica osd." << trim.from << " lcod " << trim.trim_to << dendl;
./osd/PeeringState.cc:  psdout(10) << "all_activated_and_committed" << dendl;
./osd/PeeringState.cc:  psdout(10) << "In ReplicaActive, about to call activate" << dendl;
./osd/PeeringState.cc:  psdout(10) << "Activate Finished" << dendl;
./osd/PeeringState.cc:  psdout(10) << __func__ << " " << evt.epoch << " telling primary" << dendl;
./osd/PeeringState.cc:  psdout(10) << "received log from " << logevt.from << dendl;
./osd/PeeringState.cc:    ldout(ps->cct,10) << __func__ << " pool is deleted" << dendl;
./osd/PeeringState.cc:  psdout(10) << "got info+log from osd." << logevt.from << " " << msg->info << " " << msg->log << dendl;
./osd/PeeringState.cc:  psdout(10) << "got info from osd." << infoevt.from << " " << infoevt.info << dendl;
./osd/PeeringState.cc:      psdout(10) << " have osd." << peer << " info " << ps->peer_info[peer] << dendl;
./osd/PeeringState.cc:      psdout(10) << " already requested info from osd." << peer << dendl;
./osd/PeeringState.cc:      psdout(10) << " not querying info from down osd." << peer << dendl;
./osd/PeeringState.cc:      psdout(10) << " querying info from osd." << peer << dendl;
./osd/PeeringState.cc:      psdout(10) << " last_epoch_started moved forward, rebuilding prior" << dendl;
./osd/PeeringState.cc:	  psdout(20) << " dropping osd." << *p << " from info_requested, no longer in probe set" << dendl;
./osd/PeeringState.cc:      psdout(20) << "Common peer features: " << hex << ps->get_min_peer_features() << dec << dendl;
./osd/PeeringState.cc:      psdout(20) << "Common acting features: " << hex << ps->get_min_acting_features() << dec << dendl;
./osd/PeeringState.cc:      psdout(20) << "Common upacting features: " << hex << ps->get_min_upacting_features() << dec << dendl;
./osd/PeeringState.cc:    psdout(10) << " not contiguous with osd." << auth_log_shard << ", down" << dendl;
./osd/PeeringState.cc:  psdout(10) << " requesting log from osd." << auth_log_shard << dendl;
./osd/PeeringState.cc:  psdout(10) << "leaving GetLog" << dendl;
./osd/PeeringState.cc:    psdout(10) << "processing master log" << dendl;
./osd/PeeringState.cc:  psdout(10) << "verifying no want_acting " << ps->want_acting << " targets didn't go down" << dendl;
./osd/PeeringState.cc:      psdout(10) << " want_acting target osd." << *p << " went down, resetting" << dendl;
./osd/PeeringState.cc:  psdout(10) << "In WaitActingChange, ignoring MLocRec" << dendl;
./osd/PeeringState.cc:  psdout(10) << "In WaitActingChange, ignoring MInfoRec" << dendl;
./osd/PeeringState.cc:  psdout(10) << "In WaitActingChange, ignoring MNotifyRec" << dendl;
./osd/PeeringState.cc:      psdout(10) << " last_epoch_started moved forward, re-enter getinfo" << dendl;
./osd/PeeringState.cc:  psdout(7) << "handle_pg_notify from osd." << notevt.from << dendl;
./osd/PeeringState.cc:      psdout(10) << " osd." << *i << " is not contiguous, will restart backfill" << dendl;
./osd/PeeringState.cc:      psdout(10) << " osd." << *i << " will fully backfill; can infer empty missing set" << dendl;
./osd/PeeringState.cc:      psdout(10) << " osd." << *i << " has no missing, identical log" << dendl;
./osd/PeeringState.cc:      psdout(10) << " requesting log+missing since " << since << " from osd." << *i << dendl;
./osd/PeeringState.cc:  psdout(10) << "Noting missing from osd." << logevt.from << dendl;
./osd/PeeringState.cc:  psdout(5) << "enter " << state_name << dendl;
./osd/PeeringState.cc:  psdout(5) << "exit " << state_name << " " << dur << " " << event_count << " " << event_time << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << ": " << hoid << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << ": " << op << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << ": " << op << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << ": " << op->tid << dendl;
./osd/ReplicatedBackend.cc:  dout(10) << __func__ << " " << poid << " pos " << pos << dendl;
./osd/ReplicatedBackend.cc:      dout(25) << "CRC header " << cleanbin(hdrbl, encoded, true) << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << __func__ << " Out of space (failsafe) processing push request." << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << __func__ << " Out of space (failsafe) processing pull response (push)." << dendl;
./osd/ReplicatedBackend.cc:  dout(30) << __func__ << " missing before " << get_parent()->get_log().get_missing().get_items() << dendl;
./osd/ReplicatedBackend.cc:    dout(20) << __func__ << " start tracking temp " << m->new_temp_oid << dendl;
./osd/ReplicatedBackend.cc:    dout(20) << __func__ << " stop tracking temp " << m->discard_temp_oid << dendl;
./osd/ReplicatedBackend.cc:    dout(30) << __func__ << " is_missing " << pmissing.is_missing(soid) << dendl;
./osd/ReplicatedBackend.cc:      dout(30) << " add_next_event entry " << e << dendl;
./osd/ReplicatedBackend.cc:      dout(30) << " entry is_delete " << e.is_delete() << dendl;
./osd/ReplicatedBackend.cc:  dout(30) << __func__ << " missing after" << get_parent()->get_log().get_missing().get_items() << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << __func__ << ": caching (was) enabled, skipping clone subsets" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << "calc_head_subsets " << head << " -- osd_recover_clone_overlap disabled" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << "skipping clone, nothing needs to clone" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << "skipping clone, too many holes" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << __func__ << ": caching (was) enabled, skipping clone subsets" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << "calc_clone_subsets " << soid << " -- osd_recover_clone_overlap disabled" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << "skipping clone, too many holes" << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << " snapset " << ssc->snapset << dendl;
./osd/ReplicatedBackend.cc:    dout(10) << " pulling " << recovery_info << dendl;
./osd/ReplicatedBackend.cc:      dout(15) << "push_to_replica missing head " << head << ", pushing raw clone" << dendl;
./osd/ReplicatedBackend.cc:    dout(15) << "push_to_replica snapset is " << ssc->snapset << dendl;
./osd/ReplicatedBackend.cc:    dout(15) << "push_to_replica snapset is " << ssc->snapset << dendl;
./osd/ReplicatedBackend.cc:      dout(20) << __func__ << " repair complete" << dendl;
./osd/ReplicatedBackend.cc:      dout(1) << __func__ << " get omap header failed: " << cpp_strerror(-r) << dendl;
./osd/ReplicatedBackend.cc:      dout(1) << __func__ << " getattrs failed: " << cpp_strerror(-r) << dendl;
./osd/ReplicatedBackend.cc:      dout(0) << __func__ << ": bad object_info_t: " << recovery_info.soid << dendl;
./osd/ReplicatedBackend.cc:    dout(0) << __func__ << ": inject EIO " << recovery_info.soid << dendl;
./osd/ReplicatedBackend.cc:        dout(5) << __func__ << ": oid " << soid << " error " << r << dendl;
./osd/ReplicatedBackend.cc:  dout(20) << __func__ << ": " << soid << " from " << from << dendl;
./osd/ReplicatedBackend.cc:  dout(20) << __func__ << " soid " << soid << dendl;
./osd/ReplicatedBackend.cc:	dout(10) << __func__ << " clean up peer " << p << dendl;
./osd/ECTransaction.cc:      ldpp_dout(dpp, 20) << __func__ << ": new_size start " << new_size << dendl;
./osd/ClassHandler.cc:  ldout(cct, 10) << __func__ << dendl;
./osd/ClassHandler.cc:      ldout(cct, 10) << __func__ << " found " << cname << dendl;
./osd/ClassHandler.cc:      ldout(cct, 0) << "_get_class not permitted to load " << cname << dendl;
./osd/ClassHandler.cc:    ldout(cct, 10) << "_get_class adding new class name " << cname << " " << cls << dendl;
./osd/ClassHandler.cc:    ldout(cct, 10) << "_load_class " << cls->name << " from " << fname << dendl;
./osd/ClassHandler.cc:    ldout(cct, 10) << "_load_class " << cls->name << " satisfied dependency " << dc->name << dendl;
./osd/ClassHandler.cc:  ldout(cct, 10) << "_load_class " << cls->name << " success" << dendl;
./osd/ClassHandler.cc:  ldout(cct, 10) << "register_class " << cname << " status " << cls->status << dendl;
./osd/ClassHandler.cc:    ldout(cct, 0) << "class " << cname << " isn't loaded; is the class registering under the wrong name?" << dendl;
./osd/ClassHandler.cc:  ldout(handler->cct, 10) << "register_method " << name << "." << mname << " flags " << flags << " " << (void*)func << dendl;
./osd/ClassHandler.cc:  ldout(handler->cct, 10) << "register_cxx_method " << name << "." << mname << " flags " << flags << " " << (void*)func << dendl;
./osd/Session.cc:	dout(20) << __func__ << " now " << *b << dendl;
./osd/Session.cc:	dout(20) << __func__ << " deleting " << *b << dendl;
./osd/Session.cc:    dout(20) << __func__ << " clearing begin bin " << q->first << dendl;
./osd/Session.cc:      dout(20) << __func__ << " clearing pg bin " << p->first << dendl;
./osd/Session.cc:    dout(10) << __func__ << " session " << this << " disconnected" << dendl;
./osd/pg_scrubber.cc:      dout(10) << "nodeep_scrub set, aborting" << dendl;
./osd/pg_scrubber.cc:    dout(10) << "noscrub set, aborting" << dendl;
./osd/pg_scrubber.cc:  dout(15) << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:    dout(10) << "scrubber event -->> StartScrub epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:    dout(10) << "scrubber event --<< StartScrub" << dendl;
./osd/pg_scrubber.cc:  dout(15) << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:    dout(10) << "scrubber event -->> AfterRepairScrub epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:    dout(10) << "scrubber event --<< AfterRepairScrub" << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:    dout(1) << "got a replica scrub request while Primary!" << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event -->> " << __func__ << " epoch: " << epoch_queued << dendl;
./osd/pg_scrubber.cc:  dout(10) << "scrubber event --<< " << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " state deep? " << state_test(PG_STATE_DEEP_SCRUB) << dendl;
./osd/pg_scrubber.cc:  dout(20) << __func__ << " pg(" << m_pg_id << ") planned:" << req_flags << dendl;
./osd/pg_scrubber.cc:  dout(15) << __func__ << " last-update: " << e << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " " << soid << " preempted" << dendl;
./osd/pg_scrubber.cc:    dout(20) << __func__ << " scrub state is PendingTimer, sleeping" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " awaiting" << m_maps_status << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " start same_interval:" << m_interval_start << dendl;
./osd/pg_scrubber.cc:  dout(15) << "_scan_snaps starts" << dendl;
./osd/pg_scrubber.cc:    dout(20) << __func__ << " " << hoid << dendl;
./osd/pg_scrubber.cc:	  dout(15) << __func__ << " wait on repair!" << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " while pos empty " << pos.ret << dendl;
./osd/pg_scrubber.cc:      dout(5) << "objects_list_range error: " << pos.ret << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " pos.ls.empty()? " << (pos.ls.empty() ? "+" : "-") << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " be r " << r << dendl;
./osd/pg_scrubber.cc:      dout(20) << __func__ << " in progress" << dendl;
./osd/pg_scrubber.cc:  dout(20) << __func__ << " finishing" << dendl;
./osd/pg_scrubber.cc:  dout(20) << __func__ << " done, got " << map.objects.size() << " items" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " input: " << request << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " has maps, analyzing" << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << "  comparing replica scrub maps" << dendl;
./osd/pg_scrubber.cc:    dout(2) << ss.str() << dendl;
./osd/pg_scrubber.cc:      dout(10) << __func__ << ": discarding scrub results" << dendl;
./osd/pg_scrubber.cc:      dout(10) << __func__ << ": updating scrub object" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " min epoch:" << m_replica_min_epoch << dendl;
./osd/pg_scrubber.cc:  dout(15) << __func__ << " " << *m << dendl;
./osd/pg_scrubber.cc:  dout(15) << "map version is " << m_received_maps[m->from].valid_through << dendl;
./osd/pg_scrubber.cc:    dout(1) << __func__ << err_txt << " from OSD " << m->from << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " replica was preempted, setting flag" << dendl;
./osd/pg_scrubber.cc:    dout(15) << __func__ << " all repl-maps available" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << *op->get_req() << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " already reserved." << dendl;
./osd/pg_scrubber.cc:      dout(20) << __func__ << ": failed to reserve remotely" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " reserved? " << (granted ? "yes" : "no") << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << *op->get_req() << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << *op->get_req() << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << *op->get_req() << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << ": checking authoritative" << dendl;
./osd/pg_scrubber.cc:    dout(2) << ss.str() << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << " undoing the repair" << dendl;
./osd/pg_scrubber.cc:    dout(15) << __func__ << " Try to auto repair after scrub errors" << dendl;
./osd/pg_scrubber.cc:      dout(20) << __func__ << " All may be fixed" << dendl;
./osd/pg_scrubber.cc:	dout(10) << "m_pg->recovery_state.update_stats()" << dendl;
./osd/pg_scrubber.cc:      dout(10) << "scrub finished, requeuing snap_trimmer" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(20) << " creating PgScrubber for " << pg->pg_id << " / " << m_pg_whoami << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << dendl;
./osd/pg_scrubber.cc:      dout(10) << __func__ << " <ReplicaReservations> reserve<-> " << p.osd << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << m_reserved_peers << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " <ReplicaReservations> granted-> " << from << dendl;
./osd/pg_scrubber.cc:    dout(10) << " rejecting late-coming reservation from " << from << dendl;
./osd/pg_scrubber.cc:    dout(10) << " already had osd." << from << " reserved" << dendl;
./osd/pg_scrubber.cc:    dout(10) << " osd." << from << " scrub reserve = success" << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " <ReplicaReservations> rejected-> " << from << dendl;
./osd/pg_scrubber.cc:  dout(10) << __func__ << " " << *op->get_req() << dendl;
./osd/pg_scrubber.cc:    dout(15) << " ignoring late-coming rejection from " << from << dendl;
./osd/pg_scrubber.cc:    dout(10) << " already had osd." << from << " reserved" << dendl;
./osd/pg_scrubber.cc:    dout(10) << " osd." << from << " scrub reserve = fail" << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << ": failed to reserve locally " << dendl;
./osd/pg_scrubber.cc:  dout(20) << __func__ << ": local OSD scrub resources reserved" << dendl;
./osd/pg_scrubber.cc:    dout(10) << __func__ << ": failed to reserve at Primary request" << dendl;
./osd/pg_scrubber.cc:  dout(20) << __func__ << ": scrub resources reserved at Primary request" << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << " Out of space (failsafe) processing push request." << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": " << from << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": continuing " << op << dendl;
./osd/ECBackend.cc:      dout(10) << __func__ << ": IDLE return " << op << dendl;
./osd/ECBackend.cc:      dout(10) << __func__ << ": READING return " << op << dendl;
./osd/ECBackend.cc:	  dout(10) << __func__ << ": WRITING return " << op << dendl;
./osd/ECBackend.cc:	  dout(10) << __func__ << ": WRITING continue " << op << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << ": starting " << *i << dendl;
./osd/ECBackend.cc:    dout(10) << "checking " << *i << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": built op " << h->ops.back() << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": " << *_op->get_req() << dendl;
./osd/ECBackend.cc:  dout(30) << __func__ << " missing before " << get_parent()->get_log().get_missing().get_items() << dendl;
./osd/ECBackend.cc:    dout(30) << __func__ << " is_missing " << pmissing.is_missing(op.soid) << dendl;
./osd/ECBackend.cc:      dout(30) << " add_next_event entry " << e << dendl;
./osd/ECBackend.cc:      dout(30) << " entry is_delete " << e.is_delete() << dendl;
./osd/ECBackend.cc:  dout(30) << __func__ << " missing after" << get_parent()->get_log().get_missing().get_items() << dendl;
./osd/ECBackend.cc:        dout(25) << __func__ << " case1: reading the complete chunk/shard." << dendl;
./osd/ECBackend.cc:        dout(25) << __func__ << " case2: going to do fragmented read." << dendl;
./osd/ECBackend.cc:        dout(20) << __func__ << " read request=" << j->get<1>() << " r=" << r << " len=" << bl.length() << dendl;
./osd/ECBackend.cc:          dout(5) << __func__ << ": No hinfo for " << i->first << dendl;
./osd/ECBackend.cc:	  dout(20) << __func__ << ": Checking hash of " << i->first << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << " Calling on_all_commit on " << i->second << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": reply " << op << dendl;
./osd/ECBackend.cc:    dout(20) << __func__ << ": dropped " << op << dendl;
./osd/ECBackend.cc:      dout(20) << __func__ << " to_read skipping" << dendl;
./osd/ECBackend.cc:      dout(20) << __func__ << " to_read skipping" << dendl;
./osd/ECBackend.cc:    dout(20) << __func__ << " shard=" << from << " error=" << i->second << dendl;
./osd/ECBackend.cc:        dout(20) << __func__ << " have shard=" << j->first.shard << dendl;
./osd/ECBackend.cc:	dout(20) << __func__ << " minimum_to_decode failed" << dendl;
./osd/ECBackend.cc:	    dout(10) << __func__ << ": Not ignoring errors, use one shard err=" << err << dendl;
./osd/ECBackend.cc:    dout(20) << __func__ << " Complete: " << rop << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << " readop not complete: " << rop << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << ": cancelling " << i->second << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": op " << *op << " starting" << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << ": checking acting " << *i << dendl;
./osd/ECBackend.cc:      dout(10) << __func__ << ": checking backfill " << *i << dendl;
./osd/ECBackend.cc:	dout(10) << __func__ << ": checking missing_loc " << *i << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": starting " << op << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": starting read " << op << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": started " << op << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": Getting attr on " << hoid << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << ": not in cache " << hoid << dendl;
./osd/ECBackend.cc:      dout(10) << __func__ << ": found on disk, size " << st.st_size << dendl;
./osd/ECBackend.cc:	  dout(5) << __func__ << " " << hoid << " missing hinfo attr" << dendl;
./osd/ECBackend.cc:	  dout(5) << __func__ << ": getattr failed: " << cpp_strerror(r) << dendl;
./osd/ECBackend.cc:	  dout(0) << __func__ << ": Can't decode hinfo for " << hoid << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": " << *op << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": " << *op << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": starting commit on " << *op << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": " << cache << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": " << cache << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": written: " << written << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": op: " << *op << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": written_set: " << written_set << dendl;
./osd/ECBackend.cc:      dout(20) << __func__ << ": " << hpair << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << ": " << *op << dendl;
./osd/ECBackend.cc:  dout(20) << __func__ << ": " << cache << dendl;
./osd/ECBackend.cc:          ldpp_dout(dpp, 30) << "offset: " << offset << dendl;
./osd/ECBackend.cc:          ldpp_dout(dpp, 30) << "range offset: " << range.first.get_off() << dendl;
./osd/ECBackend.cc:          ldpp_dout(dpp, 30) << "length: " << length << dendl;
./osd/ECBackend.cc:          ldpp_dout(dpp, 30) << "range length: " << range.first.get_len()  << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << " have/error shards=" << already_read << dendl;
./osd/ECBackend.cc:    dout(10) << __func__ << " want attrs again" << dendl;
./osd/ECBackend.cc:  dout(10) << __func__ << " " << poid << " pos " << pos << dendl;
./osd/ECBackend.cc:    dout(0) << "_scan_list  " << poid << " could not retrieve hash info" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << ": " << hoid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " snapset " << recovery_info.ss << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " snaps " << snaps << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << " kicking unreadable waiters on " << hoid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "pushed " << soid << " to all replicas" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " kicking degraded waiters on " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " kicking unreadable waiters on " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(7) << "object " << soid << " v " << v << ", already recovering." << dendl;
./osd/PrimaryLogPG.cc:    dout(7) << "object " << soid << " v " << v << ", is unfound." << dendl;
./osd/PrimaryLogPG.cc:    dout(7) << "object " << soid << " v " << v << ", recovering." << dendl;
./osd/PrimaryLogPG.cc:      dout(30) << __func__ << " " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << soid << " " << op << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " PG is WAIT state" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " not readable" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " not readable" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " wasn't wait or laggy" << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << "getattr (sobj=" << sobj << ", attr=" << filter.get_xattr() << ") returned " << ret << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "do_pg_op " << *m << dendl;
./osd/PrimaryLogPG.cc:	dout(0) << "unable to decode PGLS_FILTER description in " << *m << dendl;
./osd/PrimaryLogPG.cc:	  dout(0) << "unable to decode PGNLS handle in " << *m << dendl;
./osd/PrimaryLogPG.cc:        dout(10) << "pgnls handle=" << response.handle << dendl;
./osd/PrimaryLogPG.cc:	dout(0) << "unable to decode PGLS_FILTER description in " << *m << dendl;
./osd/PrimaryLogPG.cc:        dout(10) << " pgls pg=" << m->get_pg() << " count " << list_size << dendl;
./osd/PrimaryLogPG.cc:	  dout(0) << "unable to decode PGLS handle in " << *m << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " scrubls pg=" << m->get_pg() << " != " << info.pgid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " corrupted scrub_ls_arg_t" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "waiting for flush on " << op << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " peered, not active, waiting for active on " << op << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << ": op " << *m << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " no session" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": PARALLELEXEC not implemented " << *m << dendl;
./osd/PrimaryLogPG.cc:    dout(4) << "do_op empty oid name is not allowed" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "do_op " << m->get_source_addr() << " is blocklisted" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " fail-safe full check failed, dropping request." << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << ": write to clone not valid " << *m << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << ": waiting for scrub" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " waiting for " << version << " to commit" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "LIST_SNAPS with incorrect context" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "non-LIST_SNAPS on snapdir" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": find_object_context got error " << r << dendl;
./osd/PrimaryLogPG.cc:  dout(25) << __func__ << " oi " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": skipping rw locks" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": part of flush, will ignore write lock" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " no flush in progress, aborting" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " waiting for rw locks " << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " obc " << *obc << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " returned an error: " << r << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": ignoring redirect due to flag" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " blocked on " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << ": " << head << " is degraded, waiting" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << ": waiting for scrub" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " r=" << r << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " op_returns=" << entries.back().op_returns << dendl;
./osd/PrimaryLogPG.cc:      ldpp_dout(pg, 20) << "finished " << __func__ << " r=" << r << dendl;
./osd/PrimaryLogPG.cc:      ldpp_dout(pg, 10) << " sending commit on " << *m << " " << reply << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": ignoring cache due to flag" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " blocked on " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " cache miss; ask the primary" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " cache pool full, proxying read" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " cache pool full, waiting" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " cache pool full, waiting" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " cache pool full, waiting" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " promote throttled" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " Start proxy read for " << *m << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no proxyread_op found" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no in_progress_proxy_ops found" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " " << oid << " is not completed  " << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << soid << " requeuing " << ls.size() << " requests" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << prdop->soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " Start proxy write for " << *m << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << ": decrement reference on offset oid: " << p->first << dendl;
./osd/PrimaryLogPG.cc:	  dout(20) << __func__ << " requested chunks don't exist in chunk_map " << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no proxywrite_op found" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no in_progress_proxy_ops found" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " sending commit on " << pwop << " " << reply << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << pwop->soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << ctx << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << " user_at_version " << ctx->user_at_version << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << __func__ << " op " << i << " outdata overflow" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " op order client." << n << " tid " << t << " (first)" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " op order client." << n << " tid " << t << " last was " << p->second << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " update_log_only -- result=" << result << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " sending reply on " << *m << " " << reply << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "do_scan " << *m << dendl;
./osd/PrimaryLogPG.cc:	dout(1) << __func__ << ": Canceling backfill: Full." << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " canceled backfill (too full?)" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "do_backfill " << *m << dendl;
./osd/PrimaryLogPG.cc:  dout(7) << __func__ << " " << m->ls << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": Unable to get a wlock on " << coid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": Unable to get a wlock on " << head_oid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " trimming whiteout on " << coid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << coid << " snaps " << old_snaps << " -> " << new_snaps << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << coid << " removing " << head_oid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " trimming whiteout on " << oi.soid << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << coid << " filtering snapset on " << head_oid << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << ": nosnaptrim set, not kicking" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << ": clean and snaps to trim, kicking" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "snap_trimmer posting" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "snap_trimmer complete" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << "do_xattr_cmp_u64 '" << v1 << "' vs '" << v2 << "' op " << op << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << "do_xattr_cmp_str '" << v1s << "' vs '" << v2s << "' op " << op << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << " convert tmap to omap for " << ctx->new_obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "tmapup is a no-op" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "tmapup read " << newop.outdata.length() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "tmapup header " << header.length() << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "tmapup new header " << header.length() << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "tmapup initial nkeys " << nkeys << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "tmapup op " << (int)op << " key " << key << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << "  (have_next=" << have_next << " nextkey=" << nextkey << ")" << dendl;
./osd/PrimaryLogPG.cc:	  dout(20) << "  keep " << nextkey << " " << nextval.length() << dendl;
./osd/PrimaryLogPG.cc:	  dout(20) << "  drop " << nextkey << " " << nextval.length() << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << "   set " << key << " " << val.length() << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << "   create " << key << " " << val.length() << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "  invalid tmap op " << (int)op << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << "  keep " << nextkey << " " << nextval.length() << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "tmapup final nkeys " << nkeys << dendl;
./osd/PrimaryLogPG.cc:      dout(0) << " **** debug sanity check, looks ok ****" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << "tmapput write " << obl.length() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " clearing whiteout on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << ": length not aligned to chunk size" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": init value not provided" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": async_read noted for " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " zero length extent" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " object DNE" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": async_read noted for " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << " oi.size: " << oi.size << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << " oi.truncate_seq: " << oi.truncate_seq << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << " op.extent.truncate_seq: " << op.extent.truncate_seq << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << " op.extent.truncate_size: " << op.extent.truncate_size << dendl;
./osd/PrimaryLogPG.cc:  dout(30) << __func__ << "op.extent.length is now " << op.extent.length << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " async_read noted for " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << "sparse_read does not support truncation sequence " << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " async_read (was sparse_read) noted for " << soid << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " sparse read ended up empty for " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "do_osd_op " << soid << " " << ops << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "do_osd_op  " << osd_op << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " map_extents done on object " << soid << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "call unable to decode class + method + indata" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "call method " << cname << "." << mname << " does not exist" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "call method " << cname << "." << mname << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "method called response length=" << outdata.length() << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "stat oi has " << oi.size << " " << oi.mtime << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "stat oi object does not exist" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "cache-try-flush without SKIPRWLOCKS flag set" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "cache-try-flush on a pinned object, consider unpin this object first" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "cache-flush with SKIPRWLOCKS flag set" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "cache-flush on a pinned object, consider unpin this object first" << dendl;
./osd/PrimaryLogPG.cc:          dout(10) << __func__ << " CEPH_OSD_OP_CACHE_FLUSH got ENOENT" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "cache-evict on a pinned object, consider unpin this object first" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "bad cmp mode " << (int)op.xattr.cmp_mode << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "comparison returned false" << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "comparison returned " << result << " " << cpp_strerror(-result) << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "comparison returned true" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << " snapset " << ssc->snapset << dendl;
./osd/PrimaryLogPG.cc:          dout(20) << " clone " << *clone_iter << " snaps " << ci.snaps << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "clean_regions modified" << ctx->clean_regions << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << " object dne, truncate is a no-op" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "watch: oi.user_version=" << oi.user_version<< dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << " found existing watch " << w << " by " << entity << dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << " registered new watch " << w << " by " << entity << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << " found existing watch " << w << " by " << entity << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << " found existing watch " << w << " by " << entity << dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << " can't remove: no watch by " << entity << dendl;
./osd/PrimaryLogPG.cc:        dout(10) << " pin object is only allowed on the cache tier " << dendl;
./osd/PrimaryLogPG.cc:        dout(10) << " pin object is only allowed on the cache tier " << dendl;
./osd/PrimaryLogPG.cc:	  dout(20) << " set-redirect self is invalid" << dendl;
./osd/PrimaryLogPG.cc:	  dout(5) << " the object is already a manifest " << dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << __func__ << " error: " << cpp_strerror(result) << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "set-redirect oid:" << oi.soid << " user_version: " << oi.user_version << dendl;
./osd/PrimaryLogPG.cc:	  dout(5) << " the object is already a manifest " << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << "tier-promote oid:" << oi.soid << " manifest: " << obs.oi.manifest << dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << "tmapput key " << key << dendl;
./osd/PrimaryLogPG.cc:	      dout(10) << "TMAPPUT is unordered; resorting" << dendl;
./osd/PrimaryLogPG.cc:	    dout(20) << "Found key " << iter->key() << dendl;
./osd/PrimaryLogPG.cc:	  dout(20) << "setting vals: " << dendl;
./osd/PrimaryLogPG.cc:	    dout(20) << "\t" << i->first << dendl;
./osd/PrimaryLogPG.cc:	    dout(20) << " copy from self is invalid" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " error: " << cpp_strerror(result) << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "unable to get tmap for zero sized " << ctx->new_obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " will disconnect watcher " << p->first << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " setting whiteout on " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " deleting whiteout on " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "_rollback_to " << soid << " snapid " << snapid << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << " setting omap flag on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << " clearing omap flag on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " clearing DIRTY flag" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " setting DIRTY flag" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " deletion, decrementing num_dirty and clearing flag" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " op snapset is old" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " got greedy write on clone_obc " << *ctx->clone_obc << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "do_osd_op_effects disconnect watcher " << watcher << dendl;
./osd/PrimaryLogPG.cc:  dout(15) << "do_osd_op_effects " << entity << " con " << conn.get() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "do_osd_op_effects, notify " << *p << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "starting notify on watch " << i->first << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "notify_ack " << make_pair(*(p->watch_cookie), p->notify_id) << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "notify_ack " << make_pair("NULL", p->notify_id) << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "acking notify on watch " << i->first << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << hoid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << hoid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " invalid snapc " << ctx->snapc << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " full, replying to FULL_TRY op" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " full, dropping request (bad client)" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " set mtime to " << ctx->new_obs.oi.mtime << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " mtime unchanged at " << ctx->new_obs.oi.mtime << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " no snapset (this is a clone)" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " object " << soid <<  " marks clean_regions " << ctx->log.back().clean_regions << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " got attrs" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << ": async_read noted for " << soid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " got data" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << " got omap" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " got reqids" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " got reqids " << reply_obj.reqids << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << *obc << " " << cop << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << *obc << " " << cop << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no copy_op found" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " no more snaps for " << oid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " using temp " << cop->results.temp_oid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " fetching more" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << "fill_in_final_tx: writing to temp object" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " success; committing" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " complete r = " << cpp_strerror(r) << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no copy_op found" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " num_chunk: " << obj_cop->num_chunk << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " took lock on obc, " << obj_cop->obc->rwstate << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " complete r = " << cpp_strerror(r) << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << "finish_copyfrom on " << ctx->obs->oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": exists, removing" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " clearing whiteout on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " setting omap flag on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " clearing omap flag on " << obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " snaps " << results->snaps << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " filtered snaps " << results->snaps << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " abort; will clean up partial work" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " took lock on obc, " << obc->rwstate << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " whiteout " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " creating whiteout on " << soid << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " setting omap flag on " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " new_snapset " << tctx->new_snapset << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " took lock on obc, " << obc->rwstate << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << " fingerprint algorithm is not set " << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << __func__ << " unrecognized chunk-algorithm " << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no manifest_op found" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " took write lock" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " waiting on write lock " << mop->op << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " snapset " << snapset << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << " missing clone is " << next << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " no older clones" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " piggybacking on existing flush " << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " canceling previous flush; it will fail" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no flush_op found" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " requeueing dups" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " object no longer exists" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " requeueing dups" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << " blocked by scrub" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " clearing DIRTY flag for " << oid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " took write lock" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " failed write lock, no op; failing" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " requeueing for " << ctx->at_version << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "op_applied version " << applied_version << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " commit: " << *repop << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " removing " << *repop << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "   q front is " << *repop_queue.front() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "new_repop rep_tid " << rep_tid << " on " << *ctx->op->get_req() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "new_repop rep_tid " << rep_tid << " (no op)" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << ": " << *repop << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << ": " << *repop << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << *repop << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << repop << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << entries << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << "PrimaryLogPG::check_blocklisted_watchers for pg " << get_pgid() << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << "PrimaryLogPG::check_blocklisted_obc_watchers for obc " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(30) << "watch: Found " << j->second->get_entity() << " cookie " << j->second->get_cookie() << dendl;
./osd/PrimaryLogPG.cc:    dout(30) << "watch: Check entity_addr_t " << ea << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "watch: Found blocklisted watcher for " << ea << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "populate_obc_watchers " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "  unconnected watcher " << p->first << " will expire " << expire << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "handle_watch_timeout obc " << obc << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "handle_watch_timeout not active, no-op" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " object " << obc->obs.oi.soid << " dne" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "create_object_context " << (void*)obc.get() << " " << oi.soid << " " << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << ": obc NOT found in cache: " << soid << dendl;
./osd/PrimaryLogPG.cc:      dout(0) << __func__ << ": obc corrupt: " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " " << oid << " no snapset" << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " clone is degraded or backfilling " << soid << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " clone is recovering " << soid << dendl;
./osd/PrimaryLogPG.cc:	dout(20) << __func__ << " missing clone " << soid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " replica missing clone" << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(1) << __func__ << " " << soid << " empty snapset -- DNE" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << oi.soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " " << soid << " still blocked" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " " << soid << " requeuing " << ls.size() << " requests" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " requeuing if still active: " << (is_active() ? "yes" : "no") << dendl;
./osd/PrimaryLogPG.cc:        dout(0) << __func__ << " Can't decode snapset: " << e.what() << dendl;
./osd/PrimaryLogPG.cc:	     dout(20) << __func__ << ": soid " << soid << " needs to be deleted from replica " << shard << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " missing but already recovering head " << head << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << soid << " " << v << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << oid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "obc = " << *obc << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << ": " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << " primary missing oid " << soid << " version " << v << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "pick_newest_available " << oid << " " << v << " on osd." << osd->whoami << " (local)" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "pick_newest_available " << oid << " " << h << " on osd." << peer << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "pick_newest_available " << oid << " " << v << " (newest)" << dendl;
./osd/PrimaryLogPG.cc:  dout(3) << __func__ << " " << pg_log_entry_t::get_op_name(what) << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << e << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << e << dendl;
./osd/PrimaryLogPG.cc:	dout(0) << "do_command r=" << 0 << " " << rs << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " canceling repop tid " << repop->rep_tid << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " requeuing " << *repop->op->get_req() << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " also requeuing ondisk waiters " << p->second << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "activate not all replicas are up-to-date, queueing recovery" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "activate queueing backfill" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "activate all replicas clean, no recovery" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " discarding empty hit_set" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " clearing hit set" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(15) << __func__ << " flags: " << m_planned_scrub << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << ": " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " kicking degraded waiters on " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " kicking unreadable waiters on " << soid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "recovery raced and were queued twice, ignoring!" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "deferring backfill due to NOBACKFILL" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "deferring backfill due to NOREBALANCE" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "deferring backfill due to !backfill_reserved" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << "queueing RequestBackfill" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << " started " << started << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " still have " << unfound << " unfound" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "recovery done, queuing backfill" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << "recovery done, no backfill" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "recovery done, backfill done" << dendl;
./osd/PrimaryLogPG.cc:  dout(25) << __func__ << " " << missing.get_items() << dendl;
./osd/PrimaryLogPG.cc:	      dout(10) << " already reverting " << soid << dendl;
./osd/PrimaryLogPG.cc:	      dout(10) << " reverting " << soid << " to " << latest->prior_version << dendl;
./osd/PrimaryLogPG.cc:	    dout(10) << " need to pull prior_version " << alternate_need << " for revert " << item << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << ": on " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << ": on " << soid << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " missing but already recovering head " << head << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << __func__ << " Error " << r << " on oid " << soid << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << "(" << max << ")" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << " peer osd." << peer << " missing " << m_sz << " objects." << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " peer osd." << peer << " missing " << pm->second.get_items() << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << ": " << soid << " still unfound" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << ": already recovering " << soid << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << ": " << soid << " is a delete, removing" << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << __func__ << ": " << soid << " still missing on primary" << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << __func__ << ": recover_object_replicas(" << soid << ")" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << "   my backfill interval " << backfill_info << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << " peer shard " << bt << " backfill " << pbi << dendl;
./osd/PrimaryLogPG.cc:	dout(10) << " scanning peer osd." << bt << " from " << pbi.end << dendl;
./osd/PrimaryLogPG.cc:      dout(10) << " reached end for both local and all peers" << dendl;
./osd/PrimaryLogPG.cc:	    dout(0) << __func__ << " Error " << r << " trying to backfill " << backfill_info.begin << dendl;
./osd/PrimaryLogPG.cc:  dout(5) << "backfill_pos is " << backfill_pos << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << *i << " is still in flight" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "starting new_last_backfill at " << new_last_backfill << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << " pending_backfill_update " << i->first << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "possible new_last_backfill at " << new_last_backfill << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "final new_last_backfill at " << new_last_backfill << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " " << oid << " v " << v << " to peers " << peers << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << __func__ << " Error " << r << " on oid " << oid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__<< ": bi is current " << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << __func__ << ": " << e.soid << " removed" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "scanning pg log first" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << "scanning projected log" << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << "scan_range from " << bi->begin << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << " got " << ls.size() << " items, next " << bi->end << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << ls << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << "  " << *p << " " << obc->obs.oi.version << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << "  " << *p << " " << oi.version << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << hoid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << hoid << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << params << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " no update" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " " << to << " .. " << info.last_update << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__  << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " archive " << oid << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " removing " << oid << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " keeping existing state" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " no agent state, stopping" << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " idle, stopping" << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << " got " << ls.size() << " objects" << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (hit set) " << *p << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (degraded) " << *p << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (missing head) " << *p << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (no obc) " << *p << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (dne) " << obc->obs.oi.soid << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (scrubbing) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (blocked) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (request pending) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (omap to EC) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " resetting atime and temp histograms" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " wrap around " << agent_state->start << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << dendl;
./osd/PrimaryLogPG.cc:	  dout(10) << __func__ << " unreadable " << oid << ", waiting" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (clean) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (cache_pinned) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (too young) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (flushing) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " flushing " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (dirty) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (scrubbing) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (watchers) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (blocked) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (cache_pinned) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (clones) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:      dout(20) << __func__ << " skip (too young) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:  dout(10) << __func__ << " evicting " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " skip (cannot get lock) " << obc->obs.oi << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " " << this << " delaying, ignored" << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << " stats invalid (post-split), idle" << dendl;
./osd/PrimaryLogPG.cc:    dout(30) << __func__ << " evict_effort " << was << " quantized by " << inc << " to " << evict_effort << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << ": " << v << dendl;
./osd/PrimaryLogPG.cc:    dout(20) << __func__ << ": " << **i << dendl;
./osd/PrimaryLogPG.cc:  dout(20) << __func__ << ": returning true" << dendl;
./osd/PrimaryLogPG.cc:  dout(15) << __func__ << " is scrub active? " << m_scrubber->is_scrub_active() << dendl;
./osd/PrimaryLogPG.cc:    dout(10) << __func__ << " scrub isn't active" << dendl;
./osd/PrimaryLogPG.cc:    dout(0) << __func__ << " No other replicas available for " << soid << dendl;
./osd/PrimaryLogPG.cc:  ldout(pg->cct, 20) << "enter " << state_name << dendl;
./osd/PrimaryLogPG.cc:  ldout(pg->cct, 20) << "exit " << state_name << dendl;
./osd/PrimaryLogPG.cc:  ldout(pg->cct, 10) << "NotTrimming react KickTrim" << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << "NotTrimming not primary or active" << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << "NotTrimming not clean or nothing to trim" << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << " scrubbing, will requeue snap_trimmer after" << dendl;
./osd/PrimaryLogPG.cc:  ldout(pg->cct, 10) << "WaitReservation react SnapTrimReserved" << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << "something changed, reverting to NotTrimming" << dendl;
./osd/PrimaryLogPG.cc:  ldout(pg->cct, 10) << "AwaitAsyncWork: trimming snap " << snap_to_trim << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << "got ENOENT" << dendl;
./osd/PrimaryLogPG.cc:      ldout(pg->cct, 10) << " removing from snap_trimq_repeat" << dendl;
./osd/PrimaryLogPG.cc:    ldout(pg->cct, 10) << "AwaitAsyncWork react trimming " << object << dendl;
./osd/PrimaryLogPG.cc:	ldout(pg->cct, 10) << "Snaptrim error=" << error << dendl;
./osd/PrimaryLogPG.cc:	ldout(pg->cct, 10) << "letting the ones we already started finish" << dendl;
./osd/scrub_machine.cc:  dout(20) << " event: --vvvv---- " << nm << dendl;
./osd/scrub_machine.cc:  dout(20) << " event: --^^^^---- " << nm << dendl;
./osd/scrub_machine.cc:    dout(20) << " state: " << boost::core::demangle(typeid(siw).name()) << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> NotActive" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> ReservingReplicas" << dendl;
./osd/scrub_machine.cc:  dout(10) << "ReservingReplicas::react(const ReservationFailure&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "ReservingReplicas::react(const FullReset&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> ActiveScrubbing" << dendl;
./osd/scrub_machine.cc:  dout(15) << __func__ << dendl;
./osd/scrub_machine.cc:  dout(10) << __func__ << dendl;
./osd/scrub_machine.cc:  dout(10) << "ActiveScrubbing::react(const FullReset&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/RangeBlocked" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/PendingTimer" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/NewChunk" << dendl;
./osd/scrub_machine.cc:    dout(15) << __func__ << " selection OK" << dendl;
./osd/scrub_machine.cc:    dout(10) << __func__ << " selected chunk is busy" << dendl;
./osd/scrub_machine.cc:  dout(10) << "NewChunk::react(const SelectedChunkFree&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << " -- state -->> Act/WaitPushes" << dendl;
./osd/scrub_machine.cc:  dout(10) << " -- state -->> Act/WaitLastUpdate" << dendl;
./osd/scrub_machine.cc:  dout(10) << "WaitLastUpdate::on_new_updates(const UpdatesApplied&)" << dendl;
./osd/scrub_machine.cc:    dout(10) << "wait for EC read/modify/writes to queue" << dendl;
./osd/scrub_machine.cc:  dout(10) << "WaitLastUpdate::react(const InternalAllUpdates&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << " -- state -->> Act/BuildMap" << dendl;
./osd/scrub_machine.cc:    dout(10) << __func__ << " preempted!!!" << dendl;
./osd/scrub_machine.cc:      dout(20) << "waiting for the backend..." << dendl;
./osd/scrub_machine.cc:      dout(10) << "BuildMap::BuildMap() Error! Aborting. Ret: " << ret << dendl;
./osd/scrub_machine.cc:  dout(10) << "BuildMap::react(const IntLocalMapDone&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/DrainReplMaps" << dendl;
./osd/scrub_machine.cc:  dout(10) << "DrainReplMaps::react(const GotReplicas&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/WaitReplicas" << dendl;
./osd/scrub_machine.cc:  dout(10) << "WaitReplicas::react(const GotReplicas&)" << dendl;
./osd/scrub_machine.cc:    dout(10) << "WaitReplicas::react(const GotReplicas&) got all" << dendl;
./osd/scrub_machine.cc:      dout(10) << "WaitReplicas::react(const GotReplicas&) PREEMPTED!" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> Act/WaitDigestUpdate" << dendl;
./osd/scrub_machine.cc:  dout(10) << "WaitDigestUpdate::react(const DigestUpdate&)" << dendl;
./osd/scrub_machine.cc:  dout(15) << "ScrubMachine created " << m_pg_id << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> ReplicaWaitUpdates" << dendl;
./osd/scrub_machine.cc:  dout(10) << "ReplicaWaitUpdates::react(const FullReset&)" << dendl;
./osd/scrub_machine.cc:  dout(10) << "-- state -->> ActiveReplica" << dendl;
./osd/scrub_machine.cc:    dout(10) << "replica scrub job preempted" << dendl;
./osd/scrub_machine.cc:  dout(15) << "ActiveReplica::react(const SchedReplica&) Ret: " << ret << dendl;
./osd/scrub_machine.cc:    dout(20) << "waiting for the backend..." << dendl;
./osd/scrub_machine.cc:  dout(10) << "ActiveReplica::react(const FullReset&)" << dendl;
./osd/PGLog.cc:    lgeneric_subdout(cct, osd, 20) << " complete_to " << complete_to->version << dendl;
./osd/PGLog.cc:  lgeneric_subdout(cct, osd, 20) << "earliest_dup_version = " << earliest_dup_version << dendl;
./osd/PGLog.cc:    lgeneric_subdout(cct, osd, 20) << "trim " << e << dendl;
./osd/PGLog.cc:	lgeneric_subdout(cct, osd, 20) << "updating write_from_dups from " << *write_from_dups << " to " << e.version << dendl;
./osd/PGLog.cc:        lgeneric_subdout(cct, osd, 20) << " log is now empty" << dendl;
./osd/PGLog.cc:    lgeneric_subdout(cct, osd, 20) << "trim dup " << e << dendl;
./osd/PGLog.cc:  dout(10) << __func__ << " proposed trim_to = " << trim_to << dendl;
./osd/PGLog.cc:    dout(10) << __func__ << " missing = " << missing.num_missing() << dendl;
./osd/PGLog.cc:    dout(10) << "trim " << log << " to " << trim_to << dendl;
./osd/PGLog.cc:      dout(10) << " after trim complete_to " << log.complete_to->version << dendl;
./osd/PGLog.cc:    dout(10) << " peer osd." << from << " last_update now " << lu << dendl;
./osd/PGLog.cc:  dout(20) << __func__ << " original_crt = " << original_crt << dendl;
./osd/PGLog.cc:    dout(10) << "rewind_divergent_log future divergent " << entry << dendl;
./osd/PGLog.cc:    dout(20) << "pg_missing_t sobject: " << i->first << dendl;
./osd/PGLog.cc:    dout(10) << "merge_log extending tail to " << olog.tail << dendl;
./osd/PGLog.cc:      dout(15) << *to << dendl;
./osd/PGLog.cc:    dout(10) << "merge_log extending head to " << olog.head << dendl;
./osd/PGLog.cc:      dout(20) << "  ? " << *from << dendl;
./osd/PGLog.cc:    dout(20) << __func__ << " original_crt = " << original_crt << dendl;
./osd/PGLog.cc:      dout(10) << "merge_log divergent " << oe << dendl;
./osd/PGLog.cc:    dout(10) << "log is not dirty" << dendl;
./osd/PGLog.cc:  // dout(10) << "write_log_and_missing, clearing up to " << dirty_to << dendl;
./osd/PGLog.cc:    // dout(10) << "write_log_and_missing, clearing from " << dirty_from << dendl;
./osd/PGLog.cc:    //dout(10) << "write_log_and_missing: writing divergent_priors" << dendl;
./osd/PGLog.cc:    //   dout(10) << "write_log_and_missing, clearing from " << dirty_from << dendl;
./osd/PGLog.cc:    //dout(10) << "write_log_and_missing: writing divergent_priors" << dendl;
./osd/PGLog.cc:    dout(20) << __func__ << " check for log entry: " << *i << " = " << r << dendl;
./osd/PGLog.cc:      dout(20) << __func__ << " store version = " << oi.version << dendl;
./osd/PGLog.cc:        ldpp_dout(dpp, 20) << "read_log_and_missing " << e << dendl;
./osd/PGBackend.cc:  dout(20) << __func__ << " " << op << dendl;
./osd/PGBackend.cc:  dout(20) << __func__ << " " << op << dendl;
./osd/PGBackend.cc:  ldpp_dout(dpp, 20) << __func__ << ": entry=" << entry << dendl;
./osd/PGBackend.cc:  dout(10) << __func__ << dendl;
./osd/PGBackend.cc:  dout(10) << __func__ << " " << pos << dendl;
./osd/PGBackend.cc:    dout(25) << __func__ << "  " << poid << dendl;
./osd/PGBackend.cc:	dout(20) << __func__ << " missing data digest on " << *k << dendl;
./osd/PGBackend.cc:	dout(20) << __func__ << " missing omap digest on " << *k << dendl;
./osd/PGBackend.cc:	    dout(20) << __func__ << " will update data digest on " << *k << dendl;
./osd/PGBackend.cc:	    dout(20) << __func__ << " will update omap digest on " << *k << dendl;
./osd/scheduler/mClockScheduler.cc:  dout(1) << __func__ << " mclock profile: " << mclock_profile << dendl;
./osd/osd_types.cc:      ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " now down" << dendl;
./osd/osd_types.cc:	ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " no longer exists" << dendl;
./osd/osd_types.cc:	ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " (re)marked as lost" << dendl;
./osd/osd_types.cc:      ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " now up" << dendl;
./osd/osd_types.cc:      ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " no longer exists" << dendl;
./osd/osd_types.cc:        ldpp_dout(dpp, 10) << "affected_by_map osd." << o << " (re)marked as lost" << dendl;
./osd/osd_types.cc:  lgeneric_subdout(cct, osd, 20) << "copy_up_to/copy_after earliest_dup_version " << earliest_dup_version << dendl;
./osd/osd_types.cc:  lgeneric_subdout(cct, osd, 20) << __func__ << " v " << v << dendl;
./osd/osd_types.cc:    lgeneric_subdout(cct, osd, 20) << __func__ << " copy log version " << i->version << dendl;
./osd/osd_types.cc:  lgeneric_subdout(cct, osd, 20) << __func__ << " max " << max << dendl;
./osd/osd_types.cc:    lgeneric_subdout(cct, osd, 20) << __func__ << " copy log version " << i->version << dendl;
./osd/osd_types.cc:    //dout(20) << "write_info bigbl " << bigbl.length() << dendl;
./osd/SnapMapper.cc:    dout(20) << __func__ << " " << oid << " got err " << r << dendl;
./osd/SnapMapper.cc:    dout(20) << __func__ << " " << oid << " got.empty()" << dendl;
./osd/SnapMapper.cc:    dout(20) << __func__ << " " << oid << " " << out->snaps << dendl;
./osd/SnapMapper.cc:      dout(1) << __func__ << " " << oid << " empty snapset" << dendl;
./osd/SnapMapper.cc:    dout(20) << __func__ << " " << oid << " (out == NULL)" << dendl;
./osd/SnapMapper.cc:  dout(20) << __func__ << " " << oid << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " rm " << i << dendl;
./osd/SnapMapper.cc:  dout(20) << __func__ << " " << oid << " " << in.snaps << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " set " << i.first << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " rm " << i << dendl;
./osd/SnapMapper.cc:  dout(20) << __func__ << " " << oid << " " << snaps << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " set " << i.first << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " " << next.first << dendl;
./osd/SnapMapper.cc:  dout(20) << __func__ << " " << oid << dendl;
./osd/SnapMapper.cc:  dout(20) << __func__ << " " << oid << dendl;
./osd/SnapMapper.cc:      dout(20) << __func__ << " rm " << i << dendl;
./osd/SnapMapper.cc:  dout(10) << __func__ << " purged_snaps " << purged_snaps << dendl;
./osd/SnapMapper.cc:  dout(10) << __func__ << dendl;
./osd/SnapMapper.cc:  dout(10) << __func__ << " end, found " << stray.size() << " stray" << dendl;
./osd/SnapMapper.cc:      dout(10) << __func__ << " converted " << n << " keys" << dendl;
./osd/PrimaryLogScrub.cc:      dout(20) << mode << "  " << soid << " " << *oi << dendl;
./osd/PrimaryLogScrub.cc:      dout(20) << __func__ << " " << mode << " new head " << head << dendl;
./osd/PrimaryLogScrub.cc:	  dout(20) << "  snapset " << *snapset << dendl;
./osd/PrimaryLogScrub.cc:      dout(20) << __func__ << " " << mode << " matched clone " << soid << dendl;
./osd/PrimaryLogScrub.cc:    dout(10) << __func__ << " recording digests for " << p->first << dendl;
./osd/PrimaryLogScrub.cc:      dout(20) << "updating scrub digest " << num_digest_updates_pending << dendl;
./osd/PrimaryLogScrub.cc:  dout(10) << __func__ << " (" << mode << ") finish" << dendl;
./osd/PrimaryLogScrub.cc:  dout(15) << __func__ << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " start" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " empty queue" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " oids " << agent_oids << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " finish" << dendl;
./osd/OSD.cc:  dout(20) << __func__ << "  new_prob " << new_prob << dendl;
./osd/OSD.cc:  ldpp_dout(dpp, 20) << __func__ << " type " << get_full_state_name(type) << " adjust_used " << (adjust_used >> 10) << "KiB" << dendl;
./osd/OSD.cc:    ldpp_dout(dpp, 10) << __func__ << " tentative usage is " << ratio << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " Before kb_used() " << new_stat.statfs.kb_used()  << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " After kb_used() " << new_stat.statfs.kb_used() << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " backfill adjusted " << new_stat << dendl;
./osd/OSD.cc:  dout(10) << "send_pg_temp " << pg_temp_wanted << dendl;
./osd/OSD.cc:  dout(20) << __func__ << dendl;
./osd/OSD.cc:  dout(20) << __func__ << dendl;
./osd/OSD.cc:  dout(20) << __func__ << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " pruning " << *i << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " keeping " << *i << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << scrubs_local << " local + " << scrubs_remote << " remote >= max " << cct->_conf->osd_max_scrubs << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << scrubs_local << " local + " << scrubs_remote << " remote >= max " << cct->_conf->osd_max_scrubs << dendl;
./osd/OSD.cc:    dout(0) << __func__ << " telling mon we are shutting down" << dendl;
./osd/OSD.cc:  dout(0) << __func__ << " starting shutdown" << dendl;
./osd/OSD.cc:    dout(0) << __func__ << " starting shutdown" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " ignoring msg" << dendl;
./osd/OSD.cc:      dout(10) << __func__ << " missing incremental map " << e << dendl;
./osd/OSD.cc:  dout(10) << "add_map_bl " << e << " " << bl.length() << " bytes" << dendl;
./osd/OSD.cc:  dout(10) << "add_map_inc_bl " << e << " " << bl.length() << " bytes" << dendl;
./osd/OSD.cc:    dout(30) << "get_map " << epoch << " -cached" << dendl;
./osd/OSD.cc:      dout(30) << "get_map " << epoch << " - miss, below lower bound" << dendl;
./osd/OSD.cc:    dout(20) << "get_map " << epoch << " - loading and decoding " << map << dendl;
./osd/OSD.cc:    dout(20) << "get_map " << epoch << " - return initial " << map << dendl;
./osd/OSD.cc:  dout(7) << *pg << " misdirected op in " << m->get_map_epoch() << dendl;
./osd/OSD.cc:  dout(10) << "queueing " << *pg << " for snaptrim" << dendl;
./osd/OSD.cc:  dout(15) << "queue a scrub event (" << *msg << ") for " << *pg << ". Epoch: " << epoch << dendl;
./osd/OSD.cc:  dout(15) << "queue a scrub event (" << *msg << ") for " << *pg << ". Epoch: " << epoch << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " on " << pgid << " e " << e  << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pg->pg_id << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pg->pg_id << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << source << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << target << " source " << source << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pg->pg_id << dendl;
./osd/OSD.cc:      dout(10) << __func__ << " " << *i << dendl;
./osd/OSD.cc:    dout(0) << " have superblock" << dendl;
./osd/OSD.cc:    dout(1) << __func__ << " storage numa node " << store_node << dendl;
./osd/OSD.cc:	dout(1) << " objectstore and network numa nodes all match" << dendl;
./osd/OSD.cc:    dout(1) << __func__ << " not setting numa affinity" << dendl;
./osd/OSD.cc:    dout(1) << "triggering manual compaction" << dendl;
./osd/OSD.cc:    dout(20) << "clearing all caches" << dendl;
./osd/OSD.cc:    dout(1) << __func__ << " disabling" << dendl;
./osd/OSD.cc:    dout(1) << __func__ << " enabling" << dendl;
./osd/OSD.cc:  dout(2) << "journal " << journal_path << dendl;
./osd/OSD.cc:  dout(2) << "boot" << dendl;
./osd/OSD.cc:      dout(20) << "configured osd_max_object_name[space]_len looks ok" << dendl;
./osd/OSD.cc:    dout(5) << "Upgrading superblock adding: " << diff << dendl;
./osd/OSD.cc:    dout(10) << "init creating/touching snapmapper object" << dendl;
./osd/OSD.cc:    dout(10) << "init creating/touching purged_snaps object" << dendl;
./osd/OSD.cc:      dout(1) << "warning: got an error loading one or more classes: " << cpp_strerror(r) << dendl;
./osd/OSD.cc:  dout(2) << "superblock: I am osd." << superblock.whoami << dendl;
./osd/OSD.cc:    dout(2) << "compacting object store's omap" << dendl;
./osd/OSD.cc:  dout(10) << "ensuring pgs have consumed prior maps" << dendl;
./osd/OSD.cc:  dout(0) << "done with init, starting boot process" << dendl;
./osd/OSD.cc:  dout(0) << "shutdown" << dendl;
./osd/OSD.cc:  dout(10) << "op sharded tp stopped" << dendl;
./osd/OSD.cc:  dout(10) << "stopping agent" << dendl;
./osd/OSD.cc:  dout(10) << "noting clean unmount in epoch " << get_osdmap_epoch() << dendl;
./osd/OSD.cc:      dout(20) << " kicking pg " << pg << dendl;
./osd/OSD.cc:  dout(10) << "syncing store" << dendl;
./osd/OSD.cc:    dout(10) << "flushing journal" << dendl;
./osd/OSD.cc:  dout(10) << "Store synced" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " cmd: " << cmd << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " osd_crush_update_on_start = false" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " crush location is " << cct->crush_location << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " osd_class_update_on_start = false" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " no device class stored locally" << dendl;
./osd/OSD.cc:  dout(10) << "write_superblock " << superblock << dendl;
./osd/OSD.cc:  dout(10) << "read_superblock " << superblock << dendl;
./osd/OSD.cc:  dout(10) << __func__ << dendl;
./osd/OSD.cc:    dout(20) << " clearing temps in " << *p << " pgid " << pgid << dendl;
./osd/OSD.cc:	dout(20) << "  removing " << *p << " object " << *q << dendl;
./osd/OSD.cc:    generic_dout(10) << __func__ << " " << objects << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pgid << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " " << pgid << " " << pg << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " " << pg->pg_id << " not found" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " " << pg->pg_id << " waiting for merge" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << pg->pg_id << " " << pg << dendl;
./osd/OSD.cc:  dout(0) << "load_pgs" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " pg_num_history " << pg_num_history << dendl;
./osd/OSD.cc:      dout(10) << "load_pgs ignoring unrecognized " << *it << dendl;
./osd/OSD.cc:    dout(10) << "pgid " << pgid << " coll " << coll_t(pgid) << dendl;
./osd/OSD.cc:      dout(10) << "load_pgs " << *it << " deleting dne" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " loaded " << *pg << dendl;
./osd/OSD.cc:  dout(0) << __func__ << " opened " << num << " pgs" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " hit max pg, dropping" << dendl;
./osd/OSD.cc:      dout(10) << __func__ << " ignoring " << pgid << ", pool dne" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " new pg " << *pg << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " pg " << pg->first << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pgid << " created " << created << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " " << debug.str() << dendl;
./osd/OSD.cc:  dout(20) << "need_heartbeat_peer_update" << dendl;
./osd/OSD.cc:	dout(10) << "maybe_update_heartbeat_peers forcing update after " << dur << " seconds" << dendl;
./osd/OSD.cc:  dout(10) << "maybe_update_heartbeat_peers updating" << dendl;
./osd/OSD.cc:    dout(10) << " adding neighbor peer osd." << *p << dendl;
./osd/OSD.cc:      dout(10) << " adding random peer osd." << n << dendl;
./osd/OSD.cc:  dout(10) << "maybe_update_heartbeat_peers " << heartbeat_peers.size() << " peers, extras " << extras << dendl;
./osd/OSD.cc:  dout(10) << "reset_heartbeat_peers" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " new stamps " << *s->stamps << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " new stamps " << *s->stamps << dendl;
./osd/OSD.cc:    dout(30) << "heartbeat_entry sleeping for " << wait << dendl;
./osd/OSD.cc:    dout(30) << "heartbeat_entry woke up" << dendl;
./osd/OSD.cc:  dout(30) << "heartbeat" << dendl;
./osd/OSD.cc:    dout(30) << "heartbeat: daily_loadavg " << daily_loadavg << dendl;
./osd/OSD.cc:  dout(30) << "heartbeat checking stats" << dendl;
./osd/OSD.cc:  dout(5) << __func__ << " " << new_stat << dendl;
./osd/OSD.cc:      dout(30) << "heartbeat osd." << peer << " has no open con" << dendl;
./osd/OSD.cc:    dout(30) << "heartbeat sending ping to osd." << peer << dendl;
./osd/OSD.cc:  dout(30) << "heartbeat lonely?" << dendl;
./osd/OSD.cc:      dout(10) << "i have no heartbeat peers; checking mon for new map" << dendl;
./osd/OSD.cc:  dout(30) << "heartbeat done" << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " con " << con << " s " << s.get() << dendl;
./osd/OSD.cc:      dout(10) << "heartbeat_reset closing (old) failed hb con " << con << dendl;
./osd/OSD.cc:  dout(10) << "tick" << dendl;
./osd/OSD.cc:      dout(1) << __func__ << " checking mon for new map" << dendl;
./osd/OSD.cc:  dout(10) << "tick_without_osd_lock" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " con " << con << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " on mon" << dendl;
./osd/OSD.cc:  dout(2) << "ms_handle_reset con " << con << " session " << session.get() << dendl;
./osd/OSD.cc:  dout(2) << "ms_handle_refused con " << con << " session " << session.get() << dendl;
./osd/OSD.cc:    dout(1) << "not healthy; waiting to boot" << dendl;
./osd/OSD.cc:  dout(1) << __func__ << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << *m << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " want state " << s << dendl;
./osd/OSD.cc:  dout(1) << "start_waiting_for_healthy" << dendl;
./osd/OSD.cc:    dout(1) << "is_healthy false -- internal heartbeat failed" << dendl;
./osd/OSD.cc:  dout(10) << "_send_boot" << dendl;
./osd/OSD.cc:    dout(1) << __func__ << " " << i.first << ": " << i.second << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << *pm << dendl;
./osd/OSD.cc:  dout(10) << "send_alive up_thru currently " << up_thru << " want " << up_thru_wanted << dendl;
./osd/OSD.cc:    dout(10) << "send_alive want " << up_thru_wanted << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << e << ", nothing requested" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " sending" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " not sending" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " pool " << pool << " dne" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " pg " << spgid << " not found" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " done queueing pgs, updating superblock" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " done" << dendl;
./osd/OSD.cc:      dout(10) << "block_device_get_metrics failed for /dev/" << dev << dendl;
./osd/OSD.cc:  dout(30) << "heartbeat_dispatch " << m << dendl;
./osd/OSD.cc:    dout(10) << "ping from " << m->get_source_inst() << dendl;
./osd/OSD.cc:    dout(0) << "dropping unexpected message " << *m << " from " << m->get_source_inst() << dendl;
./osd/OSD.cc:  dout(20) << "OSD::ms_dispatch: " << *m << dendl;
./osd/OSD.cc:  dout(10) << "jaeger tracer after " << opentracing::Tracer::Global() << dendl;
./osd/OSD.cc:    dout(10) << "ping from " << m->get_source() << dendl;
./osd/OSD.cc:  dout(10) << "do_waiters -- start" << dendl;
./osd/OSD.cc:  dout(10) << "do_waiters -- finish" << dendl;
./osd/OSD.cc:  dout(20) << "_dispatch " << m << " " << *m << dendl;
./osd/OSD.cc:        dout(7) << "no OSDMap, not booted" << dendl;
./osd/OSD.cc:  dout(10) << "handle_scrub " << *m << dendl;
./osd/OSD.cc:  dout(10) << __func__ <<  " " << *m << dendl;
./osd/OSD.cc:    dout(20) << "scrub_random_backoff lost coin flip, randomly backing off" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " couldn't read loadavgs\n" << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " sched_scrub starts" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << ": OSD cannot inc scrubs" << dendl;
./osd/OSD.cc:      dout(15) << __func__ << ": not scheduling scrubs due to active recovery" << dendl;
./osd/OSD.cc:  dout(20) << "sched_scrub load_is_low=" << (int)load_is_low << dendl;
./osd/OSD.cc:      dout(30) << "sched_scrub examine " << scrub_job.pgid << " at " << scrub_job.sched_time << dendl;
./osd/OSD.cc:	dout(20) << __func__ << " pg  " << scrub_job.pgid << " not found" << dendl;
./osd/OSD.cc:	dout(20) << __func__ << " pg  " << scrub_job.pgid << " reserve failed, skipped" << dendl;
./osd/OSD.cc:	dout(20) << __func__ << ": already in progress pgid " << scrub_job.pgid << dendl;
./osd/OSD.cc:	dout(10) << __func__ << ": reserve in progress pgid " << scrub_job.pgid << dendl;
./osd/OSD.cc:        dout(10) << __func__ << " scheduled a scrub!" << " (~" << scrub_job.pgid << "~)" << dendl;
./osd/OSD.cc:	dout(20) << __func__ << " pg  " << scrub_job.pgid << " local reserve failed, nothing to be done now" << dendl;
./osd/OSD.cc:  dout(20) << "sched_scrub done" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << ": start" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << ": examine " << pgid << dendl;
./osd/OSD.cc:        dout(15) << __func__ << ": reschedule " << pgid << dendl;
./osd/OSD.cc:  dout(10) << __func__ << ": done" << dendl;
./osd/OSD.cc:        lgeneric_subdout(cct,osd,20) << ss.str() << dendl;
./osd/OSD.cc:    dout(20) << " removing old osdmap epoch " << e << dendl;
./osd/OSD.cc:    dout(0) << "ignoring osdmap until we have initialized" << dendl;
./osd/OSD.cc:    dout(10) << " no new maps here, dropping" << dendl;
./osd/OSD.cc:      dout(10) << "handle_osd_map  got full map for epoch " << e << dendl;
./osd/OSD.cc:      dout(10) << "handle_osd_map  got inc map for epoch " << e << dendl;
./osd/OSD.cc:	  dout(10) << __func__ << " bailing because last < start (" << last << "<" << start << ")" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " pg_num_history " << pg_num_history << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << first << ".." << last << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " bailing, we are shutting down" << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " bailing, we are shutting down" << dendl;
./osd/OSD.cc:      dout(10) << "up_epoch is " << up_epoch << dendl;
./osd/OSD.cc:	dout(10) << "boot_epoch is " << boot_epoch << dendl;
./osd/OSD.cc:      dout(1) << "state: booting -> active" << dendl;
./osd/OSD.cc:    dout(0) << __func__ << " shutdown OSD via async signal" << dendl;
./osd/OSD.cc:      dout(0) << __func__ << " enabling on-disk ERASURE CODES compat feature" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pgs << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " " << *pg << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " missing map " << next_epoch << dendl;
./osd/OSD.cc:	    dout(1) << __func__ << " merging " << pg->pg_id << dendl;
./osd/OSD.cc:	    dout(20) << __func__ << " not ready to merge yet" << dendl;
./osd/OSD.cc:	      dout(20) << __func__ << " kicking source " << i << dendl;
./osd/OSD.cc:  dout(7) << "consume_map version " << osdmap->get_epoch() << dendl;
./osd/OSD.cc:  dout(7) << "activate_map version " << osdmap->get_epoch() << dendl;
./osd/OSD.cc:      dout(1) << "pausing recovery (NORECOVER flag set)" << dendl;
./osd/OSD.cc:      dout(1) << "unpausing recovery (NORECOVER flag unset)" << dendl;
./osd/OSD.cc:    dout(7) << "from pre-up epoch " << epoch << " < " << up_epoch << dendl;
./osd/OSD.cc:    dout(7) << "still in boot state, dropping message " << *m << dendl;
./osd/OSD.cc:    dout(10) << __func__ << " splitting " << *parent << " into " << *i << dendl;
./osd/OSD.cc:  dout(10) << "handle_pg_create " << *m << dendl;
./osd/OSD.cc:      dout(20) << "ignoring pg on deleted pool " << on << dendl;
./osd/OSD.cc:    dout(20) << "mkpg " << on << " e" << created << "@" << ci->second << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " not up in osdmap" << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " not active" << dendl;
./osd/OSD.cc:	dout(20) << __func__ << " skipping down osd." << osd << dendl;
./osd/OSD.cc:  dout(7) << __func__ << " " << *m << " from " << m->get_source() << dendl;
./osd/OSD.cc:  dout(7) << __func__ << " " << *m << " from " << m->get_source() << dendl;
./osd/OSD.cc:  dout(7) << __func__ << " " << *m << " from " << m->get_source() << dendl;
./osd/OSD.cc:  dout(7) << __func__ << " " << *m << " from " << m->get_source() << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << *m << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " " << pgid << dendl;
./osd/OSD.cc:  dout(10) << " pg " << pgid << " dne" << dendl;
./osd/OSD.cc:    dout(15) << __func__ << " defer until " << defer_recovery_until << dendl;
./osd/OSD.cc:    dout(15) << __func__ << " paused" << dendl;
./osd/OSD.cc:    dout(10) << "do_recovery starting " << reserved_pushes << " " << *pg << dendl;
./osd/OSD.cc:    dout(20) << "  active was " << service.recovery_oids[pg->pg_id] << dendl;
./osd/OSD.cc:  dout(20) << "  active was " << recovery_oids[pg->pg_id] << dendl;
./osd/OSD.cc:  dout(20) << "  active oids was " << recovery_oids[pg->pg_id] << dendl;
./osd/OSD.cc:  dout(15) << __func__ << " " << pgid << " " << evt->get_desc() << dendl;
./osd/OSD.cc:  dout(10) << "dequeue_op " << op << " finish" << dendl;
./osd/OSD.cc:    dout(0) << __func__ << ": scrub interval change" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " -- start" << dendl;
./osd/OSD.cc:  dout(10) << __func__ << " -- finish" << dendl;
./osd/OSD.cc:  dout(10) << "setting " << queries.size() << " queries" << dendl;
./osd/OSD.cc:  dout(20) << "reports for " << reports.size() << " queries" << dendl;
./osd/OSD.cc:  dout(10) << pg->pg_id << " " << pg << dendl;
./osd/OSD.cc:  dout(10) << slot->pg->pg_id << " " << slot->pg << dendl;
./osd/OSD.cc:  dout(20) << slot->pg->pg_id << " " << slot->epoch << " -> " << e << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << pgid << dendl;
./osd/OSD.cc:      dout(20) << __func__ << "  " << pgid << " empty, pruning" << dendl;
./osd/OSD.cc:  dout(10) << *pgids << dendl;
./osd/OSD.cc:	dout(10) << "priming slot " << p->first << " e" << p->second << dendl;
./osd/OSD.cc:    dout(20) << __func__ << "  marking merge participant " << pgid << dendl;
./osd/OSD.cc:    dout(10) << pg->pg_id << " " << pg << dendl;
./osd/OSD.cc:  dout(0) << "using op scheduler " << *scheduler << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " empty q, waiting" << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " need return immediately" << dendl;
./osd/OSD.cc:          dout(10) << __func__ << " discarding in-flight oncommit " << c << dendl;
./osd/OSD.cc:        dout(10) << __func__ << " discarding in-flight oncommit " << c << dendl;
./osd/OSD.cc:      dout(10) << __func__ << " dequeue future request at " << future_time << dendl;
./osd/OSD.cc:      dout(10) << __func__ << " discarding in-flight oncommit " << c << dendl;
./osd/OSD.cc:      dout(20) << __func__ << " slot " << token << " no longer there" << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " " << qi << " pg " << pg << dendl;
./osd/OSD.cc:	    dout(20) << __func__ << " ignored create on " << qi << dendl;
./osd/OSD.cc:  dout(20) << __func__ << " " << item << dendl;
./osd/OSD.cc:    dout(20) << __func__ << " " << item << dendl;
./librbd/ImageState.cc:    ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << dendl;
./librbd/ImageState.cc:    ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << dendl;
./librbd/ImageState.cc:    ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << dendl;
./librbd/ImageState.cc:      ldout(m_cct, 20) << "QuiesceWatchers::" << __func__ << ": queue" << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:    ldout(cct, 5) << "dropping update notification to watchers" << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": snap_id=" << snap_id << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": handle=" << *handle << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": handle=" << handle << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/ImageState.cc:    ldout(cct, 5) << "incomplete refresh: not updating sequence" << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << " r=" << r << dendl;
./librbd/ImageState.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": handle=" << *handle << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": handle=" << handle << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/ImageState.cc:  ldout(cct, 20) << __func__ << ": handle=" << handle << " r=" << r << dendl;
./librbd/librbd.cc:    ldout(cct, 20) << "C_AioCompletion::finish: r=" << r << dendl;
./librbd/librbd.cc:    ldout(cct, 20) << "C_OpenComplete::finish: r=" << r << dendl;
./librbd/librbd.cc:  ldout(ictx->cct, 20) << "list_lockers r = " << r << " lockers.size() = " << lockers.size() << dendl;
./librbd/internal.cc:    ldout(cct, 2) << "adding rbd image to directory..." << dendl;
./librbd/internal.cc:    ldout(cct, 2) << "creating rbd image..." << dendl;
./librbd/internal.cc:    ldout(cct, 2) << "done." << dendl;
./librbd/internal.cc:    ldout(ictx->cct, 20) << "info " << ictx << dendl;
./librbd/internal.cc:    ldout(cct, 20) << __func__ << " " << ictx << " fd " << fd << " type" << type << dendl;
./librbd/internal.cc:    ldout(cct, 20) << __func__ << ": ictx=" << ictx << dendl;
./librbd/internal.cc:    ldout(cct, 20) << __func__ << ": ictx=" << ictx << dendl;
./librbd/internal.cc:    ldout(cct, 20) << __func__ << ": ictx=" << ictx << dendl;
./librbd/internal.cc:    ldout(ictx->cct, 20) << "list_locks on image " << ictx << dendl;
./librbd/internal.cc:    ldout(cct, 20) << "invalidate_cache " << ictx << dendl;
./librbd/internal.cc:      ldout(cct, 20) << "failed to invalidate image cache" << dendl;
./librbd/internal.cc:    ldout(cct, 20) << "metadata_get " << ictx << " key=" << key << dendl;
./librbd/internal.cc:    ldout(cct, 20) << "metadata_list " << ictx << dendl;
./librbd/crypto/luks/Header.cc:      ldout(m_cct, 5) << "[libcryptsetup] " << msg << dendl;
./librbd/crypto/luks/Header.cc:      ldout(m_cct, 10) << "[libcryptsetup] " << msg << dendl;
./librbd/crypto/luks/Header.cc:      ldout(m_cct, 20) << "[libcryptsetup] " << msg << dendl;
./librbd/crypto/luks/Header.cc:  ldout(m_cct, 20) << "read size = " << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(image_ctx->cct, 20) << "aligned read r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(cct, 20) << "aligned read r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(cct, 20) << "unaligned read r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(image_ctx->cct, 20) << "unaligned write r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/crypto/CryptoObjectDispatch.cc:      ldout(image_ctx->cct, 20) << "unaligned write r=" << r << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/DeepCopyRequest.cc:    ldout(m_cct, 10) << "snapshot copy canceled" << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/DeepCopyRequest.cc:    ldout(m_cct, 10) << "image copy canceled" << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/DeepCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/NativeFormat.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 20) << "work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:      ldout(cct, 20) << "sending http request: work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:      ldout(cct, 20) << "resetting HTTP session: work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:      ldout(cct, 20) << "queueing HTTP request: work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 20) << "work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 20) << "work=" << work.get() << ", r=" << -ec.value() << dendl;
./librbd/migration/HttpClient.cc:        ldout(cct, 5) << "remote peer stream closed, retrying request" << dendl;
./librbd/migration/HttpClient.cc:      ldout(cct, 20) << "sending http request: work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "work=" << work.get() << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "work=" << work.get() << ", r=" << -ec.value() << dendl;
./librbd/migration/HttpClient.cc:        ldout(cct, 5) << "remote peer stream closed, retrying request" << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 20) << "work=" << work.get() << ", r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:    ldout(cct, 15) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 10) << "url=" << m_url << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 20) << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 15) << dendl;
./librbd/migration/HttpClient.cc:  ldout(m_cct, 15) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/OpenSourceImageRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/migration/S3Stream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/S3Stream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/S3Stream.cc:  ldout(m_cct, 20) << "byte_extents=" << byte_extents << dendl;
./librbd/migration/S3Stream.cc:  ldout(m_cct, 20) << dendl;
./librbd/migration/ImageDispatch.cc:  ldout(cct, 10) << "ictx=" << image_ctx << dendl;
./librbd/migration/ImageDispatch.cc:  ldout(cct, 10) << dendl;
./librbd/migration/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/migration/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/migration/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/migration/HttpStream.cc:  ldout(m_cct, 10) << "url=" << m_url << dendl;
./librbd/migration/HttpStream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/HttpStream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/HttpStream.cc:  ldout(m_cct, 20) << "byte_extents=" << byte_extents << dendl;
./librbd/migration/FileStream.cc:    ldout(cct, 20) << dendl;
./librbd/migration/FileStream.cc:    ldout(cct, 20) << "byte_extent=" << byte_extent << dendl;
./librbd/migration/FileStream.cc:    ldout(cct, 20) << "r=" << r << dendl;
./librbd/migration/FileStream.cc:  ldout(m_cct, 10) << "file_path=" << file_path << dendl;
./librbd/migration/FileStream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/FileStream.cc:  ldout(m_cct, 10) << dendl;
./librbd/migration/FileStream.cc:      ldout(m_cct, 10) << "size=" << offset << dendl;
./librbd/migration/FileStream.cc:  ldout(m_cct, 20) << byte_extents << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "cluster_offset=" << cluster_offset << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "cluster_offset=" << cluster_offset << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "l2_table_offset=" << l2_table_offset << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "l2_table_offset=" << request.l2_table_offset << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << dendl;
./librbd/migration/QCOWFormat.cc:      ldout(cct, 20) << "image offset DNE in QCOW image" << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << dendl;
./librbd/migration/QCOWFormat.cc:    ldout(cct, 20) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 10) << "snap_id=" << snap_id << dendl;
./librbd/migration/QCOWFormat.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawFormat.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/migration/SourceSpecBuilder.cc:  ldout(cct, 10) << dendl;
./librbd/migration/SourceSpecBuilder.cc:  ldout(cct, 10) << dendl;
./librbd/migration/SourceSpecBuilder.cc:  ldout(cct, 10) << dendl;
./librbd/migration/SourceSpecBuilder.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/RawSnapshot.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/migration/RawSnapshot.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:  ldout(cct, 10) << "name=" << m_snap_info.name << dendl;
./librbd/migration/RawSnapshot.cc:  ldout(cct, 10) << dendl;
./librbd/migration/RawSnapshot.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/migration/RawSnapshot.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/migration/Utils.cc:  ldout(cct, 10) << "url=" << url << dendl;
./librbd/Operations.cc:        ldout(cct, 5) << "update notification on missing header" << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Operations.cc:    ldout(cct, 5) << operation << " timed out notifying lock owner" << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << __func__ << ": " << op << " " << ctx << dendl;
./librbd/Operations.cc:          ldout(m_image_ctx.cct, 20) << "start " << op << " " << ctx << dendl;
./librbd/Operations.cc:    ldout(cct, 20) << __func__ << ": " << op << " in flight" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << __func__ << ": " << op << " r=" << r << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "flatten" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "flatten finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "flatten" << dendl;
./librbd/Operations.cc:  ldout(cct, 10) << "rebuild_object_map" << dendl;
./librbd/Operations.cc:  ldout(cct, 10) << "rebuild object map finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/Operations.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/Operations.cc:  ldout(cct, 2) << "resize finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 5) << this << " " << __func__ << ": limit=" << limit << dendl;
./librbd/Operations.cc:  ldout(cct, 2) << "update_features finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "metadata_set finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 5) << this << " " << __func__ << ": key=" << key << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "metadata_remove finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 5) << this << " " << __func__ << ": key=" << key << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "migrate" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "migrate finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "migrate" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "sparsify" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "resparsify finished" << dendl;
./librbd/Operations.cc:  ldout(cct, 20) << "sparsify" << dendl;
./librbd/api/PoolMetadata.cc:      ldout(cct, 1) << "metadata " << key << " does not exist" << dendl;
./librbd/api/Pool.cc:    ldout(m_cct, 15) << dendl;
./librbd/api/Pool.cc:    ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/api/Pool.cc:    ldout(m_cct, 15) << dendl;
./librbd/api/Pool.cc:    ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/api/Pool.cc:      ldout(m_cct, 15) << "out-of-sync metadata" << dendl;
./librbd/api/Pool.cc:  ldout(cct, 10) << dendl;
./librbd/api/Pool.cc:  ldout(cct, 10) << dendl;
./librbd/api/DiffIterate.cc:      ldout(cct, 5) << "fast diff disabled" << dendl;
./librbd/api/DiffIterate.cc:      ldout(cct, 5) << "fast diff enabled" << dendl;
./librbd/api/DiffIterate.cc:        ldout(cct, 20) << "object " << object << dendl;
./librbd/api/DiffIterate.cc:              ldout(cct, 20) << " reporting parent overlap " << o << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 20) << "offset=" << offset << ", total=" << total << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 20) << "state_description=" << m_state_description << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/api/Migration.cc:    ldout(cct, 10) << "Source image is not found. Trying trash" << dendl;
./librbd/api/Migration.cc:    ldout(cct, 10) << "source image id from trash: " << src_image_id << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << "migration spec: " << migration_spec << dendl;
./librbd/api/Migration.cc:    ldout(cct, 10) << "the source image is opened" << dendl;
./librbd/api/Migration.cc:    ldout(cct, 10) << "the destination image is opened" << dendl;
./librbd/api/Migration.cc:      ldout(cct, 10) << "re-opening the destination image" << dendl;
./librbd/api/Migration.cc:  ldout(cct, 20) << "updated opts=" << opts << dendl;
./librbd/api/Migration.cc:  ldout(cct, 20) << "updated opts=" << opts << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << io_ctx.get_pool_name() << "/" << image_name << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << io_ctx.get_pool_name() << "/" << image_name << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << io_ctx.get_pool_name() << "/" << image_name << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << io_ctx.get_pool_name() << "/" << image_name << dendl;
./librbd/api/Migration.cc:  ldout(cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << "succeeded" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:          ldout(m_cct, 5) << "lost exclusive lock, retrying remote" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << "succeeded" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:      ldout(m_cct, 10) << "relinking children" << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "removing dst image snapshots" << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "removing group" << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "removing dst image" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << "succeeded" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << "succeeded" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "mirroring is not enabled for this image" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "mirroring is not enabled for image" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:        ldout(m_cct, 5) << "skipping snapshot " << snap.name << dendl;
./librbd/api/Migration.cc:    ldout(m_cct, 10) << "no need for parent re-attach" << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Migration.cc:  ldout(m_cct, 10) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 20) << "creating new peer-client-id config-key" << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "peer_client_id=" << *peer_client_id << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 5) << "caps mismatch for existing user" << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 5) << "insufficient permissions to create user" << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 5) << "mirroring not supported by OSD" << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "site_name=" << site_name << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "mon_host=" << mon_host << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "token=" << token_bl.to_str() << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "token=" << token_bl.to_str() << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 10) << "remote pool does not exist" << dendl;
./librbd/api/Mirror.cc:      ldout(cct, 5) << "duplicate UUID detected, retrying" << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "uuid=" << uuid << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "uuid=" << uuid << dendl;
./librbd/api/Mirror.cc:    ldout(cct, 5) << "mirror peer uuid " << uuid << " does not exist" << dendl;
./librbd/api/Mirror.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Removing snapshots" << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Rolling back snapshots" << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Requesting exclusive locks for images" << dendl;
./librbd/api/Group.cc:  ldout(cct, 2) << "adding group to directory..." << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "group_remove " << &io_ctx << " " << group_name << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "io_ctx=" << &io_ctx << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Found " << image_count << " images in group" << dendl;
./librbd/api/Group.cc:    ldout(cct, 20) << "Opening image with id " << image.spec.image_id << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Issued open request waiting for the completion" << dendl;
./librbd/api/Group.cc:    ldout(cct, 20) << "Sending quiesce notification" << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Requesting exclusive locks for images" << dendl;
./librbd/api/Group.cc:  ldout(cct, 20) << "Sending unquiesce notification" << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "image_ctx=" << ictx << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "list " << &io_ctx << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "io_ctx=" << &io_ctx << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "image_ctx=" << ictx << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "ictx=" << ictx << dendl;
./librbd/api/Image.cc:      ldout(cct, 1) << "pool " << it.second << " no longer exists" << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "name=" << image_name << dendl;
./librbd/api/Image.cc:  ldout(cct, 20) << "children flatten " << ictx->name << dendl;
./librbd/api/Namespace.cc:  ldout(cct, 5) << "name=" << name << dendl;
./librbd/api/Namespace.cc:  ldout(cct, 5) << "name=" << name << dendl;
./librbd/api/Namespace.cc:    ldout(cct, 5) << "image directory not empty" << dendl;
./librbd/api/Namespace.cc:    ldout(cct, 5) << "image trash not empty" << dendl;
./librbd/api/Namespace.cc:  ldout(cct, 5) << dendl;
./librbd/api/Namespace.cc:  ldout(cct, 5) << "name=" << name << dendl;
./librbd/api/Io.cc:  ldout(cct, 20) << "ictx=" << &image_ctx << dendl;
./librbd/api/Trash.cc:  ldout(ictx->cct, 10) << dendl;
./librbd/api/Trash.cc:    ldout(cct, 10) << "not pool mirroring mode" << dendl;
./librbd/api/Trash.cc:  ldout(cct, 10) << dendl;
./librbd/api/Trash.cc:  ldout(cct, 20) << "list_trash_image_specs " << &io_ctx << dendl;
./librbd/api/Trash.cc:  ldout(cct, 20) << &io_ctx << " name=" << image_name << dendl;
./librbd/api/Trash.cc:      ldout(cct, 10) << "cannot move v1 image to trash" << dendl;
./librbd/api/Trash.cc:  ldout(cct, 20) << __func__ << " " << &io_ctx << dendl;
./librbd/api/Trash.cc:  ldout(cct, 20) << __func__ << " " << &io_ctx << dendl;
./librbd/api/Trash.cc:  ldout(cct, 20) << &io_ctx << dendl;
./librbd/api/Trash.cc:      ldout(cct, 2) << "an image with the same name already exists" << dendl;
./librbd/api/Trash.cc:    ldout(cct, 2) << "adding id object" << dendl;
./librbd/api/Trash.cc:  ldout(cct, 2) << "adding rbd image to v2 directory..." << dendl;
./librbd/api/Trash.cc:  ldout(cct, 2) << "removing image from trash..." << dendl;
./librbd/api/Snapshot.cc:  ldout(ictx->cct, 20) << "snap_remove " << ictx << " " << snap_id << dendl;
./librbd/api/Snapshot.cc:    ldout(ictx->cct, 20) << "snap_get_name " << ictx << " " << snap_id << dendl;
./librbd/api/Snapshot.cc:    ldout(ictx->cct, 20) << "snap_get_id " << ictx << " " << snap_name << dendl;
./librbd/api/Snapshot.cc:  ldout(ictx->cct, 20) << "snap_list " << ictx << dendl;
./librbd/api/Snapshot.cc:  ldout(ictx->cct, 20) << "snap_exists " << ictx << " " << snap_name << dendl;
./librbd/api/Snapshot.cc:  ldout(ictx->cct, 20) << "snap_remove " << ictx << " " << snap_name << " flags: " << flags << dendl;
./librbd/watcher/RewatchRequest.cc:  ldout(cct, 10) << dendl;
./librbd/watcher/RewatchRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/watcher/RewatchRequest.cc:  ldout(cct, 10) << dendl;
./librbd/watcher/RewatchRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/watcher/RewatchRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/watcher/Notifier.cc:    ldout(m_cct, 20) << "pending=" << m_pending_aio_notifies << dendl;
./librbd/watcher/Notifier.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/watcher/Notifier.cc:  ldout(m_cct, 20) << "pending=" << m_pending_aio_notifies << dendl;
./librbd/PluginRegistry.cc:    ldout(cct, 5) << "attempting to load plugin: " << token << dendl;
./librbd/PluginRegistry.cc:  ldout(cct, 20) << dendl;
./librbd/PluginRegistry.cc:  ldout(cct, 20) << dendl;
./librbd/PluginRegistry.cc:  ldout(cct, 20) << dendl;
./librbd/image_watcher/NotifyLockOwner.cc:  ldout(cct, 20) << dendl;
./librbd/image_watcher/NotifyLockOwner.cc:  ldout(cct, 20) << ": r=" << r << dendl;
./librbd/image_watcher/NotifyLockOwner.cc:    ldout(cct, 1) << ": no lock owners detected" << dendl;
./librbd/ConfigWatcher.cc:  ldout(cct, 10) << dendl;
./librbd/ConfigWatcher.cc:  ldout(cct, 10) << dendl;
./librbd/ConfigWatcher.cc:  ldout(cct, 10) << "changed_keys=" << changed_keys << dendl;
./librbd/cache/ObjectCacherWriteback.cc:    ldout(m_cct, 20) << "aio_cb completing " << dendl;
./librbd/cache/ObjectCacherWriteback.cc:    ldout(m_cct, 20) << "aio_cb finished" << dendl;
./librbd/cache/ObjectCacherWriteback.cc:    ldout(m_cct, 20) << "C_OrderedWrite completing " << m_result << dendl;
./librbd/cache/ObjectCacherWriteback.cc:    ldout(m_cct, 20) << "C_OrderedWrite finished " << m_result << dendl;
./librbd/cache/ObjectCacherWriteback.cc:  ldout(m_ictx->cct, 20) << "write will wait for result " << result << dendl;
./librbd/cache/ObjectCacherWriteback.cc:  ldout(m_ictx->cct, 20) << "complete_writes() oid " << oid << dendl;
./librbd/cache/ImageWriteback.cc:  ldout(cct, 20) << "on_finish=" << on_finish << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:    ldout(cct, 5) << "non-parent image: skipping" << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 20) << "object_no=" << object_no << " " << *extents << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:    ldout(cct, 20) << "Parent cache connected to RO daemon." << dendl;
./librbd/cache/ParentCacheObjectDispatch.cc:  ldout(cct, 20) << "file path: " << file_path << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/cache/WriteLogImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 5) << "enabling caching..." << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 20) << "object_no=" << object_no << " " << *extents << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:    ldout(cct, 20) << "no extents to read" << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:      ldout(cct, 5) << "saw first user flush, enabling writeback" << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/ObjectCacherObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:      ldout(cct, 5) << "first user flush: enabling write-around" << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "dispatching: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 20) << "queueing: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 20) << "blocked by in-flight IO: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "blocked on overlap: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "dispatching: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "queueing: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:      ldout(cct, 20) << "queueing unblocked: tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 20) << "r=" << r << ", tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "dispatching unoptimized IO: tid=" << it.first << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "dispatching IO: tid=" << it.first << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "dispatching flush: tid=" << it.first << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:  ldout(cct, 20) << "r=" << r << ", tid=" << tid << dendl;
./librbd/cache/WriteAroundObjectDispatch.cc:    ldout(cct, 20) << "completing flush: tid=" << it.first << dendl;
./librbd/cache/pwl/SyncPoint.cc:  ldout(m_cct, 20) << "sync point " << sync_gen_num << dendl;
./librbd/cache/pwl/DiscardRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/DiscardRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/DiscardRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/DiscardRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/DiscardRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 99) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 99) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << " cell=" << cell << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << " cell=" << m_cell << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << " cell=" << m_cell << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 5) << "cell " << m_cell << " already released for " << this << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 15) << this << " completing user req" << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 20) << this << " user req already completed" << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 15) << this << " finishing" << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 20) << this << " already finished" << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 99) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 99) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << __func__ << " write_req=" << this << " cell=" << guard_ctx.cell << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 15) << "write_req=" << this << " cell=" << this->get_cell() << dendl;
./librbd/cache/pwl/Request.cc:    ldout(pwl.get_context(), 20) << "write_req=" << *this << " op_set=" << op_set.get() << dendl;
./librbd/cache/pwl/Request.cc:      ldout(pwl.get_context(), 20) << "operation=[" << *operation << "]" << dendl;
./librbd/cache/pwl/Request.cc:  ldout(cct, 15) << "write_req=" << this << " cell=" << this->get_cell() << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << " cell=" << guard_ctx.cell << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:   ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/Request.cc:  ldout(pwl.get_context(), 20) << this << dendl;
./librbd/cache/pwl/rwl/ReadRequest.cc:  ldout(m_cct, 20) << "(" << get_name() << "): r=" << r << dendl;
./librbd/cache/pwl/rwl/ReadRequest.cc:  ldout(m_cct, 20) << "(" << get_name() << "): r=" << r << " bl=" << *m_out_bl << dendl;
./librbd/cache/pwl/rwl/LogOperation.cc:  ldout(m_cct, 20) << bl << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:    ldout(m_image_ctx.cct, 20) << "operation=[" << *operation << "]" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:        ldout(m_image_ctx.cct, 20) << "skipping non-write op: " << *operation << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:    ldout(m_image_ctx.cct, 6) << "closing pmem pool" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:      ldout(m_image_ctx.cct, 5) << "Removing empty pool file: " << this->m_log_pool_name << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:    ldout(m_image_ctx.cct, 5) << "Not removing pool file: " << this->m_log_pool_name << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(cct, 20) << "Look for entries to retire" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:    ldout(cct, 20) << "Retiring " << retiring_entries.size() << " entries" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:            ldout(cct, 20) << "Retiring non-write: " << *entry << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:    ldout(cct, 20) << "Nothing to retire" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:        ldout(m_image_ctx.cct, 20) << "should flush " << ops_to_flush << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:      ldout(m_image_ctx.cct, 10) << "Retired " << retired << " times" << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:      ldout(m_image_ctx.cct, 20) << "skipping non-write op: " << *operation << dendl;
./librbd/cache/pwl/rwl/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ShutdownRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/ImageCacheState.cc:  ldout(m_image_ctx->cct, 20) << __func__ << " Remove state: " << dendl;
./librbd/cache/pwl/ImageCacheState.cc:  ldout(image_ctx->cct, 20) << "image_cache_state:" << cache_state_str << dendl;
./librbd/cache/pwl/ImageCacheState.cc:    ldout(image_ctx->cct, 20) << "Do not desire to use image cache." << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << dendl;
./librbd/cache/pwl/LogMap.cc:    ldout(m_cct, 20) << entry << dendl;
./librbd/cache/pwl/LogMap.cc:        ldout(m_cct, 20) << "map entry completely occluded by new log entry" << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << "*log_entry=" << *log_entry << dendl;
./librbd/cache/pwl/LogMap.cc:    ldout(m_cct, 20) << "log entry has zero map entries: " << erased.log_entry << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << "block_extent=" << block_extent << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << "block_extent=" << block_extent << dendl;
./librbd/cache/pwl/LogMap.cc:  ldout(m_cct, 20) << "count=" << std::distance(p.first, p.second) << dendl;
./librbd/cache/pwl/LogMap.cc:    ldout(m_cct, 20) << entry << dendl;
./librbd/cache/pwl/ssd/ReadRequest.cc:  ldout(m_cct, 20) << "(" << get_name() << "): r=" << r << dendl;
./librbd/cache/pwl/ssd/ReadRequest.cc:  ldout(m_cct, 20) << "(" << get_name() << "): r=" << r << " bl=" << *m_out_bl << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(m_image_ctx.cct, 5) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:      ldout(m_image_ctx.cct, 5) << "didn't hit RAM" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 5) << "block device is closed" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(cct,5) << "Decoded superblock" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(cct, 5) << "decoded ssd log entries" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(m_image_ctx.cct, 20) << "Finished root update " << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(m_image_ctx.cct, 20) << "operation=[" << *operation << "]" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(cct, 20) << "Look for entries to retire" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:            ldout(cct, 20) << "The log entry is " << *(*it) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(cct, 20) << "Nothing to retire" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(cct, 20) << "Appending " << ops.size() << " log entries." << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << "data_pos: " << data_pos << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(cct, 20) << "finished aio_write log entries" << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(m_image_ctx.cct, 15) << "Start to callback." << dendl;
./librbd/cache/pwl/ssd/WriteLog.cc:    ldout(m_image_ctx.cct, 15) << "Finish the update of pool root." << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/InitRequest.cc:  ldout(cct, 10) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 15) << "enter" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 15) << "exit" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 1) << bl.c_str() << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(m_image_ctx.cct, 5) << "Adding sync point " << kv.first << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(m_image_ctx.cct, 10) << "Loaded to sync point=[" << *sync_point_entry << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct,5) << "image name: " << m_image_ctx.name << " id: " << m_image_ctx.id << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct,5) << "pwl_size: " << m_cache_state->size << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct,5) << "pwl_path: " << m_cache_state->path << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 5) << "Removed the existing pool file." << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(cct, 5) << "Can't find the existed pool file " << m_log_pool_name << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(cct,1) << "write log is empty" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct,20) << "new sync point = [" << m_current_sync_point << "]" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct,5) << "image name: " << m_image_ctx.name << " id: " << m_image_ctx.id << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 6) << "shutdown complete" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 6) << "image cache cleaned" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(m_image_ctx.cct, 6) << "flushing" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 6) << "waiting for in flight operations" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 6) << "Done internal_flush in shutdown" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 6) << "internal_flush in shutdown" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 20) << "discard log entry" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 20) << "write or writesame log entry" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 20) << map_entry << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "aio_write" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "on_finish=" << on_finish << " flush_source=" << flush_source << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(cct, 05) << "never initialized" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 20) << "flush_req=" << flush_req << " cell=" << guard_ctx.cell << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:          ldout(m_image_ctx.cct, 5) << "now persisting on flush" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "aio_writesame" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:            ldout(m_image_ctx.cct, 5) << " cw_req=" << cw_req << " compare matched" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:            ldout(m_image_ctx.cct, 15) << " cw_req=" << cw_req << " compare failed" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:                ldout(m_image_ctx.cct, 15) << " cw_req=" << cw_req << " mismatch at " << bl_index << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "in-flight request cell: " << cell << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "released_cell=" << released_cell << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:          ldout(cct, 20) << "current barrier cell=" << detained_cell << " req=" << req << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 20) << "current barrier released cell=" << released_cell << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 20) << "submitting queued request to blockguard: " << req << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "exit" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 15) << "Another thread is appending" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 20) << __func__ << ": completing" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 20) << "dispatching" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(m_image_ctx.cct, 20) << "deferred IOs: " << m_deferred_ios.size() << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(m_image_ctx.cct, 6) << "deferred processing disabled" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << "Look for dirty entries" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 5) << "Flush during shutdown supressed" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 20) << "Nothing new to flush" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(cct, 20) << "Next dirty entry isn't flushable yet" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 20) << "no dirty entries" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 5) << "flush during shutdown suppressed" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 5) << "flush ops still in progress" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:      ldout(cct, 20) << "dirty entries remain" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(m_image_ctx.cct, 20) << "invalidate=" << invalidate << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:    ldout(m_image_ctx.cct, 05) << "never initialized" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:        ldout(m_image_ctx.cct, 20) << "cell=" << guard_ctx.cell << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:	    ldout(m_image_ctx.cct, 6) << "flush_dirty_entries finished" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:                ldout(m_image_ctx.cct, 6) << "Invalidating" << dendl;
./librbd/cache/pwl/AbstractWriteLog.cc:  ldout(cct, 20) << dendl;
./librbd/cache/pwl/LogOperation.cc:  ldout(m_cct, 20) << __func__ << " " << this << dendl;
./librbd/cache/pwl/LogOperation.cc:    ldout(m_cct, 20) << __func__ << " " << this << " on_append=" << on_append << dendl;
./librbd/cache/pwl/LogOperation.cc:  ldout(m_cct, 20) << __func__ << " " << this << dendl;
./librbd/cache/pwl/LogOperation.cc:                     ldout(this->m_cct,20) << __func__ << " " << this << " m_extent_ops_persist completed" << dendl;
./librbd/cache/pwl/LogOperation.cc:                     ldout(this->m_cct, 20) << __func__ << " " << this << " m_extent_ops_appending completed" << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 20) << "=" << lock_owner << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:    ldout(m_cct, 10) << "woke up waiting (re)acquire" << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << "woke up waiting (re)acquire" << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:    ldout(m_cct, 5) << "unable to acquire exclusive lock" << dendl;
./librbd/ManagedLock.cc:    ldout(m_cct, 5) << "successfully acquired exclusive lock" << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:      ldout(m_cct, 10) << "updating lock is not supported" << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ManagedLock.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/ImageWatcher.cc:  ldout(cct, 10) << this << " unregistering image watcher" << dendl;
./librbd/ImageWatcher.cc:  ldout(cct, 10) << this << " "  << __func__ << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << ": " << __func__ << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " notify acquired lock" << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " notify released lock" << dendl;
./librbd/ImageWatcher.cc:    ldout(m_image_ctx.cct, 15) << this << " requesting exclusive lock" << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " notify request lock" << dendl;
./librbd/ImageWatcher.cc:    ldout(m_image_ctx.cct, 5) << this << " peer will not release lock" << dendl;
./librbd/ImageWatcher.cc:    ldout(m_image_ctx.cct, 5) << "async request timed out: " << id << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " image header updated" << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " exclusive lock released" << dendl;
./librbd/ImageWatcher.cc:  ldout(m_image_ctx.cct, 10) << this << " exclusive lock requested" << dendl;
./librbd/ImageWatcher.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/ImageWatcher.cc:  ldout(cct, 10) << this << " C_ResponseMessage: r=" << r << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/CreateRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/CreateRequest.cc:    ldout(m_cct, 20) << "done." << dendl;
./librbd/journal/OpenRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/OpenRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/OpenRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/OpenRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/OpenRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/journal/ResetRequest.cc:    ldout(m_cct, 5) << "journal does not exist" << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/journal/ResetRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/journal/ResetRequest.cc:   ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/journal/ObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/journal/ObjectDispatch.cc:  ldout(cct, 20) << "journal_tid=" << journal_tid << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << this << " " << __func__ << dendl;
./librbd/journal/RemoveRequest.cc:  ldout(m_cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/journal/RemoveRequest.cc:    ldout(m_cct, 20) << "done." << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 20) << ": ExecuteOp::" << __func__ << dendl;
./librbd/journal/Replay.cc:      ldout(cct, 5) << ": lost exclusive lock -- skipping op" << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 5) << ": lost exclusive lock -- skipping event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": op_tid=" << op_tid << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": AIO discard event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": AIO write event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": AIO flush event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": AIO writesame event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": AIO CompareAndWrite event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap create event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap remove event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap rename event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap protect event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap unprotect event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap rollback start event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Rename event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Resize start event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Flatten start event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Demote/Promote event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Snap limit event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Update features event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Metadata set event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": Metadata remove event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": unknown event" << dendl;
./librbd/journal/Replay.cc:  ldout(cct, 20) << ": r=" << r << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 10) << ": resuming paused AIO" << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 20) << ": completing safe context: " << ctx << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 20) << ": completing flush context: " << on_flush << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 5) << ": ignoring event after shut down" << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 5) << ": ignoring event after shut down" << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 5) << ": ignoring event after shut down" << dendl;
./librbd/journal/Replay.cc:    ldout(cct, 5) << ": no-op IO event beyond image size" << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 5) << this << ": ictx=" << &m_image_ctx << dendl;
./librbd/Journal.cc:  ldout(cct, 5) << __func__ << ": image=" << image_id << dendl;
./librbd/Journal.cc:  ldout(cct, 5) << __func__ << ": image=" << image_id << dendl;
./librbd/Journal.cc:  ldout(cct, 5) << __func__ << ": image=" << image_id << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:      ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 10) << this << " " << __func__ << ": op_tid=" << op_tid << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << ": new state=" << state << dendl;
./librbd/Journal.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << this << " " << __func__ << ": primary image" << dendl;
./librbd/Journal.cc:    ldout(cct, 20) << this << " " << __func__ << ": no listeners" << dendl;
./librbd/MirroringWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/MirroringWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/MirroringWatcher.cc:  ldout(cct, 20) << ": mode updated: " << payload.mirror_mode << dendl;
./librbd/MirroringWatcher.cc:  ldout(cct, 20) << ": image state updated" << dendl;
./librbd/ObjectMap.cc:  ldout(cct, 20) << dendl;
./librbd/ObjectMap.cc:  ldout(cct, 20) << "in-flight update cell: " << cell << dendl;
./librbd/ObjectMap.cc:  ldout(cct, 20) << "cell=" << cell << ", r=" << r << dendl;
./librbd/ObjectMap.cc:      ldout(cct, 20) << "skipping update of invalid object map" << dendl;
./librbd/ObjectMap.cc:      ldout(cct, 20) << "object map update not required" << dendl;
./librbd/plugin/WriteLogImageCache.cc:  ldout(cct, 5) << dendl;
./librbd/plugin/ParentCache.cc:  ldout(cct, 5) << dendl;
./librbd/plugin/ParentCache.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:    ldout(cct, 1) << "shrinking the image is not permitted" << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:    ldout(cct, 5) << "resize operation interrupted" << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/ResizeRequest.cc:  ldout(cct, 5) << "r=" << *result << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:      ldout(m_cct, 1) << "lost exclusive lock during sparsify" << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SparsifyRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SparsifyRequest.cc:    ldout(cct, 5) << "sparsify operation interrupted" << dendl;
./librbd/operation/RenameRequest.cc:      ldout(cct, 1) << "image already exists" << dendl;
./librbd/operation/RenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/RenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/RenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/RenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/RenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotProtectRequest.cc:      ldout(cct, 1) << "snapshot is already protected" << dendl;
./librbd/operation/SnapshotProtectRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/Request.cc:    ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/operation/Request.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRenameRequest.cc:      ldout(cct, 1) << "snapshot already exists" << dendl;
./librbd/operation/SnapshotRenameRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/MigrateRequest.cc:      ldout(cct, 1) << "lost exclusive lock during migrate" << dendl;
./librbd/operation/MigrateRequest.cc:    ldout(cct, 10) << dendl;
./librbd/operation/MigrateRequest.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/operation/MigrateRequest.cc:    ldout(cct, 10) << "r=" << r << dendl;
./librbd/operation/MigrateRequest.cc:  ldout(cct, 10) << dendl;
./librbd/operation/MigrateRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/operation/MigrateRequest.cc:  ldout(cct, 10) << "from 0 to " << overlap_objects << dendl;
./librbd/operation/MigrateRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/MigrateRequest.cc:  ldout(cct, 10) << dendl;
./librbd/operation/MetadataSetRequest.cc:  ldout(cct, 20) << this << " " << __func__ << " r=" << r << dendl;
./librbd/operation/MetadataSetRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << " r=" << r << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/EnableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:      ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:    ldout(cct, 5) << "snapshot rollback operation interrupted" << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/MetadataRemoveRequest.cc:  ldout(cct, 20) << this << " " << __func__ << " r=" << r << dendl;
./librbd/operation/MetadataRemoveRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotLimitRequest.cc:  ldout(cct, 5) << this << " " << __func__ << " r=" << r << dendl;
./librbd/operation/SnapshotLimitRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << " r=" << r << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:      ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/operation/DisableFeaturesRequest.cc:  ldout(cct, 20) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(cct, 5) << this << " should_complete: " << " r=" << r << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "RESIZE_OBJECT_MAP" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "TRIM_IMAGE" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "VERIFY_OBJECTS" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "SAVE_OBJECT_MAP" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "UPDATE_HEADER" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:    ldout(cct, 5) << "rebuild object map operation interrupted" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(cct, 5) << this << " send_resize_object_map" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(cct, 5) << this << " send_trim_image" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(cct, 5) << this << " send_verify_objects" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(cct, 5) << this << " send_save_object_map" << dendl;
./librbd/operation/RebuildObjectMapRequest.cc:  ldout(m_image_ctx.cct, 5) << this << " send_update_header" << dendl;
./librbd/operation/FlattenRequest.cc:      ldout(cct, 1) << "lost exclusive lock during flatten" << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/FlattenRequest.cc:    ldout(cct, 5) << "flatten operation interrupted" << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/FlattenRequest.cc:    ldout(cct, 5) << "image already flattened" << dendl;
./librbd/operation/FlattenRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:    ldout(cct, 10) << this << " retrieved children: r=" << r << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:      ldout(cct, 1) << "snapshot is already unprotected" << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/SnapshotUnprotectRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/operation/ObjectMapIterate.cc:  ldout(cct, 5) << this << " should_complete: " << " r=" << r << dendl;
./librbd/operation/ObjectMapIterate.cc:  ldout(cct, 5) << this << " send_verify_objects" << dendl;
./librbd/operation/ObjectMapIterate.cc:  ldout(cct, 5) << this << " send_invalidate_object_map" << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:        ldout(cct, 1) << "No such snapshot" << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:      ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/operation/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/operation/TrimRequest.cc:    ldout(image_ctx.cct, 10) << "removing (with copyup) " << oid << dendl;
./librbd/operation/TrimRequest.cc:    ldout(image_ctx.cct, 10) << "removing " << oid << dendl;
./librbd/operation/TrimRequest.cc:  ldout(cct, 5) << this << " should_complete: r=" << r << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << "trim operation interrupted" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << " PRE_TRIM" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << " COPYUP_OBJECTS" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << " REMOVE_OBJECTS" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << " POST_TRIM" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << "CLEAN_BOUNDARY" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 5) << "FINISHED" << dendl;
./librbd/operation/TrimRequest.cc:    ldout(cct, 20) << " ex " << *p << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreReleaseRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/exclusive_lock/ImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/exclusive_lock/ImageDispatch.cc:    ldout(cct, 5) << "exclusive lock required: delaying IO" << dendl;
./librbd/exclusive_lock/ImageDispatch.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/exclusive_lock/ImageDispatch.cc:    ldout(cct, 5) << "IO raced with exclusive lock shutdown" << dendl;
./librbd/exclusive_lock/PreAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PreAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PreAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:    ldout(cct, 5) << "exclusive lock dynamically disabled" << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/exclusive_lock/PostAcquireRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:      ldout(m_cct, 10) << "lock owner is still alive" << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:    ldout(m_cct, 5) << "no lock owner" << dendl;
./librbd/managed_lock/BreakRequest.cc:    ldout(m_cct, 5) << "no longer lock owner" << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/BreakRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/GetLockerRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/GetLockerRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/GetLockerRequest.cc:    ldout(m_cct, 20) << "no lockers detected" << dendl;
./librbd/managed_lock/GetLockerRequest.cc:    ldout(m_cct, 5) <<"locked by external mechanism: tag=" << lock_tag << dendl;
./librbd/managed_lock/GetLockerRequest.cc:    ldout(m_cct, 5) << "incompatible shared lock type detected" << dendl;
./librbd/managed_lock/GetLockerRequest.cc:    ldout(m_cct, 5) << "incompatible exclusive lock type detected" << dendl;
./librbd/managed_lock/GetLockerRequest.cc:    ldout(m_cct, 20) << "no valid lockers detected" << dendl;
./librbd/managed_lock/GetLockerRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/ReleaseRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/ReacquireRequest.cc:  ldout(cct, 10) << dendl;
./librbd/managed_lock/ReacquireRequest.cc:  ldout(cct, 10) << ": r=" << r << dendl;
./librbd/managed_lock/ReacquireRequest.cc:    ldout(cct, 10) << ": OSD doesn't support updating lock" << dendl;
./librbd/managed_lock/AcquireRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/AcquireRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/AcquireRequest.cc:    ldout(m_cct, 20) << "no lockers detected" << dendl;
./librbd/managed_lock/AcquireRequest.cc:    ldout(m_cct, 5) << "incompatible lock detected" << dendl;
./librbd/managed_lock/AcquireRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/AcquireRequest.cc:    ldout(m_cct, 5) << "already locked, refreshing locker" << dendl;
./librbd/managed_lock/AcquireRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/managed_lock/AcquireRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/managed_lock/AcquireRequest.cc:    ldout(m_cct, 5) << "lock owner is still alive" << dendl;
./librbd/io/QosImageDispatch.cc:  ldout(cct, 5) << "ictx=" << image_ctx << dendl;
./librbd/io/QosImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QosImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/FlushTracker.cc:  ldout(cct, 20) << dendl;
./librbd/io/FlushTracker.cc:  ldout(cct, 20) << "tid=" << tid << ", flush_tid=" << flush_tid << dendl;
./librbd/io/FlushTracker.cc:  ldout(cct, 20) << "tid=" << tid << ", flush_tid=" << flush_tid << dendl;
./librbd/io/FlushTracker.cc:    ldout(cct, 20) << "completing flushes: " << flush_ctxs << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << "image_extents=" << image_extents << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/io/ImageDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(m_ictx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(m_ictx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "snap_id=" << read_snap_id << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:    ldout(image_ctx->cct, 20) << "version=" << *m_version << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:      ldout(image_ctx->cct, 20) << "guarding write" << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:      ldout(image_ctx->cct, 10) << "migration parent gone, restart io" << dendl;
./librbd/io/ObjectRequest.cc:    ldout(image_ctx->cct, 10) << "failed to write object" << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(image_ctx->cct, 20) << dendl;
./librbd/io/ObjectRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/ObjectRequest.cc:  ldout(cct, 20) << "object_interval=" << object_interval << dendl;
./librbd/io/ObjectRequest.cc:      ldout(cct, 1) << "need to read full object" << dendl;
./librbd/io/ObjectRequest.cc:        ldout(cct, 20) << "clearing truncate diff: " << trunc_interval << dendl;
./librbd/io/ObjectRequest.cc:      ldout(cct, 20) << "object exists at snap id " << end_snap_id << dendl;
./librbd/io/ObjectRequest.cc:      ldout(cct, 20) << "skipping prior snapshot " << dendl;
./librbd/io/ObjectRequest.cc:  ldout(cct, 20) << "snapshot_delta=" << snapshot_delta << dendl;
./librbd/io/ObjectRequest.cc:  ldout(cct, 20) << "snapshot_delta=" << *m_snapshot_delta << dendl;
./librbd/io/AsyncOperation.cc:      ldout(image_ctx->cct, 20) << "completed flush: " << flush_ctx << dendl;
./librbd/io/AsyncOperation.cc:  ldout(m_image_ctx->cct, 20) << this << " " << __func__ << dendl;
./librbd/io/AsyncOperation.cc:  ldout(m_image_ctx->cct, 20) << this << " " << __func__ << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 5) << "ictx=" << image_ctx << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/QueueImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/ImageDispatcher.cc:  ldout(cct, 5) << dendl;
./librbd/io/ObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/io/ObjectDispatch.cc:  ldout(cct, 20) << "object_no=" << object_no << " " << *extents << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 5) << "ictx=" << image_ctx << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 5) << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 20) << intersects << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "latency stats not collected yet" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "no pending requests" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 20) << "delayed: " << delayed << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:  ldout(cct, 20) << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:        ldout(m_image_ctx->cct, 20) << "already dispatched" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "object_no=" << object_no << ": not found" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "canceling task " << m_timer_task << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "nothing to schedule" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:    ldout(cct, 20) << "garbage collecting " << object_requests << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:      ldout(cct, 20) << "nothing to schedule" << dendl;
./librbd/io/SimpleSchedulerObjectDispatch.cc:      ldout(cct, 20) << "running timer task " << m_timer_task << dendl;
./librbd/io/ReadResult.cc:    ldout(cct, 20) << "dropping read result" << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 5) << "ictx=" << image_ctx << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 20) << "r=" << r << ", tid=" << tid << dendl;
./librbd/io/WriteBlockImageDispatch.cc:    ldout(cct, 10) << "flushing all in-flight IO for blocked writes" << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 10) << dendl;
./librbd/io/WriteBlockImageDispatch.cc:  ldout(cct, 10) << dendl;
./librbd/io/ImageRequest.cc:    ldout(cct, 20) << "snapshot_delta=" << *snapshot_delta << dendl;
./librbd/io/ImageRequest.cc:  ldout(m_image_ctx.cct, 10) << get_request_type() << dendl;
./librbd/io/RefreshImageDispatch.cc:  ldout(cct, 5) << "ictx=" << image_ctx << dendl;
./librbd/io/RefreshImageDispatch.cc:  ldout(cct, 20) << "tid=" << tid << dendl;
./librbd/io/RefreshImageDispatch.cc:    ldout(cct, 15) << "on_dispatched=" << on_dispatched << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 5) << "parent detached" << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "no-op, skipping" << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << "flatten=" << m_flatten << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 10) << "restart deep-copy with flatten" << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "skipping" << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "skipping copyup" << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << dendl;
./librbd/io/CopyupRequest.cc:      ldout(cct, 20) << "add_copyup_ops " << req << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "copyup with empty snapshot context" << dendl;
./librbd/io/CopyupRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "completing request " << req << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "restarting request " << req << dendl;
./librbd/io/CopyupRequest.cc:  ldout(m_image_ctx->cct, 15) << "deep_copied=" << deep_copied << dendl;
./librbd/io/CopyupRequest.cc:    ldout(cct, 20) << "processing full copy-up" << dendl;
./librbd/io/ObjectDispatcher.cc:  ldout(cct, 5) << dendl;
./librbd/io/ObjectDispatcher.cc:  ldout(cct, 5) << dendl;
./librbd/io/ObjectDispatcher.cc:  ldout(cct, 20) << "object_no=" << object_no << dendl;
./librbd/io/Utils.cc:  ldout(cct, 20) << dendl;
./librbd/io/AioCompletion.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/io/AioCompletion.cc:  ldout(cct, 20) << dendl;
./librbd/io/AioCompletion.cc:  ldout(cct, 20) << dendl;
./librbd/io/AioCompletion.cc:  ldout(cct, 20) << "pending=" << count << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 20) << "=" << accept << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 20) << "r=" << r << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 20) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << ": features=" << features << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:    ldout(m_image_ctx.cct, 10) << ": peer nacked lock request" << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << ": r=" << r << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << ": r=" << r << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/ExclusiveLock.cc:  ldout(m_image_ctx.cct, 10) << dendl;
./librbd/mirror/snapshot/RemoveImageStateRequest.cc:  ldout(cct, 15) << oid << dendl;
./librbd/mirror/snapshot/RemoveImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/RemoveImageStateRequest.cc:  ldout(cct, 15) << oid << dendl;
./librbd/mirror/snapshot/RemoveImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/RemoveImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "name=" << m_image_state.name << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "snap_limit=" << m_image_state.snap_limit << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/SetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:      ldout(cct, 15) << "located newer mirror snapshot" << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:    ldout(cct, 15) << "missing snapshot: snap_id=" << m_snap_id << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:    ldout(cct, 15) << "failed to locate snapshot " << m_snap_id << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/UnlinkPeerRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/DemoteRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/snapshot/DemoteRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/mirror/snapshot/DemoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/DemoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/DemoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "ns=" << ns << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreateNonPrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "scheduler_ticks=" << m_scheduler_ticks << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:      ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:      ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/PromoteRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/WriteImageStateRequest.cc:  ldout(cct, 15) << oid << dendl;
./librbd/mirror/snapshot/WriteImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/WriteImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:    ldout(cct, 15) << "snap_id=" << *m_snap_id << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "peer=" << peer_uuid << ", snap_id=" << snap_id << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/CreatePrimaryRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/ImageMeta.cc:  ldout(m_image_ctx->cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/ImageMeta.cc:  ldout(m_image_ctx->cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/ImageMeta.cc:  ldout(m_image_ctx->cct, 15) << dendl;
./librbd/mirror/snapshot/ImageMeta.cc:  ldout(m_image_ctx->cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/GetImageStateRequest.cc:  ldout(cct, 15) << oid << dendl;
./librbd/mirror/snapshot/GetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/GetImageStateRequest.cc:  ldout(cct, 15) << "r=" << r << dendl;
./librbd/mirror/snapshot/Utils.cc:        ldout(cct, 20) << "needs rollback" << dendl;
./librbd/mirror/snapshot/Utils.cc:        ldout(cct, 20) << "rollback_snap_id=" << *rollback_snap_id << dendl;
./librbd/mirror/snapshot/Utils.cc:  ldout(cct, 20) << "no previous mirror snapshots found" << dendl;
./librbd/mirror/snapshot/Utils.cc:  ldout(cct, 20) << "no previous mirror snapshots found" << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/DemoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:      ldout(cct, 20) << "mirroring is not enabled for this image" << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 10) << "r=" << *result << dendl;
./librbd/mirror/DisableRequest.cc:  ldout(cct, 20) << "removed image state from rbd_mirroring object" << dendl;
./librbd/mirror/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/PromoteRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/PromoteRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:    ldout(m_cct, 20) << "mirroring is disabled" << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/ImageStateUpdateRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetInfoRequest.cc:    ldout(m_cct, 20) << "mirroring is disabled" << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetInfoRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetStatusRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/GetStatusRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetStatusRequest.cc:  ldout(cct, 20) << dendl;
./librbd/mirror/GetStatusRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetStatusRequest.cc:  ldout(cct, 20) << "r=" << r << dendl;
./librbd/mirror/ImageRemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/ImageRemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/ImageRemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/ImageRemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/ImageRemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/GetUuidRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/mirror/GetUuidRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/GetUuidRequest.cc:      ldout(m_cct, 5) << "mirror uuid missing" << dendl;
./librbd/mirror/GetUuidRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:      ldout(m_cct, 10) << "mirroring is already enabled" << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10)  << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/mirror/EnableRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/object_map/CreateRequest.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/object_map/CreateRequest.cc:  ldout(cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/object_map/Request.cc:  ldout(cct, 20) << this << " should_complete: r=" << r << dendl;
./librbd/object_map/Request.cc:    ldout(cct, 20) << "INVALIDATE" << dendl;
./librbd/object_map/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/SnapshotCreateRequest.cc:  ldout(cct, 5) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/UnlockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/UnlockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 10) << "snap_id=" << m_current_snap_id << dendl;
./librbd/object_map/DiffRequest.cc:    ldout(cct, 10) << "fast-diff feature not enabled" << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/object_map/DiffRequest.cc:    ldout(cct, 10) << "object map " << oid << " does not exist" << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 20) << "loaded object map " << oid << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 20) << "computed overlap diffs" << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 20) << "computed resize diffs" << dendl;
./librbd/object_map/DiffRequest.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/object_map/SnapshotRollbackRequest.cc:  ldout(cct, 5) << this << " " << __func__ << dendl;
./librbd/object_map/RemoveRequest.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/object_map/RemoveRequest.cc:  ldout(cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/object_map/UpdateRequest.cc:  ldout(m_image_ctx.cct, 20) << "r=" << r << dendl;
./librbd/object_map/UpdateRequest.cc:    ldout(m_image_ctx.cct, 20) << dendl;
./librbd/object_map/LockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/LockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/LockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/LockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/LockRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/object_map/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *ret_val << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "snap_oid=" << snap_oid << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "oid=" << oid << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "oid=" << oid << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/object_map/SnapshotRemoveRequest.cc:    ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/DetachChildRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:    ldout(m_cct, 5) << "image id already in-use" << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CreateRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:    ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": plugins=" << plugins << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:    ldout(cct, 5) << "user does not have write permission" << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/OpenRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:      ldout(cct, 5) << "image has snapshots - not removing" << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/PreRemoveRequest.cc:    ldout(cct, 5) << "skipping attached child" << dendl;
./librbd/image/PreRemoveRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/SetSnapRequest.cc:  ldout(cct, 10) << __func__ << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CloneRequest.cc:    ldout(m_cct, 1) << "clone v2 required for cross-namespace clones" << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:    ldout(m_cct, 5) << "image id already in-use" << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/CloneRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << " r=" << *result << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << " r=" << *result << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << " r=" << *result << dendl;
./librbd/image/RefreshParentRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/SetFlagsRequest.cc:  ldout(cct, 20) << __func__ << dendl;
./librbd/image/SetFlagsRequest.cc:  ldout(cct, 20) << __func__ << ": r=" << *result << dendl;
./librbd/image/DetachParentRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachParentRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/DetachParentRequest.cc:    ldout(cct, 10) << "retrying using legacy parent method" << dendl;
./librbd/image/DetachParentRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/AttachParentRequest.cc:  ldout(cct, 5) << "parent_image_spec=" << m_parent_image_spec << dendl;
./librbd/image/AttachParentRequest.cc:  ldout(cct, 5) << dendl;
./librbd/image/AttachParentRequest.cc:      ldout(cct, 10) << "retrying using legacy parent method" << dendl;
./librbd/image/AttachParentRequest.cc:  ldout(cct, 5) << "r=" << r << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << "object_watchers=" << m_object_watchers << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << "mirror_watchers=" << m_mirror_watchers << dendl;
./librbd/image/ListWatchersRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/ListWatchersRequest.cc:            ldout(m_cct, 20) << "filtering out my instance: " << w << dendl;
./librbd/image/ListWatchersRequest.cc:            ldout(m_cct, 20) << "filtering out mirror instance: " << w << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:    ldout(m_cct, 5) << "image has snapshots - not removing" << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/RemoveRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/CloseRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/ValidatePoolRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/image/GetMetadataRequest.cc:  ldout(m_cct, 15) << "start_key=" << m_last_key << dendl;
./librbd/image/GetMetadataRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/GetMetadataRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": " << "r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": " << "r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 5) << "ignoring dynamically disabled exclusive lock" << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 5) << "adding non-primary read-only image flag" << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 5) << "removing non-primary read-only image flag" << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << "retrying using legacy parent method" << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 1) << "migrating feature set" << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": " << "r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << "out-of-sync snapshot state detected" << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << "retrying using legacy snapshot methods" << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << "retrying using legacy snapshot methods (jewel)" << dendl;
./librbd/image/RefreshRequest.cc:      ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:    ldout(cct, 10) << this << " " << __func__ << ": r=" << *result << dendl;
./librbd/image/RefreshRequest.cc:  ldout(cct, 20) << this << " " << __func__ << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:      ldout(m_cct, 5) << "child already exists" << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:      ldout(m_cct, 5) << "child already exists" << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 15) << "r=" << r << dendl;
./librbd/image/AttachChildRequest.cc:  ldout(m_cct, 5) << "r=" << r << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/MoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/RemoveRequest.cc:    ldout(m_cct, 5) << "failed to close image:" << cpp_strerror(r) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/RemoveRequest.cc:    ldout(m_cct, 5) << "failed to remove image:" << cpp_strerror(r) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/trash/RemoveRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/AsioEngine.cc:  ldout(m_cct, 20) << dendl;
./librbd/AsioEngine.cc:  ldout(m_cct, 20) << dendl;
./librbd/ImageCtx.cc:    ldout(cct, 10) << this << " " << __func__ << dendl;
./librbd/ImageCtx.cc:          ldout(cct, 10) << "canceling async request: " << req << dendl;
./librbd/ImageCtx.cc:    ldout(cct, 20) << __func__ << dendl;
./librbd/ImageCtx.cc:        ldout(cct, 0) << __func__ << ": ignoring config " << key << dendl;
./librbd/ImageCtx.cc:          ldout(cct, 20) << __func__ << ": " << key << "=" << val << dendl;
./librbd/ImageCtx.cc:      ldout(cct, 5) << this << ": disabling zero-copy writes" << dendl;
./librbd/asio/ContextWQ.cc:  ldout(m_cct, 20) << dendl;
./librbd/asio/ContextWQ.cc:  ldout(m_cct, 20) << dendl;
./librbd/asio/ContextWQ.cc:  ldout(m_cct, 20) << dendl;
./librbd/Watcher.cc:  ldout(cct, 10) << "id=" << notify_id << ", " << "handle=" << handle << dendl;
./librbd/Watcher.cc:  ldout(cct, 10) << "r=" << r << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 5) << "blocked=" << blocked << dendl;
./librbd/Watcher.cc:    ldout(m_cct, 5) << "blocked_count=" << m_blocked_count << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 5) << "blocked_count=" << m_blocked_count << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/Watcher.cc:      ldout(m_cct, 10) << "image is closing, skip rewatch" << dendl;
./librbd/Watcher.cc:      ldout(m_cct, 5) << "object does not exist" << dendl;
./librbd/Watcher.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/TrashWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/TrashWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/TrashWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/TrashWatcher.cc:  ldout(cct, 20) << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 20) << dst_object << " -> " << *src_objects << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 10) << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 10) << "r=" << r << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:    ldout(m_cct, 10) << "fast-diff optimization disabled" << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:    ldout(m_cct, 10) << "image copy canceled" << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:      ldout(m_cct, 20) << "skipping non-existent object " << ono << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 20) << "object_num=" << ono << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 20) << "object_no=" << object_no << ", r=" << r << dendl;
./librbd/deep_copy/ImageCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << "snap_name=" << m_snap_name << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCreateRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:      ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 10) << "snapshot copy canceled" << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SnapshotCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "image_extents=" << m_image_extents << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "snapshot_delta=" << m_snapshot_delta << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:      ldout(m_cct, 20) << "object DNE: src_snap_seq=" << src_snap_seq << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:    ldout(m_cct, 20) << "assert_snapc_seq=" << dst_snap_seq << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:            ldout(m_cct, 20) << "create+truncate op" << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:            ldout(m_cct, 20) << "remove op" << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:          ldout(m_cct, 20) << "trunc op: " << sbe.get_off() << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:    ldout(m_cct, 10) << "concurrent deep copy" << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:      ldout(m_cct, 20) << "parent overlap=" << src_parent_overlap << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:      ldout(m_cct, 5) << "object DNE for snap_id: " << dst_snap_seq << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:        ldout(m_cct, 20) << "no parent overlap" << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:          ldout(m_cct, 20) << "no parent overlap" << dendl;
./librbd/deep_copy/ObjectCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/MetadataCopyRequest.cc:  ldout(m_cct, 20) << "start_key=" << m_last_metadata_key << dendl;
./librbd/deep_copy/MetadataCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/MetadataCopyRequest.cc:  ldout(m_cct, 20) << "count=" << m_metadata.size() << dendl;
./librbd/deep_copy/MetadataCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/MetadataCopyRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./librbd/deep_copy/SetHeadRequest.cc:  ldout(m_cct, 20) << "r=" << r << dendl;
./client/Inode.cc:    lsubdout(client->cct, client, 15) << "open_dir " << dir << " on " << this << dendl;
./client/Inode.cc:      lsubdout(client->cct, client, 10) << __func__ << ": open" << dendl;
./client/Inode.cc:  lsubdout(client->cct, client, 10) << __func__ << " " << *this << dendl;
./client/barrier.cc:  cldout(cl, 1) << "C_Block_Sync for " << ino << dendl;
./client/Trace.cc:    //generic_dout(0) << "** unable to open trace file " << filename << dendl;
./client/Trace.cc:  //generic_dout(2) << "opened traced file '" << filename << "'" << dendl;
./client/SyntheticClient.cc:  dout(15) << "initing" << dendl;
./client/SyntheticClient.cc:    dout(0) << "failed to initialize: " << cpp_strerror(err) << dendl;
./client/SyntheticClient.cc:  dout(15) << "mounting" << dendl;
./client/SyntheticClient.cc:    dout(0) << "failed to mount: " << cpp_strerror(err) << dendl;
./client/SyntheticClient.cc:  dout(5) << "run" << dendl;
./client/SyntheticClient.cc:    dout(3) << "mode " << mode << dendl;
./client/SyntheticClient.cc:          dout(2) << "only " << run_only << dendl;
./client/SyntheticClient.cc:          dout(2) << "onlyrange [" << first << ", " << last << ") includes me" << dendl;
./client/SyntheticClient.cc:          dout(2) << "not running " << exclude << dendl;
./client/SyntheticClient.cc:	    dout(2) << "until " << iarg1 << dendl;
./client/SyntheticClient.cc:	    dout(2) << "until " << iarg1 << " (no limit)" << dendl;
./client/SyntheticClient.cc:          dout(2) << "sleep " << iarg1 << dendl;
./client/SyntheticClient.cc:          dout(2) << "sleepuntil " << iarg1 << dendl;
./client/SyntheticClient.cc:          dout(2) << "randomwalk " << iarg1 << dendl;
./client/SyntheticClient.cc:	  dout(2) << "placement dump " << sarg1 << dendl;
./client/SyntheticClient.cc:          dout(2) << "makedirmess " << sarg1 << " " << iarg1 << dendl;
./client/SyntheticClient.cc:          dout(2) << "makedirs " << sarg1 << " " << iarg1 << " " << iarg2 << " " << iarg3 << dendl;
./client/SyntheticClient.cc:          dout(2) << "statdirs " << sarg1 << " " << iarg1 << " " << iarg2 << " " << iarg3 << dendl;
./client/SyntheticClient.cc:          dout(2) << "readdirs " << sarg1 << " " << iarg1 << " " << iarg2 << " " << iarg3 << dendl;
./client/SyntheticClient.cc:          dout(2) << "thrashlinks " << sarg1 << " " << iarg1 << " " << iarg2 << " " << iarg3 << dendl;
./client/SyntheticClient.cc:          dout(2) << "makefiles " << num << " " << count << " " << priv << dendl;
./client/SyntheticClient.cc:          dout(2) << "makefiles2 " << num << " " << count << " " << priv << dendl;
./client/SyntheticClient.cc:          dout(2) << "createshared " << num << dendl;
./client/SyntheticClient.cc:          dout(2) << "openshared " << num << dendl;
./client/SyntheticClient.cc:          dout(2) << "fullwalk" << sarg1 << dendl;
./client/SyntheticClient.cc:          dout(2) << "repeatwalk " << sarg1 << dendl;
./client/SyntheticClient.cc:        dout(1) << "WRITING SYN CLIENT" << dendl;
./client/SyntheticClient.cc:	dout(1) << "OVERLOADING OSD 0" << dendl;
./client/SyntheticClient.cc:        dout(1) << "READING SYN CLIENT" << dendl;
./client/SyntheticClient.cc:        dout(1) << "RANDOM READ WRITE SYN CLIENT" << dendl;
./client/SyntheticClient.cc:        dout(1) << "RANDOM READ WRITE SYN CLIENT" << dendl;
./client/SyntheticClient.cc:          dout(0) << "trace " << tfile << " prefix=" << prefix << " count=" << iarg1 << " data=" << playdata << dendl;
./client/SyntheticClient.cc:            dout(0) << " trace " << tfile << " loop " << (i+1) << "/" << iarg1 << " done in " << (double)lat << " seconds" << dendl;
./client/SyntheticClient.cc:	  dout(1) << "done " << dendl;
./client/SyntheticClient.cc:  dout(1) << "syn done, unmounting " << dendl;
./client/SyntheticClient.cc:  dout(DBL) << "cd .. -> " << cwd << dendl;
./client/SyntheticClient.cc:  dout(4) << "play trace prefix '" << prefix << "'" << dendl;
./client/SyntheticClient.cc:      dout(5) << "'root' ino is " << inodeno_t(stx.stx_ino) << dendl;
./client/SyntheticClient.cc:      dout(0) << "warning: play_trace couldn't lookup up my per-client directory" << dendl;
./client/SyntheticClient.cc:	dout(1) << "play_trace at line " << t.get_line() << dendl;
./client/SyntheticClient.cc:    dout(4) << (t.get_line()-1) << ": trace op " << op << dendl;
./client/SyntheticClient.cc:        dout(1) << "getdir on " << a << " returns " << r << dendl;
./client/SyntheticClient.cc:      dout(0) << (t.get_line()-1) << ": *** trace hit unrecognized symbol '" << op << "' " << dendl;
./client/SyntheticClient.cc:  dout(10) << "trace finished on line " << t.get_line() << dendl;
./client/SyntheticClient.cc:    dout(1) << "leftover close " << fi->second << dendl;
./client/SyntheticClient.cc:    dout(1) << "leftover closedir " << fi->second << dendl;
./client/SyntheticClient.cc:    dout(1) << "leftover ll_release " << fi->second << dendl;
./client/SyntheticClient.cc:    dout(1) << "leftover ll_releasedir " << fi->second << dendl;
./client/SyntheticClient.cc:    dout(1) << "getdir on " << basedir << " returns " << r << dendl;
./client/SyntheticClient.cc:      dout(1) << "stat error on " << file << " r=" << r << dendl;
./client/SyntheticClient.cc:      dout(1) << "getdir on " << dir << " returns " << r << dendl;
./client/SyntheticClient.cc:	dout(1) << "stat error on " << file << " r=" << r << dendl;
./client/SyntheticClient.cc:      dout(0) << dir << ": expected " << expect << dendl;
./client/SyntheticClient.cc:      dout(0) << dir << ":      got " << actual << dendl;
./client/SyntheticClient.cc:      dout(0) << p->first << " nlink " << p->second << " != " << nlink_seen[p->first] << "seen" << dendl;
./client/SyntheticClient.cc:  dout(5) << "reading from " << fn << " fd " << fd << dendl;
./client/SyntheticClient.cc:    dout(0) << "lstat error for file " << fn << dendl;
./client/SyntheticClient.cc:  dout(0) << "file size is " << filesize << dendl;
./client/SyntheticClient.cc:  dout(0) << "(osd, start, length) tuples for file " << fn << dendl;
./client/SyntheticClient.cc:    dout(1) << "can't make base dir? " << basedir << dendl;
./client/SyntheticClient.cc:  dout(3) << "make_dirs " << basedir << " dirs " << dirs << " files " << files << " depth " << depth << dendl;
./client/SyntheticClient.cc:    dout(1) << "can't make base dir? " << basedir << dendl;
./client/SyntheticClient.cc:  dout(3) << "stat_dirs " << basedir << " dirs " << dirs << " files " << files << " depth " << depth << dendl;
./client/SyntheticClient.cc:  dout(3) << "read_dirs " << basedir << " dirs " << dirs << " files " << files << " depth " << depth << dendl;
./client/SyntheticClient.cc:    dout(0) << "getdir couldn't readdir " << basedir << ", stopping" << dendl;
./client/SyntheticClient.cc:      dout(2) << "read_dirs failed stat on " << d << ", stopping" << dendl;
./client/SyntheticClient.cc:  dout(0) << "makefiles time is " << end << " or " << ((double)end / (double)num) <<" per file" << dendl;
./client/SyntheticClient.cc:  dout(0) << "orig " << end << dendl;
./client/SyntheticClient.cc:  dout(0) << "copy " << end << dendl;
./client/SyntheticClient.cc:    dout(0) << "in OSD overload" << dendl;
./client/SyntheticClient.cc:    dout(1) << "OSD Overload workload: trying file " << filename << dendl;
./client/SyntheticClient.cc:  dout(5) << "writing to " << fn << " fd " << fd << dendl;
./client/SyntheticClient.cc:      dout(0) << "stopping" << dendl;
./client/SyntheticClient.cc:    dout(2) << "writing block " << i << "/" << chunks << dendl;
./client/SyntheticClient.cc:      dout(0) << "write " << (bytes / el / 1048576.0) << " MB/sec" << dendl;
./client/SyntheticClient.cc:  //dout(5) << "SyntheticClient::write_fd: writing to fd " << fd << dendl;
./client/SyntheticClient.cc:      dout(0) << "stopping" << dendl;
./client/SyntheticClient.cc:    dout(2) << "writing block " << i << "/" << chunks << dendl;
./client/SyntheticClient.cc:    dout(0) << "Write file " << sarg1 << dendl;
./client/SyntheticClient.cc:  dout(5) << "reading from " << fn << " fd " << fd << dendl;
./client/SyntheticClient.cc:    dout(2) << "reading block " << i << "/" << chunks << dendl;
./client/SyntheticClient.cc:      dout(1) << "read_file got r = " << r << ", probably end of file" << dendl;
./client/SyntheticClient.cc:      dout(0) << "read " << (bytes / el / 1048576.0) << " MB/sec" << dendl;
./client/SyntheticClient.cc:      dout(0) << " + " << (bad-1) << " other bad 16-byte bits in this block" << dendl;
./client/SyntheticClient.cc:      dout(6) << "create_objects " << i << "/" << (nobj+1) << dendl;
./client/SyntheticClient.cc:    dout(10) << "writing " << oid << dendl;
./client/SyntheticClient.cc:	  dout(20) << "waiting for " << unsafe << " unsafe" << dendl;
./client/SyntheticClient.cc:	dout(10) << "waiting for " << unsafe << " unsafe" << dendl;
./client/SyntheticClient.cc:  dout(5) << "create_objects done" << dendl;
./client/SyntheticClient.cc:      dout(10) << "write to " << oid << dendl;
./client/SyntheticClient.cc:      dout(10) << "read from " << oid << dendl;
./client/SyntheticClient.cc:	  dout(20) << "waiting for " << unack << " unack" << dendl;
./client/SyntheticClient.cc:  dout(5) << "reading from " << fn << " fd " << fd << dendl;
./client/SyntheticClient.cc:        dout(2) << "reading block " << offset << "/" << chunks << dendl;
./client/SyntheticClient.cc:	  dout(1) << "read_file got r = " << r << ", probably end of file" << dendl;
./client/SyntheticClient.cc:      dout(2) << "writing block " << offset << "/" << chunks << dendl;
./client/SyntheticClient.cc:	dout(0) << " + " << (bad-1) << " other bad 16-byte bits in this block" << dendl;
./client/SyntheticClient.cc:  dout(5) << "reading from " << fn << " fd " << fd << dendl;
./client/SyntheticClient.cc:      dout(2) << "reading block " << offset << "/" << chunks << dendl;
./client/SyntheticClient.cc:	dout(1) << "read_file got r = " << r << ", probably end of file" << dendl;
./client/SyntheticClient.cc:        dout(2) << "writing block " << offset << "/" << chunks << dendl;
./client/SyntheticClient.cc:	dout(0) << " + " << (bad-1) << " other bad 16-byte bits in this block" << dendl;
./client/SyntheticClient.cc:  //dout(1) << "random_walk() will do " << left << " ops" << dendl;
./client/SyntheticClient.cc:      dout(DBL) << "die says up" << dendl;
./client/SyntheticClient.cc:      dout(DBL) << "cd " << s << " -> " << cwd << dendl;
./client/SyntheticClient.cc:        dout(DBL) << "empty dir, up" << dendl;
./client/SyntheticClient.cc:    //dout(DBL) << "op is " << op << dendl;
./client/SyntheticClient.cc:            dout(DBL) << "stat in empty dir, up" << dendl;
./client/SyntheticClient.cc:        //dout(DBL) << " got " << *it << dendl;
./client/SyntheticClient.cc:      //dout(DBL) << "r = " << r << ", client doesn't have " << cwd << ", cd .." << dendl;
./client/SyntheticClient.cc:      dout(DBL) << "r = " << r << ", client may not have " << cwd << ", cd .." << dendl;
./client/SyntheticClient.cc:  dout(DBL) << "closing files" << dendl;
./client/SyntheticClient.cc:  dout(DBL) << "done" << dendl;
./client/SyntheticClient.cc:    dout(0) << "first" << dendl;
./client/SyntheticClient.cc:    dout(0) << "sleep" << dendl;
./client/SyntheticClient.cc:    dout(0) << "again" << dendl;
./client/SyntheticClient.cc:  dout(1) << "import_find " << base << " from " << find << " data=" << data << dendl;
./client/SyntheticClient.cc:    //dout(0) << "leading dir " << filename << " " << dirnum << dendl;
./client/SyntheticClient.cc:      dout(20) << "skipping leading dir " << dirnum << " " << filename << dendl;
./client/SyntheticClient.cc:    dout(20) << " mode " << modestring << " to " << oct << mode << dec << dendl;
./client/SyntheticClient.cc:      dout(10) << "symlink from '" << link << "' -> '" << target << "'" << dendl;
./client/SyntheticClient.cc:  dout(0) << "lookup_hash(" << ino << ", #" << dirino << "/" << name << ") = " << r << dendl;
./client/SyntheticClient.cc:  dout(0) << "lookup_ino(" << ino << ") = " << r << dendl;
./client/SyntheticClient.cc:  dout(0) << "file " << filename << " size is " << size << dendl;
./client/SyntheticClient.cc:    dout(0) << "got " << bl.length() << " bytes at " << pos << dendl;
./client/SyntheticClient.cc:      dout(0) << " including bit from previous block" << dendl;
./client/Client.cc:  ldout(cct, 10) << "inode_num " << inode_num << "inode_num & 0x3ff=" << (inode_num & 0x3ff)<< dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << ino << " -> " << vino << dendl;
./client/Client.cc:    ldout(cct, 1) << __func__ << " forcing close of fh " << fd << " ino " << fh->inode->ino << dendl;
./client/Client.cc:    ldout(cct, 1) << __func__ << " forcing close of dir " << dirp << " ino " << dirp->inode->ino << dendl;
./client/Client.cc:    ldout(cct, 1) << "  dir " << in->dir << " size " << in->dir->dentries.size() << dendl;
./client/Client.cc:      ldout(cct, 1) << "   " << in->ino << " dn " << it->first << " " << it->second << " ref " << it->second->ref << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << dendl;
./client/Client.cc:    ldout(cct, 10) << "shutdown stopping cache invalidator finisher" << dendl;
./client/Client.cc:    ldout(cct, 10) << "shutdown stopping dentry invalidator finisher" << dendl;
./client/Client.cc:    ldout(cct, 10) << "shutdown stopping interrupt finisher" << dendl;
./client/Client.cc:    ldout(cct, 10) << "shutdown stopping remount finisher" << dendl;
./client/Client.cc:    ldout(cct, 10) << "shutdown stopping inode release finisher" << dendl;
./client/Client.cc:  ldout(cct, 20) << "trim_cache size " << lru.lru_get_size() << " max " << max << dendl;
./client/Client.cc:    ldout(cct, 15) << "trim_cache trimmed root " << root << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " mds." << mds << dendl;
./client/Client.cc:    ldout(cct, 10) << "size " << in->size << " -> " << size << dendl;
./client/Client.cc:      ldout(cct, 0) << "Hmmm, truncate_seq && truncate_size changed on non-file inode!" << dendl;
./client/Client.cc:    ldout(cct, 30) << "Yay have enough caps to look at our times" << dendl;
./client/Client.cc:    ldout(cct, 30) << "Don't have enough caps, just taking mds' time values" << dendl;
./client/Client.cc:    ldout(cct, 12) << __func__ << " had " << *in << " caps " << ccap_string(st->cap.caps) << dendl;
./client/Client.cc:      ldout(cct, 20) << " dir hash is " << (int)in->dir_layout.dl_dir_hash << dendl;
./client/Client.cc:    ldout(cct, 12) << __func__ << " adding " << *in << " caps " << ccap_string(st->cap.caps) << dendl;
./client/Client.cc:      ldout(cct, 10) << " marking (I_COMPLETE|I_DIR_ORDERED) on empty dir " << *in << dendl;
./client/Client.cc:  ldout(cct, 15) << __func__ << " " << *dn << " " << *dlease << " from " << from << dendl;
./client/Client.cc:  ldout(cct, 20) << "got dirfrag map for " << in->ino << " frag " << dst->frag << " to mds " << dst->auth << dendl;
./client/Client.cc:      ldout(cct, 10) << " clearing (I_COMPLETE|I_DIR_ORDERED) on " << *diri << dendl;
./client/Client.cc:	ldout(cct, 10) << " clearing I_DIR_ORDERED on " << *diri << dendl;
./client/Client.cc:      ldout(cct, 10) << "insert_trace got new frag " << fg << " -> " << dst.frag << dendl;
./client/Client.cc:      ldout(cct, 15) << "" << i << ": '" << dname << "'" << dendl;
./client/Client.cc:      ldout(cct, 15) << __func__ << "  " << hex << dn->offset << dec << ": '" << dname << "' -> " << in->ino << dendl;
./client/Client.cc:    ldout(cct, 10) << "insert_trace -- already got unsafe; ignoring" << dendl;
./client/Client.cc:    ldout(cct, 10) << "insert_trace -- no trace" << dendl;
./client/Client.cc:	ldout(cct, 10) << " unlinking rename src dn " << od << " for traceless reply" << dendl;
./client/Client.cc:	ldout(cct, 10) << " unlinking unlink/rmdir dn " << d << " for traceless reply" << dendl;
./client/Client.cc:  ldout(cct, 10) << " features 0x" << hex << features << dec << dendl;
./client/Client.cc:    ldout(cct, 10) << " faking snap lookup weirdness" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " resend_mds specified as mds." << mds << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " starting with req->inode " << *in << dendl;
./client/Client.cc:      ldout(cct, 20) << __func__ << " starting with req->dentry inode " << *in << dendl;
./client/Client.cc:      ldout(cct, 10) << __func__ << " " << *in << " is snapped, using nonsnap parent" << dendl;
./client/Client.cc:          ldout(cct, 10) << "got unlinked inode, can't look at parent" << dendl;
./client/Client.cc:	ldout(cct, 10) << __func__ << " from dirfragtree hash" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " from caps on inode " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << "did not get mds through better means, so chose random mds " << mds << dendl;
./client/Client.cc:  ldout(cct, 20) << "mds is " << mds << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " for mds." << mds << dendl;
./client/Client.cc:     ldout(cct, 10) << "delegated_inos: " << ocres.delegated_inos << dendl;
./client/Client.cc:    ldout(cct, 10) << "make_request created ino " << created_ino << dendl;
./client/Client.cc:    ldout(cct, 20) << "make_request target is " << *ptarget->get() << dendl;
./client/Client.cc:      ldout(cct, 20) << "make_request created, target is " << *ptarget->get() << dendl;
./client/Client.cc:	  ldout(cct, 5) << "create got ino " << created_ino << " but then failed on lookup; EINTR?" << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " injecting fixed oldest_client_tid(1)" << dendl;
./client/Client.cc:	  ldout(cct, 10) << " target mds." << mds << " has stopped, remove it from fragmap" << dendl;
./client/Client.cc:	  ldout(cct, 10) << " target mds." << mds << " has stopped, trying a random mds" << dendl;
./client/Client.cc:	ldout(cct, 10) << " target mds." << mds << " not active, waiting for new mdsmap" << dendl;
./client/Client.cc:	ldout(cct, 10) << "waiting for session to mds." << mds << " to open" << dendl;
./client/Client.cc:    ldout(cct, 20) << "awaiting reply|forward|kick on " << &caller_cond << dendl;
./client/Client.cc:  ldout(cct, 20) << "sendrecv kickback on tid " << tid << " " << request->dispatch_cond << dendl;
./client/Client.cc:  ldout(cct, 20) << "lat " << lat << dendl;
./client/Client.cc:      ldout(cct, 25) << "dropping caps " << ccap_string(drop) << dendl;
./client/Client.cc:	ldout(cct, 25) << "reset requested_max_size due to not wanting any file write cap" << dendl;
./client/Client.cc:    ldout(cct, 25) << "preemptively releasing dn to mds" << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " read hostname '" << u.nodename << "'" << dendl;
./client/Client.cc:    ldout(cct, 1) << __func__ << " failed to read hostname (" << cpp_strerror(r) << ")" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " mds." << mds << dendl;
./client/Client.cc:  ldout(cct, 2) << __func__ << " mds." << s->mds_num << " seq " << s->seq << dendl;
./client/Client.cc:  ldout(cct, 5) << __func__ << " mds." << s->mds_num << " seq " << s->seq << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *m << " from mds." << from << dendl;
./client/Client.cc:    ldout(cct, 10) << " discarding session message from sessionless mds " << m->get_source_inst() << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " set sent_stamp to " << request->sent_stamp << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *r << " to mds." << mds << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " no pending request on tid " << tid << dendl;
./client/Client.cc:      ldout(cct, 20) << "have to return ESTALE" << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " signalling caller " << (void*)request->caller_cond << dendl;
./client/Client.cc:    ldout(cct, 10) << "inactive, discarding " << *m << dendl;
./client/Client.cc:      ldout(cct, 10) << "unmounting: trim pass, cache shrank, poking unmount()" << dendl;
./client/Client.cc:      ldout(cct, 1) << __func__ << ": cancelling command op " << tid << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << " epoch " << m->get_epoch() << dendl;
./client/Client.cc:	ldout(cct, 1) << "we may miss the MDSMap::RECONNECT, close mds session ... " << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " to mds." << mds << dendl;
./client/Client.cc:      ldout(cct, 10) << "    path " << path << dendl;
./client/Client.cc:	ldout(cct, 10) << " snaprealm " << *in->snaprealm << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " for mds." << session->mds_num << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " for mds." << session->mds_num << dendl;
./client/Client.cc:  ldout(cct, 10) << " mds." << s->mds_num << " seq now " << s->seq << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *m << dendl;
./client/Client.cc:    ldout(cct, 10) << " don't have vino " << vino << dendl;
./client/Client.cc:      ldout(cct, 10) << " don't have dir|dentry " << m->get_ino() << "/" << m->dname <<dendl;
./client/Client.cc:    ldout(cct, 10) << " revoked DN lease on " << dn << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " on " << *in << " n = " << n << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " deleting " << *in << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " on " << *in << " n = " << n << dendl;
./client/Client.cc:  ldout(cct, 15) << __func__ << " dir " << dir << " on " << in << dendl;
./client/Client.cc:    ldout(cct, 20) << "link  inode " << in << " parents now " << in->dentries << dendl;
./client/Client.cc:    ldout(cct, 20) << "unlink  inode " << in << " parents now " << in->dentries << dendl;
./client/Client.cc:    ldout(cct, 15) << "unlink  removing '" << dn->name << "' dn " << dn << dendl;
./client/Client.cc:    ldout(cct, 5) << __func__ << " got first FILE_BUFFER ref on " << *in << dendl;
./client/Client.cc:    ldout(cct, 5) << __func__ << " got first FILE_CACHE ref on " << *in << dendl;
./client/Client.cc:	ldout(cct, 10) << __func__ << " finishing pending cap_snap on " << *in << dendl;
./client/Client.cc:	ldout(cct, 5) << __func__ << " dropped last FILE_BUFFER ref on " << *in << dendl;
./client/Client.cc:      ldout(cct, 5) << __func__ << " dropped last FILE_CACHE ref on " << *in << dendl;
./client/Client.cc:	   ldout(cct, 10) << "wanted_max_size " << in->wanted_max_size << " -> " << endoff << dendl;
./client/Client.cc:	ldout(cct, 10) << "waiting on max_size, endoff " << endoff << " max_size " << in->max_size << " on " << *in << dendl;
./client/Client.cc:	  ldout(cct, 10) << "waiting on cap_snap write to complete" << dendl;
./client/Client.cc:	  ldout(cct, 10) << "waiting for WRBUFFER to get dropped" << dendl;
./client/Client.cc:      ldout(cct, 10) << "waiting for caps " << *in << " need " << ccap_string(need) << " want " << ccap_string(want) << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " on " << *in << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " injecting failure to release caps" << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " issued " << ccap_string(cap->issued) << " vs " << ccap_string(would_have_issued) << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " implemented " << ccap_string(cap->implemented) << " vs " << ccap_string(would_have_implemented) << dendl;
./client/Client.cc:      ldout(cct, 15) << "auth cap, requesting max_size " << in->requested_max_size << dendl;
./client/Client.cc:      ldout(cct, 15) << "auth cap, reset requested_max_size due to not wanting any file write cap" << dendl;
./client/Client.cc:      ldout(cct, 10) << "completed revocation of " << ccap_string(cap.implemented & ~cap.issued) << dendl;
./client/Client.cc:      ldout(cct, 10) << "delaying cap release" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << " snapc " << old_snapc << " used " << ccap_string(used) << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " already have pending cap_snap on " << *in << dendl;
./client/Client.cc:      ldout(cct, 10) << __func__ << " WR used on " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " not dirty|writing on " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << " capsnap " << (void *)&capsnap << " used " << ccap_string(used) << dendl;
./client/Client.cc:  ldout(cct, 10) << "flush_snaps on " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << ino << " " << off << "~" << len << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << " " << off << "~" << len << dendl;
./client/Client.cc:  ldout(cct, 20) << "_release " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << "_flush " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << " nothing to flush" << dendl;
./client/Client.cc:    ldout(cct, 8) << __func__ << ": FULL, purging for ENOSPC" << dendl;
./client/Client.cc:    ldout(cct, 10) << " nothing to flush" << dendl;
./client/Client.cc:  ldout(cct, 10) << "_flushed " << *in << dendl;
./client/Client.cc:    ldout(cct, 15) << __func__ << " first one, opened snaprealm " << in->snaprealm << dendl;
./client/Client.cc:         ldout(cct, 0) << "WARNING: " <<  "inode " << *in << " caps on mds." << mds << " != auth_cap." << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " mds." << mds << " on " << in << dendl;
./client/Client.cc:      ldout(cct, 10) << " removing myself from flushing_cap list" << dendl;
./client/Client.cc:    ldout(cct, 15) << __func__ << " last one, closing snaprealm " << in.snaprealm << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " mds." << s->mds_num << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << ino << dendl;
./client/Client.cc:	ldout(cct, 20) << " removing unused, unneeded non-auth cap on " << *in << dendl;
./client/Client.cc:      ldout(cct, 20) << " trying to trim dentries for " << *in << dendl;
./client/Client.cc:          ldout(cct, 20) << " queueing dentry for trimming: " << dn->name << dendl;
./client/Client.cc:          ldout(cct, 20) << "  not expirable: " << dn->name << dendl;
./client/Client.cc:        ldout(cct, 20) << __func__ << " counting as trimmed: " << *in << dendl;
./client/Client.cc:  ldout(cct, 20) << " trimming queued dentries: " << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " " << ccap_string(flushing) << " " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " (more) " << ccap_string(flushing) << " " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " mds." << mds << dendl;
./client/Client.cc:      ldout(cct, 20) << " reflushing caps on " << *in << " to mds." << mds << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " " << *realm << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << r << " " << realm << " " << realm->nref << " -> " << (realm->nref + 1) << dendl;
./client/Client.cc:    ldout(cct, 20) << __func__ << " " << r << " fail" << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << r << " " << realm << " " << realm->nref << " -> " << (realm->nref + 1) << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " len " << bl.length() << dendl;
./client/Client.cc:      ldout(cct, 15) << __func__ << " " << *realm << " self|parent updated" << dendl;
./client/Client.cc:      ldout(cct, 15) << "  snapc " << realm->get_snap_context() << dendl;
./client/Client.cc:      ldout(cct, 10) << " flushing caps on " << *realm << dendl;
./client/Client.cc:      ldout(cct, 10) << " no new snap on " << *realm << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *m << dendl;
./client/Client.cc:    ldout(cct, 10) << " splitting off " << *realm << dendl;
./client/Client.cc:	ldout(cct, 10) << " moving " << *in << " from " << *in->snaprealm << dendl;
./client/Client.cc:      ldout(cct, 10) << "adjusting snaprealm " << child_realm << " parent" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *m << " from mds." << mds << dendl;
./client/Client.cc:      ldout(cct, 5) << __func__ << " don't have vino " << vino << " on IMPORT, immediately releasing" << dendl;
./client/Client.cc:      ldout(cct, 5) << __func__ << " don't have vino " << vino << ", dropping" << dendl;
./client/Client.cc:    ldout(cct, 5) << __func__ << " don't have " << *in << " cap on mds." << mds << dendl;
./client/Client.cc:      ldout(cct, 15) << "reset requested_max_size after cap import" << dendl;
./client/Client.cc:    ldout(cct, 10) << " tid " << m->get_client_tid() << " != any cap bit tids" << dendl;
./client/Client.cc:	ldout(cct, 10) << " " << *in << " !flushing" << dendl;
./client/Client.cc:      ldout(cct, 10) << " tid " << flush_ack_tid << " != " << capsnap.flush_tid << dendl;
./client/Client.cc:  ldout(cct, 5) << __func__ << " in " << *in <<dendl;
./client/Client.cc:    ldout(cct, 10) << "max_size " << in->max_size << " -> " << m->get_max_size() << dendl;
./client/Client.cc:    ldout(cct, 10) << "  revocation of " << ccap_string(revoked) << dendl;
./client/Client.cc:    ldout(cct, 10) << "  caps unchanged at " << ccap_string(cap->issued) << dendl;
./client/Client.cc:    ldout(cct, 10) << "  grant, new caps are " << ccap_string(new_caps & ~cap->issued) << dendl;
./client/Client.cc:  ldout(cct, 5) << __func__ << " " << in << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *in << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << in << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *in << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << in << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *dir << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << dir << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *dir << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << dir << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *dir << "; " << "; name " << name << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << dir << " = " << r <<  dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << relpath << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *in << "; " << perms << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << in << " = " << r <<  dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << ": resolving `*' to all MDS daemons" << dendl;
./client/Client.cc:      ldout(cct, 10) << __func__ << ": appending " << info.human_name() << " to targets" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " learned FSMap version " << fsmap_latest << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << ": tid=" << m->get_tid() << dendl;
./client/Client.cc:    ldout(cct, 1) << __func__ << ": unknown tid " << tid << ", dropping" << dendl;
./client/Client.cc:  ldout(cct, 10) << "Subscribing to map '" << want << "'" << dendl;
./client/Client.cc:        ldout(cct, 10) << "mds cluster unavailable: epoch=" << mdsmap->get_epoch() << dendl;
./client/Client.cc:	ldout(cct, 1) << __func__ << " EACCES on parent of mount point; quotas may not work" << dendl;
./client/Client.cc:      ldout(cct, 1) << "opened trace file '" << cct->_conf->client_trace << "'" << dendl;
./client/Client.cc:      ldout(cct, 1) << "FAILED to open trace file '" << cct->_conf->client_trace << "'" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: // client trace data structs" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: struct stat st;" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: struct utimbuf utim;" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: int readlinkbuf_len = 1000;" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: char readlinkbuf[readlinkbuf_len];" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: map<string, inode_t*> dir_contents;" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: map<int, int> open_files;" << dendl;
./client/Client.cc:  ldout(cct, 3) << "op: int fd;" << dendl;
./client/Client.cc:      ldout(cct, 1) << mds_ranks_closing.size() << " mds(s) did not respond to session close -- timing out." << dendl;
./client/Client.cc:    ldout(cct, 2) << "unmounting (" << (abort ? "abort)" : "blocklisted)") << dendl;
./client/Client.cc:    ldout(cct, 2) << "unmounting" << dendl;
./client/Client.cc:    ldout(cct, 0) << " destroyed lost open file " << fh << " on " << *fh->inode << dendl;
./client/Client.cc:    ldout(cct, 0) << " destroyed lost open file " << fh << " on " << *(fh->inode) << dendl;
./client/Client.cc:    ldout(cct, 0) << " destroyed lost open dir " << dirp << " on " << *dirp->inode << dendl;
./client/Client.cc:	ldout(cct, 0) << "null inode_map entry ino " << p.first << dendl;
./client/Client.cc:	ldout(cct, 0) << " drop dirty caps on " << *in << dendl;
./client/Client.cc:    ldout(cct, 1) << "closing trace file '" << cct->_conf->client_trace << "'" << dendl;
./client/Client.cc:  ldout(cct, 2) << "unmounted." << dendl;
./client/Client.cc:        ldout(cct, 20) << __func__ << " injecting failure to send cap release message" << dendl;
./client/Client.cc:  ldout(cct, 20) << "tick" << dendl;
./client/Client.cc:      ldout(cct, 20) << "upkeep thread waiting interval " << interval << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << dendl;
./client/Client.cc:    ldout(cct, 5) << __func__ << ": rank=0 does not support metrics" << dendl;
./client/Client.cc:  ldout(cct, 10) << "renew_caps()" << dendl;
./client/Client.cc:    ldout(cct, 15) << "renew_caps requesting from mds." << p.first << dendl;
./client/Client.cc:  ldout(cct, 10) << "renew_caps mds." << session->mds_num << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " on " << path << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " res is " << r << dendl;
./client/Client.cc:	ldout(cct, 8) << __func__ << " found target " << (*target)->ino << dendl;
./client/Client.cc:      ldout(cct, 20) << " no cap on " << dn->inode->vino() << dendl;
./client/Client.cc:      ldout(cct, 10) << __func__ << " concluded ENOENT locally for " << *dir << " dn '" << dname << "'" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " " << *dir << " " << dname << " = " << r << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " " << *dir << " " << dname << " = " << **target << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *dir << " name " << name << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << ": " << path << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << path << dendl;
./client/Client.cc:    ldout(cct, 10) << " " << i << " " << *cur << " " << dname << dendl;
./client/Client.cc:    ldout(cct, 20) << "  (path is " << path << ")" << dendl;
./client/Client.cc:      ldout(cct, 20) << " symlink count " << symlinks << ", value is '" << next->symlink << "'" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << ": " << relpath << dendl;
./client/Client.cc:  ldout(cct, 10) << "Client::mkdirs " << relpath << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " got through " << i << " directories on path " << relpath << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " mask " << ccap_string(mask) << " issued=" << yes << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " result=" << res << dendl;
./client/Client.cc:      ldout(cct,10) << "changing uid to " << stx->stx_uid << dendl;
./client/Client.cc:      ldout(cct,10) << "changing gid to " << stx->stx_gid << dendl;
./client/Client.cc:      ldout(cct,10) << "changing mode to " << stx->stx_mode << dendl;
./client/Client.cc:      ldout(cct,10) << "changing btime to " << in->btime << dendl;
./client/Client.cc:    ldout(cct,10) << "changing mode to " << stx->stx_mode << dendl;
./client/Client.cc:    ldout(cct,10) << "changing uid to " << stx->stx_uid << dendl;
./client/Client.cc:    ldout(cct,10) << "changing gid to " << stx->stx_gid << dendl;
./client/Client.cc:      ldout(cct,10) << "changing size to " << stx->stx_size << dendl;
./client/Client.cc:      ldout(cct,10) << "unable to set size to " << stx->stx_size << ". Too large!" << dendl;
./client/Client.cc:  ldout(cct, 10) << "_setattr result=" << res << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " enter (relpath " << relpath << " mask " << mask << ")" << dendl;
./client/Client.cc:    ldout(cct, 3) << __func__ << " exit on error!" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " exit (relpath " << relpath << " mask " << mask << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " enter (relpath " << relpath << " want " << want << ")" << dendl;
./client/Client.cc:    ldout(cct, 3) << __func__ << " exit on error!" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " exit (relpath " << relpath << " mask " << stx->stx_mask << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " enter (relpath " << relpath << " mask " << mask << ")" << dendl;
./client/Client.cc:    ldout(cct, 3) << __func__ << " exit on error!" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " exit (relpath " << relpath << " mask " << mask << ")" << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << "(" << in->ino << ") = " << 0 << " (" << *dirpp << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << dir << ") = 0" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << "(" << dirp << ")" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " detaching inode " << dirp->inode << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << dirp << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << dirp << ") = " << d->offset << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << dirp << ", " << offset << ")" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " advance from " << fg << " to END" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " advance from " << dirp->buffer_frag << " to " << fg << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " frag " << cur << " maps to " << fg << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << dirp << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " got EAGAIN, retrying" << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " got error " << res << ", setting end flag" << dendl;
./client/Client.cc:    ldout(cct, 10) << " dir is empty" << dendl;
./client/Client.cc:      ldout(cct, 15) << " skipping null '" << dn->name << "'" << dendl;
./client/Client.cc:      ldout(cct, 15) << " skipping mismatch shared gen '" << dn->name << "'" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << dirp << " on " << dirp->inode->ino << " at end" << dendl;
./client/Client.cc:    ldout(cct, 15) << " including ." << dendl;
./client/Client.cc:    ldout(cct, 15) << " including .." << dendl;
./client/Client.cc:      ldout(cct, 10) << " fetching next chunk of this frag" << dendl;
./client/Client.cc:	ldout(cct, 10) << " marking (I_COMPLETE|I_DIR_ORDERED) on " << *diri << dendl;
./client/Client.cc:	ldout(cct, 10) << " marking I_COMPLETE on " << *diri << dendl;
./client/Client.cc:  ldout(cct, 3) << "getdir(" << relpath << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << "open enter(" << relpath << ", " << cflags << "," << mode << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << "open exit(" << path << ", " << cflags << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " enter(" << ino << ", #" << dirino << "/" << name << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " exit(" << ino << ", #" << dirino << "/" << name << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " enter(" << vino << ")" << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " exit(" << vino << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " enter(" << ino->ino << ")" << dendl;
./client/Client.cc:      ldout(cct, 8) << __func__ << " found parent " << (*parent)->ino << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " exit(" << ino->ino << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " enter(" << ino->ino << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " exit(" << ino->ino << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << in->ino << " mode " << cmode << dendl;
./client/Client.cc:  //ldout(cct, 3) << "op: client->close(open_files[ " << fh << " ]);" << dendl;
./client/Client.cc:  //ldout(cct, 3) << "op: open_files.erase( " << fh << " );" << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " " << f << " mode " << f->mode << " on " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " " << f << " on inode " << *in << " no async_err state" << dendl;
./client/Client.cc:  ldout(cct, 3) << "close enter(" << fd << ")" << dendl;
./client/Client.cc:  ldout(cct, 3) << "close exit(" << fd << ")" << dendl;
./client/Client.cc:    ldout(cct, 1) << __func__ << ": invalid whence value " << whence << dendl;
./client/Client.cc:  ldout(cct, 8) << "_lseek(" << f << ", " << offset << ", " << whence << ") = " << f->pos << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << f << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " BLOCKING on " << f << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " UNBLOCKING on " << f << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << f << dendl;
./client/Client.cc:  ldout(cct, 3) << "read(" << fd << ", " << (void*)buf << ", " << size << ", " << offset << ") = " << r << dendl;
./client/Client.cc:  lgeneric_subdout(client->cct, client, 20) << "client." << client->get_nodeid() << " " << "C_Readahead on " << f->inode << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << " " << off << "~" << len << dendl;
./client/Client.cc:	ldout(cct, 20) << "readahead initiated, c " << onfinish2 << dendl;
./client/Client.cc:	ldout(cct, 20) << "readahead was no-op, already cached" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *in << " " << off << "~" << len << dendl;
./client/Client.cc:  ldout(cct, 3) << "write(" << fd << ", \"...\", " << size << ", " << offset << ") = " << r << dendl;
./client/Client.cc:        ldout(cct, 3) << "pwritev(" << fh << ", \"...\", " << totallen << ", " << offset << ") = " << w << dendl;
./client/Client.cc:        ldout(cct, 3) << "preadv(" << fh << ", " <<  offset << ") = " << r << dendl;
./client/Client.cc:  //ldout(cct, 7) << "write fh " << fh << " size " << size << " offset " << offset << dendl;
./client/Client.cc:  ldout(cct, 10) << "cur file size is " << in->size << dendl;
./client/Client.cc:  ldout(cct, 10) << " snaprealm " << *in->snaprealm << dendl;
./client/Client.cc:    ldout(cct, 7) << "wrote to " << totalwritten+offset << ", extending file size" << dendl;
./client/Client.cc:    ldout(cct, 7) << "wrote to " << totalwritten+offset << ", leaving file size at " << in->size << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << ": " << f << " on inode " << *in << " no async_err state" << dendl;
./client/Client.cc:  ldout(cct, 8) << "_fsync on " << *in << " " << (syncdataonly ? "(dataonly)":"(data+metadata)") << dendl;
./client/Client.cc:    ldout(cct, 15) << "using return-valued form of _fsync" << dendl;
./client/Client.cc:  } else ldout(cct, 10) << "no metadata needs to commit" << dendl;
./client/Client.cc:    ldout(cct, 15) << "waiting on unsafe requests, last tid " << req->get_tid() <<  dendl;
./client/Client.cc:    ldout(cct, 15) << "waiting on data to flush" << dendl;
./client/Client.cc:    ldout(cct, 15) << "got " << r << " from flush writeback" << dendl;
./client/Client.cc:    ldout(cct, 10) << "ino " << in->ino << " has no uncommitted writes" << dendl;
./client/Client.cc:  ldout(cct, 8) << "_fsync(" << f << ", " << (syncdataonly ? "dataonly)":"data+metadata)") << dendl;
./client/Client.cc:  ldout(cct, 5) << "fstat(" << fd << ", " << stbuf << ") = " << r << dendl;
./client/Client.cc:      ldout(cct, 3) << "fstatx exit on error!" << dendl;
./client/Client.cc:  ldout(cct, 3) << "fstatx(" << fd << ", " << stx << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 3) << "chdir(" << relpath << ")  cwd now " << cwd->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *cwd << dendl;
./client/Client.cc:      ldout(cct, 10) << __func__ << " looking up parent for " << *in << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << fh << " ino " << in->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << "_getlk " << fh << " ino " << in->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << "_setlk " << fh << " ino " << in->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << "_setlk " << fh << " ino " << in->ino << " result=" << ret << dendl;
./client/Client.cc:  ldout(cct, 10) << "_flock " << fh << " ino " << in->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << "_flock " << fh << " ino " << in->ino << " result=" << ret << dendl;
./client/Client.cc:    ldout(cct, 1) << "using dentry_invalidate_cb" << dendl;
./client/Client.cc:    ldout(cct, 1) << "using remount_cb" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << dendl;
./client/Client.cc:    ldout(cct, 15) << __func__ << " waiting on data to flush" << dendl;
./client/Client.cc:    ldout(cct, 15) << __func__ << " flush finished" << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << *in << " " << !!enable << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << fh << " " << fh->inode->ino << " " << !!enable << dendl;
./client/Client.cc:    ldout(cct, 10) << "open_snapdir created snapshot inode " << *in << dendl;
./client/Client.cc:    ldout(cct, 10) << "open_snapdir had snapshot inode " << *in << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vino << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << name << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << in << " " << in->ino << " -> " << in->ll_ref << dendl;
./client/Client.cc:  ldout(cct, 20) << __func__ << " " << in << " " << in->ino << " " << num << " -> " << in->ll_ref << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " " << ino << " " << count << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << " " << vino << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << _get_vino(in) << " = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << _get_vino(in) << " = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << _get_vino(in) << " = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << _get_vino(in) << " = " << res << dendl;
./client/Client.cc:  ldout(cct, 8) << "_getxattr(" << in->ino << ", \"" << name << "\", " << size << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vino << " " << name << " size " << size << dendl;
./client/Client.cc:  ldout(cct, 8) << __func__ << "(" << in->ino << ", " << size << ") = " << r << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vino << " size " << size << dendl;
./client/Client.cc:  ldout(cct, 15) << __func__ << ": name = " << name << dendl;
./client/Client.cc:      ldout(cct, 20) << __func__ << ": waiting for latest osdmap" << dendl;
./client/Client.cc:      ldout(cct, 20) << __func__ << ": got latest osdmap: " << ec << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << vino << " " << name << " size " << size << dendl;
./client/Client.cc:  ldout(cct, 8) << "_removexattr(" << in->ino << ", \"" << name << "\") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_removexattr " << vino << " " << name << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_readlink " << vino << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_readlink " << vino << " = " << r << dendl;
./client/Client.cc:  ldout(cct, 8) << "mknod(" << path << ", 0" << oct << mode << dec << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_mknod " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_mknodx " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 10) << "_mkdir: making request" << dendl;
./client/Client.cc:  ldout(cct, 10) << "_mkdir result is " << res << dendl;
./client/Client.cc:  ldout(cct, 8) << "_mkdir(" << path << ", 0" << oct << mode << dec << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_mkdir " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_mkdirx " << vparent << " " << name << dendl;
./client/Client.cc:  ldout(cct, 8) << "unlink(" << path << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_unlink " << vino << " " << name << dendl;
./client/Client.cc:  ldout(cct, 8) << "rmdir(" << path << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_rmdir " << vino << " " << name << dendl;
./client/Client.cc:  ldout(cct, 10) << "rename result is " << res << dendl;
./client/Client.cc:  ldout(cct, 8) << "_rename(" << from << ", " << to << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 10) << "link result is " << res << dendl;
./client/Client.cc:  ldout(cct, 8) << "link(" << existing << ", " << path << ") = " << res << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_opendir " << vino << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_releasedir " << dirp << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_fsyncdir " << dirp << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_open " << vino << " " << ceph_flags_sys2wire(flags) << dendl;
./client/Client.cc:  ldout(cct, 20) << "_ll_create created = " << created << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_read " << fh << " " << fh->inode->ino << " " << " " << off << "~" << len << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_flush " << fh << " " << fh->inode->ino << " " << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_fsync " << fh << " " << fh->inode->ino << " " << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_sync_inode " << *in << " " << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " " << fh << " " << fh->inode->ino << " " << dendl;
./client/Client.cc:  ldout(cct, 3) << "ll_getlk (fh)" << fh << " " << fh->inode->ino << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "  (fh) " << fh << " " << fh->inode->ino << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "  (fh) " << fh << " " << fh->inode->ino << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << " tid " << req->get_tid() << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << relpath << ") = 0" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << fd << ") = 0" << dendl;
./client/Client.cc:  ldout(cct, 3) << __func__ << "(" << fd << ", " << length << ", " << offset << ") = 0" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " on " << con->get_peer_addr() << dendl;
./client/Client.cc:  ldout(cct, 0) << __func__ << " on " << con->get_peer_addr() << dendl;
./client/Client.cc:  ldout(cct, 0) << __func__ << " on " << con->get_peer_addr() << dendl;
./client/Client.cc:	  ldout(cct, 1) << "reset from mds we were closing; we'll call that closed" << dendl;
./client/Client.cc:	    ldout(cct, 1) << "reset from mds we were opening; retrying" << dendl;
./client/Client.cc:	      ldout(cct, 1) << "reset from mds we were open; close mds session for reconnect" << dendl;
./client/Client.cc:	      ldout(cct, 1) << "reset from mds we were open; mark session as stale" << dendl;
./client/Client.cc:  ldout(cct, 1) << __func__ << " on " << con->get_peer_addr() << dendl;
./client/Client.cc:    ldout(cct, 10) << __func__ << " realm " << realm->ino << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << in->vino() << " -> " << quota_in->vino() << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " ino " << in->ino << " result=" << r << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " dir ino " << dir->ino << " result=" << r << dendl;
./client/Client.cc:      ldout(cct, 10) << "mds." << mds << " not active, waiting for new mdsmap" << dendl;
./client/Client.cc:      ldout(cct, 10) << "waiting for session to mds." << mds << " to open" << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << ": waiting for OSD epoch " << reclaim_osd_epoch << dendl;
./client/Client.cc:  ldout(cct, 10) << __func__ << " " << *reply << " from mds." << from << dendl;
./client/Client.cc:    ldout(cct, 10) << " discarding reclaim reply from sessionless mds." <<  from << dendl;
./client/Client.cc:  ldout(cct, 5) << __func__ << " epoch = " << e << dendl;
./libcephsqlite.cc:    ldout(cct, 5) << "initializing RADOS handle as " << cct->_conf->name << dendl;
./libcephsqlite.cc:    ldout(cct, 5) << "completed connection to RADOS with address " << s << dendl;
./libcephsqlite.cc:  ldout(cct, 1) << "cct: " << cct << dendl;
./libcephsqlite.cc:  ldout(cct, 1) << "complete" << dendl;
./objclass/class_api.cc:       dout(ceph::dout::need_dynamic(level)) << buf << dendl;
./kv/MemDB.cc:  dout(10) << __func__ << " Saving MemDB to file: "<< _get_data_fn().c_str() << dendl;
./kv/MemDB.cc:    dout(10) << __func__ << " Key:"<< iter->first << dendl;
./kv/MemDB.cc:  dout(10) << __func__ << " Reading MemDB from file: "<< _get_data_fn().c_str() << dendl;
./kv/MemDB.cc:    dout(10) << __func__ << " Key:"<< key << dendl;
./kv/MemDB.cc:  dout(1) << __func__ << dendl;
./kv/MemDB.cc:  dout(10) << __func__ << " Destroying MemDB instance: "<< dendl;
./kv/rocksdb_cache/BinnedLRUCache.cc:  ldout(cct, 10) << __func__ << " High Pri Pool Ratio set to " << ratio << dendl;
./kv/LevelDBStore.cc:    dout(1) << "load leveldb options failed" << dendl;
./kv/LevelDBStore.cc:    dout(1) << "load leveldb options failed" << dendl;
./kv/RocksDBStore.cc:	dout(10) << __func__ << " db_path " << path << " size " << size << dendl;
./kv/RocksDBStore.cc:    dout(10) << __func__ << " using custom Env " << priv << dendl;
./kv/RocksDBStore.cc:      dout(1) << __func__ << " bad sharding: " << dendl;
./kv/RocksDBStore.cc:      dout(1) << __func__ << sharding_text << dendl;
./kv/RocksDBStore.cc:      dout(1) << __func__ << std::string(error_position - &sharding_text[0], ' ') << "^" << error_msg << dendl;
./kv/RocksDBStore.cc:  dout(5) << __func__ << " opts_str=" << opts_str << dendl;
./kv/RocksDBStore.cc:    dout(20) << __func__ << " sharding=" << stored_sharding_text << dendl;
./kv/RocksDBStore.cc:    dout(30) << __func__ << " no sharding" << dendl;
./kv/RocksDBStore.cc:  dout(5) << __func__ << " column families from rocksdb: " << rocksdb_cfs << dendl;
./kv/RocksDBStore.cc:	    dout(5) << __func__ << " failed to create block cache for params: " << block_cache_opt << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " load rocksdb options failed" << dendl;
./kv/RocksDBStore.cc:      dout(10) << __func__ << " existing_cfs=" << existing_cfs.size() << dendl;
./kv/RocksDBStore.cc:	dout(10) << __func__ << " missing_cfs=" << missing_cfs.size() << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " waiting for compaction thread to stop" << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " compaction thread to stopped" << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " load rocksdb options failed" << dendl;
./kv/RocksDBStore.cc:  dout(10) << __func__ << " stored_sharding: " << stored_sharding_text << dendl;
./kv/RocksDBStore.cc:  dout(10) << __func__ << " enter" << dendl;
./kv/RocksDBStore.cc:    dout(10) << __func__ << " waiting" << dendl;
./kv/RocksDBStore.cc:  dout(10) << __func__ << " exit" << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " bad sharding: " << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << new_sharding << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << std::string(error_position - &new_sharding[0], ' ') << "^" << error_msg << dendl;
./kv/RocksDBStore.cc:    dout(1) << __func__ << " load rocksdb options failed" << dendl;
./kv/RocksDBStore.cc:  dout(5) << "existing columns = " << existing_columns << dendl;
./kv/RocksDBStore.cc:    dout(10) << "column " << cfs_to_open[i].name << " handle " << (void*)handles[i] << dendl;
./kv/RocksDBStore.cc:  dout(5) << "target columns = " << new_sharding_columns << dendl;
./kv/RocksDBStore.cc:  dout(5) << "missing columns = " << missing_columns << dendl;
./kv/RocksDBStore.cc:    dout(10) << "created column " << full_name << " handle = " << (void*)cf << dendl; 
./kv/RocksDBStore.cc:    dout(10) << "processing column " << full_name << dendl;
./kv/RocksDBStore.cc:      dout(5) << "Column " << name << " is part of new sharding." << dendl;
./kv/RocksDBStore.cc:    dout(5) << "Column " << name << " not part of new sharding. Deleting." << dendl;
./kv/RocksDBStore.cc:    dout(5) << " column=" << (void*)handle << " prefix=" << fixed_prefix << dendl;
./kv/RocksDBStore.cc:      dout(30) << "key=" << pretty_binary_string(raw_key.ToString()) << dendl;
./kv/RocksDBStore.cc:	dout(8) << "refreshing iterator" << dendl;
./kv/RocksDBStore.cc:	dout(10) << "processed " << keys_processed << " keys, moved " << keys_moved << dendl;
./kv/RocksDBStore.cc:    dout(1) << "failed to prepare db for reshard" << dendl;
./kv/RocksDBStore.cc:      dout(10) << "Prefix: " << fixed_prefix << dendl;
./kv/RocksDBStore.cc:    dout(5) << "failed to cleanup after reshard" << dendl;
./rgw/rgw_process.cc:    dout(20) << "RGWWQ: empty" << dendl;
./rgw/rgw_process.cc:  dout(20) << "RGWWQ:" << dendl;
./rgw/rgw_process.cc:    dout(20) << "req: " << hex << *iter << dec << dendl;
./rgw/rgw_process.cc:  dout(20) << "enqueued request req=" << hex << req << dec << dendl;
./rgw/rgw_process.cc:  dout(20) << "dequeued request req=" << hex << req << dec << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "init permissions" << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "recalculating target" << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "retargeting skipped because of SubOp mode" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "reading permissions" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "init op" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "verifying op mask" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "verifying op permissions" << dendl;
./rgw/rgw_process.cc:      dout(2) << "overriding permissions due to system operation" << dendl;
./rgw/rgw_process.cc:      dout(2) << "overriding permissions due to admin operation" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "verifying op params" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "pre-executing" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "executing" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 2) << "completing" << dendl;
./rgw/rgw_process.cc:  ldpp_dout(s, 2) << "initializing for trans_id = " << s->trans_id << dendl;
./rgw/rgw_process.cc:  ldpp_dout(s, 10) << "handler=" << typeid(*handler).name() << dendl;
./rgw/rgw_process.cc:  ldpp_dout(s, 2) << "getting op " << s->op << dendl;
./rgw/rgw_process.cc:      ldpp_dout(op, 5) << "WARNING: failed to read pre request script. error: " << rc << dendl;
./rgw/rgw_process.cc:        ldpp_dout(op, 5) << "WARNING: failed to execute pre request script. error: " << rc << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op,0) << "Scheduling request failed with " << ret << dendl;
./rgw/rgw_process.cc:  ldpp_dout(op, 10) << "op=" << typeid(*op).name() << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "verifying requester" << dendl;
./rgw/rgw_process.cc:      dout(10) << "failed to authorize request" << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "normalizing buckets and tenants" << dendl;
./rgw/rgw_process.cc:      dout(10) << "failed to run post-auth init" << dendl;
./rgw/rgw_process.cc:      dout(10) << "user is suspended, uid=" << s->user->get_id() << dendl;
./rgw/rgw_process.cc:    dout(0) << "authentication failed" << e.what() << dendl;
./rgw/rgw_process.cc:      ldpp_dout(op, 5) << "WARNING: failed to read post request script. error: " << rc << dendl;
./rgw/rgw_process.cc:        ldpp_dout(op, 5) << "WARNING: failed to execute post request script. error: " << rc << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "op status=" << op_ret << dendl;
./rgw/rgw_process.cc:    ldpp_dout(op, 2) << "http status=" << s->err.http_ret << dendl;
./rgw/rgw_process.cc:    ldpp_dout(s, 2) << "http status=" << s->err.http_ret << dendl;
./rgw/rgw_rest_realm.cc:    ldout(store->ctx(), 5) << "failed to read period" << dendl;
./rgw/rgw_tools.cc:    dout(20) << "WARNING: blocking librados call" << dendl;
./rgw/rgw_tools.cc:    dout(20) << "WARNING: blocking librados call" << dendl;
./rgw/rgw_tools.cc:    dout(20) << "WARNING: blocking librados call" << dendl;
./rgw/rgw_tools.cc:    ldout(cct, 0) << __func__ << " failed to allocate buf" << dendl;
./rgw/rgw_tools.cc:    ldout(cct, 0) << __func__ << " raced! will retry.." << dendl;
./rgw/rgw_orphan.cc:  ldout(store->ctx(), 20) << "storing " << entries.size() << " entries at " << oid << ": " << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 20) << " > " << iter->first << dendl;
./rgw/rgw_orphan.cc:         ldout(store->ctx(), 20) << "adding obj: " << *cur << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 20) << "oid_fp=" << oid_fp << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 1) << "iterated through " << total << " objects" << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 10) << "bucket_instance=" << *iter << " total=" << total << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 5) << "skipping object as it fits in a head" << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 20) << __func__ << ": oid for obj=" << result.obj << ": " << *iter << dendl;
./rgw/rgw_orphan.cc:    ldpp_dout(dpp, -1) << __func__ << ": ERROR: RGWRados::get_bucket_instance_info() returned ret=" << ret << dendl;
./rgw/rgw_orphan.cc:    ldpp_dout(dpp, -1) << __func__ << ": ERROR: RGWRados::get_bucket_instance_info() returned ret=" << ret << dendl;
./rgw/rgw_orphan.cc:  ldpp_dout(dpp, 10) << "building linked oids for bucket instance: " << bucket_instance_id << dendl;
./rgw/rgw_orphan.cc:        ldpp_dout(dpp, 20) << "obj entry: " << entry.key.name << dendl;
./rgw/rgw_orphan.cc:        ldpp_dout(dpp, 20) << "obj entry: " << entry.key.name << " [" << entry.key.instance << "]" << dendl;
./rgw/rgw_orphan.cc:      ldpp_dout(dpp, 20) << __func__ << ": entry.key.name=" << entry.key.name << " entry.key.instance=" << entry.key.instance << dendl;
./rgw/rgw_orphan.cc:    ldpp_dout(dpp, 0) << "building linked oids index: " << iter->first << "/" << buckets_instance_index.size() << dendl;
./rgw/rgw_orphan.cc:        ldout(store->ctx(), 20) << " indexed entry: " << eiter->first << dendl;
./rgw/rgw_orphan.cc:        ldout(store->ctx(), 20) << "linked: " << key << dendl;
./rgw/rgw_orphan.cc:        ldout(store->ctx(), 20) << "skipping: " << key << " (mtime=" << mtime << " threshold=" << time_threshold << ")" << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 20) << "leaked: " << key << dendl;
./rgw/rgw_orphan.cc:      ldpp_dout(dpp, 0) << __func__ << "(): initializing state" << dendl;
./rgw/rgw_orphan.cc:      ldpp_dout(dpp, 0) << __func__ << "(): building index of all objects in pool" << dendl;
./rgw/rgw_orphan.cc:      ldpp_dout(dpp, 0) << __func__ << "(): building index of all bucket indexes" << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 0) << __func__ << "(): building index of all linked objects" << dendl;
./rgw/rgw_orphan.cc:        ldout(store->ctx(), 0) << "ERROR: couldn't remove " << iter->second << ": ret=" << r << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 0) << "ERROR: remove_index(" << all_objs_index << ") returned ret=" << r << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 0) << "ERROR: remove_index(" << buckets_instance_index << ") returned ret=" << r << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 0) << "ERROR: remove_index(" << linked_objs_index << ") returned ret=" << r << dendl;
./rgw/rgw_orphan.cc:    ldout(store->ctx(), 0) << "ERROR: could not remove job name (" << search_info.job_name << ") ret=" << r << dendl;
./rgw/rgw_orphan.cc:      ldout(store->ctx(), 10) << "bucket_instance=" << *iter << " total=" << total << dendl;
./rgw/rgw_orphan.cc:        ldpp_dout(dpp, 20) << "obj entry: " << entry.key.name << dendl;
./rgw/rgw_lua_request.cc:    ldout(s->cct, 1) << "Lua ERROR: missing rados store, cannot use ops log"  << dendl;
./rgw/rgw_lua_request.cc:      ldout(s->cct, 1) << "Lua ERROR: " << err << dendl;
./rgw/rgw_lua_request.cc:    ldout(s->cct, 1) << "Lua ERROR: " << e.what() << dendl;
./rgw/rgw_trim_datalog.cc:    ldout(cct, 10) << "fetching sync status for zone " << zone_id << dendl;
./rgw/rgw_trim_datalog.cc:        ldout(cct, 20) << "query sync status from " << c.first << dendl;
./rgw/rgw_trim_datalog.cc:      ldout(cct, 4) << "failed to fetch sync status from all peers" << dendl;
./rgw/rgw_trim_datalog.cc:    ldout(cct, 10) << "trimming log shards" << dendl;
./rgw/rgw_auth_s3.cc:  dout(10) << "get_canon_resource(): dest=" << dest << dendl;
./rgw/rgw_auth_s3.cc:        dout(0) << "NOTICE: missing date for auth header" << dendl;
./rgw/rgw_auth_s3.cc:        dout(0) << "NOTICE: failed to parse date for auth header" << dendl;
./rgw/rgw_auth_s3.cc:        dout(0) << "NOTICE: bad date (predates epoch): " << req_date << dendl;
./rgw/rgw_auth_s3.cc:    dout(10) << "NOTICE: request time skew too big." << dendl;
./rgw/rgw_auth_s3.cc:    dout(10) << "req_tp=" << req_tp << ", cur_tp=" << cur_tp << dendl;
./rgw/rgw_auth_s3.cc:    dout(10) << "NOTICE: exp out of range, exp = " << exp << dendl;
./rgw/rgw_auth_s3.cc:    dout(10) << "NOTICE: now = " << now << ", req_sec = " << req_sec << ", exp = " << exp << dendl;
./rgw/rgw_auth_s3.cc:    ldpp_dout(dpp, 10) << "credentials string is too short" << dendl;
./rgw/rgw_auth_s3.cc:      ldpp_dout(dpp, 10) << "NOTICE: auth header missing key: " << k << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "v4 signature format = " << signature << dendl;
./rgw/rgw_auth_s3.cc:    ldpp_dout(dpp, 10) << "error reading date via http_x_amz_date" << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "v4 credential format = " << credential << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "access key id = " << access_key_id << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "credential scope = " << credential_scope << dendl;
./rgw/rgw_auth_s3.cc:      dout(10) << "warning env var not available " << token_env.c_str() << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "payload request hash = " << request_payload_hash << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "canonical request = " << sanitize{canonical_req} << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "date_k    = " << date_k << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "region_k  = " << region_k << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "service_k = " << service_k << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "signing_k = " << signing_key << dendl;
./rgw/rgw_auth_s3.cc:  ldpp_dout(dpp, 10) << "generated signature = " << signature << dendl;
./rgw/rgw_auth_s3.cc:    ldout(cct, 10) << "ceph_armor failed" << dendl;
./rgw/rgw_auth_s3.cc:  dout(30) << "AWSv4ComplMulti: stream_pos_was=" << stream_pos_was << ", to_extract=" << to_extract << dendl;
./rgw/rgw_auth_s3.cc:    dout(30) << "AWSv4ComplMulti: to_extract=" << to_extract << ", data_len=" << data_len << dendl;
./rgw/rgw_auth_s3.cc:    dout(30) << "AWSv4ComplMulti: to_extract=" << to_extract << ", received=" << received << dendl;
./rgw/rgw_auth_s3.cc:  dout(20) << "AWSv4ComplMulti: filled=" << buf_pos << dendl;
./rgw/rgw_auth_s3.cc:      ldpp_dout(dpp, 10) << "negative AWSv4's content length, aborting" << dendl;
./rgw/rgw_kafka.cc:        ldout(cct, 20) << "Kafka destroy: invoking callback with tag=" << cb_tag.tag << dendl;
./rgw/rgw_kafka.cc:    ldout(conn->cct, 20) << "Kafka run: n/ack received, (no callback) with result=" << result << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 20) << "Kafka connect: successfully configured SSL+SASL security" << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 20) << "Kafka connect: successfully configured SSL security" << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 20) << "Kafka connect: successfully configured CA location" << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 20) << "Kafka connect: using default CA location" << dendl;
./rgw/rgw_kafka.cc:    ldout(conn->cct, 20) << "Kafka connect: successfully configured security" << dendl;
./rgw/rgw_kafka.cc:    ldout(conn->cct, 1) << "Kafka connect: failed to create producer: " << errstr << dendl;
./rgw/rgw_kafka.cc:  ldout(conn->cct, 20) << "Kafka connect: successfully created new producer" << dendl;
./rgw/rgw_kafka.cc:  ldout(conn->cct, 1) << "Kafka connect: configuration failed: " << errstr << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 1) << "Kafka publish: connection had an issue while message was in the queue. error: " << status_to_string(conn->status) << dendl;
./rgw/rgw_kafka.cc:        ldout(conn->cct, 1) << "Kafka publish: failed to create topic: " << message->topic << " error: " << status_to_string(err) << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 20) << "Kafka publish: successfully created topic: " << message->topic << dendl;
./rgw/rgw_kafka.cc:        ldout(conn->cct, 20) << "Kafka publish: reused existing topic: " << message->topic << dendl;
./rgw/rgw_kafka.cc:      ldout(conn->cct, 10) << "Kafka publish: failed to produce: " << rd_kafka_err2str(err) << dendl;
./rgw/rgw_kafka.cc:        ldout(conn->cct, 20) << "Kafka publish (with callback, tag=" << *tag << "): OK. Queue has: " << q_len << " callbacks" << dendl;
./rgw/rgw_kafka.cc:        ldout(conn->cct, 1) << "Kafka publish (with callback): failed with error: callback queue full" << dendl;
./rgw/rgw_kafka.cc:        ldout(conn->cct, 20) << "Kafka publish (no callback): OK" << dendl;
./rgw/rgw_kafka.cc:          ldout(conn->cct, 10) << "Kafka run: connection is deleted" << dendl;
./rgw/rgw_kafka.cc:          ldout(conn->cct, 10) << "Kafka run: connection status is: " << status_to_string(conn->status) << dendl;
./rgw/rgw_kafka.cc:          ldout(conn->cct, 20) << "Kafka run: retry connection" << dendl;
./rgw/rgw_kafka.cc:            ldout(conn->cct, 10) << "Kafka run: connection (" << broker << ") retry failed" << dendl;
./rgw/rgw_kafka.cc:            ldout(conn->cct, 10) << "Kafka run: connection (" << broker << ") retry successfull" << dendl;
./rgw/rgw_kafka.cc:      ldout(cct, 1) << "Kafka connect: manager is stopped" << dendl;
./rgw/rgw_kafka.cc:      ldout(cct, 1) << "Kafka connect: URL parsing failed" << dendl;
./rgw/rgw_kafka.cc:      ldout(cct, 1) << "Kafka connect: user/password are only allowed over secure connection" << dendl;
./rgw/rgw_kafka.cc:        ldout(cct, 1) << "Kafka connect: endpoint marked for deletion" << dendl;
./rgw/rgw_kafka.cc:      ldout(cct, 20) << "Kafka connect: connection found" << dendl;
./rgw/rgw_kafka.cc:      ldout(cct, 1) << "Kafka connect: max connections exceeded" << dendl;
./rgw/rgw_kafka.cc:    ldout(cct, 10) << "Kafka connect: new connection is created. Total connections: " << connection_count << dendl;
./rgw/rgw_http_client_curl.cc:      dout(0) << __func__ << " failed to set locks" << dendl;
./rgw/rgw_http_client_curl.cc:      dout(0) << __func__ << " failed to unlock" << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 0) << "ERROR: endpoints not configured for upstream zone" << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 5) << __func__ << ": send_request() resource=" << resource << " returned ret=" << ret << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 5) << __func__ << ": send_request() resource=" << resource << " returned ret=" << ret << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 5) << __func__ << ": send_request() resource=" << resource << " returned ret=" << ret << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 5) << __func__ << ": send_request() resource=" << resource << " returned ret=" << ret << dendl;
./rgw/rgw_rest_conn.cc:    ldout(cct, 5) << __func__ << ": send_request() resource=" << resource << " returned ret=" << ret << dendl;
./rgw/rgw_quota.cc:  ldout(store->ctx(), 20) << "async stats refresh response for bucket=" << bucket << dendl;
./rgw/rgw_quota.cc:  ldout(store->ctx(), 20) << "async stats refresh response for bucket=" << bucket << dendl;
./rgw/rgw_quota.cc:        ldout(store->ctx(), 0) << "ERROR: quota async refresh returned ret=" << r << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get bucket info for bucket=" << bucket << " r=" << r << dendl;
./rgw/rgw_quota.cc:  ldout(store->ctx(), 20) << "initiating async quota refresh for bucket=" << bucket << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get bucket info for bucket=" << bucket.name << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 20) << "AsyncRefreshHandler::handle_response() r=" << r << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get bucket info for bucket=" << _b << " r=" << r << dendl;
./rgw/rgw_quota.cc:  ldout(store->ctx(), 20) << "initiating async quota refresh for user=" << user << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get bucket info for user=" << user << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 20) << "AsyncRefreshHandler::handle_response() r=" << r << dendl;
./rgw/rgw_quota.cc:      ldout(cct, 20) << "BucketsSyncThread: start" << dendl;
./rgw/rgw_quota.cc:          ldout(cct, 20) << "BucketsSyncThread: sync user=" << user << " bucket=" << bucket << dendl;
./rgw/rgw_quota.cc:            ldout(cct, 0) << "WARNING: sync_bucket() returned r=" << r << dendl;
./rgw/rgw_quota.cc:      ldout(cct, 20) << "BucketsSyncThread: done" << dendl;
./rgw/rgw_quota.cc:      ldout(cct, 20) << "UserSyncThread: start" << dendl;
./rgw/rgw_quota.cc:          ldout(cct, 5) << "ERROR: sync_all_users() returned ret=" << ret << dendl;
./rgw/rgw_quota.cc:      ldout(cct, 20) << "UserSyncThread: done" << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get user stats for user=" << user << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "could not get bucket info for bucket=" << _b << " r=" << r << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "ERROR: sync_user_stats() for user=" << _u << ", bucket=" << bucket << " returned " << r << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 5) << "ERROR: can't read user header: ret=" << ret << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 20) << "user is idle, not doing a full sync (user=" << user << ")" << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 0) << "ERROR: failed user stats sync, ret=" << ret << dendl;
./rgw/rgw_quota.cc:    ldout(store->ctx(), 10) << "ERROR: can't get key: ret=" << ret << dendl;
./rgw/rgw_quota.cc:      ldout(store->ctx(), 0) << "ERROR: lists_keys_next(): ret=" << ret << dendl;
./rgw/rgw_quota.cc:      ldout(store->ctx(), 20) << "RGWUserStatsCache: sync user=" << user << dendl;
./rgw/rgw_quota.cc:        ldout(store->ctx(), 5) << "ERROR: sync_user() failed, user=" << user << " ret=" << ret << dendl;
./rgw/rgw_cr_tools.cc:      ldpp_dout(dpp, 20) << "NOTICE: bucket already exists under a different user (bucket=" << bucket << " user=" << user << " bucket_owner=" << info.owner << dendl;
./rgw/rgw_cr_tools.cc:      ldpp_dout(dpp, 0) << "WARNING: failed to unlink bucket: ret=" << r << dendl;
./rgw/rgw_cr_tools.cc:    ldpp_dout(dpp, 0) << "ERROR: bucket creation (bucket=" << bucket << ") return ret=" << ret << dendl;
./rgw/rgw_cr_tools.cc:    ldpp_dout(dpp, -1) << "ERROR: put object returned error: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_cr_tools.cc:    ldpp_dout(dpp, -1) << "ERROR: " << __func__ << "(): get_sync_policy_handler() returned " << r << dendl;
./rgw/rgw_admin.cc:    ldpp_dout(dpp(), 0) << "ERROR: failed to decode manifest" << dendl;
./rgw/rgw_admin.cc:	ldpp_dout(dpp(), 20) << "could not init bucket info for hint bucket=" << b << " ... skipping" << dendl;
./rgw/rgw_admin.cc:      ldpp_dout(dpp(), 20) << "could not get bucket sync policy handler for hint bucket=" << hint_bucket << " ... skipping" << dendl;
./rgw/rgw_admin.cc:        ldpp_dout(dpp(), 20) << "found at time=" << start_time - time_ofs << " time_ofs=" << time_ofs << dendl;
./rgw/rgw_admin.cc:        ldpp_dout(dpp(), 0) << "WARNING: check_min_obj_stripe_size failed, r=" << ret << dendl;
./rgw/rgw_admin.cc:      ldpp_dout(dpp(), 20) << "skipped object" << dendl;
./rgw/rgw_admin.cc:              ldpp_dout(dpp(), 0) << "WARNING: check_min_obj_stripe_size failed, r=" << r << dendl;
./rgw/rgw_sync_checkpoint.cc:    ldpp_dout(dpp, 1) << "bucket sync caught up with empty source" << dendl;
./rgw/rgw_sync_checkpoint.cc:      ldpp_dout(dpp, 0) << "bucket checkpoint timed out waiting for incremental sync to catch up" << dendl;
./rgw/rgw_sync_checkpoint.cc:      ldpp_dout(dpp, 0) << "bucket sync checkpoint failed: " << cpp_strerror(r) << dendl;
./rgw/rgw_sync_checkpoint.cc:  ldpp_dout(dpp, 0) << "bucket checkpoint complete" << dendl;
./rgw/rgw_rest.cc:  ldout(cct, 20) << "RGW hostnames: " << hostnames_set << dendl;
./rgw/rgw_rest.cc:  ldout(cct, 20) << "RGW S3website hostnames: " << hostnames_s3website_set << dendl;
./rgw/rgw_rest.cc:    ldpp_dout(s, 5) << "NOTICE:  open produce torrent file " << dendl;
./rgw/rgw_rest.cc:    ldpp_dout(s, 20) << "request content_type params:" << dendl;
./rgw/rgw_rest.cc:  ldpp_dout(s, 0) << "RGWPutACLs_ObjStore::get_params read data is: " << data.c_str() << dendl;
./rgw/rgw_rest.cc:      ldpp_dout(s, 20) << "bad marker: "  << marker << dendl;
./rgw/rgw_rest.cc:  ldpp_dout(s, 10) << "rgw api priority: s3=" << api_priority_s3 << " s3website=" << api_priority_s3website << dendl;
./rgw/rgw_rest.cc:    ldpp_dout(s, 10) << "host=" << info.host << dendl;
./rgw/rgw_rest.cc:	ldpp_dout(s, 10) << "bad content length, aborting" << dendl;
./rgw/rgw_rest.cc:    ldpp_dout(s, 10) << "negative content length, aborting" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 10) << "WARNING: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to read bucket topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to write bucket topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: topic not found" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: topic not found" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topic '" << topic_name << "' info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:  ldout(store->ctx(), 20) << "successfully read topic '" << topic_name << "' info" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write topics to bucket '" << bucket.name << "': ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:  ldout(store->ctx(), 20) << "successfully wrote " << bucket_topics.topics.size() << " topics to bucket '" << bucket.name << "'" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topic info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read bucket topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to get list of topics from bucket '" << bucket.name << "', ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:      ldout(ps->store->ctx(), 5) << "WARNING: failed to remove auto-generated topic '" << topic_name << "', ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to remove bucket topics: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:      ldout(store->ctx(), 10) << "WARNING: failed to read topics info, deletion is a no-op: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to remove topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to read subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to write subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(ps->store->ctx(), 1) << "ERROR: failed to remove subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: cannot add subscription to topic: topic not found" << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to write subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:      ldout(store->ctx(), 1) << "ERROR: failed to read subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 10) << "WARNING: failed to read topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:        ldout(store->ctx(), 1) << "ERROR: failed to write topics info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldout(store->ctx(), 1) << "ERROR: failed to delete subscription info: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to read sub config: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to read bucket info for events bucket: bucket=" << sub_conf.dest.bucket_name << " ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to list bucket: bucket=" << sub_conf.dest.bucket_name << " ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:      ldpp_dout(dpp, 1) << "ERROR: failed to event (not a valid base64)" << dendl;
./rgw/rgw_pubsub.cc:      ldpp_dout(dpp, 1) << "ERROR: failed to decode event" << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to read sub config: ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to read bucket info for events bucket: bucket=" << sub_conf.dest.bucket_name << " ret=" << ret << dendl;
./rgw/rgw_pubsub.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to remove event (obj=" << obj << "): ret=" << ret << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Policy name: " << policy_name << " not found" << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Policy name: " << policy_name << " not found" << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Invalid name length " << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Invalid path length " << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Invalid chars in name " << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Invalid chars in path " << dendl;
./rgw/rgw_role.cc:    ldout(cct, 0) << "ERROR: Invalid session duration, should be between 3600 and 43200 seconds " << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "create_default: error initializing zone params: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "create_default: error in create_default  zone params: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 10) << "zone_params::create_default() returned -EEXIST, we raced with another default zone_params creation" << dendl;
./rgw/rgw_zone.cc:      ldpp_dout(dpp, 0) << "create_default: error in init existing zone params: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "error storing zone group info: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 10) << "create_default() returned -EEXIST, we raced with another zonegroup creation" << dendl;
./rgw/rgw_zone.cc:        ldout(cct, 0) << "NOTICE: overriding master zone: " << master_zone << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "WARNING: could not read zone params for zone id=" << zone.id << " name=" << zone.name << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 10) << "could not read realm id: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:          ldout(cct, 0) << "error in read_id for object name: " << name << " : " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "error decoding data from " << pool << ":" << oid << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: failed to decode obj from " << pool << ":" << oid << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "Error delete default obj name  " << name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "Error delete obj name  " << name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error delete object id " << id << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error read_id " << new_name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error storing new obj info " << new_name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error storing new name " << new_name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error delete old obj name  " << old_name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "failed reading obj info from " << pool << ":" << oid << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: failed to decode obj from " << pool << ":" << oid << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 10) << "ERROR: name " << name << " already in use for obj id " << id << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "failed reading obj id  " << id << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR:  storing info for " << id << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 20) << __func__ << "(): store_info() returned ret=" << ret << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 20) << __func__ << "(): store_name() returned ret=" << ret << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR creating new realm object " << name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR creating control for new realm " << name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:      ldpp_dout(dpp, 0) << "ERROR: creating new period for realm " << name << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "ERROR: failed to init period " << current_period << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: failed set current period " << current_period << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "WARNING: failed to set realm as default realm, ret=" << ret << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: period update: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: period.reflect(): " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 1) << "error read_lastest_epoch " << pool << ":" << oid << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "error decoding data from " << pool << ":" << oid << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "ERROR: failed to read latest_epoch" << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "ERROR: failed to write latest_epoch" << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "failed reading obj info from " << pool << ":" << get_period_oid() << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: failed to decode obj from " << pool << ":" << get_period_oid() << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR:  storing info for " << id << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR: setting latest epoch " << id << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: updating period map: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:  ldout(cct, 20) << __func__ << " realm " << realm_id << " period " << get_id() << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "ERROR: failed to list zonegroups: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "WARNING: zg.init() failed: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 20) << "skipping zonegroup " << zg.get_name() << " zone realm id " << zg.realm_id << ", not on our realm " << realm_id << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "ERROR: zonegroup " << zg.get_name() << " should have a master zone " << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "ERROR: failed to store zonegroup info for zonegroup=" << iter.first << ": " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:  ldout(cct, 20) << __func__ << " realm " << realm_id << " period " << id << dendl;
./rgw/rgw_zone.cc:  ldpp_dout(dpp, 20) << __func__ << " realm " << realm.get_id() << " period " << current_period.get_id() << dendl;
./rgw/rgw_zone.cc:      ldpp_dout(dpp, 0) << "failed to create new period: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "failed to store period: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "failed to set latest epoch: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "failed to update local objects: " << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 0) << "Error: init zone " << iter << ":" << cpp_strerror(-r) << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 10) << "WARNING: store->list_zones() returned r=" << r << dendl;
./rgw/rgw_zone.cc:    ldout(cct, 0) << "Error: get_zones_pool_names" << r << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 10) << "couldn't find old data placement pools config, setting up new ones for the zone" << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 0) << "ERROR: fix_pool_names returned r=" << r << dendl;
./rgw/rgw_zone.cc:    ldpp_dout(dpp, 10) << "WARNING: failed to set zone as default, r=" << r << dendl;
./rgw/rgw_zone.cc:      ldout(cct, 10) << "could not read realm id: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_zone.cc:    ldout(cct,0) << "Error updating periodmap, multiple master zonegroups configured "<< dendl;
./rgw/rgw_zone.cc:    ldout(cct,0) << "master zonegroup: " << master_zonegroup << " and  " << zonegroup.get_id() <<dendl;
./rgw/services/svc_sys_obj_core.cc:      ldout(rados_svc->ctx(), 0) << "ERROR: obj.oid is empty" << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(rados_svc->ctx(), 0) << "ERROR: obj.oid is empty" << dendl;
./rgw/services/svc_sys_obj_core.cc:  ldpp_dout(dpp, 20) << "get_system_obj_state: rctx=" << (void *)rctx << " obj=" << obj << " state=" << (void *)s << " s->prefetch_data=" << s->prefetch_data << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldpp_dout(dpp, 20) << "get_system_obj_state: setting s->obj_tag to " << s->obj_tag.c_str() << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldpp_dout(dpp, 20) << "get_system_obj_state: s->obj_tag was set empty" << dendl;
./rgw/services/svc_sys_obj_core.cc:        ldpp_dout(dpp, 20) << "Read xattr: " << iter->first << dendl;
./rgw/services/svc_sys_obj_core.cc:  ldout(cct, 20) << "rados->read ofs=" << ofs << " len=" << len << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "rados_obj.operate() r=" << r << " bl.length=" << bl->length() << dendl;
./rgw/services/svc_sys_obj_core.cc:  ldout(cct, 20) << "rados_obj.operate() r=" << r << " bl.length=" << bl->length() << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 5) << "raced with an object write, abort" << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:  ldout(cct, 15) << "omap_set obj=" << obj << " key=" << key << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 20) << "get_rados_obj() on obj=" << obj << " returned " << r << dendl;
./rgw/services/svc_sys_obj_core.cc:    ldout(cct, 10) << "failed to list objects pool_iterate_begin() returned r=" << r << dendl;
./rgw/services/svc_sys_obj_core.cc:      ldout(cct, 10) << "failed to list objects pool_iterate returned r=" << r << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "ERROR: unregister_watch() returned ret=" << ret << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "ERROR: register_watch() returned ret=" << ret << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "ERROR: notify_obj.open() returned r=" << r << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "ERROR: notify_obj.operate() returned r=" << r << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "WARNING: register_watch_aio() returned " << r << dendl;
./rgw/services/svc_notify.cc:      ldout(cct, 0) << "WARNING: async watch returned " << r << dendl;
./rgw/services/svc_notify.cc:    ldout(cct, 0) << "ERROR: rados->unwatch2() returned r=" << r << dendl;
./rgw/services/svc_notify.cc:    ldout(cct, 0) << "ERROR: rados->watch_flush() returned r=" << r << dendl;
./rgw/services/svc_notify.cc:  ldout(cct, 20) << "add_watcher() i=" << i << dendl;
./rgw/services/svc_notify.cc:    ldout(cct, 2) << "all " << num_watchers << " watchers are set, enabling cache" << dendl;
./rgw/services/svc_notify.cc:  ldout(cct, 20) << "remove_watcher() i=" << i << dendl;
./rgw/services/svc_notify.cc:    ldout(cct, 2) << "removed watcher, disabling cache" << dendl;
./rgw/services/svc_notify.cc:	ldout(cct, 20) << "robust_notify: acked by " << id << dendl;
./rgw/services/svc_notify.cc:	      ldout(cct, 20) << "robust_notify: acked by " << id << dendl;
./rgw/services/svc_bi_rados.cc:    ldout(cct, 0) << "could not find placement rule " << *rule << " within zonegroup " << dendl;
./rgw/services/svc_bi_rados.cc:    ldout(cct, 0) << "ERROR: empty bucket_id for bucket operation" << dendl;
./rgw/services/svc_bi_rados.cc:    ldout(cct, 0) << "ERROR: empty bucket id for bucket operation" << dendl;
./rgw/services/svc_bi_rados.cc:    ldout(cct, 10) << "get_bucket_index_object() returned ret=" << ret << dendl;
./rgw/services/svc_bi_rados.cc:        ldpp_dout(dpp, -1) << "ERROR: failed writing data log (info.bucket=" << info.bucket << ", shard_id=" << shard_id << ")" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldpp_dout(dpp, 20) << "could not init bucket info for hint bucket=" << b << " ... skipping" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldpp_dout(dpp, 20) << "could not get bucket sync policy handler for hint bucket=" << hint_bucket << " ... skipping" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldpp_dout(dpp, 0) << "ERROR: svc.bucket->read_bucket_instance_info(key=" << bucket_key << ") returned r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:    ldpp_dout(dpp, 20) << "ERROR: could not find policy handler for zone=" << zone << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:    ldpp_dout(dpp, 20) << "ERROR: failed to init bucket sync policy handler: r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:    ldpp_dout(dpp, 20) << "ERROR: failed to resolve policy hints: bucket_key=" << bucket_key << ", r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:    ldpp_dout(dpp, 20) << "couldn't put bucket_sync_policy cache entry, might have raced with data changes" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldout(cct, 0) << "ERROR: cannot update hint index: failed to read: r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: failed to flush hint index: obj=" << obj << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:  ldout(cct, 0) << "ERROR: failed to flush hint index: too many retries (obj=" << obj << "), likely a bug" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:    ldout(cct, 0) << "ERROR: failed reading data (obj=" << obj << "), r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to decode entries, ignoring" << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << bucket_info.bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << dest_bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << dest_bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << bucket_info.bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << source_bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:        ldout(cct, 0) << "ERROR: failed to update targets index for bucket=" << source_bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:  ldout(cct, 20) << __func__ << "(): bucket=" << bucket_info.bucket << ": orig_sources=" << orig_sources << " new_sources=" << sources << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:  ldout(cct, 20) << __func__ << "(): bucket=" << bucket_info.bucket << ":  potential sources added=" << added_sources << " removed=" << removed_sources << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:  ldout(cct, 20) << __func__ << "(): bucket=" << bucket_info.bucket << ": orig_dests=" << orig_dests << " new_dests=" << dests << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:  ldout(cct, 20) << __func__ << "(): bucket=" << bucket_info.bucket << ":  potential dests added=" << added_dests << " removed=" << removed_dests << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: failed to update sources index for bucket=" << bucket << " r=" << r << dendl;
./rgw/services/svc_bucket_sync_sobj.cc:      ldout(cct, 0) << "ERROR: failed to read targets index for bucket=" << bucket << " r=" << r << dendl;
./rgw/services/svc_meta.cc:    ldout(cct, 0) << __func__ << "(): ERROR: backend type not found" << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to create be handler: r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to create be handler: r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: could not decode buffer info, caught buffer::error" << dendl;
./rgw/services/svc_bucket_sobj.cc:      ldpp_dout(dpp, -1) << "ERROR: do_read_bucket_instance_info failed: " << ret << dendl;
./rgw/services/svc_bucket_sobj.cc:      ldpp_dout(dpp, 20) << "do_read_bucket_instance_info, bucket instance not found (key=" << key << ")" << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 20) << "couldn't put binfo cache entry, might have raced with data changes" << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: could not decode buffer info, caught buffer::error" << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 20) << "rgw_get_bucket_info: old bucket info, bucket=" << info->bucket << " owner " << info->owner << dendl;
./rgw/services/svc_bucket_sobj.cc:  ldpp_dout(dpp, 20) << "rgw_get_bucket_info: bucket instance: " << entry_point.bucket << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, -1) << "ERROR: read_bucket_instance_from_oid failed: " << ret << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 20) << "couldn't put binfo cache entry, might have raced with data changes" << dendl;
./rgw/services/svc_bucket_sobj.cc:        ldpp_dout(dpp, 0) << "ERROR: " << __func__ << "(): read_bucket_instance_info() of key=" << key << " returned r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:      ldpp_dout(dpp, 0) << "ERROR: " << __func__ << "(): svc.bi->handle_overwrite() of key=" << key << " returned r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to update bucket instance sync index: r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:    ldpp_dout(dpp, 0) << "ERROR: " << __func__ << "(): read_stats returned r=" << r << dendl;
./rgw/services/svc_bucket_sobj.cc:      ldpp_dout(dpp, 0) << "ERROR: " << __func__ << "(): read_bucket_stats returned r=" << r << dendl;
./rgw/services/svc_rados.cc:    ldout(cct, 20) << "RGWRados::pool_iterate: got " << oid << dendl;
./rgw/services/svc_rados.cc:    ldout(rados_svc->cct, 0) << "WARNING: pool_create returned " << r << dendl;
./rgw/services/svc_rados.cc:    ldout(rados_svc->cct, 0) << "WARNING: ioctx_create returned " << r << dendl;
./rgw/services/svc_rados.cc:    ldout(rados_svc->cct, 0) << "WARNING: application_enable returned " << r << dendl;
./rgw/services/svc_rados.cc:        ldout(rados_svc->cct, 0) << "WARNING: async pool_create returned " << r << dendl;
./rgw/services/svc_rados.cc:      ldout(rados_svc->cct, 0) << "WARNING: ioctx_create returned " << ret << dendl;
./rgw/services/svc_rados.cc:    ldout(pool->rados_svc->cct, 10) << "failed to parse cursor: " << marker << dendl;
./rgw/services/svc_rados.cc:      ldout(pool->rados_svc->cct, 10) << "failed to list objects pool_iterate returned r=" << r << dendl;
./rgw/services/svc_rados.cc:  ldout(cct, 20) << __func__ << "(): auth registy supported: methods=" << methods << " modes=" << modes << dendl;
./rgw/services/svc_rados.cc:      ldout(cct, 20) << __func__ << "(): method " << method << " is insecure" << dendl;
./rgw/services/svc_rados.cc:      ldout(cct, 20) << __func__ << "(): mode " << mode << " is insecure" << dendl;
./rgw/services/svc_zone.cc:    ldpp_dout(dpp, 0) << "failed reading realm info: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldpp_dout(dpp, 20) << "realm  " << realm->get_name() << " " << realm->get_id() << dendl;
./rgw/services/svc_zone.cc:      ldpp_dout(dpp, 0) << "failed reading current period info: " << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldpp_dout(dpp, 20) << "current period " << current_period->get_id() << dendl;  
./rgw/services/svc_zone.cc:    ldpp_dout(dpp, -1) << "failed converting region to zonegroup : ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldpp_dout(dpp, -1) << "failed converting regionmap: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 10) << " cannot find current period zonegroup using local zonegroup" << dendl;
./rgw/services/svc_zone.cc:  ldout(cct, 10) << "Cannot find current period zone using local zone" << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 10) << " Using default name "<< default_zone_name << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 1) << "Cannot find zone id=" << zone_params->get_id() << " (name=" << zone_params->get_name() << "), switching to local zonegroup configuration" << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 20) << "zone " << zone_params->get_name() << " found"  << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "WARNING: could not find zone config in zonegroup for local zone (" << zone_id() << "), will use defaults" << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << "WARNING: can't generate connection for zone " << z.id << " id " << z.name << ": no endpoints defined" << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 20) << "generating connection object for zone " << z.name << " id " << z.id << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 20) << "NOTICE: not syncing to/from zone " << z.name << " id " << z.id << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 20) << "System already converted " << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) <<  __func__ << " failed init default region: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) <<  __func__ << " failed reading old default region: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) <<  __func__ << " failed to list regions: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << ": error initializing default zone params: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << ": error in initializing default zonegroup: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:	  ldout(cct, 0) <<  __func__ << " failed init region "<< *iter << ": " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) <<  __func__ << " Error initing new realm: " << cpp_strerror(-ret)  << dendl;
./rgw/services/svc_zone.cc:      ldpp_dout(dpp, 0) <<  __func__ << " Error creating new realm: " << cpp_strerror(-ret)  << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " Error setting realm as default: " << cpp_strerror(-ret)  << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " Error initing realm: " << cpp_strerror(-ret)  << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " Error initing current period: " << cpp_strerror(-ret)  << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << __func__ << " Converting  " << *iter << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " failed init zonegroup: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " Setting default zone as master for default region" << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " Converting zone" << iter->first << dendl;
./rgw/services/svc_zone.cc:        ldout(cct, 0) << __func__ << " failed to init zoneparams  " << iter->first <<  ": " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:        ldout(cct, 0) << __func__ << " zone is part of another cluster " << iter->first <<  " skipping " << dendl;
./rgw/services/svc_zone.cc:        ldout(cct, 0) << __func__ << " failed to update zoneparams " << iter->first <<  ": " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:        ldout(cct, 0) << __func__ << " failed to init zoneparams " << iter->first <<  ": " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:        ldout(cct, 0) << __func__ << " failed to add zonegroup to current_period: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " failed to update new period: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " failed to store new period: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " failed to update local objects: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << __func__ << " failed init zonegroup" << iter << ": ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:  ldout(cct, 20) << "period zonegroup init ret " << ret << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "failed reading zonegroup info: " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:  ldout(cct, 20) << "period zonegroup name " << zonegroup->get_name() << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 20) << "using current period zonegroup " << zonegroup->get_name() << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << "failed init zonegroup: " << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << "failed reading zone params info: " << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 10) << " Using default name "<< default_zone_name << dendl;
./rgw/services/svc_zone.cc:       ldout(cct, 0) << "failed reading zone params info: " << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:	    ldout(cct, 0) << "error updating zonegroup : " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:	    ldout(cct, 0) << "error initializing zonegroup : " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:	    ldout(cct, 0) << "error initializing zonegroup : " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "failed reading zonegroup info: ret "<< ret << " " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 10) << "Creating default zonegroup " << dendl;
./rgw/services/svc_zone.cc:  ldpp_dout(dpp, 20) << "zonegroup " << zonegroup->get_name() << dendl;
./rgw/services/svc_zone.cc:	  ldout(cct, 0) << "error initializing zonegroup : " << cpp_strerror(-ret) << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "error decoding regionmap from " << pool << ":" << oid << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "could not find zonegroup " << zonegroup_id << " in current period" << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << "misconfiguration, zonegroup default placement id should not be empty." << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "user not permitted to use placement rule " << titer->first  << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 5) << "requested storage class does not exist: " << storage_class << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "ERROR: couldn't decode avail_pools" << dendl;
./rgw/services/svc_zone.cc:      ldout(cct, 0) << "WARNING: could not save avail pools map info ret=" << ret << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "WARNING: could not save avail pools map info ret=" << ret << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "ERROR: cannot find entry for redirect zone: " << zone_public_config->redirect_zone << dendl;
./rgw/services/svc_zone.cc:    ldout(cct, 0) << "ERROR: redirect zone, conn->get_endpoint() returned ret=" << ret << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to create be handler: r=" << r << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 20) << "RGWSI_User_RADOS::read_user_info(): anonymous user" << dendl;
./rgw/services/svc_user_rados.cc:      ldpp_dout(dpp, -1)  << "ERROR: rgw_get_user_info_by_uid(): user id mismatch: " << user_id.user_id << " != " << user << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to decode user info, caught buffer::error" << dendl;
./rgw/services/svc_user_rados.cc:        ldpp_dout(dpp, 0) << "WARNING: can't store user info, access key already mapped to another user" << dendl;
./rgw/services/svc_user_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: tenant mismatch: " << old_info.user_id.tenant << " != " << new_info.user_id.tenant << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 10) << "removing key index: " << kiter->first << dendl;
./rgw/services/svc_user_rados.cc:      ldout(cct, 0) << "ERROR: could not remove " << kiter->first << " (access key object), should be fixed (err=" << ret << ")" << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 10) << "removing swift subuser index: " << k.id << dendl;
./rgw/services/svc_user_rados.cc:      ldout(cct, 0) << "ERROR: could not remove " << k.id << " (swift name object), should be fixed (err=" << ret << ")" << dendl;
./rgw/services/svc_user_rados.cc:  ldpp_dout(dpp, 10) << "removing email index: " << info.user_email << dendl;
./rgw/services/svc_user_rados.cc:  ldpp_dout(dpp, 10) << "removing user buckets index" << dendl;
./rgw/services/svc_user_rados.cc:    ldout(cct, 0) << "ERROR: could not remove " << info.user_id << ":" << uid_bucks << ", should be fixed (err=" << ret << ")" << dendl;
./rgw/services/svc_user_rados.cc:  ldpp_dout(dpp, 10) << "removing user index: " << user_info.user_id << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: could not remove " << user_info.user_id << ":" << uid_obj << ", should be fixed (err=" << ret << ")" << dendl;
./rgw/services/svc_user_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to decode user info, caught buffer::error" << dendl;
./rgw/services/svc_user_rados.cc:    ldout(cct, 0) << "ERROR: error adding bucket to user: ret=" << ret << dendl;
./rgw/services/svc_user_rados.cc:    ldout(cct, 0) << "ERROR: error removing bucket from user: ret=" << ret << dendl;
./rgw/services/svc_user_rados.cc:    ldout(cct, 20) << "cls_user_update_buckets() returned " << r << dendl;
./rgw/services/svc_user_rados.cc:    ldout(cct, 20) << "RGWSI_User_RADOS::list_buckets(): anonymous user" << dendl;
./rgw/services/svc_meta_be_sobj.cc:    ldout(cct, 0) << "ERROR: possible bug: " << __FILE__ << ":" << __LINE__ << ":" << __func__ << "(): bad variant access" << dendl;
./rgw/services/svc_cls.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start mfa service" << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 4) << "failed to open rados context for " << o << dendl;
./rgw/services/svc_cls.cc:  ldout(cct, 20) << "OTP check, otp_id=" << otp_id << " result=" << (int)result.result << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 20) << "OTP create, otp_id=" << config.id << " result=" << (int)r << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 20) << "OTP remove, otp_id=" << id << " result=" << (int)r << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 4) << "failed to open rados context for " << o << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 20) << "OTP set entries.size()=" << entries.size() << " result=" << (int)r << dendl;
./rgw/services/svc_cls.cc:    ldout(cct, 4) << "failed to open rados context for " << o << dendl;
./rgw/services/svc_mdlog.cc:      ldpp_dout(dpp, 0) << "ERROR: meta history is empty, but cannot remove it (" << cpp_strerror(-ret) << ")" << dendl;
./rgw/services/svc_mdlog.cc:  ldout(cct, 10) << "find_oldest_period returning empty cursor" << dendl;
./rgw/services/svc_mdlog.cc:    ldpp_dout(dpp, 10) << "initializing mdlog history" << dendl;
./rgw/services/svc_mdlog.cc:    ldout(cct, 10) << "rewriting mdlog history" << dendl;
./rgw/services/svc_otp.cc:    ldout(ctx(), 0) << "ERROR: failed to create be handler: r=" << r << dendl;
./rgw/services/svc_bilog_rados.cc:  ldout(cct, 20) << __func__ << ": " << bucket_info.bucket << " marker " << marker << " shard_id=" << shard_id << " max " << max << dendl;
./rgw/services/svc_sys_obj_cache.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to distribute cache: r=" << r << dendl;
./rgw/services/svc_sys_obj_cache.cc:      ldout(cct, 0) << "ERROR: failed to distribute cache for " << obj << dendl;
./rgw/services/svc_sys_obj_cache.cc:      ldout(cct, 0) << "ERROR: failed to distribute cache for " << obj << dendl;
./rgw/services/svc_sys_obj_cache.cc:      ldout(cct, 0) << "ERROR: failed to distribute cache for " << obj << dendl;
./rgw/services/svc_sys_obj_cache.cc:    ldout(cct, 0) << "ERROR: got bad notification" << dendl;
./rgw/services/svc_sys_obj_cache.cc:    ldout(cct, 0) << "ERROR: buffer::error" << dendl;
./rgw/services/svc_sys_obj_cache.cc:    ldout(cct, 0) << "WARNING: got unknown notification op: " << info.op << dendl;
./rgw/services/svc_sync_modules.cc:  ldpp_dout(dpp, 20) << "started sync module instance, tier type = " << zone_public_config.tier_type << dendl;
./rgw/librgw.cc:  dout(20) << __func__ << " SIGUSR1 ignored" << dendl;
./rgw/librgw.cc:      lsubdout(cct, rgw, 5) << "RGWLibProcess GC" << dendl;
./rgw/librgw.cc:      dout(20) << "process_request() returned " << ret << dendl;
./rgw/librgw.cc:      dout(20) << "process_request() returned " << ret << dendl;
./rgw/librgw.cc:      ldpp_dout(op, 1) << "failed to derive cognate RGWOp (invalid op?)" << dendl;
./rgw/librgw.cc:      ldpp_dout(op, 10) << "failed to initialize request" << dendl;
./rgw/librgw.cc:      dout(10) << "failed to initialize RGWOp" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "authorizing" << dendl;
./rgw/librgw.cc:	dout(10) << "failed to authorize request" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "reading op permissions" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "init op" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "verifying op mask" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "verifying op permissions" << dendl;
./rgw/librgw.cc:	  ldpp_dout(op, 2) << "overriding permissions due to system operation" << dendl;
./rgw/librgw.cc:	  ldpp_dout(op, 2) << "overriding permissions due to admin operation" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "verifying op params" << dendl;
./rgw/librgw.cc:      ldpp_dout(s, 2) << "executing" << dendl;
./rgw/librgw.cc:      dout(0) << "authentication failed" << e.what() << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "http status=" << http_ret << dendl;
./rgw/librgw.cc:      ldpp_dout(op, 1) << "failed to derive cognate RGWOp (invalid op?)" << dendl;
./rgw/librgw.cc:      ldpp_dout(op, 10) << "failed to initialize request" << dendl;
./rgw/librgw.cc:      dout(10) << "failed to initialize RGWOp" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "authorizing" << dendl;
./rgw/librgw.cc:      dout(10) << "failed to authorize request" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "reading op permissions" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "init op" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "verifying op mask" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "verifying op permissions" << dendl;
./rgw/librgw.cc:	ldpp_dout(op, 2) << "overriding permissions due to system operation" << dendl;
./rgw/librgw.cc:	ldpp_dout(op, 2) << "overriding permissions due to admin operation" << dendl;
./rgw/librgw.cc:    ldpp_dout(s, 2) << "verifying op params" << dendl;
./rgw/librgw.cc:      ldpp_dout(op, 1) << "failed to derive cognate RGWOp (invalid op?)" << dendl;
./rgw/librgw.cc:    dout(1) << "final shutdown" << dendl;
./rgw/rgw_rest_iam.cc:    ldout(s->cct, 10) << "Content of POST: " << post_body << dendl;
./rgw/rgw_rest_iam.cc:    ldout(s->cct, 10) << "init_from_header returned err=" << ret <<  dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "cache get: name=" << name << " : miss" << dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "cache get: name=" << name << " : expiry miss" << dendl;
./rgw/rgw_cache.cc:      ldout(cct, 10) << "lost race! cache get: name=" << name << " : miss" << dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "cache get: name=" << name << " : hit (negative entry)" << dendl;
./rgw/rgw_cache.cc:      ldout(cct, 20) << "chain_cache_entry: couldn't find cache locator" << dendl;
./rgw/rgw_cache.cc:      ldout(cct, 10) << "updating xattr: name=" << iter->first << " bl.length()=" << iter->second.length() << dendl;
./rgw/rgw_cache.cc:      ldout(cct, 10) << "removing xattr: name=" << iter->first << dendl;
./rgw/rgw_cache.cc:      ldout(cct, 10) << "appending xattr: name=" << iter->first << " bl.length()=" << iter->second.length() << dendl;
./rgw/rgw_cache.cc:  ldout(cct, 10) << "removing " << name << " from cache" << dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "removing entry: name=" << *iter << " from cache LRU" << dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "adding " << name << " to cache LRU end" << dendl;
./rgw/rgw_cache.cc:    ldout(cct, 10) << "moving " << name << " to cache LRU end" << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(cct, 0) << "ERROR: could not parse configurable value for cloud sync module: " << key << ": " << sval << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(cct, 0) << "ERROR: ambiguous profile connection configuration, connection_id=" << profile.connection_id << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(cct, 0) << "ERROR: profile configuration reference non-existent connection_id=" << profile.connection_id << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(cct, 0) << "ERROR: remote connection undefined for sync profile" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(cct, 0) << "ERROR: profile configuration reference non-existent acls id=" << profile.acls_id << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(cct, 0) << "WARNING: duplicate target configuration in sync module" << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(cct, 5) << "sync module config (parsed representation):\n" << ss.str() << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(sc->cct, 20) << "updated target: (root) -> " << root_profile->target_path << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(sc->cct, 20) << "updated target: " << t.first << " -> " << t.second->target_path << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(cct, 0) << "ERROR: failed to decode policy off attrs" << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(cct, 0) << "WARNING: acl attrs not provided" << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(sc->cct, 0) << "ERROR: " << __func__ << "(): conn->get_obj() returned ret=" << ret << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(sc->cct, 20) << __func__ << ":" << " headers=" << headers << " extra_data.length()=" << extra_data.length() << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to parse response extra data. len=" << extra_data.length() << " data=" << extra_data.c_str() << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(cct, 20) << "acl_mappings: Could not find " << orig_grantee << " .. ignoring" << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(cct, 20) << "acl_mappings: set acl: " << header_str << "=" << s << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to get etag from PUT request" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to abort multipart upload for dest object=" << dest_obj << " (retcode=" << retcode << ")" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to initialize multipart upload for dest object=" << dest_obj << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 0) << "ERROR: failed to initialize xml parser for parsing multipart init response from server" << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 5) << "ERROR: failed to parse xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 5) << "ERROR: unexpected xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(sc->cct, 20) << "init multipart result: bucket=" << result.bucket << " key=" << result.key << " upload_id=" << result.upload_id << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to initialize multipart upload for dest object=" << dest_obj << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 0) << "ERROR: failed to initialize xml parser for parsing multipart init response from server" << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 5) << "ERROR: failed to parse xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 5) << "ERROR: unexpected xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:      ldout(sc->cct, 20) << "complete multipart result: location=" << result.location << " bucket=" << result.bucket << " key=" << result.key << " etag=" << result.etag << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to abort multipart upload dest obj=" << dest_obj << " upload_id=" << upload_id << " retcode=" << retcode << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to remove sync status obj obj=" << status_obj << " retcode=" << retcode << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to read sync status of object " << src_obj << " retcode=" << retcode << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 0) << "ERROR: failed to sync obj=" << src_obj << ", sync via multipart upload, upload_id=" << status.upload_id << " part number " << status.cur_part << " (error: " << cpp_strerror(-retcode) << ")" << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 0) << "ERROR: failed to store multipart upload state, retcode=" << retcode << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 20) << "sync of object=" << src_obj << " via multipart upload, finished sending part #" << status.cur_part << " etag=" << pcur_part_info->etag << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to complete multipart upload of obj=" << src_obj << " (error: " << cpp_strerror(-retcode) << ")" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to abort multipart upload obj=" << src_obj << " upload_id=" << status.upload_id << " part number " << status.cur_part << " (" << cpp_strerror(-retcode) << ")" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: failed to decode pg ver attr, ignoring" << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct, 0) << "ERROR: failed to decode source zone short_id attr, ignoring" << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "ERROR: cannot find http connection to zone " << sc->source_zone << dendl;
./rgw/rgw_sync_module_aws.cc:          ldout(sc->cct,0) << "AWS: creating bucket " << target_bucket_name << dendl;
./rgw/rgw_sync_module_aws.cc:            ldout(sc->cct, 0) << "ERROR: failed to initialize xml parser for parsing multipart init response from server" << dendl;
./rgw/rgw_sync_module_aws.cc:            ldout(sc->cct, 5) << "ERROR: failed to parse xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:            ldout(sc->cct, 5) << "ERROR: unexpected xml: " << str << dendl;
./rgw/rgw_sync_module_aws.cc:            ldout(sc->cct, 0) << "ERROR: failed to decode rest obj out of headers=" << headers << ", attrs=" << attrs << dendl;
./rgw/rgw_sync_module_aws.cc:        ldout(sc->cct, 0) << "AWS: removing aws object at" << path << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(sc->cct, 0) << instance.id << ": sync_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " versioned_epoch=" << versioned_epoch.value_or(0) << dendl;
./rgw/rgw_sync_module_aws.cc:    ldout(sc->cct, 0) <<"rm_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
./rgw/rgw_bucket_sync.cc:      ldout(cct, 20) << __func__ << "(): pipe_map (zone=" << zone << " bucket=" << bucket_key << "): adding potential pipe: " << pipe << dendl;
./rgw/rgw_bucket_sync.cc:      ldout(cct, 20) << __func__ << "(): flow manager (bucket=" << effective_bucket_key << "): adding source pipe: " << pipe << dendl;
./rgw/rgw_bucket_sync.cc:      ldout(cct, 20) << __func__ << "(): flow manager (bucket=" << effective_bucket_key << "): adding dest pipe: " << pipe << dendl;
./rgw/rgw_cors_s3.cc:      dout(10) << "RGWCORSRule::xml_end, el : " << el << ", data : " << s << dendl;
./rgw/rgw_cors_s3.cc:      dout(0) << "RGWCORSRule has id of length greater than 255" << dendl;
./rgw/rgw_cors_s3.cc:    dout(10) << "RGWCORRule id : " << data << dendl;  
./rgw/rgw_cors_s3.cc:    dout(0) << "RGWCORSRule does not have even one AllowedOrigin" << dendl;
./rgw/rgw_cors_s3.cc:    dout(10) << "RGWCORSRule - origin : " << obj->get_data() << dendl;
./rgw/rgw_cors_s3.cc:      dout(0) << "RGWCORSRule's MaxAgeSeconds " << obj->get_data() << " is an invalid integer" << dendl;
./rgw/rgw_cors_s3.cc:    dout(10) << "RGWCORSRule : max_age : " << max_age << dendl;
./rgw/rgw_cors_s3.cc:      dout(10) << "RGWCORSRule - exp_hdr : " << obj->get_data() << dendl;
./rgw/rgw_cors_s3.cc:      dout(10) << "RGWCORSRule - allowed_hdr : " << obj->get_data() << dendl;
./rgw/rgw_cors_s3.cc:    dout(0) << "CORSConfiguration should have atleast one CORSRule" << dendl;
./rgw/rgw_asio_frontend.cc:      ldout(cct, 4) << "write_data failed: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:        ldout(cct, 4) << "failed to read body: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:      ldout(cct, 20) << "failed to read header: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:      ldout(cct, 1) << "failed to read header: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:        ldout(cct, 5) << "failed to write response: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:      ldout(cct, 1) << "====== req done http_status=400 ======" << dendl;
./rgw/rgw_asio_frontend.cc:        ldout(cct, 1) << "failed to lock: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:        ldout(cct, 1) << "failed to connect client: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx, -1) << "unable to setgid " << gid << ": " << cpp_strerror(err) << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx, -1) << "unable to setuid " << uid << ": " << cpp_strerror(err) << dendl;
./rgw/rgw_asio_frontend.cc:        ldout(ctx(), 0) << "WARNING: invalid value for max_connection_backlog=" << it->second << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx(), 4) << "frontend listening on " << l.endpoint << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx(), 1) << "accept failed: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:          ldout(ctx(), 1) << "ssl handshake failed: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(cct, 4) << "frontend spawning " << thread_count << " threads" << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(ctx(), 4) << "frontend initiating shutdown..." << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(ctx(), 4) << "frontend joining threads..." << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(ctx(), 4) << "frontend done" << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(ctx(), 4) << "frontend pausing connections..." << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx(), 1) << "frontend failed to pause: " << ec.message() << dendl;
./rgw/rgw_asio_frontend.cc:    ldout(ctx(), 4) << "frontend paused" << dendl;
./rgw/rgw_asio_frontend.cc:  ldout(ctx(), 4) << "frontend unpaused" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "EVP: failed to 1st initialization stage" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "EVP: failed to 2nd initialization stage" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "EVP: cannot disable PKCS padding" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "EVP: EVP_CipherUpdate failed" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "EVP: EVP_CipherFinal_ex failed" << dendl;
./rgw/rgw_crypt.cc:      ldout(cct, 25) << "Encrypted " << size << " bytes"<< dendl;
./rgw/rgw_crypt.cc:      ldout(cct, 5) << "Failed to encrypt" << dendl;
./rgw/rgw_crypt.cc:      ldout(cct, 25) << "Decrypted " << size << " bytes"<< dendl;
./rgw/rgw_crypt.cc:      ldout(cct, 5) << "Failed to decrypt" << dendl;
./rgw/rgw_crypt.cc:    ldout(cct, 5) << "Key size must be 256 bits long" << dendl;
./rgw/rgw_crypt.cc:      ldout(cct, 0) << "ERROR: couldn't decode manifest" << dendl;
./rgw/rgw_crypt.cc:        ldout(cct, 20) << "Manifest part " << i << ", size=" << parts_len[i] << dendl;
./rgw/rgw_crypt.cc:  ldout(cct, 25) << "Decrypt " << bl_len << " bytes" << dendl;
./rgw/rgw_crypt.cc:  ldout(cct, 25) << "Decrypt flushing " << cache.length() << " bytes" << dendl;
./rgw/rgw_crypt.cc:  ldout(cct, 25) << "Encrypt " << data.length() << " bytes" << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 5) << "ERROR: Insecure request, rgw_crypt_require_ssl is set" << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 5) << "ERROR: invalid encryption key size" << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 5) << "ERROR: Invalid key md5 size" << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 5) << "ERROR: Invalid key md5 hash" << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 5) << "ERROR: insecure request, rgw_crypt_require_ssl is set" << dendl;
./rgw/rgw_crypt.cc:	  ldout(s->cct, 5) << "ERROR: not provide a valid key id" << dendl;
./rgw/rgw_crypt.cc:	  ldout(s->cct, 5) << "ERROR: failed to retrieve actual key from key_id: " << key_id << dendl;
./rgw/rgw_crypt.cc:        ldout(s->cct, 0) << "ERROR: failed to decode 'rgw crypt default encryption key' to 256 bit string" << dendl;
./rgw/rgw_crypt.cc:  ldout(s->cct, 15) << "Encryption mode: " << stored_mode << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 5) << "ERROR: Insecure request, rgw_crypt_require_ssl is set" << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 5) << "ERROR: The requested encryption algorithm is not valid, must be AES256." << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 5) << "ERROR: Invalid encryption key size" << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 5) << "ERROR: Invalid key md5 size " << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 5) << "ERROR: Insecure request, rgw_crypt_require_ssl is set" << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 10) << "ERROR: failed to retrieve actual key from key_id: " << key_id << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 0) << "ERROR: failed to decode 'rgw crypt default encryption key' to 256 bit string" << dendl;
./rgw/rgw_crypt.cc:      ldout(s->cct, 0) << "ERROR: missing or invalid " RGW_ATTR_CRYPT_KEYSEL << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: No AES cryto handler found !" << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: Invalid rgw sts key, please ensure its length is 16" << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: No Key handler found !" << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: Encrypting session token returned an error !" << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: error message is empty !" << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: Incorrect value of duration: " << duration << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: Incorrect size of iamPolicy: " << iamPolicy.size() << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "ERROR: Incorrect size of roleArn: " << roleArn.size() << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "ERROR: Either role session name is empty or role session size is incorrect: " << roleSessionName.size() << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "ERROR: Role session name is incorrect: " << roleSessionName << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "ERROR: Either provider id is empty or provider id length is incorrect: " << providerId.length() << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "ERROR: Either external id is empty or external id length is incorrect: " << externalId.length() << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "ERROR: Invalid external Id: " << externalId << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "Either serial number is empty or serial number length is incorrect: " << serialNumber.size() << dendl;
./rgw/rgw_sts.cc:      ldout(cct, 0) << "Incorrect serial number: " << serialNumber << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "Either token code is empty or token code size is invalid: " << tokenCode.size() << dendl;
./rgw/rgw_sts.cc:        ldpp_dout(dpp, 0) << "Role doesn't exist: " << roleName << dendl;
./rgw/rgw_sts.cc:        ldpp_dout(dpp, 0) << "Invalid Role ARN: Path in ARN does not match with the role path: " << path << " " << r_path << dendl;
./rgw/rgw_sts.cc:    ldpp_dout(dpp, 0) << "Invalid role arn: " << arn << dendl;
./rgw/rgw_sts.cc:    ldout(cct, 0) << "Error in parsing role arn: " << req.getRoleARN() << dendl;
./rgw/rgw_sts.cc:    ldpp_dout(dpp, 0) << "Error in parsing role arn: " << req.getRoleARN() << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "CreateTopic Action 'Name' argument is missing" << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "CreateTopic Action failed to create queue for persistent topics. error:" << ret << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "GetTopic Action 'TopicArn' argument is missing or invalid" << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "GetTopicAttribute Action 'TopicArn' argument is missing or invalid" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "DeleteTopic Action 'TopicArn' argument is missing or invalid" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "DeleteTopic Action failed to remove queue for persistent topics. error:" << ret << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 10) << "Content of POST: " << post_body << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to read XML payload" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "XML payload missing" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to initialize XML parser" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to parse XML payload" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to parse XML payload. error: " << err << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "missing required param 'notification'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "param 'notification' should not have any value" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "request must be on a bucket" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "missing notification id" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "missing topic ARN in notification: '" << notif_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "topic ARN has invalid format: '" << c.topic_arn << "' in notification: '" << notif_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "unknown event type in notification: '" << notif_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to get topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 20) << "successfully auto-generated unique topic '" << unique_topic_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 20) << "successfully auto-generated notification for unique topic '" << unique_topic_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "failed to auto-generate subscription '" << notif_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 20) << "successfully auto-generated subscription '" << notif_name << "'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "missing required param 'notification'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "request must be on a bucket" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to remove notification of topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "failed to remove auto-generated topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 1) << "failed to get list of topics from bucket '" << bucket_info.bucket.name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "failed to remove auto-generated subscription '" << notif_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 20) << "notification '" << notif_name << "' already removed" << dendl;
./rgw/rgw_rest_pubsub.cc:        ldout(s->cct, 1) << "failed to get subscription '" << topic_sub_name << "' info, ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:          ldout(s->cct, 1) << "failed to remove auto-generated subscription '" << topic_sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "missing required param 'notification'" << dendl;
./rgw/rgw_rest_pubsub.cc:      ldout(s->cct, 1) << "request must be on a bucket" << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 1) << "failed to get list of topics from bucket '" << bucket_info.bucket.name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub.cc:    ldout(s->cct, 1) << "failed to get notification info for '" << notif_name << "', ret=" << op_ret << dendl;
./rgw/rgw_auth_keystone.cc:  ldpp_dout(dpp, 20) << "token_id=" << token_id << dendl;
./rgw/rgw_auth_keystone.cc:    ldpp_dout(dpp, 0) << "Keystone credential parse error: malformed json" << dendl;
./rgw/rgw_auth_keystone.cc:      ldpp_dout(dpp, 0) << "Keystone credential not present in return from server" << dendl;
./rgw/rgw_auth_keystone.cc:    ldpp_dout(dpp, 0) << "Keystone credential parse error: " << err.what() << dendl;
./rgw/rgw_auth_keystone.cc:      ldpp_dout(dpp, 0) << "Secret string does not correctly sign payload, cache miss" << dendl;
./rgw/rgw_auth_keystone.cc:    ldpp_dout(dpp, 0) << "No stored secret string, cache miss" << dendl;
./rgw/rgw_realm_watcher.cc:    ldout(cct, 4) << "No realm, disabling dynamic reconfiguration." << dendl;
./rgw/rgw_realm_watcher.cc:  ldout(cct, 10) << "Watching " << oid << dendl;
./rgw/rgw_rest_user_policy.cc:    ldout(s->cct, 0) << "ERROR: Invalid policy name length " << dendl;
./rgw/rgw_rest_user_policy.cc:    ldout(s->cct, 0) << "ERROR: Invalid chars in policy name " << dendl;
./rgw/rgw_rest_user_policy.cc:    ldpp_dout(this, 0) << "ERROR: forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user_policy.cc:    ldout(s->cct, 20) << "failed to parse policy: " << e.what() << dendl;
./rgw/rgw_rest_user_policy.cc:    ldpp_dout(this, 0) << "ERROR: attrs not found for user" << user_name << dendl;
./rgw/rgw_rest_user_policy.cc:        ldpp_dout(this, 0) << "ERROR: policy not found" << policy << dendl;
./rgw/rgw_rest_user_policy.cc:      ldpp_dout(this, 0) << "ERROR: RGW_ATTR_USER_POLICY not found" << dendl;
./rgw/rgw_rest_user_policy.cc:    ldout(s->cct, 20) << "ERROR: user name is empty" << dendl;
./rgw/rgw_rest_user_policy.cc:    ldpp_dout(this, 0) << "ERROR: attrs not found for user" << user_name << dendl;
./rgw/rgw_rest_user_policy.cc:      ldpp_dout(this, 0) << "ERROR: RGW_ATTR_USER_POLICY not found" << dendl;
./rgw/rgw_rest_user_policy.cc:    ldout(s->cct, 20) << "ERROR: One of policy name or user name is empty"<< dendl;
./rgw/rgw_rest_user_policy.cc:      ldpp_dout(this, 5) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user_policy.cc:    ldpp_dout(this, 0) << "ERROR: forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_swift.cc:      dout(0) << "Error creating/updating the cors configuration" << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(this, 20) << "neither length nor chunked encoding" << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "content type wasn't provided, trying to guess" << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "ERROR: failed to get Delete-At param" << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(this, 5) << "invalid multipart-manifest http param: " << multipart_manifest << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(this, 5) << "failed to read input for slo r=" << r << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(this, 5) << "too many entries in slo request: " << slo_info->entries.size() << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "ERROR: failed to get Delete-At param" << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "ERROR: failed to get Delete-At param" << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 20) << "extracted Bulk Delete entry: " << path_str << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(dpp, 20) << "bulk_upload: get_exactly want=" << want << dendl;
./rgw/rgw_rest_swift.cc:      ldpp_dout(dpp, 20) << "bulk_upload: get_exactly ret=" << ret << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(dpp, 5) << "failed to parse siginfo_expires: " << err << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(dpp, 5) << "siginfo expired: " << expiration << " <= " << now.sec() << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "failed to parse FormPost's expires: " << err << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(this, 5) << "cannot get user_info of account's owner" << dendl;
./rgw/rgw_rest_swift.cc:        ldpp_dout(this, 20) << "field.name=" << pair.first << dendl;
./rgw/rgw_rest_swift.cc:        ldpp_dout(this, 20) << "field.val=" << pair.second.val << dendl;
./rgw/rgw_rest_swift.cc:        ldpp_dout(this, 20) << "field.params:" << dendl;
./rgw/rgw_rest_swift.cc:  ldpp_dout(s, 10) << "Starting retarget" << dendl;
./rgw/rgw_rest_swift.cc:  ldpp_dout(s, 10) << "Starting object retarget" << dendl;
./rgw/rgw_rest_swift.cc:  dout(10) << "ver=" << ver << " first=" << first << " req=" << req << dendl;
./rgw/rgw_rest_swift.cc:    ldpp_dout(s, 10) << "init_from_header returned err=" << ret <<  dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-time and end-time are no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:      dout(5) << "Error parsing max-entries " << max_entries_str << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 5) << "Missing period id trying to use current" << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 5) << "Missing period id" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 5) << "Missing period id trying to use current" << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 5) << "Missing period id" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-time and end-time are no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-marker is no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:      dout(5) << "end-marker and marker cannot both be provided" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 5) << "Missing period id trying to use current" << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 5) << "Missing period id" << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 5) << "Missing period id trying to use current" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error invalid parameter list" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id param " << shard_id_str << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "invalid length param " << duration_str << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 5) << "Missing period id trying to use current" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error invalid parameter list" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id param " << shard_id_str << dendl;
./rgw/rgw_rest_log.cc:  ldout(s->cct, 20) << __func__ << "(): read data: " << buf << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 0) << "ERROR: failed to parse JSON" << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 0) << "ERROR: failed to decode JSON" << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 20) << __func__ << "(): updated shard=" << *iter << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "ERROR: neither bucket nor bucket instance specified" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "could not get bucket info for bucket=" << bucket_name << dendl;
./rgw/rgw_rest_log.cc:      ldpp_dout(s, 5) << "ERROR: list_bi_log_entries()" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "ERROR: neither bucket nor bucket instance specified" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "could not get bucket info for bucket=" << bucket_name << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "ERROR: one of bucket and bucket instance, and also end-marker is mandatory" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "could not get bucket info for bucket=" << bucket_name << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 5) << "ERROR: trim_bi_log_entries() " << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-time and end-time are no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:      dout(5) << "Error parsing max-entries " << max_entries_str << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:  ldout(s->cct, 20) << __func__ << "(): read data: " << buf << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 0) << "ERROR: failed to parse JSON" << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 0) << "ERROR: failed to decode JSON" << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 20) << __func__ << "(): updated shard=" << iter->first << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 20) << __func__ << "(): modified key=" << *kiter << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-time and end-time are no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "start-marker is no longer accepted" << dendl;
./rgw/rgw_rest_log.cc:      dout(5) << "end-marker and marker cannot both be provided" << dendl;
./rgw/rgw_rest_log.cc:    dout(5) << "Error parsing shard_id " << shard << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 1) << "no sync manager" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 4) << "no 'bucket' provided" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 4) << "invalid 'bucket' provided" << dendl;
./rgw/rgw_rest_log.cc:    ldpp_dout(s, 4) << "failed to read bucket info: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_rest_log.cc:      ldpp_dout(s, 4) << "invalid 'source-bucket' provided (key=" << source_key << ")" << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 20) << "RGWOp_BILog_Status::execute(optional_yield y): getting sync status for pipe=" << pipe << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 20) << "RGWOp_BILog_Status::execute(optional_yield y): getting sync status for pipe=" << pipe << dendl;
./rgw/rgw_rest_log.cc:      ldout(s->cct, 20) << "ERROR: RGWOp_BILog_Status::execute(optional_yield y): BUG: pipe.dest.bucket was not initialized" << pipe << dendl;
./rgw/rgw_rest_log.cc:        ldpp_dout(s, 4) << "failed to read target bucket info (bucket=: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_rest_log.cc:    ldout(s->cct, 1) << "no sync manager for source-zone " << source_zone << dendl;
./rgw/rgw_bucket.cc:        ldout(store->ctx(), 0) << "could not get bucket info for bucket=" << bucket << dendl;
./rgw/rgw_bucket.cc:        dout(1) << "WARNING: cannot find obj state for obj " << obj << dendl;
./rgw/rgw_bucket.cc:        ldpp_dout(dpp, -1) << "ERROR: get obj state returned with error " << ret << dendl;
./rgw/rgw_bucket.cc:     dout(1) << "WARNING: failed sync user stats before bucket delete. ret=" <<  ret << dendl;
./rgw/rgw_bucket.cc:    ldpp_dout(dpp, 0) << "WARNING: can't bucket link because no acl on bucket=" << old_bucket << dendl;
./rgw/rgw_bucket.cc:    ldpp_dout(dpp, 0) << "WARNING: user " << user << " has no display name set" << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 20) << "Lando 10" << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 20) << "Lando 11" << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 20) << "Lando 12 r=" << r << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 20) << "Lando 13" << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 20) << "Lando 14 r=" << r << dendl;
./rgw/rgw_bucket.cc:    ldout(store->ctx(),0) << "failed to decode RGWAccessControlPolicy" << dendl;
./rgw/rgw_bucket.cc:      ldout(store->ctx(),0) << "failed to decode RGWAccessControlPolicy" << dendl;
./rgw/rgw_bucket.cc:    ldout(store->ctx(),0) << "failed to decode RGWAccessControlPolicy" << dendl;
./rgw/rgw_bucket.cc:    ldpp_dout(dpp, -1) << "Not a resharded bucket skipping" << dendl;
./rgw/rgw_bucket.cc:      ldout(cct, 0) << "ERROR: failed to decode archive meta info" << dendl;
./rgw/rgw_bucket.cc:    ldpp_dout(dpp, 5) << "SKIP: bucket removal is not allowed on archive zone: bucket:" << entry << " ... proceeding to rename" << dendl;
./rgw/rgw_bucket.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to put new bucket instance info for bucket=" << new_bi.bucket << " ret=" << ret << dendl;
./rgw/rgw_bucket.cc:      ldout(cct, 0) << "ERROR: failed to put new bucket entrypoint for bucket=" << new_be.bucket << " ret=" << ret << dendl;
./rgw/rgw_bucket.cc:      ldout(cct, 0) << "ERROR: failed to link new bucket for bucket=" << new_be.bucket << " ret=" << ret << dendl;
./rgw/rgw_bucket.cc:      ldout(cct, 0) << "ERROR: failed to put new bucket entrypoint for bucket=" << new_be.bucket << " ret=" << ret << dendl;
./rgw/rgw_bucket.cc:        ldout(cct, 0) << "ERROR: select_bucket_placement() returned " << ret << dendl;
./rgw/rgw_bucket.cc:    ldout(cct, 0) << "SKIP: bucket instance removal is not allowed on archive zone: bucket.instance:" << entry << dendl;
./rgw/rgw_bucket.cc:  ldpp_dout(dpp, 10) << "RGWRados::convert_old_bucket_info(): bucket=" << bucket << dendl;
./rgw/rgw_bucket.cc:    ldout(cct, 0) << "ERROR: get_bucket_entrypoint_info() returned " << ret << " bucket=" << bucket << dendl;
./rgw/rgw_bucket.cc:    ldout(cct, 0) << "ERROR: failed to put_linked_bucket_info(): " << ret << dendl;
./rgw/rgw_bucket.cc:          ldout(cct, 0) << "ERROR: failed converting old bucket info: " << ret << dendl;
./rgw/rgw_bucket.cc:    ldpp_dout(dpp, 0) << "bucket entry point user mismatch, can't unlink bucket: " << ep.owner << " != " << user_id << dendl;
./rgw/rgw_bucket.cc:      ldout(store->ctx(), 0) << "ERROR: list objects failed: " << cpp_strerror(-ret) << dendl;
./rgw/rgw_bucket.cc:        ldout(store->ctx(), 0) << "ERROR: failed to read object " << obj.key.name << cpp_strerror(-ret) << dendl;
./rgw/rgw_bucket.cc:        ldpp_dout(dpp, 0) << "ERROR: no acls found for object " << obj.key.name << " .Continuing with next object." << dendl;
./rgw/rgw_bucket.cc:          ldout(store->ctx(), 0) << "ERROR: modify attr failed " << cpp_strerror(-ret) << dendl;
./rgw/rgw_bucket.cc:    ldout(cct, 20) << __func__ << "(): failed to read bucket stats (r=" << r << ")" << dendl;
./rgw/rgw_bucket.cc:    ldout(cct, 20) << __func__ << "(): failed to get policy handler for bucket=" << bucket << " (r=" << r << ")" << dendl;
./rgw/rgw_swift_auth.cc:    dout(5) << "failed to parse temp_url_expires: " << err << dendl;
./rgw/rgw_swift_auth.cc:    dout(5) << "temp url expired: " << expiration << " <= " << now.sec() << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 5) << "cannot get user_info of account's owner" << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 5) << "user does not have temp url key set, aborting" << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 5) << "temp url link expired" << dendl;
./rgw/rgw_swift_auth.cc:    ldout(cct, 5) << "temp url rejected due to disallowed header" << dendl;
./rgw/rgw_swift_auth.cc:  ldpp_dout(dpp, 10) << "rgw_swift_validate_token url=" << url_buf << dendl;
./rgw/rgw_swift_auth.cc:  ldpp_dout(dpp, 10) << "swift user=" << swift_user << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 0) << "NOTICE: couldn't map swift user" << dendl;
./rgw/rgw_swift_auth.cc:  dout(20) << "build_token token=" << buf << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 0) << "NOTICE: failed to decode token" << dendl;
./rgw/rgw_swift_auth.cc:  ldpp_dout(dpp, 10) << "swift_user=" << swift_user << dendl;
./rgw/rgw_swift_auth.cc:    ldpp_dout(dpp, 0) << "NOTICE: tokens mismatch tok=" << buf << dendl;
./rgw/rgw_swift_auth.cc:      dout(0) << "NOTICE: server is misconfigured, missing rgw_swift_url_prefix or rgw_swift_url, HTTP_HOST is not set" << dendl;
./rgw/rgw_swift_auth.cc:    dout(0) << "NOTICE: RGW_SWIFT_Auth_Get::execute(): bad swift key" << dendl;
./rgw/rgw_torrent.cc:  ldout(s->cct, 20) << "NOTICE: head obj oid= " << oid << dendl;
./rgw/rgw_torrent.cc:    ldout(s->cct, 0) << "ERROR: omap_get_vals_by_keys failed: " << r << dendl;
./rgw/rgw_torrent.cc:    ldout(s->cct, 0) << "ERROR: omap key " RGW_OBJ_TORRENT " not found" << dendl;
./rgw/rgw_torrent.cc:    ldout(s->cct, 0) << "ERROR: failed to save_torrent_file() ret= "<< ret << dendl;
./rgw/rgw_torrent.cc:    ldout(s->cct, 5) << "NOTICE: announce_list is empty " << dendl;    
./rgw/rgw_torrent.cc:    ldout(s->cct, 0) << "ERROR: failed to omap_set() op_ret = " << op_ret << dendl;
./rgw/rgw_sync_module_log.cc:    ldout(sc->cct, 0) << prefix << ": SYNC_LOG: sync_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " versioned_epoch=" << versioned_epoch.value_or(0) << dendl;
./rgw/rgw_sync_module_log.cc:    ldout(sc->cct, 0) << prefix << ": SYNC_LOG: rm_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
./rgw/rgw_keystone.cc:    ldout(cct, 20) << "found cached admin token" << dendl;
./rgw/rgw_keystone.cc:    ldout(cct, 20) << "found cached barbican token" << dendl;
./rgw/rgw_keystone.cc:  ldout(cct, 20) << "Requesting secret from barbican url=" << token_url << dendl;
./rgw/rgw_keystone.cc:    ldout(cct, 20) << "Barbican process error:" << token_bl.c_str() << dendl;
./rgw/rgw_keystone.cc:    ldout(cct, 0) << "Keystone token parse error: malformed json" << dendl;
./rgw/rgw_keystone.cc:    ldout(cct, 0) << "Keystone token parse error: " << err.what() << dendl;
./rgw/rgw_keystone.cc:  ldout(cct, 20) << "invalidating revoked token id=" << token_id << dendl;
./rgw/rgw_notify.cc:        ldpp_dout(this, 1) << "ERROR: failed to read queue list. error: " << ret << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 5) << "WARNING: failed to decode entry. error: " << err.what() << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 20) << "INFO: trying to perform stale reservation cleanup for queue: " << queue_name << dendl;
./rgw/rgw_notify.cc:        ldpp_dout(this, 5) << "WARNING: queue: " << queue_name << " ownership moved to another daemon. processing will stop" << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 5) << "WARNING: queue: " << queue_name << " ownership moved to another daemon. processing will stop" << dendl;
./rgw/rgw_notify.cc:                ldpp_dout(this, 1) << "ERROR: cannot determin minimum between malformed markers: " << end_marker << ", " << entry.marker << dendl;
./rgw/rgw_notify.cc:                ldpp_dout(this, 20) << "INFO: new end marker for removal: " << end_marker << " from: " << queue_name << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 5) << "WARNING: queue: " << queue_name << " ownership moved to another daemon. processing will stop" << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 20) << "INFO: next queues processing will happen at: " << std::ctime(&tp)  << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 20) << "INFO: queue: " << queue_name << " owned (locked) by another daemon" << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 10) << "INFO: queue: " << queue_name << " should not be locked - already deleted" << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 1) << "ERROR: failed to lock queue: " << queue_name << ". error: " << ret << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 10) << "INFO: queue: " << queue_name << " now owned (locked) by this daemon" << dendl;
./rgw/rgw_notify.cc:            ldpp_dout(this, 10) << "INFO: queue: " << queue_name << " marked for removal" << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 20) << "INFO: queue: " << queue_name << " ownership (lock) renewed" << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(this, 20) << "INFO: queue: " << queue_name << " removed" << dendl;
./rgw/rgw_notify.cc:            ldpp_dout(this, 10) << "Notification worker failed with error: " << err.what() << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 10) << "Started notification manager with: " << worker_count << " workers" << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 1) << "ERROR: topic name cannot be: " << Q_LIST_OBJECT_NAME << " (conflict with queue list object name)" << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 20) << "INFO: queue for topic: " << topic_name << " already exists. nothing to do" << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 1) << "ERROR: failed to create queue for topic: " << topic_name << ". error: " << ret << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 1) << "ERROR: failed to add queue: " << topic_name << " to queue list. error: " << ret << dendl;
./rgw/rgw_notify.cc:    ldpp_dout(this, 20) << "INFO: queue: " << topic_name << " added to queue list"  << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 20) << "INFO: queue for topic: " << topic_name << " already removed. nothing to do" << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 1) << "ERROR: failed to remove queue for topic: " << topic_name << ". error: " << ret << dendl;
./rgw/rgw_notify.cc:      ldpp_dout(this, 1) << "ERROR: failed to remove queue: " << topic_name << " from queue list. error: " << ret << dendl;
./rgw/rgw_notify.cc:    ldpp_dout(this, 20) << "INFO: queue: " << topic_name << " removed from queue list"  << dendl;
./rgw/rgw_notify.cc:        ldout(res.s->cct, 1) << "ERROR: failed to parse reservation id. error: " << ret << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(dpp, 1) << "ERROR: failed to parse reservation id for extra space. error: " << ret << dendl;
./rgw/rgw_notify.cc:        ldpp_dout(dpp, 20) << "INFO: push endpoint created: " << topic.cfg.dest.push_endpoint << dendl;
./rgw/rgw_notify.cc:          ldpp_dout(dpp, 1) << "ERROR: push to endpoint " << topic.cfg.dest.push_endpoint << " failed. error: " << ret << dendl;
./rgw/rgw_sal.cc:      ldout(cct, 0) << "ERROR: failed to init services (ret=" << cpp_strerror(-ret) << ")" << dendl;
./rgw/rgw_user.cc:      ldpp_dout(dpp, 0) << "failed to read user buckets: ret=" << ret << dendl;
./rgw/rgw_user.cc:        ldpp_dout(dpp, 0) << "ERROR: could not read bucket info: bucket=" << bucket << " ret=" << ret << dendl;
./rgw/rgw_user.cc:        ldout(cct, 0) << "ERROR: could not sync bucket stats: ret=" << ret << dendl;
./rgw/rgw_user.cc:	ldpp_dout(dpp, 0) << "ERROR in check_bucket_shards: " << cpp_strerror(-ret)<< dendl;
./rgw/rgw_user.cc:      ldpp_dout(dpp, 0) << "failed to read user buckets: ret=" << ret << dendl;
./rgw/rgw_user.cc:        ldpp_dout(dpp, 0) << "ERROR: could not get bucket stats: ret=" << ret << dendl;
./rgw/rgw_user.cc:    ldpp_dout(dpp, 10) << "removing email index: " << user_info.user_email << dendl;
./rgw/rgw_user.cc:        ldpp_dout(dpp, 0) << "ERROR: could not get stats for buckets" << dendl;
./rgw/rgw_auth.cc:  ldpp_dout(dpp, 5) << "Searching permissions for uid=" << uid <<  dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 5) << "Found permission: " << iter->second << dendl;
./rgw/rgw_auth.cc:  ldpp_dout(dpp, 5) << "Permissions for user not found" << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 20) << get_name() << ": trying " << engine.get_name() << dendl;
./rgw/rgw_auth.cc:        ldpp_dout(dpp, 20) << engine.get_name() << " granted access" << dendl;
./rgw/rgw_auth.cc:      ldpp_dout(dpp, 5) << "applier throwed err=" << err << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 5) << "auth engine throwed err=" << err << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 0) << "ERROR: reading stats for the user returned error " << ret << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 5) << "NOTICE: incoming user has no buckets " << federated_user << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 5) << "NOTICE: incoming user already has buckets associated " << federated_user << ", won't be created in oidc namespace"<< dendl;
./rgw/rgw_auth.cc:  ldpp_dout(dpp, 0) << "NOTICE: couldn't map oidc federated user " << federated_user << dendl;
./rgw/rgw_auth.cc:  ldpp_dout(dpp, 20) << "from ACL got perm=" << perm << dendl;
./rgw/rgw_auth.cc:  ldpp_dout(dpp, 0) << "NOTICE: couldn't map swift user " << acct_user << dendl;
./rgw/rgw_auth.cc:      ldpp_dout(dpp, 20) << "failed to parse role policy: " << e.what() << dendl;
./rgw/rgw_auth.cc:    ldpp_dout(dpp, 20) << "failed to parse token policy: " << e.what() << dendl;
./rgw/rgw_lc.cc:      ldpp_dout(dpp, 2) << "life cycle: start" << dendl;
./rgw/rgw_lc.cc:      ldpp_dout(dpp, 2) << "life cycle: stop" << dendl;
./rgw/rgw_lc.cc:          ldpp_dout(this, 0) << "ERROR: store->list_objects():" <<dendl;
./rgw/rgw_lc.cc:      ldpp_dout(this, 0) << "ERROR: store->list_objects():" <<dendl;
./rgw/rgw_lc.cc:    ldout(store->ctx(), 5) << "Entry already exists, nothing to do" << dendl;
./rgw/rgw_lc.cc:  ldout(store->ctx(), 5) << "lc_get_entry errored ret code=" << ret << dendl;
./rgw/rgw_sync_module_es_rest.cc:    ldout(s->cct, 10) << "invalid query, failed generating request json" << dendl;
./rgw/rgw_sync_module_es_rest.cc:  ldout(s->cct, 20) << "sending request to elasticsearch, payload=" << string(in.c_str(), in.length()) << dendl;
./rgw/rgw_sync_module_es_rest.cc:    ldout(s->cct, 0) << "ERROR: failed to fetch resource (r=" << resource << ", ret=" << op_ret << ")" << dendl;
./rgw/rgw_sync_module_es_rest.cc:  ldout(s->cct, 20) << "response: " << string(out.c_str(), out.length()) << dendl;
./rgw/rgw_sync_module_es_rest.cc:    ldout(s->cct, 0) << "ERROR: failed to parse elasticsearch response" << dendl;
./rgw/rgw_sync_module_es_rest.cc:    ldout(s->cct, 0) << "ERROR: failed to decode JSON input: " << e.what() << dendl;
./rgw/rgw_reshard.cc:    ldout(store->ctx(), 0) << __func__ << " missing new bucket instance id" << dendl;
./rgw/rgw_reshard.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to write bucket info, ret=" << ret << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, 0) << __func__ << ": failed to update bucket info ret=" << ret << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, -1) << "failed to link new bucket instance (bucket_id=" << new_bucket_info.bucket.bucket_id << ": " << cpp_strerror(-ret) << ")" << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, 0) << __func__ << ": failed to update bucket info ret=" << ret << dendl;
./rgw/rgw_reshard.cc:    ldout(store->ctx(), 20) << __func__ << " Resharding is disabled"  << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, 20) << __func__ << " Resharding is disabled"  << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, 20) << "processing logshard = " << logshard << dendl;
./rgw/rgw_reshard.cc:    ldpp_dout(dpp, 20) << "finish processing logshard = " << logshard << " , ret = " << ret << dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "failed to parse policy: " << e.what() << dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: Role name is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: Role name is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: One of role name or trust policy is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: failed to parse assume role policy doc" << dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: One of role name, policy name or perm policy is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "failed to parse policy: " << e.what() << dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: One of role name or policy name is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: Role name is empty"<< dendl;
./rgw/rgw_rest_role.cc:    ldout(s->cct, 20) << "ERROR: One of role name or policy name is empty"<< dendl;
./rgw/rgw_log.cc:    ldout(s->cct, 5) << "nothing to log for operation" << dendl;
./rgw/rgw_log.cc:      ldout(s->cct, 5) << "bucket " << s->bucket_name << " doesn't exist, not logging" << dendl;
./rgw/rgw_log.cc:    ldout(s->cct, 5) << "not logging op on bucket with non-utf8 name" << dendl;
./rgw/rgw_log.cc:    ldout(s->cct, 0) << "ERROR: failed to log entry" << dendl;
./rgw/rgw_amqp.cc:        ldout(cct, 20) << "AMQP destroy: invoking callback with tag=" << cb_tag.tag << dendl;
./rgw/rgw_amqp.cc:      ldout(conn->cct, 1) << "AMQP publish: connection had an issue while message was in the queue" << dendl;
./rgw/rgw_amqp.cc:        ldout(conn->cct, 20) << "AMQP publish (no callback): OK" << dendl;
./rgw/rgw_amqp.cc:      ldout(conn->cct, 1) << "AMQP publish (no callback): failed with error " << status_to_string(rc) << dendl;
./rgw/rgw_amqp.cc:        ldout(conn->cct, 20) << "AMQP publish (with callback, tag=" << conn->delivery_tag << "): OK. Queue has: " << q_len << " callbacks" << dendl;
./rgw/rgw_amqp.cc:        ldout(conn->cct, 1) << "AMQP publish (with callback): failed with error: callback queue full" << dendl;
./rgw/rgw_amqp.cc:      ldout(conn->cct, 1) << "AMQP publish (with callback): failed with error: " << status_to_string(rc) << dendl;
./rgw/rgw_amqp.cc:          ldout(conn->cct, 10) << "AMQP run: connection is deleted" << dendl;
./rgw/rgw_amqp.cc:            ldout(conn->cct, 20) << "AMQP run: retry connection" << dendl;
./rgw/rgw_amqp.cc:              ldout(conn->cct, 10) << "AMQP run: connection (" << to_string(conn_it->first) << ") retry successfull" << dendl;
./rgw/rgw_amqp.cc:          ldout(conn->cct, 1) << "AMQP run: connection read error: " << status_to_string(rc) << dendl;
./rgw/rgw_amqp.cc:              ldout(conn->cct, 10) << "AMQP run: connection was closed by broker" << dendl;
./rgw/rgw_amqp.cc:            ldout(conn->cct, 10) << "AMQP run: message was not routable" << dendl;
./rgw/rgw_amqp.cc:            ldout(conn->cct, 10) << "AMQP run: unexpected message" << dendl;
./rgw/rgw_amqp.cc:            ldout(conn->cct, 20) << "AMQP run: multiple n/acks received with tag=" << tag << " and result=" << result << dendl;
./rgw/rgw_amqp.cc:              ldout(conn->cct, 20) << "AMQP run: invoking callback with tag=" << it->tag << dendl;
./rgw/rgw_amqp.cc:            ldout(conn->cct, 20) << "AMQP run: n/ack received, invoking callback with tag=" << tag << " and result=" << result << dendl;
./rgw/rgw_amqp.cc:          ldout(conn->cct, 10) << "AMQP run: unsolicited n/ack received with tag=" << tag << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP connect: manager is stopped" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP connect: URL parsing failed" << dendl;
./rgw/rgw_amqp.cc:        ldout(cct, 1) << "AMQP connect: endpoint marked for deletion" << dendl;
./rgw/rgw_amqp.cc:        ldout(cct, 1) << "AMQP connect: exchange mismatch" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 20) << "AMQP connect: connection found" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP connect: max connections exceeded" << dendl;
./rgw/rgw_amqp.cc:    ldout(cct, 10) << "AMQP connect: new connection is created. Total connections: " << connection_count << dendl;
./rgw/rgw_amqp.cc:    ldout(cct, 10) << "AMQP connect: new connection status is: " << status_to_string(conn->status) << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP publish: manager is not running" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP publish: no connection" << dendl;
./rgw/rgw_amqp.cc:    ldout(cct, 1) << "AMQP publish: queue is full" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP publish_with_confirm: manager is not running" << dendl;
./rgw/rgw_amqp.cc:      ldout(cct, 1) << "AMQP publish_with_confirm: no connection" << dendl;
./rgw/rgw_amqp.cc:    ldout(cct, 1) << "AMQP publish_with_confirm: queue is full" << dendl;
./rgw/rgw_acl_swift.cc:    ldout(cct, 10) << "grant user does not exist: " << uid << dendl;
./rgw/rgw_acl_swift.cc:    ldpp_dout(dpp, 20) << "trying to add grant for ACL uid=" << uid << dendl;
./rgw/rgw_acl_swift.cc:        ldout(cct, 10) << "grant user does not exist:" << uid << dendl;
./rgw/rgw_acl_swift.cc:    ldpp_dout(dpp, 0) << "ERROR: JSONParser::parse returned error=" << dendl;
./rgw/rgw_acl_swift.cc:    ldout(cct, 0) << "admins: " << admin << dendl;
./rgw/rgw_acl_swift.cc:    ldout(cct, 0) << "read-write: " << readwrite << dendl;
./rgw/rgw_acl_swift.cc:    ldout(cct, 0) << "read-only: " << readonly << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 20) << " payload = " << payload << dendl;
./rgw/rgw_rest_sts.cc:      ldpp_dout(dpp, 0) << "Couldn't get oidc provider info using input iss" << t.iss << dendl;
./rgw/rgw_rest_sts.cc:        ldpp_dout(dpp, 0) << "Client id in token doesn't match with that registered with oidc provider" << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 5) << "Invalid JWT token" << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 5) << "Invalid JWT token" << dendl;
./rgw/rgw_rest_sts.cc:      ldpp_dout(dpp, 10) << "HTTP request res: " << res << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 20) << "HTTP status: " << cert_req.get_http_status() << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 20) << "JSON Response is: " << cert_resp.c_str() << dendl;
./rgw/rgw_rest_sts.cc:              ldpp_dout(dpp, 20) << "Certificate is: " << cert.c_str() << dendl;
./rgw/rgw_rest_sts.cc:              ldpp_dout(dpp, 0) << "Cert doesn't match that with the thumbprints registered with oidc provider: " << cert.c_str() << dendl;
./rgw/rgw_rest_sts.cc:              ldpp_dout(dpp, 0) << "Signature validation failed: " << e.what() << dendl;
./rgw/rgw_rest_sts.cc:              ldpp_dout(dpp, 0) << "Signature validation failed" << dendl;
./rgw/rgw_rest_sts.cc:            ldpp_dout(dpp, 0) << "x5c not present" << dendl;
./rgw/rgw_rest_sts.cc:          ldpp_dout(dpp, 0) << "Malformed JSON object for keys" << dendl;
./rgw/rgw_rest_sts.cc:        ldpp_dout(dpp, 0) << "keys not present in JSON" << dendl;
./rgw/rgw_rest_sts.cc:      ldpp_dout(dpp, 0) << "Malformed json returned while fetching cert" << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(dpp, 0) << "JWT signed by HMAC algos are currently not supported" << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "Role Session Name is empty " << dendl;
./rgw/rgw_rest_sts.cc:    ldpp_dout(this, 0) << "failed to get role info using role arn: " << rArn << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "evaluating principal returned deny" << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "evaluating condition returned deny" << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 0) << "failed to parse policy: " << e.what() << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 0) << "User does not have permssion to perform GetSessionToken" << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "Invalid value of input duration: " << duration << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "Invalid duration in secs: " << duration_in_secs << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 0) << "ERROR: one of role arn or role session name or token is empty" << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 20) << "failed to parse policy: " << e.what() << "policy" << policy << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 0) << "ERROR: one of role arn or role session name is empty" << dendl;
./rgw/rgw_rest_sts.cc:      ldout(s->cct, 0) << "failed to parse policy: " << e.what() << "policy" << policy << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 10) << "Content of POST: " << post_body << dendl;
./rgw/rgw_rest_sts.cc:    ldout(s->cct, 10) << "init_from_header returned err=" << ret <<  dendl;
./rgw/rgw_sync_module_es.cc:          ldout(cct, 0) << "ERROR: failed to decode acl for " << bucket_info.bucket << "/" << key << dendl;
./rgw/rgw_sync_module_es.cc:          ldout(cct, 20) << "custom meta entry key=" << i.first << " not found in bucket mdsearch config: " << bucket_info.mdsearch_config << dendl;
./rgw/rgw_sync_module_es.cc:          ldout(cct, 20) << __func__ << "(): failed to parse time (" << i.second << "), skipping encoding of custom date attribute" << dendl;
./rgw/rgw_sync_module_es.cc:      ldout(sync_env->cct, 5) << conf->id << ": get elasticsearch info for zone: " << sc->source_zone << dendl;
./rgw/rgw_sync_module_es.cc:        ldout(sync_env->cct, 5) << conf->id << ": get elasticsearch failed: " << retcode << dendl;
./rgw/rgw_sync_module_es.cc:      ldout(sync_env->cct, 5) << conf->id << ": got elastic version=" << conf->es_info.get_version_str() << dendl;
./rgw/rgw_sync_module_es.cc:      ldout(sc->cct, 5) << conf->id << ": put elasticsearch index for zone: " << sc->source_zone << dendl;
./rgw/rgw_sync_module_es.cc:          ldout(sc->cct, 0) << "elasticsearch: index mapping: version >= 5" << dendl;
./rgw/rgw_sync_module_es.cc:          ldout(sc->cct, 0) << "elasticsearch: index mapping: version < 5" << dendl;
./rgw/rgw_sync_module_es.cc:          ldout(sync_env->cct, 0) << "elasticsearch: failed to initialize index: response.type=" << err_response.error.type << " response.reason=" << err_response.error.reason << dendl;
./rgw/rgw_sync_module_es.cc:        ldout(sync_env->cct, 0) << "elasticsearch: index already exists, assuming external initialization" << dendl;
./rgw/rgw_sync_module_es.cc:    ldout(sc->cct, 5) << conf->id << ": init" << dendl;
./rgw/rgw_sync_module_es.cc:    ldout(sc->cct, 5) << conf->id << ": start_sync" << dendl;
./rgw/rgw_sync_module_es.cc:    ldout(sc->cct, 10) << conf->id << ": sync_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " versioned_epoch=" << versioned_epoch.value_or(0) << dendl;
./rgw/rgw_sync_module_es.cc:      ldout(sc->cct, 10) << conf->id << ": skipping operation (bucket not approved)" << dendl;
./rgw/rgw_sync_module_es.cc:    ldout(sc->cct, 10) << conf->id << ": rm_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
./rgw/rgw_sync_module_es.cc:      ldout(sc->cct, 10) << conf->id << ": skipping operation (bucket not approved)" << dendl;
./rgw/rgw_sync_module_es.cc:    ldout(sc->cct, 10) << conf->id << ": skipping operation (not handled)" << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start finisher service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start notify service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start rados service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start zone service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldout(cct, 0) << "ERROR: failed to start datalog_rados service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start mdlog service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start sync modules service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start cls service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start config_key service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start zone_utils service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start quota service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start sysobj_core service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start sysobj_cache service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start sysobj service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start meta_be_sobj service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start meta service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start bucket service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start bucket_sync service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start user_rados service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start otp service (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to start init ctls (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldout(cct, 0) << "ERROR: failed to start init meta.user ctl (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldout(cct, 0) << "ERROR: failed to start init meta.bucket ctl (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldout(cct, 0) << "ERROR: failed to start init meta.bucket_instance ctl (" << cpp_strerror(-r) << dendl;
./rgw/rgw_service.cc:    ldout(cct, 0) << "ERROR: failed to start init otp ctl (" << cpp_strerror(-r) << dendl;
./rgw/rgw_frontend.cc:      dout(0) << "framework: " << framework << dendl;
./rgw/rgw_frontend.cc:      dout(0) << "framework conf key: " << entry << dendl;
./rgw/rgw_frontend.cc:    dout(0) << "framework conf key: " << key << ", val: " << val << dendl;
./rgw/rgw_civetweb_log.cc:  dout(0) << "civetweb: " << (void *)conn << ": " << rgw::crypt_sanitize::log_content(buf) << dendl;
./rgw/rgw_civetweb_log.cc:  dout(1) << "civetweb: " << (void *)conn << ": " << rgw::crypt_sanitize::log_content(buf) << dendl;
./rgw/rgw_file.cc:      ldout(state->cct, 0) << __func__ << " called on empty object" << dendl;
./rgw/rgw_sal_rados.cc:    ldout(cct, 0) << "ERROR: could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_sal_rados.cc:    ldout(store->ctx(), 0) << "WARNING: couldn't find acl header for bucket, generating default" << dendl;
./rgw/rgw_sal_rados.cc:     ldout(store->ctx(), 1) << "WARNING: failed sync user stats before bucket delete. ret=" <<  ret << dendl;
./rgw/rgw_sal_rados.cc:    ldpp_dout(dpp, -1) << "ERROR: unable to remove user bucket information" << dendl;
./rgw/rgw_sal_rados.cc:    ldpp_dout(dpp, 20) << "parsed: objv.tag=" << objv.tag << " objv.ver=" << objv.ver << dendl;
./rgw/rgw_sal_rados.cc:    ldpp_dout(dpp, 20) << "got creation time: << " << std::put_time(std::localtime(&ctime), "%F %T") << dendl;
./rgw/rgw_sal_rados.cc:    ldout(ctx(), 0) << "rest connection is invalid" << dendl;
./rgw/rgw_sal_rados.cc:  ldout(ctx(), 0) << "sending request to master zonegroup" << dendl;
./rgw/rgw_sal_rados.cc:  ldout(ctx(), 20) << "response: " << response.c_str() << dendl;
./rgw/rgw_sal_rados.cc:    ldout(ctx(), 0) << "failed parsing response from master zonegroup" << dendl;
./rgw/rgw_sal_rados.cc:      ldout(store->ctx(), 0) << "ERROR: " << __func__ << ": failed to decode " RGW_ATTR_DELETE_AT " attr" << dendl;
./rgw/rgw_sal_rados.cc:      ldpp_dout(dpp, 5) << "NOTE: we should not process the head object (" << obj << ") here" << dendl;
./rgw/rgw_sal_rados.cc:      ldpp_dout(dpp, 0) << "WARNING: failed to remove obj (" << obj << "), leaked" << dendl;
./rgw/rgw_sal_rados.cc:    ldpp_dout(dpp, 5) << "NOTE: we are going to process the head obj (" << *raw_head << ")" << dendl;
./rgw/rgw_sal_rados.cc:      ldpp_dout(dpp, 0) << "WARNING: failed to remove obj (" << *raw_head << "), leaked" << dendl;
./rgw/rgw_rest_user.cc:    ldout(s->cct, 0) << "cannot set system flag by non-system user" << dendl;
./rgw/rgw_rest_user.cc:      ldout(s->cct, 0) << "failed to parse op_mask: " << ret << dendl;
./rgw/rgw_rest_user.cc:      ldout(s->cct, 0) << "NOTICE: invalid dest placement: " << target_rule.to_str() << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldout(s->cct, 0) << "cannot set system flag by non-system user" << dendl;
./rgw/rgw_rest_user.cc:        ldout(s->cct, 0) << "failed to parse op_mask" << dendl;
./rgw/rgw_rest_user.cc:      ldout(s->cct, 0) << "failed to parse op_mask: " << ret << dendl;
./rgw/rgw_rest_user.cc:      ldout(s->cct, 0) << "NOTICE: invalid dest placement: " << target_rule.to_str() << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldout(store->ctx(), 20) << "invalid quota type" << dendl;
./rgw/rgw_rest_user.cc:    ldout(store->ctx(), 20) << "quota type was not specified, can't set all quotas via http headers" << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 20) << "failed initializing user info: " << op_ret << dendl;
./rgw/rgw_rest_user.cc:      ldpp_dout(this, 20) << "failed to retrieve input" << dendl;
./rgw/rgw_rest_user.cc:        ldpp_dout(this, 20) << "failed to retrieve input" << dendl;
./rgw/rgw_rest_user.cc:        ldpp_dout(this, 20) << "failed to get user info: " << op_ret << dendl;
./rgw/rgw_rest_user.cc:    ldpp_dout(this, 20) << "failed updating user info: " << op_ret << ": " << err << dendl;
./rgw/rgw_acl.cc:        ldout(cct, 0) << "ERROR: grant->get_id() failed" << dendl;
./rgw/rgw_acl.cc:    ldout(cct, 5) << "Found permission: " << iter->second << dendl;
./rgw/rgw_acl.cc:  ldout(cct, 5) << "Permissions for group not found" << dendl;
./rgw/rgw_acl.cc:  ldout(cct, 5) << "Found referer permission=" << referer_perm << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 0) << "ERROR: couldn't decode avail_pools" << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to open obj=" << obj << " (r=" << r << ")" << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to open obj=" << obj << " (r=" << r << ")" << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to open obj=" << obj << " (r=" << r << ")" << dendl;
./rgw/rgw_object_expirer_core.cc:      ldpp_dout(dpp, 1) << "cannot parse removal hint for " << hint.obj_key << dendl;
./rgw/rgw_object_expirer_core.cc:      ldpp_dout(dpp, 15) << "not actual hint for object: " << hint.obj_key << dendl;
./rgw/rgw_object_expirer_core.cc:      ldpp_dout(dpp, 1) << "cannot remove expired object: " << hint.obj_key << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(store->ctx(), 0) << "ERROR during trim: " << ret << dendl;
./rgw/rgw_object_expirer_core.cc:    ldpp_dout(dpp, 5) << __func__ << "(): failed to acquire lock on " << shard << dendl;
./rgw/rgw_object_expirer_core.cc:    ldpp_dout(dpp, 20) << "processing shard = " << shard << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 2) << "object expiration: start" << dendl;
./rgw/rgw_object_expirer_core.cc:    ldout(cct, 2) << "object expiration: stop" << dendl;
./rgw/rgw_policy_s3.cc:      dout(1) << "env var missing in policy: " << iter->first << dendl;
./rgw/rgw_policy_s3.cc:      dout(0) << "bad content-length-range param: " << first << dendl;
./rgw/rgw_policy_s3.cc:      dout(0) << "bad content-length-range param: " << second << dendl;
./rgw/rgw_policy_s3.cc:    dout(0) << "invalid condition: " << op << dendl;
./rgw/rgw_policy_s3.cc:    dout(0) << "NOTICE: policy calculated as expired: " << expiration_str << dendl;
./rgw/rgw_policy_s3.cc:      dout(20) << " policy check failed, variable not found: '" << name << "'" << dendl;
./rgw/rgw_policy_s3.cc:    dout(20) << "comparing " << name << " [" << val << "], " << check_val << dendl;
./rgw/rgw_policy_s3.cc:      dout(1) << "policy check failed, val=" << val << " != " << check_val << dendl;
./rgw/rgw_policy_s3.cc:    dout(1) << "missing policy condition" << dendl;
./rgw/rgw_policy_s3.cc:    dout(0) << "malformed json" << dendl;
./rgw/rgw_policy_s3.cc:    dout(0) << "expiration not found" << dendl;
./rgw/rgw_policy_s3.cc:    dout(0) << "conditions not found" << dendl;
./rgw/rgw_policy_s3.cc:    dout(20) << "data=" << child->get_data() << dendl;
./rgw/rgw_policy_s3.cc:    dout(20) << "is_object=" << child->is_object() << dendl;
./rgw/rgw_policy_s3.cc:    dout(20) << "is_array=" << child->is_array() << dendl;
./rgw/rgw_policy_s3.cc:      dout(20) << "adding simple_check: " << c->get_name() << " : " << c->get_data() << dendl;
./rgw/rgw_obj_manifest.cc:  dout(20) << "RGWObjManifest::operator++(): rule->part_size=" << rule->part_size << " rules.size()=" << manifest->rules.size() << dendl;
./rgw/rgw_obj_manifest.cc:    dout(20) << "RGWObjManifest::operator++(): stripe_ofs=" << stripe_ofs << " part_ofs=" << part_ofs << " rule->part_size=" << rule->part_size << dendl;
./rgw/rgw_obj_manifest.cc:  dout(20) << "RGWObjManifest::operator++(): result: ofs=" << ofs << " stripe_ofs=" << stripe_ofs << " part_ofs=" << part_ofs << " rule->part_size=" << rule->part_size << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "missing required param 'topic'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "missing required param 'event-id'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "failed to parse 'max-entries' param" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "missing required param 'topic'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "invalid event type in list: " << events_str << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:    ldout(s->cct, 1) << "failed to create notification for topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:  ldout(s->cct, 20) << "successfully created notification for topic '" << topic_name << "'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:      ldout(s->cct, 1) << "missing required param 'topic'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:    ldout(s->cct, 1) << "failed to remove notification from topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:  ldout(s->cct, 20) << "successfully removed notification from topic '" << topic_name << "'" << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:    ldout(s->cct, 1) << "failed to get topics, ret=" << op_ret << dendl;
./rgw/rgw_sync_module_pubsub_rest.cc:  ldout(s->cct, 20) << __func__ << " handler=" << (handler ? typeid(*handler).name() : "<null>") << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(cct, 1) << "endpoint validation error: malformed endpoint URL:" << dest.push_endpoint << dendl;
./rgw/rgw_rest_pubsub_common.cc:        ldout(cct, 1) << "endpoint validation error: sending password over insecure transport" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to create topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 20) << "successfully created topic '" << topic_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to get topics, ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "topics contain secret and cannot be sent over insecure transport" << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 20) << "successfully got topics" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "topic '" << topic_name << "' contain secret and cannot be sent over insecure transport" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to get topic '" << topic_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 1) << "successfully got topic '" << topic_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to remove topic '" << topic_name << ", ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 1) << "successfully removed topic '" << topic_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to create subscription '" << sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 20) << "successfully created subscription '" << sub_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "subscription '" << sub_name << "' contain secret and cannot be sent over insecure transport" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to get subscription '" << sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 20) << "successfully got subscription '" << sub_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to remove subscription '" << sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldout(s->cct, 20) << "successfully removed subscription '" << sub_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldpp_dout(this, 1) << "failed to ack event on subscription '" << sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldpp_dout(this, 20) << "successfully acked event on subscription '" << sub_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to get subscription '" << sub_name << "' for events, ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldpp_dout(this, 1) << "failed to get events from subscription '" << sub_name << "', ret=" << op_ret << dendl;
./rgw/rgw_rest_pubsub_common.cc:  ldpp_dout(this, 20) << "successfully got events from subscription '" << sub_name << "'" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "failed to get bucket info, cannot verify ownership" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "user doesn't own bucket, not allowed to create notification" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "user doesn't own bucket, cannot remove notification" << dendl;
./rgw/rgw_rest_pubsub_common.cc:    ldout(s->cct, 1) << "user doesn't own bucket, cannot get notification list" << dendl;
./rgw/rgw_kmip_client_impl.cc:    ldout(cct, 0) << "ERROR: " << __func__ << " failed final cleanup" << dendl;
./rgw/rgw_kmip_client_impl.cc:  ldout(m.cct, 10) << __func__ << " start" << dendl;
./rgw/rgw_kmip_client_impl.cc:  ldout(m.cct, 10) << __func__ << " finish" << dendl;
./rgw/rgw_rest_bucket.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_bucket.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_rest_bucket.cc:    ldpp_dout(this, 0) << "get_bucket returned ret=" << op_ret << dendl;
./rgw/rgw_metadata.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): list_get_marker() returned: r=" << r << dendl;
./rgw/rgw_period_pusher.cc:        ldout(cct, 10) << "push to " << zone << " succeeded" << dendl;
./rgw/rgw_period_pusher.cc:        ldout(cct, 10) << "waiting " << dur << "s for retry.." << dendl;
./rgw/rgw_period_pusher.cc:      ldout(cct, 4) << "sending " << conns.size() << " periods" << dendl;
./rgw/rgw_period_pusher.cc:    ldout(cct, 4) << "No zones to update" << dendl;
./rgw/rgw_period_pusher.cc:  ldout(cct, 4) << "paused for realm update" << dendl;
./rgw/rgw_rest_config.cc:    dout(5) << "failed to read zone_group map" << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(store->ctx(), 10) << "Watching " << ref.obj.oid << dendl;
./rgw/rgw_trim_bilog.cc:      ldout(store->ctx(), 4) << "Disconnected watch on " << ref.obj << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(cct, 4) << "starting trim on bucket=" << bucket_instance << dendl;
./rgw/rgw_trim_bilog.cc:        ldpp_dout(dpp, 0) << "ERROR: failed to fetch policy handler for bucket=" << bucket << dendl;
./rgw/rgw_trim_bilog.cc:          ldout(cct, 0) << "WARNING: no connection to zone " << zid << ", can't trim bucket: " << bucket << dendl;
./rgw/rgw_trim_bilog.cc:      ldout(cct, 4) << "failed to correlate bucket sync status from peers" << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(cct, 20) << "starting metadata listing at " << start_marker << dendl;
./rgw/rgw_trim_bilog.cc:  ldout(cct, 20) << "restarting metadata listing" << dendl;
./rgw/rgw_trim_bilog.cc:      ldout(cct, 10) << "fetching active bucket counters" << dendl;
./rgw/rgw_trim_bilog.cc:        ldout(cct, 10) << "failed to fetch peer bucket counters" << dendl;
./rgw/rgw_trim_bilog.cc:        ldout(cct, 4) << "failed to correlate peer bucket counters" << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(cct, 4) << "collected " << buckets.size() << " buckets for trim" << dendl;
./rgw/rgw_trim_bilog.cc:      ldpp_dout(dpp, 20) << "writing bucket trim marker=" << status.marker << dendl;
./rgw/rgw_trim_bilog.cc:      ldout(cct, 10) << "failed to notify peers of trim completion" << dendl;
./rgw/rgw_trim_bilog.cc:        ldout(cct, 4) << "failed to lock: " << cpp_strerror(retcode) << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(store->ctx(), 20) << "get_bucket_counters: " << buckets << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(store->ctx(), 20) << "bucket trim completed" << dendl;
./rgw/rgw_trim_bilog.cc:    ldout(store->ctx(), 20) << "trimmed bucket instance " << bucket_instance << dendl;
./rgw/rgw_trim_mdlog.cc:    ldout(cct, 20) << "query sync status from " << c->first << dendl;
./rgw/rgw_trim_mdlog.cc:      ldout(cct, 4) << "no peers, exiting" << dendl;
./rgw/rgw_trim_mdlog.cc:    ldout(cct, 10) << "fetching sync status for zone " << env.zone << dendl;
./rgw/rgw_trim_mdlog.cc:      ldout(cct, 4) << "failed to fetch sync status from all peers" << dendl;
./rgw/rgw_trim_mdlog.cc:      ldout(cct, 4) << "failed to calculate min sync status from peers" << dendl;
./rgw/rgw_trim_mdlog.cc:    ldout(cct, 10) << "fetching master mdlog info" << dendl;
./rgw/rgw_trim_mdlog.cc:      ldout(cct, 4) << "failed to read mdlog info from master" << dendl;
./rgw/rgw_trim_mdlog.cc:        ldout(cct, 4) << "failed to lock: " << cpp_strerror(retcode) << dendl;
./rgw/rgw_oidc_provider.cc:    ldout(cct, 0) << "ERROR: failed to parse arn" << dendl;
./rgw/rgw_oidc_provider.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to parse arn" << dendl;
./rgw/rgw_oidc_provider.cc:    ldout(cct, 0) << "ERROR: Invalid length of url " << dendl;
./rgw/rgw_oidc_provider.cc:    ldout(cct, 0) << "ERROR: Invalid number of client ids " << dendl;
./rgw/rgw_oidc_provider.cc:    ldout(cct, 0) << "ERROR: Invalid number of thumbprints " << thumbprints.size() << dendl;
./rgw/rgw_http_client.cc:      dout(20) << "WARNING: blocking http request" << dendl;
./rgw/rgw_http_client.cc:    dout(0) << "ERROR: curl_easy_pause() returned rc=" << rc << dendl;
./rgw/rgw_http_client.cc:    dout(0) << "ERROR: " << __func__ << " failed final cleanup" << dendl;
./rgw/rgw_http_client.cc:    dout(5) << "WARNING: client->receive_header() returned ret=" << ret << dendl;
./rgw/rgw_http_client.cc:    dout(5) << "WARNING: client->receive_data() returned ret=" << ret << dendl;
./rgw/rgw_http_client.cc:    dout(20) << "RGWHTTPClient::receive_http_data(): pause" << dendl;
./rgw/rgw_http_client.cc:    dout(5) << "WARNING: client->send_data() returned ret=" << ret << dendl;
./rgw/rgw_http_client.cc:  dout(20) << "sending request to " << url << dendl;
./rgw/rgw_http_client.cc:    dout(20) << "ssl verification is set to off" << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): write() returned " << ret << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: curl_multi_wait() returned " << ret << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: curl_multi_wait() returned " << ret << dendl;
./rgw/rgw_http_client.cc:      ldout(cct, 0) << "ERROR: " << __func__ << "(): read() returned " << ret << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: curl_multi_fdset returned " << ret << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: select returned " << ret << dendl;
./rgw/rgw_http_client.cc:      ldout(cct, 0) << "ERROR: " << __func__ << "(): read() returned " << ret << dendl;
./rgw/rgw_http_client.cc:  ldout(cct, 20) << __func__ << " mgr=" << this << " req_data->id=" << req_data->id << ", curl_handle=" << req_data->curl_handle << dendl;
./rgw/rgw_http_client.cc:  ldout(cct, 20) << __func__ << " mgr=" << this << " req_data->id=" << req_data->id << ", curl_handle=" << req_data->curl_handle << dendl;
./rgw/rgw_http_client.cc:  ldout(cct, 20) << __func__ << " req_data=" << req_data << " req_data->id=" << req_data->id << ", curl_handle=" << req_data->curl_handle << dendl;
./rgw/rgw_http_client.cc:    dout(0) << "ERROR: failed on curl_multi_add_handle, status=" << mstatus << dendl;
./rgw/rgw_http_client.cc:      ldout(cct, 0) << "ERROR: failed to link http request" << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: pipe(): " << cpp_strerror(e) << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: fcntl(): " << cpp_strerror(e) << dendl;
./rgw/rgw_http_client.cc:    ldout(cct, 0) << "ERROR: " << __func__ << ": write() returned ret=" << ret << dendl;
./rgw/rgw_http_client.cc:  ldout(cct, 20) << __func__ << ": start" << dendl;
./rgw/rgw_http_client.cc:      dout(0) << "ERROR: do_curl_wait() returned: " << ret << dendl;
./rgw/rgw_http_client.cc:        dout(10) << "curl_multi_perform returned: " << mstatus << dendl;
./rgw/rgw_http_client.cc:            dout(0) << "ERROR: curl error: " << curl_easy_strerror((CURLcode)result) << ", maybe network unstable" << dendl;
./rgw/rgw_http_client.cc:            dout(20) << "ERROR: msg->data.result=" << result << " req_data->id=" << id << " http_status=" << http_status << dendl;
./rgw/rgw_http_client.cc:            dout(20) << "ERROR: curl error: " << curl_easy_strerror((CURLcode)result) << dendl;
./rgw/rgw_acl_s3.cc:      ldout(cct, 0) << "ERROR: group_to_uri failed with group=" << (int)group << dendl;
./rgw/rgw_acl_s3.cc:    ldout(cct, 10) << "owner info does not exist" << dendl;
./rgw/rgw_acl_s3.cc:  ldpp_dout(dpp, 20) << "owner id=" << owner->get_id() << dendl;
./rgw/rgw_acl_s3.cc:  ldpp_dout(dpp, 20) << "dest owner id=" << dest.get_owner().get_id() << dendl;
./rgw/rgw_acl_s3.cc:          ldpp_dout(dpp, 0) << "ERROR: src_grant.get_id() failed" << dendl;
./rgw/rgw_acl_s3.cc:        ldout(cct, 10) << "grant user email=" << email << dendl;
./rgw/rgw_acl_s3.cc:          ldout(cct, 10) << "grant user email not found or other error" << dendl;
./rgw/rgw_acl_s3.cc:            ldpp_dout(dpp, 0) << "ERROR: src_grant.get_id() failed" << dendl;
./rgw/rgw_acl_s3.cc:	    ldout(cct, 10) << "grant user does not exist:" << uid << dendl;
./rgw/rgw_acl_s3.cc:	ldout(cct, 10) << "new grant: " << new_id << ":" << grant_user.display_name << dendl;
./rgw/rgw_acl_s3.cc:          ldpp_dout(dpp, 10) << "new grant: " << uri << dendl;
./rgw/rgw_acl_s3.cc:          ldpp_dout(dpp, 10) << "bad grant group:" << (int)src_grant.get_group() << dendl;
./rgw/rgw_compression.cc:      ldout(cct, 10) << "Compression for rgw is enabled, compress part " << in.length() << dendl;
./rgw/rgw_coroutine.cc:  ldout(cct, 20) << *op << ": operate()" << dendl;
./rgw/rgw_coroutine.cc:    ldout(cct, 20) << *op << ": operate() returned r=" << r << dendl;
./rgw/rgw_coroutine.cc:    ldout(cct, 15) << "stack " << (void *)this << " end" << dendl;
./rgw/rgw_coroutine.cc:        ldout(cct, 20) << "collect(): s=" << (void *)this << " stack=" << (void *)stack << " is still running" << dendl;
./rgw/rgw_coroutine.cc:        ldout(cct, 20) << "collect(): s=" << (void *)this << " stack=" << (void *)stack << " explicitly skipping stack" << dendl;
./rgw/rgw_coroutine.cc:      ldout(cct, 20) << "collect(): s=" << (void *)this << " stack=" << (void *)stack << " encountered error (r=" << r << "), skipping next stacks" << dendl;
./rgw/rgw_coroutine.cc:    ldout(cct, 20) << "collect(): s=" << (void *)this << " stack=" << (void *)stack << " is complete" << dendl;
./rgw/rgw_coroutine.cc:      ldout(cct, 20) << "stack->operate() returned ret=" << ret << dendl;
./rgw/rgw_coroutine.cc:      ldout(cct, 20) << __func__ << ":" << " stack=" << (void *)stack << " is io blocked" << dendl;
./rgw/rgw_coroutine.cc:      ldout(cct, 20) << __func__ << ":" << " stack=" << (void *)stack << " is done" << dendl;
./rgw/rgw_coroutine.cc:       ldout(cct, 5) << "completion_mgr.get_next() returned ret=" << ret << dendl;
./rgw/rgw_coroutine.cc:        ldout(cct, 5) << "completion_mgr.get_next() returned ret=" << ret << dendl;
./rgw/rgw_coroutine.cc:	ldout(cct, 5) << __func__ << "(): was stopped, exiting" << dendl;
./rgw/rgw_coroutine.cc:    ldout(cct, 20) << "clearing stack on run() exit: stack=" << (void *)stack << " nref=" << stack->get_nref() << dendl;
./rgw/rgw_coroutine.cc:    ldout(cct, 20) << "run(stacks) returned r=" << r << dendl;
./rgw/rgw_coroutine.cc:            ldout(cct, 10) << "collect() returned ret=" << ret << dendl;
./rgw/rgw_coroutine.cc:          ldout(cct, 10) << "collect() returned ret=" << ret << dendl;
./rgw/rgw_etag_verifier.cc:    ldout(cct, 0) << "ERROR: couldn't decode manifest" << dendl;
./rgw/rgw_etag_verifier.cc:    ldout(cct, 20) << "MPU Part offset:" << cur_part_ofs << dendl;
./rgw/rgw_etag_verifier.cc:      ldout(cct, 20) << "MPU Part uncompressed offset:" << ofs << dendl;
./rgw/rgw_etag_verifier.cc:    ldout(cct, 20) << "Part etag: " << calculated_etag_part << dendl;
./rgw/rgw_etag_verifier.cc:  ldout(cct, 20) << "MPU calculated ETag:" << calculated_etag << dendl;
./rgw/rgw_civetweb_frontend.cc:    dout(20) << "process_request() returned " << ret << dendl;
./rgw/rgw_cors.cc:  dout(10) << "Allowed origins : " << num_origins << dendl;
./rgw/rgw_cors.cc:    dout(10) << *it << "," << dendl;
./rgw/rgw_cors.cc:        dout(10) << "Finding " << sl << ", in " << h << ", at offset 0" << dendl;
./rgw/rgw_cors.cc:  dout(10) << "Num of rules : " << rules.size() << dendl;
./rgw/rgw_cors.cc:  dout(10) << "Number of rules: " << num_rules << dendl;
./rgw/rgw_cors.cc:    dout(10) << " <<<<<<< Rule " << loop << " >>>>>>> " << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 4) << "Notification on realm, reconfiguration scheduled" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << "Pausing frontends for realm update..." << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << "Frontends paused" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << "Store closed" << dendl;
./rgw/rgw_realm_reloader.cc:    ldout(cct, 1) << "Creating new store" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << "Finishing initialization of new store" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << " - REST subsystem init" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << " - usage subsystem init" << dendl;
./rgw/rgw_realm_reloader.cc:  ldout(cct, 1) << "Resuming frontends with new realm configuration." << dendl;
./rgw/rgw_opa.cc:  ldpp_dout(op, 2) << "authorizing request using OPA" << dendl;
./rgw/rgw_opa.cc:    ldpp_dout(op, 2) << "OPA_URL not provided" << dendl;
./rgw/rgw_opa.cc:  ldpp_dout(op, 2) << "OPA URL= " << opa_url.c_str() << dendl;
./rgw/rgw_opa.cc:    ldpp_dout(op, 2) << "OPA process error:" << bl.c_str() << dendl;
./rgw/rgw_opa.cc:    ldpp_dout(op, 2) << "OPA parse error: malformed json" << dendl;
./rgw/rgw_opa.cc:    ldpp_dout(op, 2) << "OPA rejecting request" << dendl;
./rgw/rgw_opa.cc:  ldpp_dout(op, 2) << "OPA accepting request" << dendl;
./rgw/rgw_putobj_processor.cc:    ldpp_dout(dpp, 0) << "ERROR: unexpected: get_max_chunk_size(): placement_rule=" << tail_placement_rule.to_str() << " obj=" << target_obj << " returned r=" << r << dendl;
./rgw/rgw_putobj_processor.cc:    ldpp_dout(dpp, 1) << "cannot get compression info" << dendl;
./rgw/rgw_putobj_processor.cc:      ldpp_dout(dpp, 5) << "ERROR: Append position should be zero" << dendl;
./rgw/rgw_putobj_processor.cc:      ldpp_dout(dpp, 5) << "ERROR: The object is not appendable" << dendl;
./rgw/rgw_putobj_processor.cc:      ldpp_dout(dpp, 5) << "ERROR: Append position should be equal to the obj size" << dendl;
./rgw/rgw_putobj_processor.cc:      ldpp_dout(dpp, 5) << "ERROR: failed to decode part num" << dendl;
./rgw/rgw_cr_rest.cc:          ldout(cct, 0) << "ERROR: " << __func__ << " decode_rest_obj() returned ret=" << ret << dendl;
./rgw/rgw_cr_rest.cc:          ldout(cct, 20) << __func__ << ": in_crf->read() retcode=" << retcode << dendl;
./rgw/rgw_cr_rest.cc:      ldout(cct, 20) << "read " << bl.length() << " bytes" << dendl;
./rgw/rgw_cr_rest.cc:          ldout(cct, 20) << "writing " << bl.length() << " bytes" << dendl;
./rgw/rgw_cr_rest.cc:          ldout(cct, 20) << __func__ << ": out_crf->write() retcode=" << retcode << dendl;
./rgw/rgw_op.cc:    ldout(cct, 0) << "ERROR: could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 0) << "WARNING: couldn't find acl header for bucket, generating default" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 0) << "WARNING: couldn't find acl header for object, generating default" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(s, 0) << "ERROR: failed to decode multipart upload info" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(dpp, 0) << "NOTICE: invalid dest placement: " << s->dest_placement.to_str() << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 0) << "Error reading IAM Policy: " << e.what() << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 20) << "redirect_zone_endpoint=" << s->redirect_zone_endpoint << dendl;
./rgw/rgw_op.cc:    ldpp_dout(s, 0) << "ERROR: caught buffer::error, couldn't decode TagSet" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: put_bucket_instance_info (bucket=" << s->bucket << ") returned ret=" << ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: put_bucket_instance_info (bucket=" << s->bucket << ") returned ret=" << ret << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 5) << "NOTICE: call to do_aws4_auth_completion"  << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 10) << "v4 auth ok -- do_aws4_auth_completion" << dendl;
./rgw/rgw_op.cc:    dout(5) << "req_meth is null" << dendl;
./rgw/rgw_op.cc:    dout(10) << "Method " << req_meth << " is supported" << dendl;
./rgw/rgw_op.cc:    dout(5) << "Method " << req_meth << " is not supported" << dendl;
./rgw/rgw_op.cc:        dout(5) << "Header " << hdr << " is not registered in this rule" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "no CORS configuration attr found" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: could not decode CORS, caught buffer::error" << dendl;
./rgw/rgw_op.cc:        dout(5) << "Header " << (*it) << " is not registered in this rule" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 2) << "No CORS configuration set yet for this bucket" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to decode compression info" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 2) << "overriding permissions due to system operation" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 2) << "overriding permissions due to admin operation" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "failed to read bucket policy" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to decode slo manifest" << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 2) << "RGWGetObj::handle_slo_manifest()" << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 20) << "s->obj_size=" << s->obj_size << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: failed to send_response_data ret= " << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to decode compression info, cannot decompress" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: failed to parse start date" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: failed to parse end date" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to sync user stats" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to get user's buckets stats" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: can't read user header"  << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << " forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 10) << "user=" << s->user << " bucket=" << tmp_bucket << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 20) << "rgw_create_bucket returned ret=" << op_ret << " bucket=" << s->bucket.get() << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: bucket " << s->bucket_name << " not found" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 0) << "failed to parse ver param" << dendl;
./rgw/rgw_op.cc:     ldpp_dout(this, 1) << "WARNING: failed to sync user stats before bucket delete: op_ret= " << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 5) << "x-amz-copy-source bad format" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 5) << "source bucket name is empty" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 5) << __func__ << "(): get_bucket() returned ret=" << ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 5) << __func__ << "(): get_bucket_info() returned ret=" << ret << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 5) << "x-amz-copy-source-range bad format" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 5) << "x-amz-copy-source-range bad format" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 5) << "x-amz-copy-source-range bad format not an integer" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 5) << "x-amz-copy-source-range bad format first number bigger than second" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "get_params() returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to decode compression info" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 15) << "supplied_md5_b64=" << supplied_md5_b64 << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 15) << "ceph_armor ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 15) << "supplied_md5=" << supplied_md5 << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 20) << "check_quota() returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 0) << "ERROR: get_multipart_info returned " << op_ret << ": " << cpp_strerror(-op_ret) << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 20) << "failed to get multipart info (returned " << op_ret << ": " << cpp_strerror(-op_ret) << "): probably raced with upload complete / cancel" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "dest_placement for part=" << upload_info.dest_placement << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: failed to get bucket with error" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: get copy source obj state returned with error" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 20) << "get_data() returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "second check_quota() returned op_ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "bad user manifest: " << dlo_manifest << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: torrent.handle_data() returned " << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 15) << "supplied_md5_b64=" << supplied_md5_b64 << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 15) << "ceph_armor ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 15) << "supplied_md5=" << supplied_md5 << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "bad user manifest: " << dlo_manifest << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to decode slo manifest" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << "NOTICE: object delete request with a versioned object, mfa auth not provided" << dendl;
./rgw/rgw_op.cc:          ldpp_dout(this, 0) << "ERROR: failed to handle slo manifest ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 15) << "read len=" << data.length() << " data=" << (buf ? buf : "") << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 15) << "read len=" << data.length() << " data=" << (buf ? buf : "") << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << "Bad lifecycle configuration: " << err << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 15) << "New LifecycleConfiguration:" << ss.str() << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 2) << "No CORS configuration set yet for this bucket" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:	ldpp_dout(this, 2) << "No CORS configuration set yet for this bucket" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 10) << "There is no cors rule present for " << origin << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "Missing mandatory Origin header" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "Missing mandatory Access-control-request-method header" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 2) << "No CORS configuration set yet for this bucket" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "failed to acquire lock" << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 10) << "calculated etag: " << final_etag_str << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "WARNING: failed to remove object " << meta_obj << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "WARNING: failed to unlock " << serializer->oid << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 5) << "NOTICE: multi-object delete request with a versioned object, mfa auth not provided" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 1) << "ERROR: publishing notification failed, with error: " << ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(dpp, 20) << "cannot find bucket = " << path.bucket_name << dendl;
./rgw/rgw_op.cc:      ldpp_dout(dpp, 20) << "cannot get bucket info, ret = " << ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 20) << "wrong auth for " << path << dendl;
./rgw/rgw_op.cc:      ldpp_dout(dpp, 20) << "cannot find entry " << path << dendl;
./rgw/rgw_op.cc:  ldpp_dout(dpp, 20) << "in delete_chunk" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(dpp, 20) << "bulk deleting path: " << path << dendl;
./rgw/rgw_op.cc:  ldout(cct, 20) << "append the bucket: "<< bucket_name << " to req_info" << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 20) << "got directory=" << path << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 20) << "conflicting bucket name" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "WARNING: failed to unlink bucket: ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "containers already exists" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "cannot read_policy() for bucket" << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 20) << "got file=" << path << ", size=" << size << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "non existent directory=" << bucket_name << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "object creation unauthorized" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "cannot prepare processor due to ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "body=" << data.c_str() << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 20) << "filter->process() returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 10) << "real file size different from declared" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "quota exceeded for path=" << path << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "processor::complete returned op_ret=" << op_ret << dendl;
./rgw/rgw_op.cc:  ldpp_dout(this, 20) << "start" << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 2) << "cannot read header" << dendl;
./rgw/rgw_op.cc:          ldpp_dout(this, 2) << "handling regular file" << dendl;
./rgw/rgw_op.cc:          ldpp_dout(this, 2) << "handling regular directory" << dendl;
./rgw/rgw_op.cc:        ldpp_dout(this, 2) << "terminating due to ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 2) << "an empty block" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "NOTICE: get_params() returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 20) << "failed to parse policy: " << e.what() << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: object Lock configuration cannot be enabled on existing buckets" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_op.cc:    ldout(s->cct, 5) << "unexpected xml:" << err << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: retention period must be a positive integer value" << dendl;
./rgw/rgw_op.cc:    ldout(s->cct, 20) << __func__ << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: object retention can't be set if bucket object lock not configured" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << "unexpected xml:" << err << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: the retain until date must be in the future" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: get obj attr error"<< dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << "ERROR: failed to decode RGWObjectRetention" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: bucket object lock not configured" << dendl;
./rgw/rgw_op.cc:    ldout(s->cct, 0) << __func__ <<  "decode object retention config failed" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: object legal hold can't be set if bucket object lock not configured" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_op.cc:    ldout(s->cct, 5) << "unexpected xml:" << err << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: bucket object lock not configured" << dendl;
./rgw/rgw_op.cc:    ldout(s->cct, 0) << __func__ <<  "decode object legal hold config failed" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "ERROR: malformed XML" << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 5) << "unexpected xml:" << err << dendl;
./rgw/rgw_op.cc:    ldpp_dout(this, 0) << "forward_request_to_master returned ret=" << op_ret << dendl;
./rgw/rgw_op.cc:      ldpp_dout(this, 0) << __func__ <<  "decode access_conf failed" << dendl;
./rgw/rgw_cr_rados.cc:  dout(20) << "enqueued request req=" << hex << req << dec << dendl;
./rgw/rgw_cr_rados.cc:  dout(20) << "dequeued request req=" << hex << req << dec << dendl;
./rgw/rgw_cr_rados.cc:    dout(20) << "RGWWQ: empty" << dendl;
./rgw/rgw_cr_rados.cc:  dout(20) << "RGWWQ:" << dendl;
./rgw/rgw_cr_rados.cc:    dout(20) << "req: " << hex << *iter << dec << dendl;
./rgw/rgw_cr_rados.cc:        ldout(cct, 0) << "ERROR: failed to store entries in omap" << dendl;
./rgw/rgw_cr_rados.cc:    ldout(store->ctx(), 0) << "store->fetch_remote_obj() returned r=" << r << dendl;
./rgw/rgw_cr_rados.cc:    ldout(store->ctx(), 0) << "store->fetch_remote_obj() returned r=" << r << dendl;
./rgw/rgw_cr_rados.cc:  ldout(store->ctx(), 0) << __func__ << "(): deleting obj=" << obj << dendl;
./rgw/rgw_cr_rados.cc:    ldpp_dout(dpp, 20) << __func__ << "(): get_obj_state() obj=" << obj << " returned ret=" << ret << dendl;
./rgw/rgw_cr_rados.cc:    ldpp_dout(dpp, 20) << __func__ << "(): skipping object removal obj=" << obj << " (obj mtime=" << state->mtime << ", request timestamp=" << timestamp << ")" << dendl;
./rgw/rgw_cr_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_cr_rados.cc:    ldpp_dout(dpp, 20) << __func__ << "(): delete_obj() obj=" << obj << " returned ret=" << ret << dendl;
./rgw/rgw_cr_rados.cc:        ldout(store->ctx(), 20) << *this << ": couldn't lock " << obj << ":" << lock_name << ": retcode=" << retcode << dendl;
./rgw/rgw_datalog.cc:    ldpp_dout(dpp, 20) << "RGWDataChangesLog::add_entry() sending update with now=" << now << " cur_expiration=" << expiration << dendl;
./rgw/rgw_datalog.cc:    dout(2) << "RGWDataChangesLog::ChangesRenewThread: start" << dendl;
./rgw/rgw_datalog.cc:      dout(0) << "ERROR: RGWDataChangesLog::renew_entries returned error r=" << r << dendl;
./rgw/rgw_sync.cc:        ldout(cct, 0) << "ERROR: RGWBackoffControlCR called coroutine returned " << retcode << dendl;
./rgw/rgw_sync.cc:      ldout(cct, 0) << "ERROR: call to finisher_cr() failed: retcode=" << retcode << dendl;
./rgw/rgw_sync.cc:            ldout(cct, 10) << __func__ << ": failed to fetch log status, ret=" << child_ret << dendl;
./rgw/rgw_sync.cc:          ldout(cct, 10) << __func__ << ": failed to fetch log status, ret=" << child_ret << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to fetch mdlog info" << dendl;
./rgw/rgw_sync.cc:  ldpp_dout(dpp, 20) << "remote mdlog, num_shards=" << log_info->num_shards << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(env->dpp, 0) << "ERROR: failed to read from " << p << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to read from " << p << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to list remote mdlog shard, ret=" << ret << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 5) << "lease cr failed, done early " << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to write sync status, retcode=" << retcode << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 5) << "lease cr failed, done early " << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to fetch metadata sections" << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to fetch mdlog data" << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 0) << "ERROR: can't store key: " << raw_key << " ret=" << ret << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 0) << "ERROR: can't remove key: " << raw_key << " ret=" << ret << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 20) << __func__ << "(): updating marker marker_oid=" << marker_oid << " marker=" << new_marker << " realm_epoch=" << sync_marker.realm_epoch << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << *this << ": failed to fetch remote metadata: " << section << ":" << key << ", will retry" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << *this << ": failed to store metadata: " << section << ":" << key << ", got retcode=" << retcode << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 10) << "sync: full_sync: shard_id=" << shard_id << " r=" << r << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 10) << "sync: incremental_sync: shard_id=" << shard_id << " r=" << r << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 0) << *this << ": child operation stack=" << child << " entry=" << pos << " returned " << child_ret << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(sync_env->dpp, 4) << *this << ": adjusting marker pos=" << sync_marker.marker << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 0) << "ERROR: " << __func__ << "(): RGWRadosGetOmapKeysCR() returned ret=" << retcode << dendl;
./rgw/rgw_sync.cc:	  ldpp_dout(sync_env->dpp, 4) << *this << ": saving marker pos=" << temp_marker->marker << " realm_epoch=" << realm_epoch << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to set sync marker: retcode=" << retcode << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ":" << __LINE__ << ": shard_id=" << shard_id << " mdlog_marker=" << mdlog_marker << " sync_marker.marker=" << sync_marker.marker << " period_marker=" << period_marker << dendl;
./rgw/rgw_sync.cc:          ldpp_dout(sync_env->dpp, 20) << __func__ << ":" << __LINE__ << ": shard_id=" << shard_id << " syncing mdlog for shard_id=" << shard_id << dendl;
./rgw/rgw_sync.cc:              ldpp_dout(sync_env->dpp, 10) << "found key at period_marker=" << period_marker << dendl;
./rgw/rgw_sync.cc:              ldpp_dout(sync_env->dpp, 0) << "ERROR: cannot start syncing " << log_iter->id << ". Duplicate entry?" << dendl;
./rgw/rgw_sync.cc:	ldpp_dout(sync_env->dpp, 20) << __func__ << ":" << __LINE__ << ": shard_id=" << shard_id << " mdlog_marker=" << mdlog_marker << " max_marker=" << max_marker << " sync_marker.marker=" << sync_marker.marker << " period_marker=" << period_marker << dendl;
./rgw/rgw_sync.cc:            ldpp_dout(sync_env->dpp, 10) << "RGWMetaSyncCR with no period" << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 1) << __func__ << "(): going down" << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 10) << __func__ << "(): waiting for master.." << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 1) << __func__ << "(): going down" << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to fetch sync status r=" << r << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(dpp, 20) << __func__ << "(): init" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(dpp, 0) << "ERROR: failed to init sync status r=" << r << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": init request" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": reading shard status" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": reading shard status complete" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": sending rest request" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": receiving rest response" << dendl;
./rgw/rgw_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": storing mdlog entries" << dendl;
./rgw/rgw_sync.cc:      ldpp_dout(sync_env->dpp, 20) << __func__ << ": shard_id=" << shard_id << ": storing mdlog entries complete" << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 0) << "ERROR: mdlog->get_info_async() returned ret=" << ret << dendl;
./rgw/rgw_sync.cc:  ldpp_dout(sync_env->dpp, 20) << "shard_id=" << shard_id << " marker=" << shard_info.marker << " last_update=" << shard_info.last_update << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 0) << "ERROR: failed to fetch mdlog data" << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 5) << "failed to wait for op, ret=" << ret << dendl;
./rgw/rgw_sync.cc:  ldpp_dout(sync_env->dpp, 20) << "remote mdlog, shard_id=" << shard_id << " num of shard entries: " << data.entries.size() << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 20) << "entry: name=" << entry.name << dendl;
./rgw/rgw_sync.cc:    ldpp_dout(sync_env->dpp, 10) << "failed to store md log entries shard_id=" << shard_id << " ret=" << ret << dendl;
./rgw/rgw_rest_oidc_provider.cc:    ldout(s->cct, 20) << "ERROR: Provider ARN is empty"<< dendl;
./rgw/rgw_rest_oidc_provider.cc:    ldout(s->cct, 20) << "ERROR: one of url or thumbprints is empty" << dendl;
./rgw/rgw_rest_oidc_provider.cc:      ldpp_dout(s, 0) << "ARN: " << arn << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 20) << __CEPH_ASSERT_FUNCTION << " redirecting per x-amz-website-redirect-location=" << s->redirect << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "ERROR: failed to decode pg ver attr, ignoring" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "ERROR: failed to decode pg ver attr, ignoring" << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(this,0) << "Error caught buffer::error couldn't decode TagSet " << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(this, 0) << "ERROR: failed to decode RGWObjectRetention" << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(this, 0) << "ERROR: failed to decode RGWObjectLegalHold" << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(this, 10) << "cache override headers" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 10) << "after splitting cache kv key: " << key  << " " << rgw_env->get(key.c_str())  << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this,0) << "ERROR: caught buffer::error, couldn't decode TagSet" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 5) << "Malformed tagging request: " << err << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(this, 20) << "Read " << obj_tags.count() << "tags" << dendl;
./rgw/rgw_rest_s3.cc:      ldout(s->cct,0) << "ERROR: caught buffer::error, couldn't decode TagSet" << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 5) << "Malformed tagging request: " << err << dendl;
./rgw/rgw_rest_s3.cc:  ldout(s->cct, 20) << "Read " << obj_tags.count() << "tags" << dendl;
./rgw/rgw_rest_s3.cc:          ldout(cct, 5) << "NOTICE: bad status provided in DeleteMarkerReplication element (status=" << status << ")" << dendl;
./rgw/rgw_rest_s3.cc:          ldout(cct, 5) << "NOTICE: both tag and prefix were provided in replication filter rule" << dendl;
./rgw/rgw_rest_s3.cc:            ldout(cct, 5) << "NOTICE: too many prefixes were provided in re" << dendl;
./rgw/rgw_rest_s3.cc:        ldout(cct, 5) << "NOTICE: bad status provided in rule (status=" << status << ")" << dendl;
./rgw/rgw_rest_s3.cc:        ldout(s->cct, 5) << "NOTICE: failed to convert replication configuration into sync policy pipe (rule.id=" << rule.id << "): " << cpp_strerror(-r) << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 5) << "Malformed tagging request: " << err << dendl;
./rgw/rgw_rest_s3.cc:        ldout(s->cct, 5) << "bad shard id specified: " << shard_id_str << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 10) << "NOTICE: failed to parse data: " << buf << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 10) << "NOTICE: bad versioning config input" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "ERROR: RGWSetBucketVersioning_ObjStore_S3::get_params(optional_yield y): unexpected switch case mfa_status=" << status_conf.mfa_status << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 5) << "failed to parse xml: " << buf << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 5) << "unexpected xml: " << buf << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 20) << "create bucket input data=" << buf << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "failed to parse input: " << buf << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "provided input did not specify location constraint correctly" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this,0) << "setting obj tags failed with " << ret << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this,0) << "invalid x-amz-object-lock-retain-until-date value" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this,0) << "invalid x-amz-object-lock-mode value" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this,0) << "need both x-amz-object-lock-mode and x-amz-object-lock-retain-until-date " << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this,0) << "invalid x-amz-object-lock-legal-hold value" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << "ERROR: object retention or legal hold can't be set if bucket object lock not configured" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "bad part number: " << multipart_part_str << ": " << err << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 10) << "part number with no multipart upload id" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "bad position: " << pos_str << ": " << err << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "bad position: " << pos_str << ": " << "position shouldn't be negative" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 20) << "field.name=" << pair.first << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 20) << "field.val=" << pair.second.val << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 20) << "field.params:" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "NOTICE: invalid dest placement: " << s->dest_placement.to_str() << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "Couldn't init RGWObjTags XML parser" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this,0 ) << "Invalid Tagging XML" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 5) << "Malformed tagging request: " << err << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 20) << "Read " << obj_tags.count() << "tags" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "Signature verification algorithm AWS v4 (AWS4-HMAC-SHA256)" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "Signature verification algorithm AWS v2" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "No S3 aws4 credential found!" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "No aws4 signature found!" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "No aws4 date found!" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "No S3 aws2 access key found!" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(this, 0) << "No aws2 signature found!" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 20) << "Successful Signature Verification!" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "failed to decode_base64 policy" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 20) << "POST policy: " << decoded_policy.c_str() << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "failed to parse policy" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << "policy check failed" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << "No attached policy found!" << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(this, 20) << "canned_acl=" << canned_acl << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 10) << "failed to parse time: " << if_unmod_decoded << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 0) << __func__ <<  "decode life cycle config failed" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 0) << "ERROR: failed to initialize parser" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 10) << "failed to parse data: " << buf << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(this, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(s, 5) << __func__ << ": unsupported list-type " << list_type << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 5) << "NOTICE: invalid mfa string provided: " << mfa_str << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 5) << "NOTICE: user does not have mfa device with serial=" << serial << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 20) << "NOTICE: failed to check MFA, serial=" << serial << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 0) << "failed to parse copy location" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "WARNING: no authorization backend enabled! Users will never authenticate." << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(s, 10) << __func__ << " Starting retarget" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 5) << s->err.message << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, init_permissions ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, read_permissions ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, init_processing ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, verify_op_mask ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, verify_permission ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "serve_errordoc failed, verify_params ret=" << ret << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(s, 10) << "RGWHandler_REST_S3Website::error_handler err_no=" << err_no << " http_ret=" << http_error_code << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 20) << "No special error handling today!" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "delaying v4 auth" << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(s, 10) << "ERROR: AWS4 completion for this operation NOT IMPLEMENTED" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "body content detected in multiple chunks" << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(s, 10) << "ERROR: AWS4 completion for this operation NOT IMPLEMENTED (streaming mode)" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(s, 10) << "aws4 seed signature ok... delaying v4 auth" << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(s, 10) << "access key id = " << access_key_id << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(s, 10) << "credential scope = " << credential_scope << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(s, 0) << "Signature verification algorithm AWS v2" << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(dpp, 10) << "ERROR: User id of type: " << user_info.type << " is already present" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "ERROR: access key not encoded in user info" << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "server signature=" << server_signature << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "client signature=" << signature << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "compare=" << compare << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "ERROR: Invalid session token, not base64 encoded." << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "ERROR: Invalid secret key" << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "ERROR: Decryption failed: " << error << dendl;
./rgw/rgw_rest_s3.cc:      ldout(cct, 0) << "ERROR: decode SessionToken failed: " << error << dendl;
./rgw/rgw_rest_s3.cc:    ldpp_dout(dpp, 0) << "Invalid access key" << dendl;
./rgw/rgw_rest_s3.cc:          ldpp_dout(dpp, 0) << "ERROR: Token expired" << dendl;
./rgw/rgw_rest_s3.cc:        ldpp_dout(dpp, 0) << "ERROR: Invalid expiration: " << expiration << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "server signature=" << server_signature << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "client signature=" << signature << dendl;
./rgw/rgw_rest_s3.cc:  ldpp_dout(dpp, 15) << "compare=" << compare << dendl;
./rgw/rgw_rest_s3.cc:      ldpp_dout(dpp, 5) << "ERROR: failed reading user info: uid=" << token.user << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 10) << "s3-select query: failed to retrieve query; ret = " << ret << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 10) << "s3-select query: " << m_s3select_query << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 10) << "s3-select query: failed to retrieve query;" << dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 10) << "s3-select query: failed to prase query; {" << s3select_syntax->get_error_description() << "}"<< dendl;
./rgw/rgw_rest_s3.cc:    ldout(s->cct, 10) << "RGW supports currently only NONE option for compression type" << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 0) << "ERROR: failed to read from " << p << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 0) << "ERROR: failed to read from " << p << dendl;
./rgw/rgw_data_sync.cc:      ldout(sync_env->cct, 0) << "ERROR: failed to read from " << p << dendl;
./rgw/rgw_data_sync.cc:      ldout(sync_env->cct, 0) << "ERROR: failed to list remote datalog shard, ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to fetch datalog info" << dendl;
./rgw/rgw_data_sync.cc:  ldpp_dout(dpp, 20) << "remote datalog, num_shards=" << log_info->num_shards << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 0) << "ERROR: failed to fetch metadata for section bucket.instance" << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 20) << "list metadata: section=bucket.instance key=" << *iter << dendl;
./rgw/rgw_data_sync.cc:      ldout(cct, 0) << "ERROR: " << __func__ << "(): could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_data_sync.cc:      ldout(cct, 0) << "ERROR: " << __func__ << ": caught buffer::error couldn't decode TagSet " << dendl;
./rgw/rgw_data_sync.cc:    ldout(cct, 0) << "WARNING: " << __func__ << ": pipe dest params are different than original params, must have raced with object rewrite, retrying" << dendl;
./rgw/rgw_data_sync.cc:      ldout(cct, 0) << "ERROR: " << __func__ << ": permission check failed: user not allowed to fetch object" << dendl;
./rgw/rgw_data_sync.cc:          ldout(cct, 20) << "Could not determine exact policy rule for obj=" << key << ", will read source object attributes" << dendl;
./rgw/rgw_data_sync.cc:              ldout(cct, 0) << "ERROR: " << __func__ << ": caught buffer::error couldn't decode TagSet " << dendl;
./rgw/rgw_data_sync.cc:            ldout(cct, 20) << "ERROR: " << __func__ << ": user level sync but user param not set" << dendl;
./rgw/rgw_data_sync.cc:            ldout(cct, 20) << "ERROR: " << __func__ << ": failed to init user perms manager for uid=" << *param_user << dendl;
./rgw/rgw_data_sync.cc:            ldout(cct, 20) << "ERROR: " << __func__ << ": failed to init bucket perms manager for uid=" << *param_user << " bucket=" << sync_pipe.source_bucket_info.bucket.get_key() << dendl;
./rgw/rgw_data_sync.cc:            ldout(cct, 0) << "ERROR: " << __func__ << ": permission check failed: user not allowed to write into bucket (bucket=" << sync_pipe.info.dest_bs.bucket.get_key() << ")" << dendl;
./rgw/rgw_data_sync.cc:            ldout(cct, 20) << "ERROR: " << __func__ << ": failed to init bucket perms manager for uid=" << *param_user << " bucket=" << sync_pipe.source_bucket_info.bucket.get_key() << dendl;
./rgw/rgw_data_sync.cc:      ldout(cct, 0) << "ERROR: " << __func__ << ": Too many retries trying to fetch object, possibly a bug: bucket=" << sync_pipe.source_bucket_info.bucket.get_key() << " key=" << key << dendl;
./rgw/rgw_data_sync.cc:  ldout(sc->cct, 5) << "SYNC_ARCHIVE: sync_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " versioned_epoch=" << versioned_epoch.value_or(0) << dendl;
./rgw/rgw_data_sync.cc:      ldout(sc->cct, 0) << "SYNC_ARCHIVE: sync_object: enabling object versioning for archive bucket" << dendl;
./rgw/rgw_data_sync.cc:         ldpp_dout(sync_env->dpp, 0) << "SYNC_ARCHIVE: sync_object: error versioning archive bucket" << dendl;
./rgw/rgw_data_sync.cc:  ldout(sc->cct, 0) << "SYNC_ARCHIVE: remove_object: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " versioned_epoch=" << versioned_epoch << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to run sync" << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 0) << "ERROR: failed to find zone config info for zone=" << source_zone << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 0) << "connection object to zone " << source_zone << " does not exist" << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 0) << "ERROR: failed to init remote log, r=" << r << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 5) << "ERROR: master.read_log_info() returned r=" << r << dendl;
./rgw/rgw_data_sync.cc:        ldout(cct, 0) << "ERROR: failed to fetch bucket index status" << dendl;
./rgw/rgw_data_sync.cc:    ldout(cct, 0) << "ERROR: failed to decode attribute: " << attr_name << dendl;
./rgw/rgw_data_sync.cc:      ldout(sync_env->cct, 0) << "ERROR: failed to call fetch bucket shard info oid=" << oid << " ret=" << retcode << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(dpp, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 20) << "syncstop on " << e.timestamp << dendl;
./rgw/rgw_data_sync.cc:          ldout(sync_env->cct, 20) << "detected syncstop or resync on " << entries_iter->timestamp << ", skipping entry" << dendl;
./rgw/rgw_data_sync.cc:          ldpp_dout(sync_env->dpp, 20) << __func__ << ": pipe_handler=" << handler << ": skipping" << dendl;
./rgw/rgw_data_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": pipe_handler=" << handler << ": adding" << dendl;
./rgw/rgw_data_sync.cc:          ldpp_dout(sync_env->dpp, 20) << __func__ << ": pipe_handler=" << handler << ": skipping" << dendl;
./rgw/rgw_data_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << ": pipe_handler=" << handler << ": adding" << dendl;
./rgw/rgw_data_sync.cc:        ldout(sync_env->cct, 0) << "ERROR: " << __func__ << "(): failed to fetch bucket sync hints for bucket=" << source_bucket << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(sync_env->dpp, 20) << __func__ << "(): requested source_bs=" << source_bs << " target_bs=" << target_bs << dendl;
./rgw/rgw_data_sync.cc:      ldpp_dout(sync_env->dpp, 20) << __func__ << "(): no relevant sync pipes found" << dendl;
./rgw/rgw_data_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << "(): sync pipe=" << *siter << dendl;
./rgw/rgw_data_sync.cc:      ldpp_dout(sync_env->dpp, 20) << __func__ << "(): num shards=" << num_shards << " cur_shard=" << cur_shard << dendl;
./rgw/rgw_data_sync.cc:        ldpp_dout(sync_env->dpp, 20) << __func__ << "(): sync_pair=" << sync_pair << dendl;
./rgw/rgw_data_sync.cc:          ldpp_dout(sync_env->dpp, 20) << "Got sync hint for bucket=" << *source_bucket << ": " << hiter->get_key() << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 0) << "failed in http_manager.start() ret=" << ret << dendl;
./rgw/rgw_data_sync.cc:    ldpp_dout(this, 0) << "failed to get bucket source peers info: (ret=" << ret << "): " << cpp_strerror(-ret) << dendl;
./rgw/rgw_data_sync.cc:        ldpp_dout(this, 0) << "connection object to zone " << szone << " does not exist" << dendl;
./rgw/rgw_data_sync.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to get bucket instance info: bucket=" << source_bucket << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_loadgen_process.cc:  dout(10) << "allocated request req=" << hex << req << dec << dendl;
./rgw/rgw_loadgen_process.cc:    dout(20) << "process_request() returned " << ret << dendl;
./rgw/rgw_rados.cc:      dout(0) << "ERROR: processor->process() returned error r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << __func__ << "(): notifying mdlog change, shard_id=" << *iter << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 0) << "ERROR: sync.init() returned " << ret << dendl;
./rgw/rgw_rados.cc:  ldout(ctx(), 20) << __func__ << ": source_zone=" << source_zone << ", shard_ids=" << shard_ids << dendl;
./rgw/rgw_rados.cc:    ldout(ctx(), 10) << __func__ << ": couldn't find sync thread for zone " << source_zone << ", skipping async data sync processing" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: open_pool_ctx() returned " << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << "required alignment=" << align << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << "max_chunk_size=" << *max_chunk_size << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to get data pool for object " << obj << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 20) << __func__ << "(): handling completion for key=" << c->key << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "ERROR: " << __func__ << "(): failed to initialize BucketShard, obj=" << c->obj << " r=" << r << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(this, 0) << "ERROR: " << __func__ << "(): bucket index completion failed, obj=" << c->obj << " r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: service_daemon_register() returned ret=" << ret << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: service_daemon_update_status() returned ret=" << ret << ": " << cpp_strerror(-ret) << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to initialize meta sync thread" << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to start bucket trim manager" << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 5) << "starting data sync thread for zone " << source_zone->name << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: failed to initialize data sync thread" << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: failed to initialize sync log trim thread" << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << __func__ << " bucket index max shards: " << bucket_index_max_shards << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 1) << "ERROR: failed to initialize notification manager" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to init services (ret=" << cpp_strerror(-ret) << ")" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to init ctls (ret=" << cpp_strerror(-ret) << ")" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 10) << " read " << r << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "WARNING: RGWRados::log_usage(): user name empty (bucket=" << ub.bucket << "), skipping" << dendl;
./rgw/rgw_rados.cc:      ldout(cct,0) << "usage clear on oid="<< oid << "failed with ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 20) << "skip_after_delim=" << skip_after_delim << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "get_bucket_info returned " << r << dendl;
./rgw/rgw_rados.cc:	  ldout(cct, 0) << "WARNING: could not remove bucket index (r=" << r << ")" << dendl;
./rgw/rgw_rados.cc:          ldout(cct, 0) << "WARNING: " << __func__ << "(): failed to remove bucket instance info: bucket instance=" << info.bucket.get_key() << ": r=" << r << dendl;
./rgw/rgw_rados.cc:  ldout(cct, 0) << "ERROR: could not create bucket, continuously raced with bucket creation and removal" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: cannot get data pool for obj=" << obj << ", probably misconfiguration" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: cannot get data pool for obj=" << obj << ", probably misconfiguration" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed opening data pool (pool=" << pool << "); r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed opening pool (pool=" << obj.pool << "); r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << "object does not have a locator, nothing to fix" << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 20) << __func__ << ": key=" << key << " oid=" << oid << " locator=" << locator << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 20) << __func__ << ": found bad object part: " << loc << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: open_bucket_index_shard() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << " bucket index object: " << bucket_obj.get_raw_obj() << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: open_bucket_index_shard() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << " bucket index oid: " << bucket_obj.get_raw_obj() << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: open_bucket_index_shard() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:  ldout(store->ctx(), 20) << " bucket index object: " << bucket_obj << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: open_bucket_index_shard() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:  ldout(store->ctx(), 20) << " bucket index object: " << bucket_obj << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 10) << "failed to read dest bucket info: r=" << r << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: " << __func__ << "(): cannot write object with empty name" << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: complete_atomic_modification returned r=" << r << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 0) << "ERROR: objexp_hint_add() returned r=" << r << ", object will not get removed" << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "ERROR: index_op.cancel()() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "failed to parse response extra data. len=" << extra_data_bl.length() << " data=" << extra_data_bl.c_str() << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "could not find zonegroup connection to zonegroup: " << source_zone << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "could not find zone connection to zone: " << source_zone << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "failed to parse response extra data. len=" << extra_data_bl.length() << " data=" << extra_data_bl.c_str() << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "could not find zonegroup connection to zonegroup: " << source_zone << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "could not find zone connection to zone: " << source_zone << dendl;
./rgw/rgw_rados.cc:                        ldout(cct, 5) << "Aborting fetch: source object filter returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 10) << "owner info does not exist" << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "WARNING: " << __func__ << "(): object doesn't have ACL attribute, setting default ACLs" << dendl;
./rgw/rgw_rados.cc:	ldout(cct, 0) << "ERROR: " << __func__ << "(): could not decode policy, caught buffer::error" << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "ERROR: failed to decode delete_at field in intra zone copy" << dendl;
./rgw/rgw_rados.cc:        ldout(ctx(), 0) << "ERROR: failed to decode pg ver attribute, ignoring" << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 20) << "raced with another write of obj: " << dest_obj << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "ERROR: " << __func__ << ": get_err_state() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 20) << "retrying writing object mtime=" << set_mtime << " dest_state->mtime=" << dest_state->mtime << " dest_state->exists=" << dest_state->exists << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 20) << "not retrying writing object mtime=" << set_mtime << " dest_state->mtime=" << dest_state->mtime << " dest_state->exists=" << dest_state->exists << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: retried object completion too many times, something is wrong!" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: can't copy object when both src and dest buckets are remote" << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 5) << "Copy object " << src_obj->get_bucket() << ":" << src_obj->get_oid() << " => " << dest_obj->get_bucket() << ":" << dest_obj->get_oid() << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to get max_chunk_size() for bucket " << dest_obj->get_bucket() << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << __func__ << "(): manifest src_rule=" << src_rule->to_str() << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to locate data pool for " << src_obj << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to locate data pool for " << dest_obj << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << "dest_obj=" << dest_obj << " src_obj=" << src_obj << " copy_itself=" << (int)copy_itself << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: cleanup after error failed to drop reference on obj=" << *riter << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: fail to read object data, ret = " << ret << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to read compression info" << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: read_bucket_entrypoint_info() bucket=" << bucket_info.bucket << " returned error: r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "NOTICE: get_bucket_info on bucket=" << bucket.name << " returned err=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "NOTICE: put_bucket_info on bucket=" << bucket.name << " returned err=" << r << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 20) << "enabling bucket name=" << bucket.name << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 20) << "disabling bucket name=" << bucket.name << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "NOTICE: get_bucket_info on bucket=" << bucket.name << " returned err=" << r << ", skipping bucket" << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "NOTICE: put_bucket_info on bucket=" << bucket.name << " returned err=" << r << ", skipping bucket" << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 5) << "delete_objs_inline: refcount put returned error " << ret << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "state for obj=" << obj << " is not atomic, not deferring gc operation" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "state->obj_tag is empty, not deferring gc operation" << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 0) << "defer chain tag=" << tag << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 5) << "failed to get BucketShard object: r=" << r << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 10) << "If-UnModified-Since: " << params.unmod_since << " Last-Modified: " << ctime << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: couldn't decode RGW_ATTR_DELETE_AT" << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: complete_atomic_modification returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 0) << "ERROR: index_op.cancel() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "() get_bucket_instance_info(bucket=" << obj.bucket << ") returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:  ldout(store->ctx(), 10) << "generate_fake_tag new tag=" << tag << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << "get_obj_state: rctx=" << (void *)rctx << " obj=" << obj << " state=" << (void *)s << " s->prefetch_data=" << s->prefetch_data << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: could not decode compression info for object: " << obj << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "ERROR: couldn't decode manifest" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 10) << "manifest: total_size = " << s->manifest->get_obj_size() << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 20) << "manifest: ofs=" << mi.get_ofs() << " loc=" << mi.get_location().get_raw_obj(store) << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: couldn't decode pg ver attr for object " << s->obj << ", non-critical error, ignoring" << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: couldn't decode zone short id attr for object " << s->obj << ", non-critical error, ignoring" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "get_obj_state: setting s->obj_tag to " << s->obj_tag.c_str() << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "get_obj_state: s->obj_tag was set empty" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << __func__ << ": setting s->olh_tag to " << string(s->olh_tag.c_str(), s->olh_tag.length()) << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 0) << "ERROR: " << __func__ << ": failed to decode manifest"  << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << "state for obj=" << state->obj << " is not atomic, not appending atomic test" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << "state->obj_tag is empty, not appending atomic test" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "prepare_atomic_modification: state is not atomic. state=" << (void *)state << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 10) << "setting object write_tag=" << state->write_tag << dendl;
./rgw/rgw_rados.cc:	ldpp_dout(dpp, 0) << "ERROR: failed to decode " RGW_ATTR_DELETE_AT << " attr" << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "ERROR: complete_update_index_cancel() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 20) << "Read xattr rgw_rados: " << iter->first << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 10) << "If-Modified-Since: " << dest_weight << " Last-Modified: " << src_weight << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 10) << "If-UnModified-Since: " << dest_weight << " Last-Modified: " << src_weight << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 10) << "ETag: " << string(etag.c_str(), etag.length()) << " " << " If-Match: " << if_match_str << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 10) << "ETag: " << string(etag.c_str(), etag.length()) << " " << " If-NoMatch: " << if_nomatch_str << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 5) << "failed to get BucketShard object: ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 0) << "NOTICE: resharding operation on bucket index detected, blocking" << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 20) << "reshard completion identified, new_bucket_id=" << new_bucket_id << dendl;
./rgw/rgw_rados.cc:      ldout(store->ctx(), 0) << "ERROR: update_bucket_id() new_bucket_id=" << new_bucket_id << " returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 5) << "failed to get BucketShard object: ret=" << ret << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 0) << "WARNING: could not decode policy ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(store->ctx(), 5) << "failed to get BucketShard object: ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "ERROR: failed to get max_chunk_size() for pool " << read_obj.pool << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << "rados->read obj-ofs=" << ofs << " read_ofs=" << read_ofs << " read_len=" << read_len << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 20) << "ERROR: failed to open pool context for pool=" << read_obj.pool << " r=" << r << dendl;
./rgw/rgw_rados.cc:  ldpp_dout(dpp, 20) << "rados->read r=" << r << " bl.length=" << bl.length() << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 4) << "failed to open rados context for " << read_obj << dendl;
./rgw/rgw_rados.cc:  ldout(cct, 20) << "rados->get_obj_iterate_cb oid=" << read_obj.oid << " obj-ofs=" << obj_ofs << " read_ofs=" << read_ofs << " len=" << len << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "iterate_obj() failed with " << r << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 5) << "bs.init() returned ret=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "NOTICE: resharding operation on bucket index detected, blocking" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "reshard completion identified, new_bucket_id=" << new_bucket_id << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "rgw_rados_operate() after cls_rgw_bucket_link_olh() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed writing data log" << dendl;
./rgw/rgw_rados.cc:  ldout(cct, 20) << __func__ << "(): olh_state.olh_tag=" << string(olh_state.olh_tag.c_str(), olh_state.olh_tag.length()) << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "rgw_rados_operate() after cls_rgw_bucket_link_instance() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "cls_rgw_get_olh_log() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "repair_olh failed to read olh entry for " << obj << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "cls_rgw_trim_olh_log() returned r=" << ret << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 5) << "rgw_rados_operate() after cls_rgw_clear_olh() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed to decode olh info" << dendl;
./rgw/rgw_rados.cc:        ldpp_dout(dpp, 0) << "ERROR: apply_olh_log: invalid op: " << (int)entry.op << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "ERROR: delete_obj() returned " << ret << " obj_instance=" << obj_instance << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: could not apply olh update, r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: could not trim olh log, r=" << r << dendl;
./rgw/rgw_rados.cc:        ldout(cct, 0) << "ERROR: could not clear bucket index olh entries r=" << r << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 20) << "olh_init_modification() target_obj=" << target_obj << " delete_marker=" << (int)delete_marker << " returned " << ret << dendl;
./rgw/rgw_rados.cc:      ldpp_dout(dpp, 20) << "bucket_index_link_olh() target_obj=" << target_obj << " delete_marker=" << (int)delete_marker << " returned " << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: exceeded max ECANCELED retries, aborting (EIO)" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "update_olh() target_obj=" << target_obj << " returned " << ret << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 20) << "olh_init_modification() target_obj=" << target_obj << " returned " << ret << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 20) << "bucket_index_unlink_instance() target_obj=" << target_obj << " returned " << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: exceeded max ECANCELED retries, aborting (EIO)" << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "update_olh() target_obj=" << target_obj << " returned " << ret << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "ERROR: failed to decode pending entry " << iter->first << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 0) << "ERROR: could not apply olh update, r=" << r << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 20) << "ERROR: rm_pending_entries returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << __func__ << "(): found pending entries, need to update_olh() on bucket=" << olh_obj.bucket << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 10) << "failed to parse cursor: " << cursor << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 20) << "RGWRados::pool_iterate: got " << oid << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 10) << "failed to list objects pool_iterate_begin() returned r=" << r << dendl;
./rgw/rgw_rados.cc:      ldout(cct, 10) << "failed to list objects pool_iterate returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: bi_get() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed to decode bi_entry()" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: bi_get() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 0) << "ERROR: failed to decode bi_entry()" << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.index_ctx.remove(" << bs.bucket_obj << ") returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    ldout(cct, 5) << "bs.init() returned ret=" << ret << dendl;
./rgw/rgw_rados.cc:    dout(2) << "RGWRados::remove_objs_from_index bucket=" << bucket_info.bucket << " obj=" << entry.key.name << ":" << entry.key.instance << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 0) << "WARNING: generated locator (" << loc << ") is different from listed locator (" << list_state.locator << ")" << dendl;
./rgw/rgw_rados.cc:      dout(0) << "WARNING: could not decode policy for object: " << obj << dendl;
./rgw/rgw_rados.cc:	dout(10) << "check_disk_state(): removing manifest part from index: " << loc << dendl;
./rgw/rgw_rados.cc:	  dout(0) << "WARNING: delete_obj_index() returned r=" << r << dendl;
./rgw/rgw_rados.cc:    ldpp_dout(dpp, 20) << "not resharding bucket name=" << bucket_info.bucket.name << ", orig_num=" << num_source_shards << ", new_num_shards=" << new_num_shards << dendl;
./rgw/rgw_rest_client.cc:      ldout(cct, 0) << "ERROR: failed converting content length (" << val << ") to int " << dendl;
./rgw/rgw_rest_client.cc:  ldout(cct, 10) << "receive_http_header" << dendl;
./rgw/rgw_rest_client.cc:      ldout(cct, 10) << "received header:" << line << dendl;
./rgw/rgw_rest_client.cc:      ldpp_dout(dpp, 20) << __func__ << "():> " << i.first << " -> " << rgw::crypt_sanitize::x_meta_map{i.first, i.second} << dendl;
./rgw/rgw_rest_client.cc:    ldpp_dout(dpp, 0) << "failed to create canonical s3 header" << dendl;
./rgw/rgw_rest_client.cc:  ldpp_dout(dpp, 10) << "generated canonical header: " << canonical_header << dendl;
./rgw/rgw_rest_client.cc:  ldpp_dout(dpp, 15) << "generated auth header: " << auth_hdr << dendl;
./rgw/rgw_rest_client.cc:      ldpp_dout(dpp, 20) << __func__ << "():> " << i.first << " -> " << rgw::crypt_sanitize::x_meta_map{i.first, i.second} << dendl;
./rgw/rgw_rest_client.cc:    ldpp_dout(dpp, 20) << __func__ << "(): sigv4 header: " << entry.first << ": " << entry.second << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 20) << "NOTICE: cannot identify region for connection to: " << host << dendl;
./rgw/rgw_rest_client.cc:        ldout(cct, 0) << "WARNING: cannot identify region name from host name: " << host << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 0) << "ERROR: failed to sign request" << dendl;
./rgw/rgw_rest_client.cc:  dout(20) << "RGWRESTStreamOutCB::handle_data bl.length()=" << bl.length() << " bl_ofs=" << bl_ofs << " bl_len=" << bl_len << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 0) << "ERROR: couldn't get policy ret=" << ret << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 0) << "ERROR: failed to sign request" << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 0) << "ERROR: failed converting mtime (" << s << ") to real_time " << dendl;
./rgw/rgw_rest_client.cc:      ldout(cct, 0) << "ERROR: failed converting mtime (" << s << ") to real_time " << dendl;
./rgw/rgw_rest_client.cc:    ldout(cct, 0) << "ERROR: " << __func__ << "(): send_prepare() was not called: likey a bug!" << dendl;
./rgw/rgw_rest_client.cc:      ldout(cct, 0) << "ERROR: failed to sign request" << dendl;
./rgw/rgw_rest_client.cc:        ldout(cct, 0) << "ERROR: failed parsing embedded metadata object size (" << size_str << ") to int " << dendl;
./rgw/rgw_rest_client.cc:      ldout(cct, 0) << "ERROR: failed converting embedded metadata len (" << val << ") to int " << dendl;
./rgw/rgw_common.cc:        ldpp_dout(dpp, 10) << "meta>> " << p << dendl;
./rgw/rgw_common.cc:    ldpp_dout(dpp, 10) << "x>> " << kv.first << ":" << rgw::crypt_sanitize::x_meta_map{kv.first, kv.second} << dendl;
./rgw/rgw_common.cc:    dout(0) << "parse_iso8601 failed" << dendl;
./rgw/rgw_common.cc:      ldpp_dout(dpp, 10) << "name: " << name << " val: " << val << dendl;
./rgw/rgw_common.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to decode RGWObjectRetention" << dendl;
./rgw/rgw_common.cc:      ldpp_dout(dpp, 0) << "ERROR: failed to decode RGWObjectLegalHold" << dendl;
./rgw/rgw_client_io.cc:      ldout(cct, 20) << iter.first << "=" << (x) << dendl;
./rgw/rgw_rest_metadata.cc:    ldpp_dout(s, 5) << "ERROR: can't get key: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_rest_metadata.cc:      dout(5) << "Error parsing max-entries " << max_entries_str << dendl;
./rgw/rgw_rest_metadata.cc:    dout(5) << "ERROR: can't get key: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_rest_metadata.cc:      dout(10) << "recv_body incomplete" << dendl;
./rgw/rgw_rest_metadata.cc:    ldpp_dout(s, 5) << "ERROR: can't put key: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_rest_metadata.cc:    ldpp_dout(s, 5) << "ERROR: can't remove key: " << cpp_strerror(op_ret) << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Vault token file not set in rgw_crypt_vault_token_file" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Vault token file: " << token_file << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Vault token file '" << token_file << "' not found  " << dendl;
./rgw/rgw_kms.cc:        ldout(cct, 0) << "ERROR: Permission denied reading Vault token file" << dendl;
./rgw/rgw_kms.cc:        ldout(cct, 0) << "ERROR: Failed to read Vault token file with error " << res << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "Loading Vault Token from filesystem" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Vault address not set in rgw_crypt_vault_addr" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 20) << "Vault Namespace: " << vault_namespace << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Request to Vault failed with error " << res << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Vault request failed authorization" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Failed to base64 decode key retrieved from Vault" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 20) << "Missing or invalid key version" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Parse response into JSON Object" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Key not found in JSON response from Vault using Transit Engine" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "sorry, can't allow / in keyid" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: can't make json for vault" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Parse response into JSON Object" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: response from Vault is not an object" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: no .data in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: no .data.ciphertext in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: no .data.plaintext in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: .data.ciphertext not a string in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: .data.plaintext not a string in response from Vault" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: can't make json for vault" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Parse response into JSON Object" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: response from Vault is not an object" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: no .data in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: no .data.plaintext in response from Vault" << dendl;
./rgw/rgw_kms.cc:	ldout(cct, 0) << "ERROR: .data.plaintext not a string in response from Vault" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Parse response into JSON Object" << dendl;
./rgw/rgw_kms.cc:      ldout(cct, 0) << "ERROR: Key not found in JSON response from Vault using KV Engine" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 20) << "Wrong size for key=" << key_id << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 0) << "ERROR: conf rgw_barbican_url is not set" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 5) << "Failed to retrieve token for Barbican" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 5) << "Failed to retrieve secret from Barbican:" << key_id << dendl;
./rgw/rgw_kms.cc:  ldout(cct, 20) << "Vault authentication method: " << cct->_conf->rgw_crypt_vault_auth << dendl;
./rgw/rgw_kms.cc:  ldout(cct, 20) << "Vault Secrets Engine: " << secret_engine << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 0) << "Missing or invalid secret engine" << dendl;
./rgw/rgw_kms.cc:    ldout(cct, 0) << "Missing or invalid secret engine" << dendl;
./rgw/rgw_kms.cc:  ldout(cct, 20) << "Getting KMS encryption key for key " << key_id << dendl;
./rgw/rgw_kms.cc:  ldout(cct, 20) << "SSE-KMS backend is " << kms_backend << dendl;
./rgw/rgw_kms.cc:  ldout(cct, 0) << "ERROR: Invalid rgw_crypt_s3_kms_backend: " << kms_backend << dendl;
./rgw/rgw_iam_policy.cc:  ldout(cct, 0) << "Supplied principal is discarded: " << s << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldpp_dout(dpp, 20) << "push endpoint created: " << push_endpoint->to_str() << dendl;
./rgw/rgw_sync_module_pubsub.cc:    ldout(cct, 20) << "pubsub: module config (parsed representation):\n" << json_str("config", *this, true) << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(cct, 20) << __func__ << "(): operate_wrapper() -> operate()" << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldout(cct, 20) << *this << ": operate() returned r=" << operate_ret << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(cct, 20) << __func__ << "(): RGWSingletonCR: operate_wrapper() done, need to wake up " << waiters.size() << " waiters" << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(cct, 20) << __func__ << "(): RGWSingletonCR: waking up waiter" << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(cct, 20) << __func__ << "(): singleton not started, starting" << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(cct, 20) << __func__ << "(): singleton not done yet, registering as waiter" << dendl;
./rgw/rgw_sync_module_pubsub.cc:    ldout(cct, 20) << __func__ << "(): singleton done, returning retcode=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldpp_dout(sync_env->dpp, 0) << __func__ <<  "(): decode life cycle config failed" << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldpp_dout(sync_env->dpp, 20) << "no need to set lifecycle rule on bucket, existing rule matches config" << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to set lifecycle on bucket: ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:                ldpp_dout(sync_env->dpp, 1) << "ERROR: data_access.get_bucket() bucket=" << result->bucket << " failed, ret=" << ret << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to init lifecycle on bucket (bucket=" << sub_conf->data_bucket_name << ") ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldpp_dout(sync_env->dpp, 20) << "pubsub: bucket create: using user info: " << json_str("obj", *sub->env->data_user_info, true) << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldpp_dout(sync_env->dpp, 10) << "failed to store event: " << put_obj.bucket << "/" << put_obj.key << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldpp_dout(sync_env->dpp, 20) << "event stored: " << put_obj.bucket << "/" << put_obj.key << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldout(sync_env->cct, 1) << "ERROR: missing user info when getting subscription: " << sub_name << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldout(sync_env->cct, 1) << "ERROR: failed to init subscription when getting subscription: " << sub_name << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(cct, 20) << __func__ << "(): returning result: retcode=" << retcode << " resultp=" << (void *)result << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(sc->cct, 20) << __func__ << "(): found sub instance" << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(sc->cct, 20) << __func__ << "(): first get subs" << dendl;
./rgw/rgw_sync_module_pubsub.cc:    ldout(sc->cct, 20) << __func__ << "(): executing get subs" << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldpp_dout(sync_env->dpp, 1) << ": init pubsub config zone=" << sc->source_zone << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to create rgw user: ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to create rgw user: ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldpp_dout(sync_env->dpp, 20) << "pubsub: get user info cr returned: " << json_str("obj", *env->data_user_info, true) << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(sync_env->cct, 20) << "RGWPSFindBucketTopicsCR(): found " << bucket_topics.topics.size() << " topics for bucket " << bucket << dendl;
./rgw/rgw_sync_module_pubsub.cc:      ldout(sc->cct, 20) << "pubsub: " << topics->size() << " topics found for path" << dendl;
./rgw/rgw_sync_module_pubsub.cc:          ldout(sc->cct, 20) << ": subscription: " << *siter << dendl;
./rgw/rgw_sync_module_pubsub.cc:            ldout(sc->cct, 20) << "storing event for subscription=" << *siter << " owner=" << owner << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldout(sc->cct, 1) << "ERROR: failed to store event for subscription=" << *siter << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldout(sc->cct, 20) << "push event for subscription=" << *siter << " owner=" << owner << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:                ldout(sc->cct, 1) << "ERROR: failed to push event for subscription=" << *siter << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:            ldout(sc->cct, 20) << "storing s3 event for subscription=" << *siter << " owner=" << owner << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:              ldout(sc->cct, 1) << "ERROR: failed to store s3 event for subscription=" << *siter << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:                ldout(sc->cct, 20) << "push s3 event for subscription=" << *siter << " owner=" << owner << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:                ldout(sc->cct, 1) << "ERROR: failed to push s3 event for subscription=" << *siter << " ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(sc->cct, 1) << "ERROR: RGWPSFindBucketTopicsCR returned ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(sc->cct, 20) << "no topics found for " << sync_pipe.info.source_bs.bucket << "/" << key << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(sc->cct, 1) << "ERROR: RGWPSFindBucketTopicsCR returned ret=" << retcode << dendl;
./rgw/rgw_sync_module_pubsub.cc:        ldout(sc->cct, 20) << "no topics found for " << bucket << "/" << key << dendl;
./rgw/rgw_sync_module_pubsub.cc:    ldout(sc->cct, 5) << conf->id << ": start" << dendl;
./rgw/rgw_sync_module_pubsub.cc:    ldout(cct, 1) << "ERROR: failed to parse sync module effective conf: " << jconf << dendl;
./rgw/rgw_sync_trace.cc:    ldout(store->ctx(), 0) << "ERROR: update_service_map() returned ret=" << ret << dendl;
./rgw/rgw_sync_trace.cc:    ldout(cct, 5) << "NOTICE: sync trace: bad expression: bad regex search term" << dendl;
./rgw/rgw_sync_module.cc:      ldout(sync_env->cct, 10) << "RGWStatRemoteObjCR() returned " << retcode << dendl;
./rgw/rgw_sync_module.cc:      ldout(sync_env->cct, 10) << "RGWStatRemoteObjCR() callback returned " << retcode << dendl;
./rgw/rgw_fcgi_process.cc:    dout(10) << "allocated request req=" << hex << req << dec << dendl;
./rgw/rgw_fcgi_process.cc:      dout(0) << "ERROR: FCGX_Accept_r returned " << ret << dendl;
./rgw/rgw_fcgi_process.cc:  dout(20) << "cleaning up fcgx connections" << dendl;
./rgw/rgw_fcgi_process.cc:    dout(20) << "process_request() returned " << ret << dendl;
./rgw/rgw_multi.cc:    ldpp_dout(dpp, 5) << __func__ << ": gc->send_chain() returned " << ret << dendl;
./rgw/rgw_gc.cc:  ldpp_dout(this, 20) << "RGWGC::send_chain - on object name: " << obj_names[i] << "tag is: " << tag << dendl;
./rgw/rgw_gc.cc:          ldpp_dout(this, 20) << "RGWGC::process cls_rgw_gc_list returned NO non expired entries, so setting cache entry to TRUE" << dendl;
./rgw/rgw_gc.cc:      ldpp_dout(this, 5) << "RGWGC::process removing entries, marker: " << marker << dendl;
./rgw/rgw_gc.cc:    ldpp_dout(dpp, 2) << "garbage collection: start" << dendl;
./rgw/rgw_gc.cc:      ldpp_dout(dpp, 0) << "ERROR: garbage collection process() returned error r=" << r << dendl;
./rgw/rgw_gc.cc:    ldpp_dout(dpp, 2) << "garbage collection: stop" << dendl;
./rgw/rgw_lua_utils.cc:  ldout(cct, 20) << "Lua INFO: " << message << dendl;
./rgw/rgw_main.cc:  dout(1) << __func__ << dendl;
./rgw/rgw_main.cc:    dout(1) << __func__ << " set alarm for " << secs << dendl;
./rgw/rgw_main.cc:    dout(1) << __func__ << " not setting numa affinity" << dendl;
./rgw/rgw_main.cc:    dout(0) << "WARNING: rgw_keystone_admin_token and rgw_keystone_admin_password should be avoided as they can expose secrets.  Prefer the new rgw_keystone_admin_token_path and rgw_keystone_admin_password_path options, which read their secrets from files." << dendl;
./rgw/rgw_main.cc:        dout(1) << "ERROR: failed to initialize AMQP manager" << dendl;
./rgw/rgw_main.cc:        dout(1) << "ERROR: failed to initialize Kafka manager" << dendl;
./rgw/rgw_main.cc:    dout(1) << "ERROR: failed to install lua packages from allowlist" << dendl;
./rgw/rgw_main.cc:    dout(10) << "INFO: lua packages installation output: \n" << output << dendl; 
./rgw/rgw_main.cc:    dout(5) << "WARNING: failed to install lua package: " << p << " from allowlist" << dendl;
./rgw/rgw_main.cc:      dout(0) << "WARNING: skipping unknown framework: " << framework << dendl;
./rgw/rgw_main.cc:    dout(0) << "starting handler: " << fiter->first << dendl;
./rgw/rgw_main.cc:  dout(1) << "final shutdown" << dendl;
./ceph_mds.cc:    dout(1) << __func__ << " not setting numa affinity" << dendl;
./ceph_mds.cc:      dout(0) << "--hot-standby is obsolete and has no effect" << dendl;
./compressor/zlib/ZlibCompressor.cc:      dout(10) << "Compression error: unused input" << dendl;
./compressor/zlib/ZlibCompressor.cc:      dout(10) << "Compression error: unused input" << dendl;
./ceph_mon.cc:  dout(10) << __func__ << dendl;
./ceph_mon.cc:    dout(10) << __func__ << " detected aborted sync" << dendl;
./ceph_mon.cc:      dout(10) << __func__ << " read backup monmap" << dendl;
./ceph_mon.cc:    dout(10) << __func__ << " found mkfs monmap" << dendl;
./ceph_mon.cc:    dout(10) << "public_network " << g_conf()->public_network << dendl;
./ceph_mon.cc:    dout(10) << "public_addr " << g_conf()->public_addr << dendl;
./ceph_mon.cc:    dout(10) << "public_addrv " << g_conf()->public_addrv << dendl;
./ceph_mon.cc:	  dout(0) << " have local addr " << local << dendl;
./ceph_mon.cc:	  dout(0) << " no local addrs match monmap" << dendl;
./ceph_mon.cc:      dout(0) << argv[0] << ": set fsid to " << fsid << dendl;
./ceph_mon.cc:    dout(0) << "done." << dendl;
./ceph_mon.cc:    dout(0) << g_conf()->name << " does not exist in monmap, will attempt to join an existing cluster" << dendl;
./ceph_mon.cc:      dout(0) << "using public_addrv " << ipaddrs << dendl;
./ceph_mon.cc:    dout(0) << "ceph-mon: gmon.out should be in " << s << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "worker start" << dendl;
./common/WorkQueue.cc:      ldout(cct,1) << " worker shutting down; too many threads (" << _threads.size() << " > " << _num_threads << ")" << dendl;
./common/WorkQueue.cc:    ldout(cct,20) << "worker waiting" << dendl;
./common/WorkQueue.cc:  ldout(cct,1) << "worker finish" << dendl;
./common/WorkQueue.cc:    ldout(cct, 10) << "start_threads creating and starting " << wt << dendl;
./common/WorkQueue.cc:    ldout(cct, 10) << "join_old_threads joining and deleting " << _old_threads.front() << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "start" << dendl;
./common/WorkQueue.cc:    ldout(cct, 10) << " registering config observer on " << _thread_num_option << dendl;
./common/WorkQueue.cc:  ldout(cct,15) << "started" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "stop" << dendl;
./common/WorkQueue.cc:    ldout(cct, 10) << " unregistering config observer on " << _thread_num_option << dendl;
./common/WorkQueue.cc:  ldout(cct,15) << "stopped" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "pause" << dendl;
./common/WorkQueue.cc:  ldout(cct,15) << "paused" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "pause_new" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "unpause" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "drain" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "worker start" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "sharded worker finish" << dendl;
./common/WorkQueue.cc:    ldout(cct, 10) << "start_threads creating and starting " << wt << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "start" << dendl;
./common/WorkQueue.cc:  ldout(cct,15) << "started" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "stop" << dendl;
./common/WorkQueue.cc:  ldout(cct,15) << "stopped" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "pause" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "paused" << dendl; 
./common/WorkQueue.cc:  ldout(cct,10) << "pause_new" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "paused_new" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "unpause" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "unpaused" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "drain" << dendl;
./common/WorkQueue.cc:  ldout(cct,10) << "drained" << dendl;
./common/PriorityCache.cc:      ldout(cct, 10) << __func__ << " assigning cache bytes for PRI: " << i << dendl;
./common/Throttle.cc:      ldout(cct, 2) << "_wait waiting..." << dendl;
./common/Throttle.cc:      ldout(cct, 2) << "_wait finished waiting" << dendl;
./common/Throttle.cc:  ldout(cct, 10) << "wait" << dendl;
./common/Throttle.cc:  ldout(cct, 10) << "take " << c << dendl;
./common/Throttle.cc:  ldout(cct, 10) << "get " << c << " (" << count.load() << " -> " << (count.load() + c) << ")" << dendl;
./common/Throttle.cc:      ldout(cct, 10) << "get_or_fail " << c << " failed" << dendl;
./common/EventTrace.cc:  lsubdout(ctx, eventtrace, LOG_LEVEL) << "ENTRY (" <<  func << ") " << file << ":" << line << dendl;
./common/EventTrace.cc:  lsubdout(ctx, eventtrace, LOG_LEVEL) << "EXIT (" << func << ") " << file << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 5) << "bind_and_listen " << sock_path << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 5) << "entry start" << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 5) << "entry exit" << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 30) << "OutputDataSocket: calling accept" << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 30) << "OutputDataSocket: finished accept" << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 5) << "init " << path << dendl;
./common/OutputDataSocket.cc:  ldout(m_cct, 5) << "shutdown" << dendl;
./common/config.cc:    ldout(cct, 4) << __func__ << " no callback set" << dendl;
./common/config.cc:	ldout(cct, 4) << __func__ << " callback consumed " << i.first << dendl;
./common/config.cc:      ldout(cct, 4) << __func__ << " callback ignored " << i.first << dendl;
./common/config.cc:      ldout(cct,10) << __func__ << " " << i.first << " = " << i.second << dendl;
./common/PluginRegistry.cc:  ldout(cct, 1) << __func__ << " " << type << " " << name << dendl;
./common/PluginRegistry.cc:  ldout(cct, 1) << __func__ << " " << type << " " << name << dendl;
./common/HeartbeatMap.cc:  ldout(m_cct, 10) << "add_worker '" << name << "'" << dendl;
./common/HeartbeatMap.cc:  ldout(m_cct, 10) << "remove_worker '" << h->name << "'" << dendl;
./common/HeartbeatMap.cc:  ldout(m_cct, 20) << "clear_timeout '" << h->name << "'" << dendl;
./common/HeartbeatMap.cc:    ldout(m_cct, 0) << "is_healthy injecting failure for next " << m_cct->_conf->heartbeat_inject_failure << " seconds" << dendl;
./common/win32/registry.cc:    ldout(cct_, 10) << "Creating registry key: " << strKey << dendl;
./common/win32/service.cc:  ldout(s_service->cct, 5) << "Starting service." << dendl;
./common/win32/service.cc:    ldout(s_service->cct, 5) << "Successfully started service." << dendl;
./common/win32/service.cc:    dout(5) << "Shutdown hook completed." << dendl;
./common/win32/service.cc:    dout(5) << "Successfully stopped service." << dendl;
./common/admin_socket.cc:  ldout(m_cct, 5) << "bind_and_listen " << sock_path << dendl;
./common/admin_socket.cc:	ldout(m_cct, 20) << "socket " << sock_path << " is in use" << dendl;
./common/admin_socket.cc:	ldout(m_cct, 20) << "unlink stale file " << sock_path << dendl;
./common/admin_socket.cc:  ldout(m_cct, 5) << "entry start" << dendl;
./common/admin_socket.cc:    ldout(m_cct,20) << __func__ << " waiting" << dendl;
./common/admin_socket.cc:    ldout(m_cct,20) << __func__ << " awake" << dendl;
./common/admin_socket.cc:  ldout(m_cct, 5) << "entry exit" << dendl;
./common/admin_socket.cc:  ldout(m_cct, 30) << "AdminSocket: calling accept" << dendl;
./common/admin_socket.cc:  ldout(m_cct, 30) << "AdminSocket: finished accept" << dendl;
./common/admin_socket.cc:  ldout(m_cct,10) << __func__ << dendl;
./common/admin_socket.cc:  ldout(m_cct,10) << __func__ << " cmdvec='" << cmdvec << "'" << dendl;
./common/admin_socket.cc:    ldout(m_cct, 0) << "AdminSocket: " << errss.str() << dendl;
./common/admin_socket.cc:  ldout(m_cct,10) << __func__ << " " << *m << dendl;
./common/admin_socket.cc:  ldout(m_cct,10) << __func__ << " " << *m << dendl;
./common/admin_socket.cc:      ldout(m_cct, 5) << __func__ << " " << i->first << dendl;
./common/admin_socket.cc:  ldout(m_cct, 5) << "init " << path << dendl;
./common/admin_socket.cc:  ldout(m_cct, 5) << "shutdown" << dendl;
./common/lockdep.cc:    lockdep_dout(1) << "lockdep start" << dendl;
./common/lockdep.cc:    lockdep_dout(1) << "lockdep stop" << dendl;
./common/lockdep.cc:    lockdep_dout(0) << "--- thread " << p->first << " ---" << dendl;
./common/lockdep.cc:    lockdep_dout(1) << "lockdep reusing last freed id " << tmp << dendl;
./common/lockdep.cc:  lockdep_dout(0) << "failing miserably..." << dendl;
./common/lockdep.cc:	lockdep_dout(0) << "  lock " << p.first << " " << p.second << dendl;
./common/lockdep.cc:    lockdep_dout(10) << "registered '" << name << "' as " << id << dendl;
./common/lockdep.cc:    lockdep_dout(20) << "had '" << name << "' as " << id << dendl;
./common/lockdep.cc:      lockdep_dout(10) << "unregistered '" << name << "' from " << id << dendl;
./common/lockdep.cc:  lockdep_dout(20) << "_will_lock " << name << " (" << id << ")" << dendl;
./common/lockdep.cc:	lockdep_dout(0) << "btw, i am holding these locks:" << dendl;
./common/lockdep.cc:	  lockdep_dout(0) << "  " << lock_names[q->first] << " (" << q->first << ")" << dendl;
./common/lockdep.cc:	lockdep_dout(0) << "\n" << dendl;
./common/lockdep.cc:	lockdep_dout(10) << lock_names[p->first] << " -> " << name << " at" << dendl;
./common/lockdep.cc:  lockdep_dout(20) << "_locked " << name << dendl;
./common/lockdep.cc:  lockdep_dout(20) << "_will_unlock " << name << dendl;
./common/dns_resolve.cc:  ldout(cct, 20) << "name=" << host << dendl;
./common/dns_resolve.cc:  ldout(cct, 20) << "cname host=" << host << dendl;
./common/dns_resolve.cc:    ldout(cct, 20) << "no address found for hostname " << hostname << dendl;
./common/dns_resolve.cc:    ldout(cct, 20) << "no address found for hostname " << hostname << dendl;
./common/dns_resolve.cc:    ldout(cct, 20) << "No hosts found for service " << query_str << dendl;
./common/dns_resolve.cc:    ldout(cct, 20) << "No hosts found for service " << query_str << dendl;
./common/MemoryModel.cc:    ldout(cct, 0) << "check_memory_usage unable to open " PROCPREFIX "/proc/self/status" << dendl;
./common/MemoryModel.cc:    ldout(cct, 0) << "check_memory_usage unable to open " PROCPREFIX "/proc/self/maps" << dendl;
./common/MemoryModel.cc:    //ldout(cct, 0) << "line is " << line << dendl;
./common/MemoryModel.cc:    //ldout(cct, 0) << std::hex << as << " to " << ae << std::dec << dendl;
./common/MemoryModel.cc:    //ldout(cct, 0) << "size " << size << " mode is '" << mode << "' end is '" << end << "'" << dendl;
./common/Finisher.cc:  ldout(cct, 10) << __func__ << dendl;
./common/Finisher.cc:  ldout(cct, 10) << __func__ << dendl;
./common/Finisher.cc:  ldout(cct, 10) << __func__ << " finish" << dendl;
./common/Finisher.cc:    ldout(cct, 10) << "wait_for_empty waiting" << dendl;
./common/Finisher.cc:  ldout(cct, 10) << "wait_for_empty empty" << dendl;
./common/Finisher.cc:  ldout(cct, 10) << "finisher_thread start" << dendl;
./common/Finisher.cc:      ldout(cct, 10) << "finisher_thread doing " << in_progress_queue << dendl;
./common/Finisher.cc:    ldout(cct, 10) << "finisher_thread empty" << dendl;
./common/Finisher.cc:    ldout(cct, 10) << "finisher_thread sleeping" << dendl;
./common/Finisher.cc:  ldout(cct, 10) << "finisher_thread stop" << dendl;
./common/tracer.cc:	dout(3) << "yaml loaded" << yaml << dendl;
./common/tracer.cc:	  dout(3) << "failed to load yaml file using default config" << dendl;
./common/tracer.cc:	dout(3) << "yaml loaded" << yaml << dendl;
./common/tracer.cc:      dout(3) << "tracer_jaeger init successful" << dendl;
./common/Timer.cc:  ldout(cct,10) << "init" << dendl;
./common/Timer.cc:  ldout(cct,10) << "shutdown" << dendl;
./common/Timer.cc:  ldout(cct,10) << "timer_thread starting" << dendl;
./common/Timer.cc:      ldout(cct,10) << "timer_thread executing " << callback << dendl;
./common/Timer.cc:    ldout(cct,20) << "timer_thread going to sleep" << dendl;
./common/Timer.cc:    ldout(cct,20) << "timer_thread awake" << dendl;
./common/Timer.cc:  ldout(cct,10) << "timer_thread exiting" << dendl;
./common/Timer.cc:  ldout(cct,10) << __func__ << " " << when << " -> " << callback << dendl;
./common/Timer.cc:    ldout(cct,5) << __func__ << " already shutdown, event not added" << dendl;
./common/Timer.cc:    ldout(cct,10) << "cancel_event " << callback << " not found" << dendl;
./common/Timer.cc:  ldout(cct,10) << "cancel_event " << p->second->first << " -> " << callback << dendl;
./common/Timer.cc:  ldout(cct,10) << "cancel_all_events" << dendl;
./common/Timer.cc:    ldout(cct,10) << " cancelled " << p->second->first << " -> " << p->first << dendl;
./common/Timer.cc:  ldout(cct,10) << "dump " << caller << dendl;
./common/Timer.cc:    ldout(cct,10) << " " << s->first << "->" << s->second << dendl;
./common/LogClient.cc:    ldout(cct,-1) << "log " << prio << " : " << s << dendl;
./common/LogClient.cc:    ldout(cct,0) << "log " << prio << " : " << s << dendl;
./common/LogClient.cc:    ldout(cct,0) << __func__ << " log to syslog"  << dendl;
./common/LogClient.cc:    ldout(cct,0) << __func__ << " log to graylog"  << dendl;
./common/LogClient.cc:    ldout(cct,10) << " will send " << *p << dendl;
./common/LogClient.cc:  ldout(cct,10) << __func__ << " log to self" << dendl;
./common/LogClient.cc:  ldout(cct,10) << "handle_log_ack " << *m << dendl;
./common/LogClient.cc:    ldout(cct,10) << " logged " << entry << dendl;
./dokan/dbg.cc:  dout(0) << o.str() << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << " - fd: " << fd << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:      dout(20) << __func__ << " " << path << ". File exists." << dendl;
./dokan/ceph_dokan.cc:        dout(2) << __func__ << " " << path << ". Not a directory." << dendl;
./dokan/ceph_dokan.cc:      dout(20) << __func__ << " " << path << ". Directory exists." << dendl;
./dokan/ceph_dokan.cc:        dout(2) << __func__ << " " << path << ". File is a directory." << dendl;
./dokan/ceph_dokan.cc:      dout(20) << __func__ << " " << path << ". New directory." << dendl;
./dokan/ceph_dokan.cc:    dout(20) << __func__ << " " << path << ". New file." << dendl;
./dokan/ceph_dokan.cc:        dout(2) << __func__ << " " << path << ": Not found." << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << " fd: " << fdc->fd << dendl;
./dokan/ceph_dokan.cc:    dout(10) << __func__ << ": missing context: " << path << dendl;
./dokan/ceph_dokan.cc:    dout(20) << __func__ << " DeleteOnClose: " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << " -> " << new_path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " (stubbed) " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " " << path << dendl;
./dokan/ceph_dokan.cc:  dout(20) << __func__ << " (stubbed) " << path << dendl;
./dokan/ceph_dokan.cc:    dout(0) << "Unmounted." << dendl;
./dokan/ceph_dokan.cc:    dout(0) << "Received ctrl-c." << dendl;
./dokan/ceph_dokan.cc:    dout(0) << "Received break event." << dendl;
./dokan/ceph_dokan.cc:    dout(0) << "Received console event: " << dwType << dendl;
./dokan/ceph_dokan.cc:    dout(2) << "Dokan has returned successfully" << dendl;
./mgr/BaseMgrModule.cc:    dout(10) << "MonCommandCompletion::finish()" << dendl;
./mgr/BaseMgrModule.cc:    dout(10) << "ceph_option_get " << what << " found: " << value << dendl;
./mgr/BaseMgrModule.cc:    dout(4) << "ceph_option_get " << what << " not found " << dendl;
./mgr/BaseMgrModule.cc:    dout(10) << "ceph_store_get " << what << " found: " << value.c_str() << dendl;
./mgr/BaseMgrModule.cc:    dout(4) << "ceph_store_get " << what << " not found " << dendl;
./mgr/MgrCap.cc:        ldout(cct, 20) << " allow all" << dendl;
./mgr/MgrCap.cc:        ldout(cct, 20) << " match" << dendl;
./mgr/ActivePyModules.cc:    dout(10) << " (" << hostname << ")" << dendl;
./mgr/ActivePyModules.cc:  dout(10) << " >" << dendl;
./mgr/ActivePyModules.cc:      dout(4) << "Starting thread for " << name << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "calling module " << name << " shutdown()" << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "module " << name << " shutdown() returned" << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "joining module " << name << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "joined module " << name << dendl;
./mgr/ActivePyModules.cc:  dout(10) << __func__ << ": notify_all " << notify_type << dendl;
./mgr/ActivePyModules.cc:    dout(15) << "queuing notify to " << name << dendl;
./mgr/ActivePyModules.cc:  dout(10) << __func__ << ": notify_all (clog)" << dendl;
./mgr/ActivePyModules.cc:    dout(15) << "queuing notify (clog) to " << name << dendl;
./mgr/ActivePyModules.cc:  dout(4) << __func__ << " key: " << global_key << dendl;
./mgr/ActivePyModules.cc:  dout(20) << " key: " << global_key << dendl;
./mgr/ActivePyModules.cc:    // dout(10) << __func__ << " " << final_key << " found: " << value << dendl;
./mgr/ActivePyModules.cc:    dout(10) << __func__ << " " << final_key << " found" << dendl;
./mgr/ActivePyModules.cc:    dout(10) << " " << key << " not found " << dendl;
./mgr/ActivePyModules.cc:  dout(4) << __func__ << " prefix: " << global_prefix << dendl;
./mgr/ActivePyModules.cc:    dout(0) << "mon returned " << set_cmd.r << ": " << set_cmd.outs << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "full update on " << prefix << dendl;
./mgr/ActivePyModules.cc:      dout(20) << " rm prior " << p->first << dendl;
./mgr/ActivePyModules.cc:    dout(10) << "incremental update on " << prefix << dendl;
./mgr/ActivePyModules.cc:      dout(20) << " set " << i.first << " = " << i.second->to_str() << dendl;
./mgr/ActivePyModules.cc:      dout(20) << " rm " << i.first << dendl;
./mgr/ActivePyModules.cc:  dout(10) << dendl;
./mgr/ActivePyModules.cc:        dout(20) << "Paths are:" << dendl;
./mgr/ActivePyModules.cc:          dout(20) << i.first << dendl;
./mgr/ActivePyModules.cc:  dout(10) << "ceph_foreign_option_get " << who << " " << name << dendl;
./mgr/ActivePyModules.cc:    dout(4) << "ceph_foreign_option_get " << name << " not found " << dendl;
./mgr/ActivePyModules.cc:    dout(5) << "unrecognized entity '" << who << "'" << dendl;
./mgr/ActivePyModules.cc:    dout(15) << "getting health checks for " << name << dendl;
./mgr/ActivePyModules.cc:    dout(15) << "notify (config) " << name << dendl;
./mgr/ActivePyModules.cc:  dout(4) << " module " << module_name << " set URI '" << uri << "'" << dendl;
./mgr/ActivePyModules.cc:  dout(7) << "registering msgr client handle " << addrv << dendl;
./mgr/ActivePyModules.cc:  dout(7) << "unregistering msgr client handle " << addrv << dendl;
./mgr/ActivePyModule.cc:    dout(1) << "Constructed class from module: " << get_name() << dendl;
./mgr/ActivePyModule.cc:    dout(5) << "cancelling notify " << notify_type << " " << notify_id << dendl;
./mgr/ActivePyModule.cc:    dout(5) << "cancelling notify_clog" << dendl;
./mgr/ActivePyModule.cc:    dout(20) << "Success calling '" << method << "'" << dendl;
./mgr/ActivePyModule.cc:    dout(5) << "cancelling config_notify" << dendl;
./mgr/ActivePyModule.cc:    dout(5) << "cancelling get_health_checks" << dendl;
./mgr/Mgr.cc:        dout(1) << "mon returned invalid JSON for " << key << dendl;
./mgr/Mgr.cc:      dout(4) << "mon returned valid metadata JSON for " << key << dendl;
./mgr/Mgr.cc:        dout(1) << "Skipping incomplete metadata entry for " << key << dendl;
./mgr/Mgr.cc:  dout(10) << "listing keys" << dendl;
./mgr/Mgr.cc:    dout(20) << "saw key '" << key << "'" << dendl;
./mgr/Mgr.cc:      dout(20) << "fetching '" << key << "'" << dendl;
./mgr/Mgr.cc:    dout(10) << "waiting a bit for the pre-pacific mon to process our beacon" << dendl;
./mgr/Mgr.cc:  dout(4) << "waiting for OSDMap..." << dendl;
./mgr/Mgr.cc:  dout(4) << "Initialized server at " << server.get_myaddrs() << dendl;
./mgr/Mgr.cc:  dout(4) << "Loading daemon metadata..." << dendl;
./mgr/Mgr.cc:  dout(4) << "waiting for FSMap..." << dendl;
./mgr/Mgr.cc:  dout(4) << "waiting for MgrDigest..." << dendl;
./mgr/Mgr.cc:    dout(4) << "loading config-key data from pre-pacific mon cluster..." << dendl;
./mgr/Mgr.cc:  dout(4) << "initializing device state..." << dendl;
./mgr/Mgr.cc:    dout(10) << "  updating " << devid << dendl;
./mgr/Mgr.cc:  dout(4) << "starting python modules..." << dendl;
./mgr/Mgr.cc:  dout(4) << "Using sqlite3 version: " << sqlite3_libversion() << dendl;
./mgr/Mgr.cc:  dout(4) << "Complete." << dendl;
./mgr/Mgr.cc:      dout(1) << "Skipping incomplete metadata entry" << dendl;
./mgr/Mgr.cc:      dout(1) << "Skipping incomplete metadata entry" << dendl;
./mgr/Mgr.cc:      dout(1) << "Skipping incomplete metadata entry" << dendl;
./mgr/Mgr.cc:    dout(4) << osd_metadata.at("hostname").get_str() << dendl;
./mgr/Mgr.cc:  dout(10) << "mgr shutdown init" << dendl;
./mgr/Mgr.cc:  dout(10) << "e" << m->service_map.epoch << dendl;
./mgr/Mgr.cc:  dout(20) << __func__ << dendl;
./mgr/Mgr.cc:  dout(10) << *m << dendl;
./mgr/Mgr.cc:	      dout(10) << "full update on " << msg->prefix << dendl;
./mgr/Mgr.cc:		dout(20) << " rm prior " << p->first << dendl;
./mgr/Mgr.cc:	      dout(10) << "incremental update on " << msg->prefix << dendl;
./mgr/Mgr.cc:		dout(20) << " set " << i.first << " = " << i.second->to_str() << dendl;
./mgr/Mgr.cc:		dout(20) << " rm " << i.first << dendl;
./mgr/Mgr.cc:  dout(10) << m << dendl;
./mgr/Mgr.cc:  dout(10) << m->mon_status_json.length() << dendl;
./mgr/Mgr.cc:  dout(10) << m->health_json.length() << dendl;
./mgr/Mgr.cc:  dout(10) << "done." << dendl;
./mgr/BaseMgrStandbyModule.cc:      dout(4) << __func__ << " " << what << " not found " << dendl;
./mgr/BaseMgrStandbyModule.cc:    dout(10) << "ceph_option_get " << what << " found: " << value << dendl;
./mgr/BaseMgrStandbyModule.cc:    dout(4) << "ceph_option_get " << what << " not found " << dendl;
./mgr/BaseMgrStandbyModule.cc:    dout(10) << "ceph_store_get " << what << " found: " << value.c_str() << dendl;
./mgr/BaseMgrStandbyModule.cc:    dout(4) << "ceph_store_get " << what << " not found " << dendl;
./mgr/DaemonState.cc:    dout(4) << "Removing data for " << daemon_key << dendl;
./mgr/DaemonState.cc:    dout(4) << "Removing data for " << i << dendl;
./mgr/PyModuleRegistry.cc:    dout(1) << "Loading python module '" << module_name << "'" << dendl;
./mgr/PyModuleRegistry.cc:  dout(4) << "Starting modules in standby mode" << dendl;
./mgr/PyModuleRegistry.cc:      dout(4) << "starting module " << i.second->get_name() << dendl;
./mgr/PyModuleRegistry.cc:  dout(4) << "Starting modules in active mode" << dendl;
./mgr/PyModuleRegistry.cc:    dout(4) << "Starting " << i.first << dendl;
./mgr/PyModuleRegistry.cc:      dout(10) << "ignoring disabled module " << name << dendl;
./mgr/PyModuleRegistry.cc:    // dout(10) << "Loaded module_config entry " << k << ":" << v << dendl;
./mgr/PyModuleRegistry.cc:    dout(10) << "Loaded module_config entry " << k << ":" << dendl;
./mgr/MetricCollector.cc:  dout(20) << "query=" << query << ", limit=" << limit << dendl;
./mgr/MetricCollector.cc:  dout(20) << "query_id=" << query_id << dendl;
./mgr/MetricCollector.cc:    dout(10) << query_id << " not found" << dendl;
./mgr/MetricCollector.cc:  dout(10) << query_id << dendl;
./mgr/MetricCollector.cc:  dout(20) << dendl;
./mgr/MetricCollector.cc:  dout(20) << dendl;
./mgr/MetricCollector.cc:    dout(10) << "counters for " << query_id << " not found" << dendl;
./mgr/MetricCollector.cc:        dout(20) << "counter " << key << " " << *desc_it << ": " << c << dendl;
./mgr/PyOSDMap.cc:  dout(10) << __func__ << " " << inc << dendl;
./mgr/PyOSDMap.cc:  dout(10) << __func__ << " r = " << r << dendl;
./mgr/MDSPerfMetricCollector.cc:  dout(20) << ": delayed ranks=[" << delayed_ranks << "]" << dendl;
./mgr/MgrStandby.cc:      // dout(10) << "config_callback: " << k << " : " << v << dendl;
./mgr/MgrStandby.cc:      dout(10) << "config_callback: " << k << " : " << dendl;
./mgr/MgrStandby.cc:  dout(4) << "Registered monc callback" << dendl;
./mgr/MgrStandby.cc:  dout(4) << "Complete." << dendl;
./mgr/MgrStandby.cc:  dout(20) << state_str() << dendl;
./mgr/MgrStandby.cc:    dout(15) << "noting RADOS client for blocklist: " << client << dendl;
./mgr/MgrStandby.cc:  dout(10) << "sending beacon as gid " << monc.get_global_id() << dendl;
./mgr/MgrStandby.cc:  dout(10) << __func__ << dendl;
./mgr/MgrStandby.cc:    dout(4) << "Shutting down" << dendl;
./mgr/MgrStandby.cc:  dout(1) << " e: '" << orig_argv[0] << "'" << dendl;
./mgr/MgrStandby.cc:    dout(1) << " " << i << ": '" << orig_argv[i] << "'" << dendl;
./mgr/MgrStandby.cc:    dout(1) << " cwd " << cwd << dendl;
./mgr/MgrStandby.cc:    dout(1) << "respawning with exe " << exe_path << dendl;
./mgr/MgrStandby.cc:  dout(1) << " exe_path " << exe_path << dendl;
./mgr/MgrStandby.cc:  dout(4) << "received map epoch " << map.get_epoch() << dendl;
./mgr/MgrStandby.cc:    dout(1) << "respawning because set of enabled modules changed!" << dendl;
./mgr/MgrStandby.cc:      dout(1) << "Activating!" << dendl;
./mgr/MgrStandby.cc:      dout(1) << "I am now activating" << dendl;
./mgr/MgrStandby.cc:      dout(10) << "I was already active" << dendl;
./mgr/MgrStandby.cc:      dout(4) << "Map now says I am available" << dendl;
./mgr/MgrStandby.cc:  dout(10) << state_str() << " " << *m << dendl;
./mgr/MgrClient.cc:  ldout(cct, 10) << dendl;
./mgr/MgrClient.cc:    ldout(cct, 10) << "closing mgr session" << dendl;
./mgr/MgrClient.cc:    ldout(cct, 30) << "Not handling " << *m << dendl; 
./mgr/MgrClient.cc:    ldout(cct, 4) << "No active mgr available yet" << dendl;
./mgr/MgrClient.cc:      ldout(cct, 4) << "waiting to retry connect until " << when << dendl;
./mgr/MgrClient.cc:    ldout(cct,10) << "resending " << tid << (op.tell ? " (tell)":" (cli)") << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << *m << dendl;
./mgr/MgrClient.cc:  ldout(cct, 4) << "Got map version " << map.epoch << dendl;
./mgr/MgrClient.cc:  ldout(cct, 4) << "Active mgr is now " << map.get_active_addrs() << dendl;
./mgr/MgrClient.cc:    ldout(cct, 4) << __func__ << " con " << con << dendl;
./mgr/MgrClient.cc:      ldout(cct,20) << " undeclare " << path << dendl;
./mgr/MgrClient.cc:	ldout(cct,20) << " declare " << path << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << "encoded " << report->packed.length() << " bytes" << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << *m << dendl;
./mgr/MgrClient.cc:  ldout(cct, 4) << "stats_period=" << m->stats_period << dendl;
./mgr/MgrClient.cc:    ldout(cct, 4) << "updated stats threshold: " << m->stats_threshold << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << "cmd: " << cmd << dendl;
./mgr/MgrClient.cc:    ldout(cct,20) << " no MgrMap, assuming EACCES" << dendl;
./mgr/MgrClient.cc:    ldout(cct, 5) << "no mgr session (no running mgr daemon?), waiting" << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << "target: " << name << " cmd: " << cmd << dendl;
./mgr/MgrClient.cc:    ldout(cct,20) << " no MgrMap, assuming EACCES" << dendl;
./mgr/MgrClient.cc:  ldout(cct, 20) << "tid " << tid << " r " << r << dendl;
./mgr/MgrClient.cc:  ldout(cct,1) << service << "." << name << " metadata " << metadata << dendl;
./mgr/MgrClient.cc:  ldout(cct,10) << status << dendl;
./mgr/MgrClient.cc:  ldout(cct,10) << status << dendl;
./mgr/PyModuleRunner.cc:  dout(0) << record << dendl;
./mgr/PyModuleRunner.cc:  dout(4) << "Entering thread for " << mod->get_name() << dendl;
./mgr/Gil.cc:  dout(25) << "GIL acquired for thread state " << pThreadState.ts << dendl;
./mgr/Gil.cc:    dout(20) << "Switched to new thread state " << pNewThreadState << dendl;
./mgr/Gil.cc:    dout(20) << "Destroying new thread state " << pNewThreadState << dendl;
./mgr/Gil.cc:  dout(25) << "GIL released for thread state " << pThreadState.ts << dendl;
./mgr/ClusterState.cc:  dout(10) << " v" << pending_inc.version << dendl;
./mgr/ClusterState.cc:  dout(10) << " v" << pending_inc.version << dendl;
./mgr/StandbyPyModules.cc:    dout(10) << "waiting for module " << name << " to shutdown" << dendl;
./mgr/StandbyPyModules.cc:    dout(10) << "module " << name << " shutdown" << dendl;
./mgr/StandbyPyModules.cc:    dout(10) << "joining thread for module " << i.first << dendl;
./mgr/StandbyPyModules.cc:    dout(10) << "joined thread for module " << i.first << dendl;
./mgr/StandbyPyModules.cc:      dout(4) << "Starting thread for " << name << dendl;
./mgr/StandbyPyModules.cc:    dout(1) << "Constructed class from module: " << get_name() << dendl;
./mgr/StandbyPyModules.cc:  dout(4) << __func__ << " key: " << global_key << dendl;
./mgr/StandbyPyModules.cc:  dout(4) << __func__ << " key: " << global_key << dendl;
./mgr/DaemonServer.cc:  dout(20) << __func__ << " will bind to " << addrs << dendl;
./mgr/DaemonServer.cc:      dout(1) << "Unhandled message type " << m->get_type() << dendl;
./mgr/DaemonServer.cc:      dout(4) << "initial report from osd " << osd_id << dendl;
./mgr/DaemonServer.cc:        dout(4) << "all osds have reported, sending PG state to mon" << dendl;
./mgr/DaemonServer.cc:  dout(10) << dendl;
./mgr/DaemonServer.cc:  dout(10) << dendl;
./mgr/DaemonServer.cc:  dout(10) << dendl;
./mgr/DaemonServer.cc:  dout(10) << "begin" << dendl;
./mgr/DaemonServer.cc:  dout(10) << "done" << dendl;
./mgr/DaemonServer.cc:  dout(10) << "from " << key << " " << con->get_peer_addr() << dendl;
./mgr/DaemonServer.cc:    dout(20) << "updating existing DaemonState for " << key << dendl;
./mgr/DaemonServer.cc:      dout(4) << "constructing new DaemonState for " << key << dendl;
./mgr/DaemonServer.cc:	dout(10) << "registering " << key << " in pending_service_map" << dendl;
./mgr/DaemonServer.cc:  dout(4) << "from " << m->get_connection() << "  " << key << dendl;
./mgr/DaemonServer.cc:  dout(10) << "got task status from " << key << dendl;
./mgr/DaemonServer.cc:  dout(10) << "from " << m->get_connection() << " " << key << dendl;
./mgr/DaemonServer.cc:      dout(20) << "updating existing DaemonState for " << key << dendl;
./mgr/DaemonServer.cc:      dout(20) << "success" << dendl;
./mgr/DaemonServer.cc:  dout(1) << " access denied" << dendl;
./mgr/DaemonServer.cc:  dout(20) << "orig_osds " << orig_osds << " max " << max << dendl;
./mgr/DaemonServer.cc:    dout(20) << "  parent " << parent << " children " << children << dendl;
./mgr/DaemonServer.cc:	  dout(20) << " hit max" << dendl;
./mgr/DaemonServer.cc:      dout(20) << " hit some peer failures" << dendl;
./mgr/DaemonServer.cc:  dout(10) << "decoded-size=" << cmdctx->cmdmap.size() << " prefix=" << prefix << dendl;
./mgr/DaemonServer.cc:    dout(10) << "reading commands from python modules" << dendl;
./mgr/DaemonServer.cc:      dout(10) << "reweight::by_utilization: finished with " << out_str << dendl;
./mgr/DaemonServer.cc:	  dout(20) << " " << i.first << " -> " << i.second << dendl;
./mgr/DaemonServer.cc:    dout(4) << "No handler found for '" << prefix << "'" << dendl;
./mgr/DaemonServer.cc:  dout(10) << "passing through " << cmdctx->cmdmap.size() << dendl;
./mgr/DaemonServer.cc:      dout(4) << ss.str() << dendl;
./mgr/DaemonServer.cc:      dout(4) << ss.str() << dendl;
./mgr/DaemonServer.cc:	  dout(10) << pg_map << dendl;
./mgr/DaemonServer.cc:  dout(20) << dendl;
./mgr/DaemonServer.cc:	dout(10) << "got initial map e" << service_map.epoch << dendl;
./mgr/DaemonServer.cc:	dout(10) << "got updated map e" << service_map.epoch << dendl;
./mgr/DaemonServer.cc:	dout(10) << "added missing " << key << dendl;
./mgr/DaemonServer.cc:	  dout(10) << "triggered addition of " << key << " via metadata update" << dendl;
./mgr/DaemonServer.cc:	  dout(10) << "triggered addition of " << key << " via metadata update" << dendl;
./mgr/PyModule.cc:      dout(4) << m << dendl;
./mgr/PyModule.cc:    dout(0) << "mon returned " << set_cmd.r << ": " << set_cmd.outs << dendl;
./mgr/PyModule.cc:    dout(1) << "sys.path:" << dendl;
./mgr/PyModule.cc:      dout(1) << "  " << PyUnicode_AsUTF8(PyList_GetItem(sys_path, i)) << dendl;
./mgr/PyModule.cc:    dout(20) << "loaded command " << command.cmdstring << dendl;
./mgr/PyModule.cc:  dout(10) << "loaded " << commands.size() << " commands" << dendl;
./mgr/PyModule.cc:    dout(20) << "loaded module option " << option.name << dendl;
./mgr/PyModule.cc:  dout(10) << "loaded " << options.size() << " options" << dendl;
./blk/BlockDevice.cc:  dout(20) << __func__ << " " << this << " done" << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " " << fd_directs[WRITE_LIFE_NOT_SET] << dendl;
./blk/kernel/KernelDevice.cc:    dout(1) << __func__ << " flock busy on " << path << dendl;
./blk/kernel/KernelDevice.cc:  dout(1) << __func__ << " path " << path << dendl;
./blk/kernel/KernelDevice.cc:    dout(0) << "ioctl(F_SET_FILE_RW_HINT) on " << path << " failed: " << cpp_strerror(r) << dendl;
./blk/kernel/KernelDevice.cc:      dout(20) << __func__ << " devname " << devname << dendl;
./blk/kernel/KernelDevice.cc:  dout(1) << __func__ << dendl;
./blk/kernel/KernelDevice.cc:    dout(20) << __func__ << " no VDO volume maps to " << devname << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " start" << dendl;
./blk/kernel/KernelDevice.cc:  dout(5) << __func__ << " in " << dur << dendl;;
./blk/kernel/KernelDevice.cc:    dout(10) << __func__ << dendl;
./blk/kernel/KernelDevice.cc:    dout(10) << __func__ << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " stopped" << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " start" << dendl;
./blk/kernel/KernelDevice.cc:    dout(40) << __func__ << " polling" << dendl;
./blk/kernel/KernelDevice.cc:      dout(30) << __func__ << " got " << r << " completed aios" << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " end" << dendl;
./blk/kernel/KernelDevice.cc:      dout(20) << __func__ << " sleep" << dendl;
./blk/kernel/KernelDevice.cc:      dout(20) << __func__ << " wake" << dendl;
./blk/kernel/KernelDevice.cc:      dout(20) << __func__ << " finishing" << dendl;
./blk/kernel/KernelDevice.cc:  dout(10) << __func__ << " finish" << dendl;
./blk/kernel/KernelDevice.cc:      dout(30) << __func__ << " " << *p << dendl;
./blk/kernel/KernelDevice.cc:    dout(20) << __func__ << " rebuilding buffer to be aligned" << dendl;
./blk/kernel/KernelDevice.cc:    dout(20) << __func__ << " rebuilding buffer to be aligned" << dendl;
./blk/kernel/KernelDevice.cc:	dout(30) << aio << dendl;
./blk/kernel/KernelDevice.cc:	  dout(30) << aio << dendl;
./blk/kernel/KernelDevice.cc:    dout(30) << aio << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " " << fd_directs[WRITE_LIFE_NOT_SET] << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " opening " << path << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(1) << __func__ << " path " << path << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(0) << "ioctl(F_SET_FILE_RW_HINT) on " << path << " failed: " << cpp_strerror(r) << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(20) << __func__ << " devname " << devname << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(1) << __func__ << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(20) << __func__ << " no VDO volume maps to " << devname << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " start" << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(5) << __func__ << " in " << dur << dendl;;
./blk/zoned/HMSMRDevice.cc:    dout(10) << __func__ << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(10) << __func__ << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " stopped" << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " start" << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(40) << __func__ << " polling" << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(30) << __func__ << " got " << r << " completed aios" << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " end" << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(20) << __func__ << " sleep" << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(20) << __func__ << " wake" << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(20) << __func__ << " finishing" << dendl;
./blk/zoned/HMSMRDevice.cc:  dout(10) << __func__ << " finish" << dendl;
./blk/zoned/HMSMRDevice.cc:      dout(30) << __func__ << " " << *p << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(20) << __func__ << " rebuilding buffer to be aligned" << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(20) << __func__ << " rebuilding buffer to be aligned" << dendl;
./blk/zoned/HMSMRDevice.cc:	dout(30) << aio << dendl;
./blk/zoned/HMSMRDevice.cc:	  dout(30) << aio << dendl;
./blk/zoned/HMSMRDevice.cc:    dout(30) << aio << dendl;
./blk/pmem/PMEMDevice.cc:  dout(1) << __func__ << " path " << path << dendl;
./blk/pmem/PMEMDevice.cc:  dout(1) << __func__ << dendl;
./blk/pmem/PMEMDevice.cc:  dout(20) << __func__ << " " << off << "~" << len  << dendl;
./blk/pmem/PMEMDevice.cc:  dout(5) << __func__ << " " << off << "~" << len  << dendl;
./blk/pmem/PMEMDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/pmem/PMEMDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/spdk/NVMEDevice.cc:  dout(20) << __func__ << " start" << dendl;
./blk/spdk/NVMEDevice.cc:    dout(40) << __func__ << " polling" << dendl;
./blk/spdk/NVMEDevice.cc:          dout(20) << __func__ << " write command issued " << lba_off << "~" << lba_count << dendl;
./blk/spdk/NVMEDevice.cc:          dout(20) << __func__ << " read command issued " << lba_off << "~" << lba_count << dendl;
./blk/spdk/NVMEDevice.cc:          dout(20) << __func__ << " flush command issueed " << dendl;
./blk/spdk/NVMEDevice.cc:  dout(20) << __func__ << " end" << dendl;
./blk/spdk/NVMEDevice.cc:      dout(0) << __func__ << " namespace count larger than 1, currently only use the first namespace" << dendl;
./blk/spdk/NVMEDevice.cc:    dout(1) << __func__ << " successfully attach nvme device at" << trid.traddr << dendl;
./blk/spdk/NVMEDevice.cc:    dout(0) << __func__ << " only probe local nvme device" << dendl;
./blk/spdk/NVMEDevice.cc:    dout(0) << __func__ << " device traddr (" << ctx->trid.traddr << ") not match " << trid->traddr << dendl;
./blk/spdk/NVMEDevice.cc:    dout(20) << __func__ << " read op successfully" << dendl;
./blk/spdk/NVMEDevice.cc:    dout(20) << __func__ << " flush op successfully" << dendl;
./blk/spdk/NVMEDevice.cc:  dout(1) << __func__ << " path " << p << dendl;
./blk/spdk/NVMEDevice.cc:  dout(1) << __func__ << dendl;
./blk/spdk/NVMEDevice.cc:  dout(1) << __func__ << " end" << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << " ioc " << ioc << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/spdk/NVMEDevice.cc:  dout(20) << __func__ << " " << off << "~" << len << " ioc " << ioc << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./blk/spdk/NVMEDevice.cc:  dout(5) << __func__ << " " << off << "~" << len << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 20) << "tag_tid=" << tag_tid << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/JournalRecorder.cc:    ldout(m_cct, 20) << "close already in-progress" << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "closing active object set " << object_set << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "advance to object set " << m_current_set << dendl;
./journal/JournalRecorder.cc:    ldout(m_cct, 20) << __func__ << ": r=" << r << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "opening object set " << m_current_set << dendl;
./journal/JournalRecorder.cc:    ldout(m_cct, 10) << "object set " << m_current_set << " now full" << dendl;
./journal/JournalRecorder.cc:    ldout(m_cct, 10) << "" << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "active_set=" << active_set << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "object_number=" << object_number << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << "object_number=" << object_number << dendl;
./journal/JournalRecorder.cc:      ldout(m_cct, 10) << "closing current object set " << current_set << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << object_recorder->get_oid() << dendl;
./journal/JournalRecorder.cc:  ldout(m_cct, 10) << object_recorder->get_oid() << dendl;
./journal/Journaler.cc:    ldout(m_cct, 20) << "using image pool for journal data" << dendl;
./journal/Journaler.cc:  ldout(m_cct, 5) << "creating new journal: " << m_header_oid << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_GetClient: " << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_GetClient: " << __func__ << ": r=" << r << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << ": r=" << r << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << ": r=" << r << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AllocateTag: " << __func__ << ": r=" << r << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AssertActiveTag: " << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(cct, 20) << "C_AssertActiveTag: " << __func__ << ": r=" << r << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:      ldout(m_cct, 20) << "shut_down: waiting for ops" << dendl;
./journal/JournalMetadata.cc:      ldout(m_cct, 20) << "shut_down: flushing watch" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << __func__ << ": " << m_client_id << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << __func__ << ": " << m_client_id << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << __func__ << ": " << m_client_id << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "initialized immutable metadata" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "refreshing mutable metadata" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "refreshed mutable metadata: r=" << r << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:      ldout(m_cct, 5) << __func__ << ": journal header not found" << dendl;
./journal/JournalMetadata.cc:      ldout(m_cct, 5) << __func__ << ": client blocklisted" << dendl;
./journal/JournalMetadata.cc:    ldout(m_cct, 10) << __func__ << ": reset journal watch" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "journal header updated" << dendl;
./journal/JournalMetadata.cc:    ldout(m_cct, 5) << "journal watch error: header removed" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << "committed tid=" << commit_tid << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "notifying journal header update" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "async notifying journal header update" << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 10) << "notified journal header update: r=" << r << dendl;
./journal/JournalMetadata.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalMetadata.cc:    ldout(m_cct, 20) << __func__ << ": no laggy clients to disconnect" << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 10) << __func__ << ": " << m_oid << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 20) << __func__ << ": " << m_oid << " watch" << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 20) << __func__ << ": " << m_oid << " unwatch" << dendl;
./journal/ObjectPlayer.cc:    ldout(m_cct, 20) << ": " << entry << " decoded" << dendl;
./journal/ObjectPlayer.cc:      ldout(m_cct, 10) << ": " << entry << " is duplicate, replacing" << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 20) << __func__ << ": " << m_oid << " scheduling watch" << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 20) << __func__ << ": " << m_oid << " cancelling watch" << dendl;
./journal/ObjectPlayer.cc:  ldout(m_cct, 10) << __func__ << ": " << m_oid << " polling" << dendl;
./journal/JournalPlayer.cc:    ldout(m_cct, 5) << "commit position: " << commit_position << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalPlayer.cc:      ldout(m_cct, 10) << "PREFETCH" << dendl;
./journal/JournalPlayer.cc:      ldout(m_cct, 10) << "PLAYBACK" << dendl;
./journal/JournalPlayer.cc:      ldout(m_cct, 10) << "ERROR" << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": object_num=" << object_number << dendl;
./journal/JournalPlayer.cc:        ldout(m_cct, 20) << "skipping committed entry: " << entry << dendl;
./journal/JournalPlayer.cc:      ldout(m_cct, 10) << "prefetch of object complete" << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << "switching to playback mode" << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": object_num=" << object_number << dendl;
./journal/JournalPlayer.cc:    ldout(m_cct, 20) << __func__ << ": waiting for in-flight fetch" << dendl;
./journal/JournalPlayer.cc:      ldout(m_cct, 10) << __func__ << ": waiting for full object set" << dendl;
./journal/JournalPlayer.cc:        ldout(m_cct, 10) << __func__ << ": no more entries" << dendl;
./journal/JournalPlayer.cc:        ldout(m_cct, 20) << __func__ << ": pruned " << entry << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": " << oid << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": r=" << r << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": r=" << r << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": entries available" << dendl;
./journal/JournalPlayer.cc:  ldout(m_cct, 10) << __func__ << ": replay complete: r=" << r << dendl;
./journal/JournalTrimmer.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalTrimmer.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalTrimmer.cc:  ldout(m_cct, 20) << __func__ << ": commit_tid=" << commit_tid << dendl;
./journal/JournalTrimmer.cc:  ldout(m_cct, 20) << __func__ << ": min_set=" << minimum_set << dendl;
./journal/JournalTrimmer.cc:    ldout(m_cct, 20) << "removing journal object " << oid << dendl;
./journal/JournalTrimmer.cc:  ldout(m_cct, 20) << __func__ << dendl;
./journal/JournalTrimmer.cc:    ldout(m_cct, 20) << "completing remove set context" << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << "count=" << append_buffers.size() << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << "flushing " << *future << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "detached " << *append_buffer.first << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << "tid=" << tid << ", r=" << r << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "object_bytes=" << m_object_bytes << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << *append_buffer.first << " marked safe" << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << "pending tids=" << m_in_flight_tids << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 10) << dendl;
./journal/ObjectRecorder.cc:  ldout(m_cct, 20) << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "already closed or overflowed" << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "append buffers empty" << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "forcing batch flush" << dendl;
./journal/ObjectRecorder.cc:      ldout(m_cct, 20) << "attempting to batch AIO appends" << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 10) << "max in flight appends reached" << dendl;
./journal/ObjectRecorder.cc:      ldout(m_cct, 10) << "object at capacity (" << size << ") " << *future << dendl;
./journal/ObjectRecorder.cc:      ldout(m_cct, 10) << "object beyond capacity (" << size << ") " << *future << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 20) << "flushing " << *future << dendl;
./journal/ObjectRecorder.cc:      ldout(m_cct, 20) << "stopping at requested flush future" << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 10) << "overflow" << dendl;
./journal/ObjectRecorder.cc:    ldout(m_cct, 10) << "closed" << dendl;
./ceph_osd.cc:	dout(5) << "object store type is " << store_type << dendl;
./ceph_osd.cc:    dout(1) << " objectstore numa_node " << os_numa_node << dendl;
./ceph_osd.cc:    dout(0) << "ceph-osd: gmon.out should be in " << s << dendl;
./global/pidfile.cc:    dout(0) << __func__ << ": ignore empty --pid-file" << dendl;
./global/global_init.cc:  generic_dout(0) << buf << dendl;
./global/global_init.cc:    dout(0) << priv_ss.str() << dendl;
./global/global_init.cc:  ldout(cct, 1) << "finished global_init_daemonize" << dendl;
./global/global_init.cc:    dout(0) << ss.str() << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": " << *ctx << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(0) << __func__ << ": masking IO out-of-bounds error" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(20) << __func__ << ": waiting for nbd request" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:        dout(0) << __func__ << ": terminate received" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:        dout(20) << __func__ << ": nothing to read" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(20) << *ctx << ": start" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:	  dout(0) << "disconnect request received" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": terminated" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(20) << __func__ << ": waiting for io request" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:	dout(20) << __func__ << ": no io requests, terminating" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(20) << __func__ << ": got: " << *ctx << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(20) << *ctx << ": finish" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": terminated" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": got quiesce request" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": got unquiesce request" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(20) << __func__ << ": terminated" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(10) << __func__ << ": starting" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(10) << __func__ << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(10) << __func__ << dendl;
./tools/rbd_nbd/rbd-nbd.cc:      dout(10) << __func__ << ": terminating" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:        dout(5) << "resize detected" << dendl;
./tools/rbd_nbd/rbd-nbd.cc:  dout(10) << "ioctl setup complete for " << cfg->devpath << dendl;
./tools/rbd_nbd/rbd-nbd.cc:  dout(10) << "netlink resize complete for nbd" << nbd_index << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(10) << "netlink try reconnect for " << cfg->devpath << dendl;
./tools/rbd_nbd/rbd-nbd.cc:  dout(10) << "netlink connect complete for " << cfg->devpath << dendl;
./tools/rbd_nbd/rbd-nbd.cc:  dout(10) << "netlink interface supported." << dendl;
./tools/rbd_nbd/rbd-nbd.cc:    dout(10) << " succeeded: " << err.to_str() << dendl;
./tools/rbd_nbd/rbd-nbd.cc:  dout(20) << __func__ << ": " << "notifying terminate" << dendl;
./tools/osdmaptool.cc:              //ldout(cct, 20) << __func__ << " " << pg << " up " << up << dendl;
./tools/immutable_object_cache/CacheServer.cc:  ldout(cct, 20) << dendl;
./tools/immutable_object_cache/CacheServer.cc:    ldout(cct, 1) << "m_io_service run fails: " << ec.message() << dendl;
./tools/immutable_object_cache/CacheServer.cc:  ldout(cct, 20) << dendl;
./tools/immutable_object_cache/CacheServer.cc:  ldout(cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:       ldout(m_cct, 20) << "close: " << close_ec.message() << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << "successfully connected to cache server." << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheClient.cc:    ldout(m_cct, 20) << "fault." << ec.message() << dendl;
./tools/immutable_object_cache/CacheClient.cc:           ldout(m_cct, 20) << "close: " << close_ec.message() << dendl;
./tools/immutable_object_cache/CacheClient.cc:       ldout(m_cct, 20) << "ASIO In-complete message." << ec.message() << dendl;
./tools/immutable_object_cache/CacheClient.cc:       ldout(m_cct, 20) << "ASIO async read fails : " << ec.message() << dendl;
./tools/immutable_object_cache/CacheClient.cc:       ldout(m_cct, 20) << "ASIO asyn write fails : " << ec.message() << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << "alloc entry for: " << file_name << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:    ldout(cct, 20) << "object is under promoting: " << file_name << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << "lookup: " << file_name << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << "to evict: " << file_name << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << file_name << dendl;
./tools/immutable_object_cache/SimplePolicy.cc:  ldout(cct, 20) << dendl;
./tools/immutable_object_cache/CacheController.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheController.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheController.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheController.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheController.cc:      ldout(m_cct, 5) << "can't recongize request" << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << " cache_file_name: " << cache_file_name << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << "object name = " << object_name << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << "file = " << cache_file << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << "evict cache: " << cache_file_path << dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:  ldout(m_cct, 20) << cache_file_name <<dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:    ldout(m_cct, 20) << "creating cache dir: " << cache_file_dir <<dendl;
./tools/immutable_object_cache/ObjectCacheStore.cc:      ldout(m_cct, 20) << "cache dir exists: " << cache_file_dir <<dendl;
./tools/immutable_object_cache/CacheSession.cc:       ldout(m_cct, 20) << "close: " << close_ec.message() << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << dendl;
./tools/immutable_object_cache/CacheSession.cc:  ldout(m_cct, 20) << "session fault : " << ec.message() << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(10) << ": rados addrs=" << m_addrs << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:      dout(10) << ": delaying shutdown -- init in progress" << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:    dout(5) << ": shutting down replayer for peer=" << peer << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(5) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/FSMirror.cc:      dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(5) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/FSMirror.cc:        dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/FSMirror.cc:  dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/FSMirror.cc:    dout(5) << ": shutting down replayers for peer=" << peer << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:      dout(10) << ": delaying shutdown -- init in progress" << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(5) << ": r=" << r << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:    dout(0) << ": client blocklisted" <<dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/MirrorWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": initial dir list=[" << m_directories << "]" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(5) << ": mon command r=" << r << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(0) << ": remote monitor host=" << mon_host << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": spawning " << nr_replayers << " snapshot replayer(s)" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": dir_path=" << dir_path << " locked" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": dir_path=" << dir_path << " unlocked" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": entry=" << d_name << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:        dout(20) << ": snap_path=" << snap_path << ", metadata=" << metadata << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": " << lr_str << " snap_map=" << *snap_map << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(5) << ": dir_path=" << dir_path << ", deleted snapshots=" << snaps << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": dir_path=" << dir_path << ", renamed snapshots=" << snaps << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(0) << ": backing off r=" << r << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(0) << ": backing off r=" << r << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": " << rm_stack.size() << " entries in stack" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": top of stack path=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:        dout(10) << ": done for remote directory=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(10) << ": done for remote file=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(20) << ": closing remote directory=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << ", snap_name=" << snap_name << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(0) << ": backing off r=" << r << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": " << sync_stack.size() << " entries in stack" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": top of stack path=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:        dout(10) << ": done for directory=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(10) << ": done for file=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(20) << ": closing local directory=" << entry.epath << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(5) << ": last snap-id transferred=" << last_snap_id << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:    dout(20) << ": nothing to synchronize" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": synzhronizing from snap-id=" << it->first << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(20) << ": dir_path=" << dir_path << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:  dout(10) << ": snapshot replayer=" << replayer << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(5) << ": exiting" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(5) << ": exiting as client is blocklisted" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:      dout(20) << ": trying to pick from " << m_directories.size() << " directories" << dendl;
./tools/cephfs_mirror/PeerReplayer.cc:        dout(5) << ": picked dir_path=" << *dir_path << dendl;
./tools/cephfs_mirror/watcher/RewatchRequest.cc:  dout(10) << dendl;
./tools/cephfs_mirror/watcher/RewatchRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/watcher/RewatchRequest.cc:  dout(20) << dendl;
./tools/cephfs_mirror/watcher/RewatchRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/watcher/RewatchRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": signal=" << signum << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": Initialized FSMirror for filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << ": filesystem=" << filesystem << ", r=" << r << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": Initialized FSMirror for filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": starting FSMirror: filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": filesystem=" << filesystem << ", pool_id=" << local_pool_id << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": filesystem=" << filesystem << ", r=" << r << dendl;
./tools/cephfs_mirror/Mirror.cc:      dout(10) << ": no pending actions for filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:    dout(10) << ": init failed for filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(10) << ": filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:    dout(5) << "shutting down" << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << ": filesystem=" << filesystem << ", peer=" << peer << dendl;
./tools/cephfs_mirror/Mirror.cc:    dout(5) << "shutting down" << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << ": filesystem=" << filesystem << ", peer=" << peer << dendl;
./tools/cephfs_mirror/Mirror.cc:    dout(5) << "shutting down" << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Mirror.cc:        dout(5) << ": filesystem=" << filesystem << " failed mirroring -- restarting" << dendl;
./tools/cephfs_mirror/Mirror.cc:        dout(5) << ": filesystem=" << filesystem << " is blocklisted -- restarting" << dendl;
./tools/cephfs_mirror/Mirror.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Mirror.cc:      dout(10) << ": canceling timer task=" << m_timer_task << dendl;
./tools/cephfs_mirror/Mirror.cc:    dout(10) << ": trying to shutdown filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Mirror.cc:      dout(10) << ": shutdown filesystem=" << filesystem << ", r=" << r << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:      dout(10) << ": delaying shutdown -- init in progress" << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(5) << ": r=" << r << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:    dout(0) << ": client blocklisted" <<dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/InstanceWatcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/ClusterWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/ClusterWatcher.cc:  dout(10) << ": subscribed to FSMap" << dendl;
./tools/cephfs_mirror/ClusterWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/ClusterWatcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/ClusterWatcher.cc:  dout(5) << ": peers added=" << peers_added << ", peers removed=" << peers_removed << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:      dout(5) << ": canceling timer task=" << m_timer_ctx << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(20) << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": fscid=" << fscid << ", fs_name=" << fs_name << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": fscid=" << fscid << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": peer=" << peer << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": fscid=" << fscid << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << ": fscid=" << fscid << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(10) << dendl;
./tools/cephfs_mirror/ServiceDaemon.cc:  dout(20) << ": " << m_filesystems.size() << " filesystem(s)" << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Watcher.cc:      dout(10) << ": delaying unregister -- watch register in progress" << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << ": r=" << r << dendl;
./tools/cephfs_mirror/Watcher.cc:      dout(10) << ": skipping rewatch -- unregistering" << dendl;
./tools/cephfs_mirror/Watcher.cc:      dout(5) << ": object " << m_oid << " does not exist" << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(10) << ": r=" << r << dendl;
./tools/cephfs_mirror/Watcher.cc:  dout(20) << dendl;
./tools/cephfs_mirror/Utils.cc:  dout(20) << ": filesystem=" << filesystem << dendl;
./tools/cephfs_mirror/Utils.cc:  dout(10) << ": mounted filesystem=" << filesystem << dendl;
./tools/rbd_ggate/debug.cc:    dout(ceph::dout::need_dynamic(level)) << msg << dendl;
./tools/rbd_ggate/Server.cc:  dout(10) << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << "entering run loop" << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << "exiting run loop" << dendl;
./tools/rbd_ggate/Server.cc:  dout(10) << dendl;
./tools/rbd_ggate/Server.cc:  dout(10) << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << ctx << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << ctx << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << ctx << ": r=" << r << dendl;
./tools/rbd_ggate/Server.cc:    dout(5) << "masking IO out-of-bounds error" << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << ctx << ": pad byte count: " << pad_byte_count << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << "waiting for ggate request" << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << pctx << ": start: " << *pctx << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << "terminated" << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << "waiting for io request" << dendl;
./tools/rbd_ggate/Server.cc:      dout(20) << "no io requests, terminating" << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << ctx.get() << ": got: " << *ctx << dendl;
./tools/rbd_ggate/Server.cc:    dout(20) << ctx.get() << " finish" << dendl;
./tools/rbd_ggate/Server.cc:  dout(20) << "terminated" << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << dendl;
./tools/rbd_ggate/Driver.cc:  dout(30) << m_devname << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << "newsize=" << newsize << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << "req=" << *req << dendl;
./tools/rbd_ggate/Driver.cc:  dout(20) << "req=" << req << dendl;
./tools/rbd_ggate/Watcher.cc:  dout(20) << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << ": r=" << r << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << ": r=" << r << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << ": r=" << r << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << ": r=" << r << dendl;
./tools/rbd/action/MirrorPool.cc:    dout(20) << this << " " << __func__ << ": r=" << r << dendl;
./tools/rbd/action/MergeDiff.cc:      dout(2) << " from snap " << *from << dendl;
./tools/rbd/action/MergeDiff.cc:      dout(2) << " to snap " << *to << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:    dout(10) << __func__ << ": terminating" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:    dout(10) << __func__ << ": waiting" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << __func__ << ": " << *ctx << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:    dout(0) << __func__ << ": masking IO out-of-bounds error" << *ctx << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": start" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": submitted" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": start" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": submitted" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": start" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": submitted" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": start" << dendl;
./tools/rbd_wnbd/wnbd_handler.cc:  dout(20) << *ctx << ": submitted" << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:    dout(5) << ": WNBD iterator error: " << error << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:    dout(5) << ": Registry iterator error: " << error << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(15) << __func__ << ": command arguments: " << arguments << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(5) << __func__ << ": command arguments: " << arguments << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(5) << __func__ << ": command line: " << command_line.str() << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(5) << __func__ << ": waiting for child notification." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(5) << __func__ << ": received child notification." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(5) << "Terminating unresponsive process." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:          dout(5) << "Successfully remapped: " << cfg.devpath << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:          dout(5) << "Successfully removed mapping: " << cfg.devpath << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": Receiving message." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": Executing command." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": Cleaning up connection." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": opening new pipe instance" << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": waiting for connections." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(20) << __func__ << ": Connection received." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(5) << "Accepting admin pipe connections." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:          dout(0) << "Ignoring image remap failure." << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:  dout(0) << "Mapping RBD image: " << cfg->devpath << dendl;
./tools/rbd_wnbd/rbd_wnbd.cc:      dout(5) << __func__ << ": submitted parent notification." << dendl;
./tools/crushtool.cc:      dout(2) << "lower_items " << lower_items << dendl;
./tools/crushtool.cc:      dout(2) << "lower_weights " << lower_weights << dendl;
./tools/crushtool.cc:	  dout(2) << "  item " << items[j] << " weight " << weights[j] << dendl;
./tools/crushtool.cc:	dout(2) << " in bucket " << id << " '" << name << "' size " << j << " weight " << weight << dendl;
./tools/rados/RadosImport.cc:    dout(10) << "Exported features: " << pgb.superblock.compat_features << dendl;
./tools/rados/RadosImport.cc:      dout(10) << "Don't care about the old metadata" << dendl;
./tools/rados/RadosImport.cc:    dout(10) << "alignment = " << alignment << dendl;
./tools/rados/RadosImport.cc:      dout(10) << "\tdata: offset " << ds.offset << " len " << ds.len << dendl;
./tools/rados/RadosImport.cc:          dout(10) << "write offset=" << out_offset << " len=" << rndlen << dendl;
./tools/rados/RadosImport.cc:      dout(10) << "\tattrs: len " << as.data.size() << dendl;
./tools/rados/RadosImport.cc:      dout(10) << "\tomap: size " << os.omap.size() << dendl;
./tools/rados/RadosImport.cc:        dout(10) << "END write offset=" << out_offset << " len=" << databl.length() << dendl;
./tools/rados/PoolDump.cc:    dout(10) << "OID '" << oid << "'" << dendl;
./tools/cephfs/MDSUtility.cc:  dout(4) << "waiting for MDS map..." << dendl;
./tools/cephfs/MDSUtility.cc:  dout(4) << "Got MDS map " << fsmap->get_epoch() << dendl;
./tools/cephfs/Resetter.cc:    dout(4) << "Successfully wrote header for rank " << role << dendl;
./tools/cephfs/PgFiles.cc:  dout(10) << "entering " << path << dendl;
./tools/cephfs/PgFiles.cc:      dout(20) << "Skipping non reg/dir file: " << de_path << dendl;
./tools/cephfs/PgFiles.cc:  dout(20) << "Hitting file '" << path << "'" << dendl;
./tools/cephfs/PgFiles.cc:    dout(20) << "  object " << std::string(buf) << dendl;
./tools/cephfs/PgFiles.cc:    dout(20) << "  target " << target << dendl;
./tools/cephfs/JournalTool.cc:  dout(10) << "JournalTool::main " << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "JournalTool: connecting to RADOS..." << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "JournalTool: resolving pool " << pool_id << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "JournalTool: creating IoCtx.." << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "Executing for rank " << rank << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "Writing object..." << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "Write complete." << dendl;
./tools/cephfs/JournalTool.cc:      dout(1) << "Using alternate pool " << arg_str << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "consumed " << consumed_inos.size() << " inodes" << dendl;
./tools/cephfs/JournalTool.cc:	dout(20) << "removing " << s << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "Erasing offset 0x" << std::hex << i->first << std::dec << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "inspecting lump " << frag_oid.name << dendl;
./tools/cephfs/JournalTool.cc:      dout(4) << "writing fnode to omap header" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry did not already exist, will create" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry " << key << " existed already" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry exists, checking versions..." << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry did not already exist, will create" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry " << key << " existed already" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "dentry exists, checking versions..." << dendl;
./tools/cephfs/JournalTool.cc:	dout(4) << "dentry exists, will remove" << dendl;
./tools/cephfs/JournalTool.cc:	  dout(4) << "corrupt dentry in backing store, will remove" << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "updating root 0x" << std::hex << ino << std::dec << dendl;
./tools/cephfs/JournalTool.cc:    dout(4) << "object id " << root_oid.name << dendl;
./tools/cephfs/JournalTool.cc:      dout(4) << "root does not exist, will create" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "magic ok" << dendl;
./tools/cephfs/JournalTool.cc:        dout(4) << "magic bad: '" << magic << "'" << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "erase_region " << pos << " len=" << length << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "erase_region padding=0x" << std::hex << padding << std::dec << dendl;
./tools/cephfs/JournalTool.cc:  dout(4) << "erase_region data length " << log_data.length() << dendl;
./tools/cephfs/JournalTool.cc:      dout(4) << "Wrote " << write_len << " bytes to " << oid << dendl;
./tools/cephfs/JournalTool.cc:      dout(4) << "writing modified inotable version " << inotable_ver << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "Using local file output to '" << val << "'" << dendl;
./tools/cephfs/DataScan.cc:    dout(10) << "Applying tag filter: '" << filter_tag << "'" << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "Using metadata pool output" << dendl;
./tools/cephfs/DataScan.cc:  dout(4) << "connecting to RADOS..." << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "opening data pool '" << data_pool_name << "'" << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "resolving metadata pool " << metadata_pool_id << dendl;
./tools/cephfs/DataScan.cc:      dout(4) << "Cannot stat '" << oid << "': skipping" << dendl;
./tools/cephfs/DataScan.cc:        dout(4) << "Bad object name '" << oid << "', skipping" << dendl;
./tools/cephfs/DataScan.cc:        dout(20) << "Applying filter to " << oid << dendl;
./tools/cephfs/DataScan.cc:          dout(20) << "Non-zeroth object" << dendl;
./tools/cephfs/DataScan.cc:          dout(20) << "read non-matching tag '" << read_tag << "'" << dendl;
./tools/cephfs/DataScan.cc:          dout(20) << "no tag read (" << r << ")" << dendl;
./tools/cephfs/DataScan.cc:        dout(20) << "OSD matched oid " << oid << dendl;
./tools/cephfs/DataScan.cc:	dout(10) << "Not a dirfrag: '" << oid << "'" << dendl;
./tools/cephfs/DataScan.cc:	dout(10) << "Not a dirfrag (invalid ino): '" << oid << "'" << dendl;
./tools/cephfs/DataScan.cc:      dout(4) << "Bad object name '" << oid << "', skipping" << dendl;
./tools/cephfs/DataScan.cc:      dout(10) << "Skipping system ino " << obj_name_ino << dendl;
./tools/cephfs/DataScan.cc:        dout(4) << "Corrupt backtrace on '" << oid << "': " << e.what() << dendl;
./tools/cephfs/DataScan.cc:        dout(4) << "Corrupt layout on '" << oid << "': " << e.what() << dendl;
./tools/cephfs/DataScan.cc:    dout(20) << key << " not found in result" << dendl;
./tools/cephfs/DataScan.cc:  dout(20) << "dirino=" << dirino << " target_dname=" << target_dname << dendl;
./tools/cephfs/DataScan.cc:    dout(10) << "No backtrace on '" << root_frag_oid << "'" << dendl;
./tools/cephfs/DataScan.cc:    dout(20) << "frag is " << *result_ft << dendl;
./tools/cephfs/DataScan.cc:        dout(20) << "resolved via parent, frag is " << *result_ft << dendl;
./tools/cephfs/DataScan.cc:  dout(10) << "  inode: 0x" << std::hex << ino << std::dec << dendl;
./tools/cephfs/DataScan.cc:  dout(10) << "read_version = " << read_version << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "resolving metadata pool " << metadata_pool_id << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "found metadata pool '" << metadata_pool_name << "'" << dendl;
./tools/cephfs/DataScan.cc:    dout(4) << "forcing metadata pool '" << metadata_pool_name << "'" << dendl;
./tools/cephfs/Dumper.cc:    dout(10) << "completed journal recovery" << dendl;
./tools/cephfs/Dumper.cc:      dout(10) << "Reading at pos=0x" << std::hex << pos << std::dec << dendl;
./tools/cephfs/JournalFilter.cc:      dout(4) << "Filtering by path '" << arg_str << "'" << dendl;
./tools/cephfs/JournalFilter.cc:      dout(4) << "Filtering by inode '" << arg_str << "'" << dendl;
./tools/cephfs/JournalFilter.cc:      dout(4) << "dirfrag filter: '" << frag << "'" << dendl;
./tools/cephfs/JournalFilter.cc:      dout(4) << "dentry filter: '" << frag_dentry << "'" << dendl;
./tools/cephfs/JournalScanner.cc:    dout(4) << "Pointer " << pointer_oid << " is readable" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << "JournalScanner::scan: reading header object '" << header_name << "'" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(10) << "Starting journal scan from offset 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:        dout(4) << "Reached end of journal objects" << dendl;
./tools/cephfs/JournalScanner.cc:        dout(4) << "Data at 0x" << std::hex << read_offset << " = 0x" << candidate_sentinel << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:          dout(4) << "Found sentinel at 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:      dout(4) << "read_buf size is " << read_buf.length() << dendl;
./tools/cephfs/JournalScanner.cc:      dout(10) << "Parsing data, 0x" << std::hex << read_buf.length() << std::dec << " bytes available" << dendl;
./tools/cephfs/JournalScanner.cc:          dout(4) << "Invalid container encoding at 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:        dout(10) << "Attempting decode at 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:        dout(10) << "Consumed 0x" << std::hex << consumed << std::dec << " bytes" << dendl;
./tools/cephfs/JournalScanner.cc:            dout(10) << "Valid entry at 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:          dout(10) << "Invalid entry at 0x" << std::hex << read_offset << std::dec << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << "Scanned objects, " << objects_missing.size() << " missing, " << objects_valid.size() << " valid" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << "Events scanned, " << ranges_invalid.size() << " gaps" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << "Found " << events_valid.size() << " valid events" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << "Selected " << events.size() << " events events for processing" << dendl;
./tools/cephfs/JournalScanner.cc:  dout(4) << events.size() << " events" << dendl;
./tools/cephfs/TableTool.cc:  dout(10) << __func__ << dendl;
./tools/cephfs/TableTool.cc:  dout(4) << "connecting to RADOS..." << dendl;
./tools/cephfs/TableTool.cc:  dout(4) << "resolving pool " << pool_id << dendl;
./tools/cephfs/TableTool.cc:  dout(4) << "creating IoCtx.." << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << name << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:    dout(20) << "not leader" << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "leader_instance_id=" << leader_instance_id << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:    dout(0) << "remote peer does not have mirroring configured" << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(5) << dendl;
./tools/rbd_mirror/NamespaceReplayer.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/PoolMetaCache.cc:  dout(15) << "pool_id=" << pool_id << dendl;
./tools/rbd_mirror/PoolMetaCache.cc:  dout(15) << "pool_id=" << pool_id << dendl;
./tools/rbd_mirror/PoolMetaCache.cc:  dout(15) << "pool_id=" << pool_id << dendl;
./tools/rbd_mirror/PoolMetaCache.cc:  dout(15) << "pool_id=" << pool_id << dendl;
./tools/rbd_mirror/image_map/LoadRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_map/LoadRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_map/LoadRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_map/LoadRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_map/SimplePolicy.cc:  dout(5) << "images per instance=" << images_per_instance << dendl;
./tools/rbd_mirror/image_map/UpdateRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_map/UpdateRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_map/UpdateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_map/UpdateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(20) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(5) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(5) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/image_map/Policy.cc:    dout(5) << "initial instance update" << dendl;
./tools/rbd_mirror/image_map/Policy.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/image_map/Policy.cc:    dout(5) << "removing dead instance_id=" << instance_id << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(5) << "image_id=" << image_id << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(20) << "info=" << *delete_info << ", r=" << r << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(20) << "info=" << *delete_info << ", r=" << error_code << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(20) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << "info=" << *delete_info << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << "info=" << *delete_info << ", r=" << r << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageDeleter.cc:  dout(10) << "image_id=" << image_id << ", r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "notifier_id=" << m_notifier_id << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << leader << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << releasing << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << m_timer_task << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:      dout(10) << "already locked" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(10) << "canceling due to shutdown" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(10) << "canceling due to shutdown" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "acquire_attempts=" << m_acquire_attempts << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(10) << "canceling due to shutdown" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:      dout(10) << "already locked" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(5) << "releasing due to error on notify" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(5) << "not leader, canceling" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(10) << "canceling due to shutdown" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:      dout(5) << "got another leader heartbeat, ignoring" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:      dout(5) << "got another leader lock_acquired, ignoring" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:      dout(5) << "got another leader lock_released, ignoring" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(10) << "our own notification, ignoring" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:    dout(1) << "blocklisted detected" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "heartbeat" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "lock_acquired" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "lock_released" << dendl;
./tools/rbd_mirror/LeaderWatcher.cc:  dout(10) << "unknown" << dendl;
./tools/rbd_mirror/MirrorStatusWatcher.cc:  dout(20) << dendl;
./tools/rbd_mirror/MirrorStatusWatcher.cc:  dout(20) << dendl;
./tools/rbd_mirror/MirrorStatusWatcher.cc:  dout(20) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(5) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:    dout(5) << "received on shut down, ignoring" << dendl;
./tools/rbd_mirror/Instances.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:    dout(5) << "handled on shut down, ignoring" << dendl;
./tools/rbd_mirror/Instances.cc:  dout(5) << "instance_ids=" << added_instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:  dout(20) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << "r=" << r << ", instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/Instances.cc:    dout(10) << "received on shut down, ignoring" << dendl;
./tools/rbd_mirror/Instances.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << dendl;
./tools/rbd_mirror/ImageMap.cc:      dout(20) << "starting rebalance" << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(5) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/ImageMap.cc:    dout(20) << "instance_ids=" << filtered_instance_ids << dendl;
./tools/rbd_mirror/ImageMap.cc:    dout(20) << "instance_ids=" << filtered_instance_ids << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << "mapping policy=" << policy_type << dendl;
./tools/rbd_mirror/ImageMap.cc:  dout(20) << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << m_base_cache_pri << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << cache_bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << "pri=" << pri << " " << cache_bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << "pri=" << pri << " " << bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << "pri=" << pri << " " << bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << m_committed_bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << m_committed_bytes << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << m_cache_ratio << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(30) << m_cache_ratio << dendl;
./tools/rbd_mirror/Mirror.cc:    dout(20) << cache_name << dendl;
./tools/rbd_mirror/Mirror.cc:      dout(20) << "balance" << dendl;
./tools/rbd_mirror/Mirror.cc:        dout(20) << "tune memory" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << signum << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "return" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/Mirror.cc:      dout(20) << "removing pool replayer for " << peer << dendl;
./tools/rbd_mirror/Mirror.cc:        dout(20) << "starting pool replayer for " << peer << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "peer=" << peer << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "r=" << r << ", desc=" << desc << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "on_finish=" << on_finish << dendl;
./tools/rbd_mirror/ImageReplayer.cc:      dout(10) << "canceled restart" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(5) << "no peer clusters" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(5) << "local image is primary" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(5) << "remote image is non-primary" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "start succeeded" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << "on finish complete, r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "r=" << r << ", desc=" << desc << dendl;
./tools/rbd_mirror/ImageReplayer.cc:          dout(10) << "start canceled" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:        dout(10) << "canceling restart" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:	  dout(10) << "canceling start" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:	  dout(10) << "interrupting replay" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << "canceling bootstrap" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(20) << "not running" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:      dout(15) << "shut down in-progress: ignoring update" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:          dout(15) << "replay status ready: r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:        dout(15) << "waiting for replay status" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(15) << "status=" << status << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(15) << "waiting for in-flight operations to complete" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:      dout(0) << "remote image no longer exists: scheduling deletion" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:      dout(0) << "mirror image no longer exists" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(5) << "moving image to trash" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(15) << "waiting for in-flight operations to complete" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(15) << "removing local mirror image status" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(15) << "removing remote mirror image status" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << "stop complete" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << "on start finish complete, r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << "on stop finish complete, r=" << r << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageReplayer.cc:      dout(10) << "image renamed" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(10) << "resync requested" << dendl;
./tools/rbd_mirror/ImageReplayer.cc:    dout(15) << "registered asok hook: " << m_image_spec << dendl;
./tools/rbd_mirror/ImageReplayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(15) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(15) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:      dout(10) << "deferring update due to in-flight ops" << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/MirrorStatusUpdater.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/GetMirrorImageIdRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/GetMirrorImageIdRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/GetMirrorImageIdRequest.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "remote_mirror_peer_uuid=" << m_remote_mirror_peer_uuid << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(10) << "shut down pending on completion of snapshot replay" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(10) << "local image resync requested" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(5) << "pruning unused non-primary snapshot " << prune_snap_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:      dout(5) << "local image promoted" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:      dout(15) << "skipping non-primary remote snapshot" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:      dout(10) << "unlinking from remote snapshot " << remote_snap_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:        dout(15) << "remote mirror snapshot not complete" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(10) << "remote image demoted" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "snap_id=" << snap_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(15) << "local_snap_id_end=" << m_local_snap_id_end << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(5) << "image-sync canceled" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(20) << "bytes_read=" << bytes_read << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "remote_snap_id=" << remote_snap_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(15) << "flagging snapshot rescan required" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(15) << "restarting idle replayer" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/Replayer.cc:    dout(10) << "resuming pending shut down" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "local_image_id=" << m_state_builder->local_image_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "local_image_id=" << m_state_builder->local_image_id << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:      dout(10) << "parent image does not exist" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/CreateLocalImageRequest.cc:  dout(15) << description << dendl;
./tools/rbd_mirror/image_replayer/snapshot/PrepareReplayRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/PrepareReplayRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "image_state=" << m_image_state << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(15) << "removing image-meta key '" << key << "'" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(15) << "updating image-meta key '" << key << "'" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is not a user snapshot" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is already unprotected" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is not a user snapshot" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is not a user snapshot" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is already protected" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:      dout(20) << "snapshot " << snap_id << " is not a user snapshot" << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "snap_limit=" << m_image_state.snap_limit << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/snapshot/ApplyImageStateRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:    dout(10) << "image " << m_global_image_id << " not mirrored" << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:    dout(5) << "remote image mirroring is being disabled" << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:    dout(5) << "remote image is not primary -- not syncing" << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:    dout(10) << "client not registered" << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareRemoteImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:    dout(5) << "image id " << m_local_image_id << " already in-use" << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:    dout(15) << "remote parent image snapshot not found" << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:    dout(15) << "parent image not synced to local cluster" << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:    dout(5) << "image id " << m_local_image_id << " already in-use" << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/CreateImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/PrepareLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(10) << "local image force-promoted" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(10) << "local image resync requested" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(0) << "client flagged disconnected, stopping image replay" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << ", error=" << error << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(20) << "no entries ready for replay" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << "tag_tid: " << m_replay_tag_tid << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:      dout(15) << "skipping stale demotion event" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:      dout(5) << "encountered image demotion: stopping" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << "delaying replay by " << delay << " sec" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:      dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:    dout(5) << "client flagged disconnected, stopping image replay" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:      dout(10) << "disconnected: automatic resync" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:      dout(10) << "disconnected" << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_replayer/journal/Replayer.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << "local_image_id=" << m_state_builder->local_image_id << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << "local_image_id=" << m_state_builder->local_image_id << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:      dout(10) << "parent image does not exist" << dendl;
./tools/rbd_mirror/image_replayer/journal/CreateLocalImageRequest.cc:  dout(15) << description << dendl;
./tools/rbd_mirror/image_replayer/journal/SyncPointHandler.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/SyncPointHandler.cc:  dout(20) << "client_meta=" << m_client_meta_copy << dendl;
./tools/rbd_mirror/image_replayer/journal/SyncPointHandler.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/EventPreprocessor.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << "remote tag class=" << m_remote_tag_class << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:        dout(10) << "skipping non-primary remote tag" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:      dout(10) << "using initial primary remote tag" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:          dout(10) << "found matching local demotion tag" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:          dout(10) << "found matching remote demotion tag" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:        dout(10) << "found chained remote promotion tag" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:    dout(10) << "local image is in clean replay state" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:    dout(10) << "remote image was demoted/promoted" << dendl;
./tools/rbd_mirror/image_replayer/journal/PrepareReplayRequest.cc:  dout(10) << description << dendl;
./tools/rbd_mirror/image_replayer/journal/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/journal/StateBuilder.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:    dout(10) << "previous request is still in progress, ignoring" << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:    dout(20) << "need to update tag cache" << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:  dout(20) << old_size - m_tag_cache.size() << " entries cleared" << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:    dout(20) << "retrieved tag " << master_tag_tid << ": " << m_tag << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:    dout(20) << "hit remote image non-primary epoch" << dendl;
./tools/rbd_mirror/image_replayer/journal/ReplayStatusFormatter.cc:  dout(20) << "decoded tag " << master_tag_tid << ": " << tag_data << dendl;
./tools/rbd_mirror/image_replayer/OpenImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/OpenImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/StateBuilder.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "local image does not exist" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(5) << "local image is primary" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "remote-image is non-primary" << cpp_strerror(r) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "remote_image_id=" << remote_image_id << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "local_image_id=" << local_image_id << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "local image missing" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "local image is primary -- skipping image replay" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "local image resync requested" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "client flagged disconnected -- skipping bootstrap" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "local image still syncing to remote image" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:      dout(10) << "parent image does not exist" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:    dout(10) << "request canceled" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:      dout(10) << "request canceled" << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << "r=" << r << dendl;
./tools/rbd_mirror/image_replayer/BootstrapRequest.cc:  dout(15) << description << dendl;
./tools/rbd_mirror/image_replayer/CloseImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/CloseImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:      dout(10) << ": local image does not exist" << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:    dout(5) << ": local image is not mirrored" << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:    dout(5) << ": local image mirroring is being disabled" << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:    dout(10) << ": local image is primary -- skipping image replay" << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_replayer/OpenLocalImageRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_replayer/Utils.cc:  dout(15) << dendl;
./tools/rbd_mirror/image_replayer/Utils.cc:  dout(15) << "client found: client_meta=" << *client_meta << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:      dout(5) << "remote mirror uuid missing" << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << "remote_mirror_uuid=" << remote_mirror_uuid << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << "remote_mirror_peer_uuid=" << remote_mirror_peer_uuid << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:    dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:    dout(10) << dendl;
./tools/rbd_mirror/RemotePoolPoller.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointCreateRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << ": snap_name=" << snap_name << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/image_sync/SyncPointPruneRequest.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << m_config_key << "=" << m_max_concurrent_ops << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << "id=" << id << dendl;
./tools/rbd_mirror/Throttler.cc:      dout(20) << "duplicate for already started op " << id << dendl;
./tools/rbd_mirror/Throttler.cc:      dout(20) << "duplicate for already queued op " << id << dendl;
./tools/rbd_mirror/Throttler.cc:      dout(20) << "op for " << id << " has been queued" << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << "id=" << id << dendl;
./tools/rbd_mirror/Throttler.cc:      dout(20) << "canceled queued op for " << id << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << "id=" << id << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << "ns=" << ns << dendl;
./tools/rbd_mirror/Throttler.cc:        dout(20) << "inflight_op " << *it << dendl;
./tools/rbd_mirror/Throttler.cc:    dout(20) << "queued_op " << it.first << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << "max=" << max << dendl;
./tools/rbd_mirror/Throttler.cc:  dout(20) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(10) << "C_RemoveInstanceRequest: " << this << " " << __func__ << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__ << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__ << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "instance_id=" << m_instance_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:      dout(10) << "finish: sync_id=" << sync_id << ", r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_ctx->sync_id << ", r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "sync_id=" << sync_ctx->sync_id << ", r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "leader_instance_id=" << leader_instance_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "instance_id=" << instance_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << req << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << req << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(10) << "duplicate for in-progress request" << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "instance_id=" << instance_id << ", sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(10) << "sync request for non-leader" << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(10) << "instance_id=" << instance_id << ", sync_id=" << sync_id << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(5) << "not found" << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:    dout(5) << "duplicate request" << dendl;
./tools/rbd_mirror/InstanceWatcher.cc:  dout(5) << "unknown: instance_id=" << instance_id << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "peer=" << peer << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:    dout(5) << global_image_id << ": not found" << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "global_image_id=" << global_image_id << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/InstanceReplayer.cc:  dout(10) << m_image_state_check_task << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:    dout(10) << ": image copy canceled" << dendl;
./tools/rbd_mirror/ImageSync.cc:  ldout(cct, 20) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(10) << ": r=" << r << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(20) << ": " << description << dendl;
./tools/rbd_mirror/ImageSync.cc:  dout(20) << ": r=" << r << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:  dout(20) << "enter" << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:      dout(10) << "pool " << pool_name << " no longer exists" << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:      dout(10) << "pool " << pool_id << " no longer exists" << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:      dout(10) << "mirroring is disabled for pool " << pool_name << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:      dout(10) << "access denied querying pool " << pool_name << dendl;
./tools/rbd_mirror/ClusterWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/PoolWatcher.cc:    dout(0) << "detected client is blocklisted" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:    dout(5) << "mirroring directory does not exist" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(5) << "unregister_watcher: r=" << r << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(5) << "mirroring directory not found" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(0) << "detected client is blocklisted during image refresh" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:    dout(5) << "scheduling deferred refresh" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(5) << "deferring refresh until in-flight refresh completes" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/PoolWatcher.cc:    dout(0) << "detected client is blocklisted" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:    dout(5) << "mirroring directory deleted" << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:  dout(10) << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(20) << "image_id=" << image_id << dendl;
./tools/rbd_mirror/PoolWatcher.cc:      dout(20) << "image_id=" << image_id << dendl;
./tools/rbd_mirror/pool_watcher/RefreshImagesRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/pool_watcher/RefreshImagesRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/pool_watcher/RefreshImagesRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(10) << "replaying for " << m_peer << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(10) << "connected to " << m_peer << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:      dout(10) << "mirroring is disabled for namespace " << name << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << "enter: manual=" << manual << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:        dout(10) << "handle_post_acquire_leader" << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(20) << dendl;
./tools/rbd_mirror/PoolReplayer.cc:        dout(10) << "handle_pre_release_leader" << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(10) << "leader_instance_id=" << leader_instance_id << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(5) << "instance_ids=" << instance_ids << dendl;
./tools/rbd_mirror/PoolReplayer.cc:  dout(5) << "remote_pool_meta=" << remote_pool_meta << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << "pool_id=" << pool_id << ", pool_name=" << pool_name << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << "pool_id=" << pool_id << dendl;
./tools/rbd_mirror/ServiceDaemon.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:    dout(10) << "snapshot in-use" << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:    dout(10) << "snapshot in-use" << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/SnapshotPurgeRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(10) << "image " << m_global_image_id << " is not mirrored" << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(5) << "image " << m_global_image_id << " is not mirrored" << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(10) << "image " << m_global_image_id << " is local primary" << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(10) << "image " << m_global_image_id << " is orphaned" << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(10) << "local image is not mirrored, aborting deletion." << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:    dout(10) << "local image is not mirrored" << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashMoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:    dout(10) << "image id " << m_image_id << " not in mirroring trash" << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:    dout(10) << "image id " << m_image_id << " not in mirroring trash" << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:    dout(10) << "snapshots still in-use" << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:    dout(10) << "snapshots still in-use" << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashRemoveRequest.cc:  dout(10) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(10) << "image_id=" << image_id << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:    dout(0) << "detected client is blocklisted" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:    dout(5) << "trash directory deleted" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(20) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(20) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:      dout(0) << "detected client is blocklisted" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:      dout(0) << "detected pool no longer exists" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:    dout(0) << "detected client is blocklisted" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << "unregister_watcher: r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << "last_image_id=" << m_last_image_id << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << "r=" << r << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:      dout(0) << "detected client is blocklisted during trash refresh" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:      dout(5) << "deferring refresh until in-flight refresh completes" << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./tools/rbd_mirror/image_deleter/TrashWatcher.cc:  dout(5) << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << changed << dendl;
./mon/OSDMonitor.cc:  dout(10) << "create_initial for " << mon.monmap->fsid << dendl;
./mon/OSDMonitor.cc:  dout(20) << " full crc " << pending_inc.full_crc << dendl;
./mon/OSDMonitor.cc:        dout(10) << __func__ << " found latest full map v " << v << dendl;
./mon/OSDMonitor.cc:    dout(7) << __func__ << " loading latest full map e" << latest_full << dendl;
./mon/OSDMonitor.cc:    dout(1) << osdmap << dendl;
./mon/OSDMonitor.cc:        dout(10) << " adding osd." << o << " to down_pending_out map" << dendl;
./mon/OSDMonitor.cc:        dout(10) << " removing osd." << o << " from down_pending_out map" << dendl;
./mon/OSDMonitor.cc:    dout(20) << "Stretch mode enabled in this map" << dendl;
./mon/OSDMonitor.cc:      dout(20) << "Degraded stretch mode set in this map" << dendl;
./mon/OSDMonitor.cc:	  dout(10) << "Enabling recovery stretch mode in this map" << dendl;
./mon/OSDMonitor.cc:      dout(20) << "Checking degraded stretch mode due to osd changes" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no pools, no mapping job" << dendl;
./mon/OSDMonitor.cc:      dout(0) << "crush map has features " << features << ", adjusting msgr requires" << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(10) << "update_logger" << dendl;
./mon/OSDMonitor.cc:  dout(10) << "create_pending e " << pending_inc.epoch << dendl;
./mon/OSDMonitor.cc:    dout(1) << __func__ << " Rewrote " << old_to_new << " crush IDs:" << dendl;
./mon/OSDMonitor.cc:      dout(1) << __func__ << " " << i.first << " -> " << i.second << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " " << queued << " pools queued" << dendl;
./mon/OSDMonitor.cc:      dout(20) << __func__ << " noting created pg " << pg << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " adding " << pgid << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " done with queue for " << poolid << dendl;
./mon/OSDMonitor.cc:	  dout(20) << "  debug: " << debug.str() << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " new crush map, all" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " new up osds, all" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no pools, no pg_temp priming" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " done in " << job.get_duration() << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " " << osds.size() << " interesting osds" << dendl;
./mon/OSDMonitor.cc:      dout(20) << __func__ << " osd." << osd << " " << pgs << dendl;
./mon/OSDMonitor.cc:      dout(10) << "new_state for osd." << p->first << " is 0, removing" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " first nautilus+ epoch" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " first octopus+ epoch" << dendl;
./mon/OSDMonitor.cc:      dout(2) << " osd." << i->first << " DOWN" << dendl;
./mon/OSDMonitor.cc:      dout(2) << " osd." << i->first << " DNE" << dendl;
./mon/OSDMonitor.cc:    dout(2) << " osd." << i->first << " UP " << i->second << dendl;
./mon/OSDMonitor.cc:      dout(2) << " osd." << i->first << " OUT" << dendl;
./mon/OSDMonitor.cc:      dout(2) << " osd." << i->first << " IN" << dendl;
./mon/OSDMonitor.cc:      dout(2) << " osd." << i->first << " WEIGHT " << hex << i->second << dec << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no up osds, don't share with anyone" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no up osd on our session map" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " quorum not formed, trim_to = 0" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " pgs creating, trim_to = 0" << dendl;
./mon/OSDMonitor.cc:    dout(10) << " min_last_epoch_clean " << floor << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " trim_to = " << floor << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " trim_to = 0" << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " including full map for e " << first << dendl;
./mon/OSDMonitor.cc:  dout(1) << __func__ << dendl;
./mon/OSDMonitor.cc:      dout(20) << __func__ << "   pruning full osdmap e" << v << dendl;
./mon/OSDMonitor.cc:  dout(10) << "preprocess_query " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(7) << "prepare_update " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(10) << "should_propose" << dendl;
./mon/OSDMonitor.cc:    dout(0) << " adjusting osd weights based on " << osd_weight << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:    dout(5) << __func__ << " no osds" << dendl;
./mon/OSDMonitor.cc:    dout(5) << __func__ << " no osds" << dendl;
./mon/OSDMonitor.cc:    dout(10) << " already pending failure" << dendl;
./mon/OSDMonitor.cc:    dout(10) << " already pending failure" << dendl;
./mon/OSDMonitor.cc:  dout(1) << " we're forcing failure of osd." << target_osd << dendl;
./mon/OSDMonitor.cc:      dout(10) << " no failure_info for osd." << target_osd << dendl;
./mon/OSDMonitor.cc:      dout(10) << "process_failures osd." << p->first << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " on " << failure_info.size() << " osds" << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << " reset laggy, now xi " << xi << dendl;
./mon/OSDMonitor.cc:    dout(0) << "preprocess_boot got blank addr for " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:    dout(7) << "prepare_boot msg from before last up_from, ignoring" << dendl;
./mon/OSDMonitor.cc:    dout(7) << "preprocess_boot ignoring boot from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(10) << "preprocess_boot from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:	dout(10) << " fresh osd; marking lost_at too" << dendl;
./mon/OSDMonitor.cc:    dout(10) << " old osd_info: " << info << dendl;
./mon/OSDMonitor.cc:      dout(10) << " not laggy, new xi " << xi << dendl;
./mon/OSDMonitor.cc:      dout(10) << " laggy, now xi " << xi << dendl;
./mon/OSDMonitor.cc:    dout(7) << "preprocess_alive want up_thru " << m->want << " dup from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << ": no monitor session!" << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:    dout(1) << __func__ << " ignoring stats from non-active osd." << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << ": no monitor session!" << dendl;
./mon/OSDMonitor.cc:    dout(20) << " pg_num " << pi->get_pg_num() << " already < " << m->pgid << dendl;
./mon/OSDMonitor.cc:    dout(20) << " pg_num_pending " << pi->get_pg_num_pending() << " > " << m->pgid << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:  dout(10) << "preprocess_pgtemp " << *m << dendl;
./mon/OSDMonitor.cc:  dout(7) << "preprocess_pgtemp e" << m->map_epoch << " no changes from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(7) << "prepare_pgtemp e" << m->map_epoch << " from " << m->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(7) << "preprocess_remove_snaps " << *m << dendl;
./mon/OSDMonitor.cc:  dout(7) << "prepare_remove_snaps " << *m << dendl;
./mon/OSDMonitor.cc:  dout(7) << __func__ << " " << *m << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no monitor session!" << dendl;
./mon/OSDMonitor.cc:    dout(1) << " ignoring beacon from non-active osd." << from << dendl;
./mon/OSDMonitor.cc:  dout(5) << "send_full to " << op->get_req()->get_orig_source_inst() << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " ver " << ver << dendl;
./mon/OSDMonitor.cc:    dout(0) << __func__ << " pinned: " << osdmap_manifest.pinned << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " closest pinned ver " << closest_pinned << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " found map in cache ver " << v << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << "    applying inc epoch " << v << dendl;
./mon/OSDMonitor.cc:  dout(10) << "blocklist " << av << " until " << until << dendl;
./mon/OSDMonitor.cc:  dout(10) << "blocklist " << a << " until " << until << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << " .. " << sub->session->name << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " already created " << poolid << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " looking up " << pgid << "@" << mapped << dendl;
./mon/OSDMonitor.cc:  dout(10) << osdmap << dendl;
./mon/OSDMonitor.cc:    dout(10) << "tick NOOUT flag set, not checking down osds" << dendl;
./mon/OSDMonitor.cc:      dout(10) << "expiring blocklist item " << p->first << " expired " << p->second << " < now " << now << dendl;
./mon/OSDMonitor.cc:    dout(30) << __func__ << ": checking up on osd " << i << dendl;
./mon/OSDMonitor.cc:            dout(4) << "No metadata for osd." << i << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " max_prune " << max_prune << dendl;
./mon/OSDMonitor.cc:      dout(20) << __func__ << " " << p.first << " nothing purged" << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " pool " << p.first << " purged " << purged << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " actually pruned " << actually_pruned << dendl;
./mon/OSDMonitor.cc:  dout(10) << "prepare_new_pool from " << m->get_connection() << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " got " << ret << " " << ss.str() << dendl;
./mon/OSDMonitor.cc:    dout(10) << "prepare_pool_crush_rule returns " << r << dendl;
./mon/OSDMonitor.cc:    dout(10) << "prepare_pool_size returns " << r << dendl;
./mon/OSDMonitor.cc:    dout(10) << "check_pg_num returns " << r << dendl;
./mon/OSDMonitor.cc:    dout(10) << "prepare_pool_stripe_width returns " << r << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " uuid " << uuid << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " no device_class" << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " using id " << *new_id << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " id " << id << " uuid " << uuid << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " no uuid; assuming legacy `osd create`" << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << op << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " osd." << id << " isn't destroyed" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " found id " << id << " to use" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " recreating osd." << id << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " creating new osd." << id << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " id " << id << " uuid " << uuid << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " idempotent and no params -- no op." << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " device_class will be " << device_class << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " validate secrets using osd id " << id << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " idempotent -- no op." << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " osd." << id << " does not exist." << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " purging osd." << id << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " waiting for pending crush update " << dendl;
./mon/OSDMonitor.cc:    dout(10) << "prepare_command setting new crush map" << dendl;
./mon/OSDMonitor.cc:      dout(10) << " testing map" << dendl;
./mon/OSDMonitor.cc:	dout(20) << " bucket " << bid << " is straw, can convert" << dendl;
./mon/OSDMonitor.cc:      dout(0) << "moving crush item name '" << name << "' to location " << loc << dendl;
./mon/OSDMonitor.cc:      dout(5) << "resolved crush name '" << name << "' to id " << id << dendl;
./mon/OSDMonitor.cc:    dout(5) << "linking crush item name '" << name << "' at location " << loc << dendl;
./mon/OSDMonitor.cc:	dout(20) << "erasure code profile rm " << name << ": creation canceled" << dendl;
./mon/OSDMonitor.cc:      dout(20) << "erasure code profile " << name << " try again" << dendl;
./mon/OSDMonitor.cc:	  dout(20) << "erasure code profile " << profile << " already pending" << dendl;
./mon/OSDMonitor.cc:      dout(10) << __func__ << " waiting for pending update on " << pgid << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " osd new json = " << param_json << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " osd new params " << param_map << dendl;
./mon/OSDMonitor.cc:      dout(10) << " osd create got id " << cmd_id << dendl;
./mon/OSDMonitor.cc:	    dout(20) << "erasure code profile " << erasure_code_profile << " already pending" << dendl;
./mon/OSDMonitor.cc:	  dout(20) << "erasure code profile " << erasure_code_profile << " set" << dendl;
./mon/OSDMonitor.cc:    dout(10) << "attempt to operate on non-existent pool id " << m->pool << dendl;
./mon/OSDMonitor.cc:  dout(10) << "prepare_pool_op " << *m << dendl;
./mon/OSDMonitor.cc:  dout(10) << __func__ << " " << pool << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " removing choose_args for pool " << pool << dendl;
./mon/OSDMonitor.cc:  dout(10) << "_prepare_rename_pool " << pool << dendl;
./mon/OSDMonitor.cc:    dout(10) << "_prepare_rename_pool " << pool << " pending removal" << dendl;
./mon/OSDMonitor.cc:    dout(10) << __func__ << " got " << ret << " " << ss.str() << dendl;
./mon/OSDMonitor.cc:  dout(20) << "_pool_op_reply " << ret << dendl;
./mon/OSDMonitor.cc:    dout(20) << __func__ << " nothing to fix" << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << " with dead mon zones " << dead_buckets << dendl;
./mon/OSDMonitor.cc:      dout(20) << "subtree is down!" << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/OSDMonitor.cc:  dout(20) << __func__ << dendl;
./mon/MgrStatMonitor.cc:  dout(10) << __func__ << dendl;
./mon/MgrStatMonitor.cc:  dout(10) << " " << version << dendl;
./mon/MgrStatMonitor.cc:  dout(20) << __func__ << dendl;
./mon/MgrStatMonitor.cc:  dout(10) << " " << version << dendl;
./mon/MgrStatMonitor.cc:  dout(10) << " " << version << dendl;
./mon/MgrStatMonitor.cc:    dout(1) << __func__ << " on removed pool " << *pool << dendl;
./mon/MgrStatMonitor.cc:  dout(10) << __func__ << dendl;
./mon/MonCap.cc:	ldout(cct, 20) << " allow all" << dendl;
./mon/MonCap.cc:	ldout(cct, 20) << " match" << dendl;
./mon/MgrMonitor.cc:    dout(4) << "loading version " << version << dendl;
./mon/MgrMonitor.cc:  dout(10) << __func__ << dendl;
./mon/MgrMonitor.cc:  dout(10) << __func__ << " " << pending_map << dendl;
./mon/MgrMonitor.cc:    dout(10) << __func__ << " set metadata for " << p.first << dendl;
./mon/MgrMonitor.cc:    dout(10) << __func__ << " rm metadata for " << name << dendl;
./mon/MgrMonitor.cc:    dout(1) << __func__ << " insufficient caps " << session->caps << dendl;
./mon/MgrMonitor.cc:  dout(4) << "beacon from " << m->get_gid() << dendl;
./mon/MgrMonitor.cc:  dout(4) << "beacon from " << m->get_gid() << dendl;
./mon/MgrMonitor.cc:    dout(4) << "Active daemon restart (mgr." << m->get_name() << ")" << dendl;
./mon/MgrMonitor.cc:      dout(4) << "Standby daemon restart (mgr." << m->get_name() << ")" << dendl;
./mon/MgrMonitor.cc:      dout(4) << "available " << m->get_gid() << dendl;
./mon/MgrMonitor.cc:      dout(10) << "from existing standby " << m->get_gid() << dendl;
./mon/MgrMonitor.cc:      dout(10) << "new standby " << m->get_gid() << dendl;
./mon/MgrMonitor.cc:    dout(4) << "updating map" << dendl;
./mon/MgrMonitor.cc:    dout(10) << "no change" << dendl;
./mon/MgrMonitor.cc:  dout(10) << __func__ << dendl;
./mon/MgrMonitor.cc:    dout(4) << "Dropping laggy standby " << i << dendl;
./mon/MgrMonitor.cc:    dout(4) << "Dropping active" << pending_map.active_gid << dendl;
./mon/MgrMonitor.cc:      dout(4) << "Promoted standby " << pending_map.active_gid << dendl;
./mon/MgrMonitor.cc:      dout(4) << "Active is laggy but have no standbys to replace it" << dendl;
./mon/MgrMonitor.cc:      dout(4) << "Promoted standby " << pending_map.active_gid << dendl;
./mon/MgrMonitor.cc:    dout(10) << " disabling obsolete/renamed 'orchestrator_cli'" << dendl;
./mon/MgrMonitor.cc:	  dout(4) << "No metadata for mgr." << i << dendl;
./mon/MgrMonitor.cc:  dout(4) << __func__ << " done, r=" << r << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 1) << "init, first boot, initializing epoch at 1 " << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 1) << "init, last seen epoch " << epoch << dendl;
./mon/ElectionLogic.cc:  ldout(cct, 10) << __func__ << epoch << " to " << e << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 0) << "not starting new election -- not participating" << dendl;
./mon/ElectionLogic.cc:  ldout(cct, 5) << "start -- can i be leader?" << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "defer to " << who << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 5) << "defer to " << who << ", disallowed_leaders=" << elector->get_disallowed_leaders() << dendl;
./mon/ElectionLogic.cc:  ldout(cct, 5) << "election period ended" << dendl;
./mon/ElectionLogic.cc:  ldout(cct, 5) << "I win! acked_me=" << acked_me << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << " ignoring old propose" << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << " ignoring old propose" << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << dendl;
./mon/ElectionLogic.cc:      ldout(cct, 5) << "no, we already acked " << leader_acked << " with score >=" << from_score << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 5) << "woah, that's a newer epoch, i must have rebooted.  bumping and re-starting!" << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 1) << "I should have been elected over this leader; bumping and restarting!" << dendl;
./mon/ElectionLogic.cc:    ldout(cct, 5) << "woah, that's a funny epoch, i must have rebooted.  bumping and re-starting!" << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " using current monmap" << dendl;
./mon/MonmapMonitor.cc:    dout(10) << " signaling that we need a bootstrap" << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " got " << version << dendl;
./mon/MonmapMonitor.cc:    dout(10) << __func__ << " updating min_mon_release meta" << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " monmap epoch " << pending_map.epoch << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " epoch " << pending_map.epoch << dendl;
./mon/MonmapMonitor.cc:    dout(5) << __func__ << " wait for service to be writeable" << dendl;
./mon/MonmapMonitor.cc:    dout(10) << "noting that i was, once, part of an active quorum." << dendl;
./mon/MonmapMonitor.cc:  dout(7) << __func__ << " " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/MonmapMonitor.cc:    dout(10) << "mon add setting location for " << name << " to " << loc << dendl;
./mon/MonmapMonitor.cc:    dout(20) << __func__ << " addr " << addr << " -> addrs " << addrs << dendl;
./mon/MonmapMonitor.cc:    dout(0) << __func__ << " proposing new mon." << name << dendl;
./mon/MonmapMonitor.cc:    dout(10) << "mon set_location for " << name << " to " << loc << dendl;
./mon/MonmapMonitor.cc:  dout(20) << __func__ << dendl;
./mon/MonmapMonitor.cc:  dout(20) << __func__ << dendl;
./mon/MonmapMonitor.cc:  dout(20) << __func__ << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " " << join->name << " at " << join->addrs << dendl;
./mon/MonmapMonitor.cc:    dout(10) << " insufficient caps" << dendl;
./mon/MonmapMonitor.cc:    dout(10) << " already have " << join->name << dendl;
./mon/MonmapMonitor.cc:    dout(10) << " already have " << join->addrs << dendl;
./mon/MonmapMonitor.cc:  dout(10) << __func__ << " ver " << latest_ver << dendl;
./mon/MonmapMonitor.cc:    dout(10) << __func__ << " detected empty created stamp" << dendl;
./mon/MonmapMonitor.cc:    dout(10) << __func__ << " updating created stamp to " << ctime << dendl;
./mon/PaxosService.cc:    dout(10) << " waiting for paxos -> readable (v" << m->version << ")" << dendl;
./mon/PaxosService.cc:    dout(10) << " waiting for paxos -> writeable" << dendl;
./mon/PaxosService.cc:    dout(10) << __func__ << " forced immediate propose" << dendl;
./mon/PaxosService.cc:    dout(10) << " not proposing" << dendl;
./mon/PaxosService.cc:    dout(10) << " proposal_timer already set" << dendl;
./mon/PaxosService.cc:    dout(1) << __func__ << " upgraded, format " << format_version << " -> " << new_format << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:    dout(10) << " canceling proposal_timer " << proposal_timer << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:    dout(10) << " canceling proposal_timer " << proposal_timer << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:    dout(10) << __func__ << " - proposing" << dendl;
./mon/PaxosService.cc:    dout(10) << __func__ << " - not active" << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << dendl;
./mon/PaxosService.cc:    dout(7) << __func__ << " creating new pending" << dendl;
./mon/PaxosService.cc:    dout(7) << __func__ << " we are not the leader, hence we propose nothing!" << dendl;
./mon/PaxosService.cc:    dout(10) << " canceling proposal_timer " << proposal_timer << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << " trimming to " << trim_to << ", " << to_remove << " states" << dendl;
./mon/PaxosService.cc:  dout(10) << __func__ << " from " << from << " to " << to << dendl;
./mon/PaxosService.cc:    dout(20) << __func__ << " " << v << dendl;
./mon/PaxosService.cc:      dout(20) << __func__ << " " << full_key << dendl;
./mon/PaxosService.cc:    dout(20) << " compacting prefix " << get_service_name() << dendl;
./mon/LogMonitor.cc:  dout(20) << __func__ << " expand map: " << m << dendl;
./mon/LogMonitor.cc:  dout(20) << __func__ << " expanded map: " << m << dendl;
./mon/LogMonitor.cc:  dout(10) << *this << dendl;
./mon/LogMonitor.cc:  dout(10) << "create_initial -- creating initial map" << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << " latest full " << latest_full << dendl;
./mon/LogMonitor.cc:    dout(7) << __func__ << " loading summary e" << latest_full << dendl;
./mon/LogMonitor.cc:    dout(7) << __func__ << " loaded summary e" << summary.version << dendl;
./mon/LogMonitor.cc:      dout(7) << "update_from_paxos applying incremental log " << summary.version+1 <<  " " << le << dendl;
./mon/LogMonitor.cc:  dout(10) << "create_pending v " << (get_last_committed() + 1) << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << " v" << version << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << " log v " << summary.version << dendl;
./mon/LogMonitor.cc:  dout(10) << "preprocess_query " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/LogMonitor.cc:  dout(10) << "prepare_update " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/LogMonitor.cc:  dout(10) << "preprocess_log " << *m << " from " << m->get_orig_source() << dendl;
./mon/LogMonitor.cc:    dout(10) << "  nothing new" << dendl;
./mon/LogMonitor.cc:  dout(10) << "prepare_log " << *m << " from " << m->get_orig_source() << dendl;
./mon/LogMonitor.cc:    dout(10) << " logging " << *p << dendl;
./mon/LogMonitor.cc:  dout(7) << "_updated_log for " << m->get_orig_source_inst() << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << dendl;
./mon/LogMonitor.cc:  dout(10) << __func__ << " client wants " << s->type << " ver " << s->next << dendl;
./mon/HealthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/HealthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/HealthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/HealthMonitor.cc:  dout(10) << " " << version << dendl;
./mon/HealthMonitor.cc:  dout(10) << " " << version << dendl;
./mon/HealthMonitor.cc:  dout(4) << __func__ << " done, r=" << r << dendl;
./mon/HealthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/HealthMonitor.cc:  dout(20) << __func__ << dendl;
./mon/HealthMonitor.cc:  dout(20) << __func__ << dendl;
./mon/HealthMonitor.cc:      dout(20) << __func__ << " all_versions=" << all_versions << dendl;
./mon/MonMap.cc:      lgeneric_dout(cct, 1) << " keeping " << n << " " << get_addrs(i) << dendl;
./mon/MonMap.cc:	lgeneric_dout(cct, 1) << " adding " << p << " " << a << dendl;
./mon/MonMap.cc:    lgeneric_dout(cct, 1) << "Using mon_host_override " << mon_host_override << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << " " << version << dendl;
./mon/KVMonitor.cc:  dout(10) << " " << version << dendl;
./mon/KVMonitor.cc:  dout(10) << " " << (version+1) << dendl;
./mon/KVMonitor.cc:      dout(20) << __func__ << " set " << key << dendl;
./mon/KVMonitor.cc:      dout(20) << __func__ << " rm " << key << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << dendl;
./mon/KVMonitor.cc:    dout(20) << __func__ << " not authenticated " << s->entity_name << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << dendl;
./mon/KVMonitor.cc:  dout(10) << __func__ << " updated " << updated << " / " << total << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " done" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:	ldout(cct,20) << __func__ << " waiting for monmap|config" << dendl;
./mon/MonClient.cc:	ldout(cct,10) << __func__ << " success" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " specified mon id is empty!" << dendl;
./mon/MonClient.cc:    ldout(cct,10) << __func__ << " got ping reply" << dendl;
./mon/MonClient.cc:	ldout(cct, 10) << "discarding stray monitor message " << *m << dendl;
./mon/MonClient.cc:      ldout(cct, 10) << "discarding stray monitor message " << *m << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " " << *m << dendl;
./mon/MonClient.cc:    ldout(cct,10) << " can't identify which mon we were connected to" << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " " << *m << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:    ldout(cct, 5) << "already authenticated" << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << "authenticate will time out at " << until << dendl;
./mon/MonClient.cc:	ldout(cct, 0) << "authenticate timed out after " << timeout << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " " << auth_err << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " rank " << rank << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " ranks=" << ranks << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " " << auth_err << dendl;
./mon/MonClient.cc:    ldout(cct, 1) << "no mon sessions established" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:    ldout(cct, 1) << "continuing hunt" << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " - empty" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << dendl;
./mon/MonClient.cc:      ldout(cct, 10) << __func__ << " getting new tickets!" << dendl;
./mon/MonClient.cc:    ldout(cct, 20) << "_check_auth_rotating not needed by " << entity_name << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << "_check_auth_rotating waiting for auth session" << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << "_check_auth_rotating have uptodate secrets (they expire after " << cutoff << ")" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << "_check_auth_rotating renewing rotating keys (they expired before " << cutoff << ")" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " waiting for " << timeout << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " done" << dendl;
./mon/MonClient.cc:    ldout(cct, 0) << __func__ << " timed out after " << timeout << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " " << r->tid << " " << r->cmd << dendl;
./mon/MonClient.cc:      ldout(cct,5) << __func__ << " timeout tell command " << cmd->tid << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " has tid 0, assuming it is " << r->tid << dendl;
./mon/MonClient.cc:      ldout(cct, 10) << __func__ << " " << ack->get_tid() << " not found" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " " << r->tid << " " << r->cmd << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " " << r->tid << " " << r->cmd << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " tid " << tid << " dne" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " tid " << tid << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " skipping challenge on " << con << dendl;
./mon/MonClient.cc:    ldout(cct,10) << __func__ << " added challenge on " << con << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " bad authorizer on " << con << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " opening mon connection" << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " payload " << bl.length() << dendl;
./mon/MonClient.cc:  ldout(cct, 10) << __func__ << " payload_len " << bl.length() << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << __func__ << " authenticated!" << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " will try " << auth_method << " next" << dendl;
./mon/MonClient.cc:  ldout(cct,10) << __func__ << " method " << method << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << " no handler for protocol " << method << dendl;
./mon/MonClient.cc:    ldout(cct, 1) << "peer sent an invalid global_id" << dendl;
./mon/MonClient.cc:    ldout(cct, 10) << "my global_id is " << m->global_id << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " updated rotating" << dendl;
./mon/AuthMonitor.cc:  dout(10) << *this << dendl;
./mon/AuthMonitor.cc:      dout(10) << __func__ << "requesting more ids from leader" << dendl;
./mon/AuthMonitor.cc:  dout(10) << "AuthMonitor::on_active()" << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " with keyring" << dendl;
./mon/AuthMonitor.cc:  dout(10) << "create_initial -- creating initial map" << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << dendl;
./mon/AuthMonitor.cc:    dout(7) << __func__ << " loading summary e " << latest_full << dendl;
./mon/AuthMonitor.cc:    dout(7) << __func__ << " latest length " << latest_bl.length() << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " key server version " << mon.key_server.get_ver() << dendl;
./mon/AuthMonitor.cc:  dout(10) << "increasing max_global_id to " << inc.max_global_id << dendl;
./mon/AuthMonitor.cc:  dout(10) << "create_pending v " << (get_last_committed() + 1) << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " v " << (get_last_committed() + 1) << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " auth v " << version << dendl;
./mon/AuthMonitor.cc:  dout(10) << "preprocess_query " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/AuthMonitor.cc:  dout(10) << "prepare_update " << *m << " from " << m->get_orig_source_inst() << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " num " << num << " rank " << rank << dendl;
./mon/AuthMonitor.cc:    dout(10) << __func__ << " last_allocated_id == 0" << dendl;
./mon/AuthMonitor.cc:    dout(10) << __func__ << " failed (max " << max_global_id << ")" << dendl;
./mon/AuthMonitor.cc:  dout(10) << "prep_auth() blob_size=" << m->get_auth_payload().length() << dendl;
./mon/AuthMonitor.cc:    dout(10) << "no session, dropping" << dendl;
./mon/AuthMonitor.cc:      dout(10) << "failed to decode initial auth message" << dendl;
./mon/AuthMonitor.cc:      dout(1) << "client did not provide supported auth type" << dendl;
./mon/AuthMonitor.cc:      dout(10) << "protocol specified but no s->auth_handler" << dendl;
./mon/AuthMonitor.cc:        dout(10) << "increasing global id, waitlisting message" << dendl;
./mon/AuthMonitor.cc:	dout(10) << "not the leader, requesting more ids from leader" << dendl;
./mon/AuthMonitor.cc:    dout(0) << "caught error when trying to handle auth request, probably malformed request" << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " " << keyring.size() << " keys" << dendl;
./mon/AuthMonitor.cc:      dout(0) << "import: no caps supplied" << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " " << entity << dendl;
./mon/AuthMonitor.cc:  dout(10) << " add auth entity " << auth_inc.name << dendl;
./mon/AuthMonitor.cc:  dout(30) << "    " << auth_inc.auth << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " id " << id << " uuid " << uuid << dendl;
./mon/AuthMonitor.cc:    dout(10) << __func__ << " " << cephx_entity << " does not exist" << dendl;
./mon/AuthMonitor.cc:    dout(10) << __func__ << " " << lockbox_entity << " does not exist" << dendl;
./mon/AuthMonitor.cc:    dout(10) << __func__ << " entities do not exist -- no-op." << dendl;
./mon/AuthMonitor.cc:  dout(10) << __func__ << " osd." << id << " uuid " << uuid << dendl;
./mon/AuthMonitor.cc:  dout(10) << "AuthMonitor::prepare_global_id" << dendl;
./mon/AuthMonitor.cc:  dout(1) << __func__ << " upgrading from format 0 to 1" << dendl;
./mon/AuthMonitor.cc:  dout(1) << __func__ << " upgrading from format 1 to 2" << dendl;
./mon/AuthMonitor.cc:      dout(5) << " giving " << n << " mgr '" << newcap << "'" << dendl;
./mon/AuthMonitor.cc:  dout(1) << __func__ << " upgrading from format 2 to 3" << dendl;
./mon/Elector.cc:  dout(5) << "handle_propose from " << m->get_source() << dendl;
./mon/Elector.cc:  dout(5) << "handle_ack from " << m->get_source() << dendl;
./mon/Elector.cc:  dout(5) << __func__ << " against " << peer << dendl;
./mon/Elector.cc:  dout(10) << __func__ << " to peer " << peer << dendl;
./mon/Elector.cc:  dout(20) << __func__ << " to peer " << peer << dendl;
./mon/Elector.cc:    dout(20) << __func__ << peer << " is no longer marked for pinging" << dendl;
./mon/Elector.cc:  dout(20) << __func__ << " to peer " << peer << dendl;
./mon/Elector.cc:    dout(20) << __func__ << peer << " is no longer marked for dead pinging" << dendl;
./mon/Elector.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Elector.cc:	dout(5) << "old epoch, dropping" << dendl;
./mon/MDSMonitor.cc:  dout(10) << "create_initial" << dendl;
./mon/MDSMonitor.cc:  dout(10) << __func__ << " got " << version << dendl;
./mon/MDSMonitor.cc:  dout(0) << "new map" << dendl;
./mon/MDSMonitor.cc:  dout(10) << "create_pending e" << fsmap.epoch << dendl;
./mon/MDSMonitor.cc:  dout(10) << "encode_pending e" << epoch << dendl;
./mon/MDSMonitor.cc:  dout(5) << "_note_beacon " << *m << " noting time" << dendl;
./mon/MDSMonitor.cc:    dout(0) << "preprocess_beacon on fsid " << m->get_fsid() << " != " << mon.monmap->fsid << dendl;
./mon/MDSMonitor.cc:    dout(1) << " ignoring boot message without a port" << dendl;
./mon/MDSMonitor.cc:  dout(10) << __func__ << ": GID exists in map: " << gid << dendl;
./mon/MDSMonitor.cc:    dout(7) << "mds_beacon " << *m << " has old seq, ignoring" << dendl;
./mon/MDSMonitor.cc:      dout(10) << __func__ << " standby mds_join_fs was cleared" << dendl;
./mon/MDSMonitor.cc:    dout(10) << __func__ << " health metrics for gid " << gid << " were updated" << dendl;
./mon/MDSMonitor.cc:  dout(10) << "preprocess_offload_targets " << *m << " from " << m->get_orig_source() << dendl;
./mon/MDSMonitor.cc:  dout(7) << "prepare_update " << *m << dendl;
./mon/MDSMonitor.cc:  dout(15) << __func__ << " got health from gid " << gid << " with " << m->get_health().metrics.size() << " metrics." << dendl;
./mon/MDSMonitor.cc:      dout(1) << "prepare_beacon clearing laggy flag on " << addrs << dendl;
./mon/MDSMonitor.cc:  dout(5) << "prepare_beacon pending map now:" << dendl;
./mon/MDSMonitor.cc:    dout(10) << "prepare_offload_targets " << gid << " " << m->targets << dendl;
./mon/MDSMonitor.cc:    dout(10) << "prepare_offload_targets " << gid << " not in map" << dendl;
./mon/MDSMonitor.cc:  dout(10) << "_updated " << m->get_orig_source() << " " << *m << dendl;
./mon/MDSMonitor.cc:    dout(1) << "all = " << all << dendl;
./mon/MDSMonitor.cc:          dout(1) << get_err.str() << dendl;
./mon/MDSMonitor.cc:  dout(1) << "fail_mds_gid " << gid << " mds." << info.name << " role " << info.rank << dendl;
./mon/MDSMonitor.cc:      dout(4) << __func__ << " enqueue for retry by prepare_command" << dendl;
./mon/MDSMonitor.cc:    dout(4) << __func__ << " enqueue for retry by filesystem_command" << dendl;
./mon/MDSMonitor.cc:  dout(4) << __func__ << " done, r=" << r << dendl;
./mon/MDSMonitor.cc:  dout(4) << __func__ << " prefix='" << prefix << "'" << dendl;
./mon/MDSMonitor.cc:  dout(20) << __func__ << ": " << sub->type << dendl;
./mon/MDSMonitor.cc:        dout(10) << __func__ << ": namespace_id " << namespace_id_str << dendl;
./mon/MDSMonitor.cc:    dout(10) << __func__ << ": is_mds=" << is_mds << ", fscid= " << fscid << dendl;
./mon/MDSMonitor.cc:    dout(5) << "Unable to load 'last_metadata'" << dendl;
./mon/MDSMonitor.cc:  dout(10) << __func__ << " mds meta=" << meta << dendl;
./mon/MDSMonitor.cc:      dout(5) << __func__ << ": GID " << gid << " not existent" << dendl;
./mon/MDSMonitor.cc:  dout(20) << __func__ << " in " << in << " max " << max << dendl;
./mon/MDSMonitor.cc:    dout(5) << __func__ << " mds_map is not currently resizeable" << dendl;
./mon/MDSMonitor.cc:      dout(1) << "stopping " << target << dendl;
./mon/MDSMonitor.cc:      dout(20) << "skipping stop of " << target << dendl;
./mon/MDSMonitor.cc:      dout(20) << "standby available mds." << info->global_id << dendl;
./mon/MDSMonitor.cc:        dout(20) << "examining " << rank << dendl;
./mon/PGMap.cc:        dout(4) << "OSD " << p->first << " is up, but has no stats" << dendl;
./mon/PGMap.cc:      dout(20) << " deleted pool " << p << dendl;
./mon/PGMap.cc:    dout(10) << __func__ << " skipping loop over PGs: counters look OK" << dendl;
./mon/PGMap.cc:	  ldout(cct,20) << __func__ << " adding " << pgid << dendl;
./mon/PGMap.cc:	ldout(cct,20) << __func__ << " removing merged " << pgid << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << " first " << first << " last " << last << dendl;
./mon/Paxos.cc:    dout(30) << __func__ << " apply version " << v << dendl;
./mon/Paxos.cc:  dout(15) << __func__ << " total versions " << (last-first) << dendl;
./mon/Paxos.cc:  dout(10) << "init" << dendl;
./mon/Paxos.cc:  dout(10) << "collect with pn " << accepted_pn << dendl;
./mon/Paxos.cc:  dout(10) << "handle_collect " << *collect << dendl;
./mon/Paxos.cc:    dout(10) << "store_state nothing to commit" << dendl;
./mon/Paxos.cc:  dout(10) << "handle_last " << *last << dendl;
./mon/Paxos.cc:    dout(10) << "not leader, dropping" << dendl;
./mon/Paxos.cc:      dout(10) << " sending commit to mon." << p->first << dendl;
./mon/Paxos.cc:    dout(10) << " they had a higher pn than us, picking a new one." << dendl;
./mon/Paxos.cc:	dout(10) << "that's everyone.  begin on old learned value" << dendl;
./mon/Paxos.cc:	dout(10) << "that's everyone.  active!" << dendl;
./mon/Paxos.cc:    dout(10) << "old pn, ignoring" << dendl;
./mon/Paxos.cc:  dout(1) << "collect timeout, calling fresh election" << dendl;
./mon/Paxos.cc:    dout(10) << " sending begin to mon." << *p << dendl;
./mon/Paxos.cc:  dout(10) << "handle_begin " << *begin << dendl;
./mon/Paxos.cc:    dout(10) << " we accepted a higher pn " << accepted_pn << ", ignoring" << dendl;
./mon/Paxos.cc:  dout(10) << "accepting value for " << v << " pn " << accepted_pn << dendl;
./mon/Paxos.cc:  dout(10) << "handle_accept " << *accept << dendl;
./mon/Paxos.cc:    dout(10) << " we accepted a higher pn " << accepted_pn << ", ignoring" << dendl;
./mon/Paxos.cc:    dout(10) << " this is from an old round, ignoring" << dendl;
./mon/Paxos.cc:  dout(10) << " now " << accepted << " have accepted" << dendl;
./mon/Paxos.cc:    dout(10) << " got majority, committing, done with update" << dendl;
./mon/Paxos.cc:  dout(1) << "accept timeout, calling fresh election" << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << " " << (last_committed+1) << dendl;
./mon/Paxos.cc:  dout(20) << __func__ << " " << (last_committed+1) << dendl;
./mon/Paxos.cc:    dout(10) << " sending commit to mon." << *p << dendl;
./mon/Paxos.cc:  dout(10) << "handle_commit on " << commit->last_committed << dendl;
./mon/Paxos.cc:    dout(10) << "not a peon, dropping" << dendl;
./mon/Paxos.cc:    dout(10) << " doing requested bootstrap" << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << dendl;
./mon/Paxos.cc:  dout(20) << __func__ << " waiting_for_acting" << dendl;
./mon/Paxos.cc:  dout(20) << __func__ << " waiting_for_readable" << dendl;
./mon/Paxos.cc:  dout(20) << __func__ << " waiting_for_writeable" << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << " done w/ waiters, state " << get_statename(state) << dendl;
./mon/Paxos.cc:  dout(1) << "lease_ack_timeout -- calling new election" << dendl;
./mon/Paxos.cc:  dout(20) << "reset_lease_timeout - setting timeout event" << dendl;
./mon/Paxos.cc:  dout(1) << "lease_timeout -- calling new election" << dendl;
./mon/Paxos.cc:  dout(10) << "trim to " << end << " (was " << first_committed << ")" << dendl;
./mon/Paxos.cc:    dout(10) << "trim " << v << dendl;
./mon/Paxos.cc:    dout(10) << " compacting trimmed range" << dendl;
./mon/Paxos.cc:  dout(10) << "get_new_proposal_number = " << last_pn << dendl;
./mon/Paxos.cc:  dout(10) << __func__ << " cancel all contexts" << dendl;
./mon/Paxos.cc:  dout(10) << "leader_init -- starting paxos recovery" << dendl;
./mon/Paxos.cc:  dout(10) << "peon_init -- i am a peon" << dendl;
./mon/Paxos.cc:  dout(10) << "restart -- canceling timeouts" << dendl;
./mon/Paxos.cc:    dout(10) << __func__ << " flushing" << dendl;
./mon/Paxos.cc:    dout(10) << __func__ << " flushed" << dendl;
./mon/Paxos.cc:    dout(5) << "election in progress, dropping " << *req << dendl;
./mon/Paxos.cc:  dout(5) << __func__ << " " << onfinished << dendl;
./mon/Paxos.cc:    dout(10) << __func__ << " plugged, not proposing now" << dendl;
./mon/Paxos.cc:    dout(10) << __func__ << " active, proposing now" << dendl;
./mon/Paxos.cc:    dout(10) << __func__ << " not active, will propose later" << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << " " << version << dendl;
./mon/ConfigMonitor.cc:  dout(10) << " " << version << dendl;
./mon/ConfigMonitor.cc:  dout(10) << " " << (version+1) << dendl;
./mon/ConfigMonitor.cc:      dout(20) << __func__ << " set " << key << dendl;
./mon/ConfigMonitor.cc:      dout(20) << __func__ << " rm " << key << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << " " << m->name << " host " << m->host << dendl;
./mon/ConfigMonitor.cc:  dout(20) << " config is " << out << dendl;
./mon/ConfigMonitor.cc:    dout(10) << __func__ << " waiting for kv mon to be writeable" << dendl;
./mon/ConfigMonitor.cc:      dout(20) << __func__ << " [" << section << "]" << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << dendl;
./mon/ConfigMonitor.cc:      dout(10) << __func__ << " unrecognized option '" << name << "'" << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << " got " << num << " keys" << dendl;
./mon/ConfigMonitor.cc:      dout(10) << __func__ << " device_class " << device_class << dendl;
./mon/ConfigMonitor.cc:    dout(20) << __func__ << " no change, " << out << dendl;
./mon/ConfigMonitor.cc: //  dout(20) << __func__ << " " << out << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << " to " << s->name << dendl;
./mon/ConfigMonitor.cc:    dout(20) << __func__ << " not authenticated " << s->entity_name << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << dendl;
./mon/ConfigMonitor.cc:  dout(10) << __func__ << " updated " << updated << " / " << total << dendl;
./mon/Monitor.cc:      dout(20) << " pre-nautilus cmd " << i.cmdstring << " -> " << n << dendl;
./mon/Monitor.cc:    dout(1) << "triggering manual compaction" << dendl;
./mon/Monitor.cc:  dout(10) << "features " << features << dendl;
./mon/Monitor.cc:  dout(10) << "required_features " << required_features << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << changed << dendl;
./mon/Monitor.cc:  dout(1) << "preinit fsid " << monmap->fsid << dendl;
./mon/Monitor.cc:  dout(10) << "has_ever_joined = " << (int)has_ever_joined << dendl;
./mon/Monitor.cc:      dout(1) << " initial_members " << initial_members << ", filtering seed monmap" << dendl;
./mon/Monitor.cc:      dout(10) << " monmap is " << *monmap << dendl;
./mon/Monitor.cc:      dout(10) << " extra probe peers " << extra_probe_peers << dendl;
./mon/Monitor.cc:      dout(1) << __func__ << " force sync by clearing store state" << dendl;
./mon/Monitor.cc:  dout(10) << "sync_last_committed_floor " << sync_last_committed_floor << dendl;
./mon/Monitor.cc:      dout(10) << "loading initial keyring to bootstrap authentication for mkfs" << dendl;
./mon/Monitor.cc:	dout(1) << "copying mon. key from old db to external keyring" << dendl;
./mon/Monitor.cc:  dout(2) << "init" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:      dout(10) << __func__ << " failed to decode cluster_fingerprint" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " no cluster_fingerprint" << dendl;
./mon/Monitor.cc:    dout(10) << "register_cluster_logger" << dendl;
./mon/Monitor.cc:    dout(10) << "register_cluster_logger - already registered" << dendl;
./mon/Monitor.cc:    dout(10) << "unregister_cluster_logger" << dendl;
./mon/Monitor.cc:    dout(10) << "unregister_cluster_logger - not registered" << dendl;
./mon/Monitor.cc:  dout(1) << "shutdown" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " flushing pending write" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " flushed pending write" << dendl;
./mon/Monitor.cc:  dout(0) << __func__ << dendl;
./mon/Monitor.cc:  dout(1) << " e: '" << orig_argv[0] << "'" << dendl;
./mon/Monitor.cc:    dout(1) << " " << i << ": '" << orig_argv[i] << "'" << dendl;
./mon/Monitor.cc:    dout(1) << "respawning with exe " << exe_path << dendl;
./mon/Monitor.cc:    dout(1) << " cwd " << cwd << dendl;
./mon/Monitor.cc:  dout(1) << " exe_path " << exe_path << dendl;
./mon/Monitor.cc:  dout(10) << "bootstrap" << dendl;
./mon/Monitor.cc:    dout(10) << "reverting to legacy ranks for seed monmap (epoch 0)" << dendl;
./mon/Monitor.cc:  dout(10) << "monmap " << *monmap << dendl;
./mon/Monitor.cc:      dout(0) << " removed from monmap, suicide." << dendl;
./mon/Monitor.cc:    dout(0) << " my rank is now " << newrank << " (was " << rank << ")" << dendl;
./mon/Monitor.cc:    dout(10) << "bootstrap -- triggering compaction" << dendl;
./mon/Monitor.cc:    dout(10) << "bootstrap -- finished compaction" << dendl;
./mon/Monitor.cc:  dout(10) << "probing other monitors" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(1) << __func__ << dendl;
./mon/Monitor.cc:  dout(1) << __func__ << " obtained monmap e" << latest_monmap.epoch << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << addrs << (full ? " full" : " recent") << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " clearing prefixes " << targets << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " lc " << last_committed << " from " << sync_provider << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:    dout(0) << __func__ << " unknown op " << m->op << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " cookie " << cookie << " for " << m->get_source_inst() << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " will sync prefixes " << sync_targets << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " will sync from version " << sp.last_committed << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " no cookie " << m->cookie << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " already have a cookie, ignoring" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " source does not match, discarding" << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << " cookie " << sync_cookie << " provider " << sync_provider << dendl;
./mon/Monitor.cc:    dout(20) << __func__ << " injecting delay of " << g_conf()->mon_inject_sync_get_chunk_delay << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " cookie does not match, discarding" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " source does not match, discarding" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " applying recent paxos transactions as we go" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:    dout(10) << "cancel_probe_timeout " << probe_timeout_event << dendl;
./mon/Monitor.cc:    dout(10) << "cancel_probe_timeout (none scheduled)" << dendl;
./mon/Monitor.cc:  dout(4) << "probe_timeout " << probe_timeout_event << dendl;
./mon/Monitor.cc:  dout(10) << "handle_probe " << *m << dendl;
./mon/Monitor.cc:    dout(0) << "handle_probe ignoring fsid " << m->fsid << " != " << monmap->fsid << dendl;
./mon/Monitor.cc:  dout(10) << " monmap is " << *monmap << dendl;
./mon/Monitor.cc:    dout(10) << " peer name is " << peer_name << dendl;
./mon/Monitor.cc:    dout(10) << " peer " << m->get_source_addr() << " not in map" << dendl;
./mon/Monitor.cc:    dout(10) << " currently syncing" << dendl;
./mon/Monitor.cc:    dout(10) << " existing quorum " << m->quorum << dendl;
./mon/Monitor.cc:      dout(10) << " ready to join, but i'm not in the monmap or my addr is blank, trying to join" << dendl;
./mon/Monitor.cc:      dout(10) << " mon." << m->name << " is outside the quorum" << dendl;
./mon/Monitor.cc:      dout(10) << " mostly ignoring mon." << m->name << ", not part of monmap" << dendl;
./mon/Monitor.cc:    dout(10) << " outside_quorum now " << outside_quorum << ", need " << need << dendl;
./mon/Monitor.cc:        dout(10) << " that's enough to form a new quorum, calling election" << dendl;
./mon/Monitor.cc:        dout(10) << " that's enough to form a new quorum, but it does not include me; waiting" << dendl;
./mon/Monitor.cc:      dout(10) << " that's not yet enough for a new quorum, waiting" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << "start_election" << dendl;
./mon/Monitor.cc:  dout(1) << "win_standalone_election" << dendl;
./mon/Monitor.cc:      dout(20) << "healthmon now active" << dendl;
./mon/Monitor.cc:        dout(20) << __func__ << " healthmon proposing, waiting" << dendl;
./mon/Monitor.cc:    dout(1) << __func__ << " " << i.first << ": " << i.second << dendl;
./mon/Monitor.cc:    dout(10) << " renaming myself from " << cur_name << " -> " << name << dendl;
./mon/Monitor.cc:    dout(1) << __func__ << " enabling new quorum features: " << diff << dendl;
./mon/Monitor.cc:  dout(5) << __func__ << dendl;
./mon/Monitor.cc:  dout(5) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " required_features " << required_features << dendl;
./mon/Monitor.cc:  dout(15) << __func__ << dendl;
./mon/Monitor.cc:  dout(15) << __func__ << dendl;
./mon/Monitor.cc:  dout(15) << __func__ << dendl;
./mon/Monitor.cc:  dout(15) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << (force ? " (force)" : "") << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << (capable ? "" : "not ") << "capable" << dendl;
./mon/Monitor.cc:    dout(0) << "handle_command on fsid " << m->fsid << " != " << monmap->fsid << dendl;
./mon/Monitor.cc:    dout(5) << __func__ << " dropping stray message " << *m << dendl;
./mon/Monitor.cc:    dout(5) << __func__ << " dropping stray message " << *m << dendl;
./mon/Monitor.cc:  dout(0) << "handle_command " << *m << dendl;
./mon/Monitor.cc:    dout(10) << "Got forward for noforward command " << m << dendl;
./mon/Monitor.cc:    dout(1) << __func__ << " access denied" << dendl;
./mon/Monitor.cc:    dout(5) << __func__ << " passing command to tell/asok" << dendl;
./mon/Monitor.cc:      dout(10) << " waiting for quorum" << dendl;
./mon/Monitor.cc:          dout(1) << get_err.str() << dendl;
./mon/Monitor.cc:      dout(10) << " waiting for quorum" << dendl;
./mon/Monitor.cc:    dout(10) << "forward_request won't forward (non-local) mon request " << *req << dendl;
./mon/Monitor.cc:    dout(10) << "forward_request won't double fwd request " << *req << dendl;
./mon/Monitor.cc:    dout(10) << "forward_request no session for request " << *req << dendl;
./mon/Monitor.cc:    dout(10) << " caps are " << s->caps << dendl;
./mon/Monitor.cc:    dout(10) << " mesg " << req << " from " << m->get_source_addr() << dendl;
./mon/Monitor.cc:  dout(2) << __func__ << " " << op << " " << reply << " " << *reply << dendl;
./mon/Monitor.cc:    dout(10) << "handle_route tid " << m->session_mon_tid << " null" << dendl;
./mon/Monitor.cc:    dout(10) << " not a routed request, ignoring" << dendl;
./mon/Monitor.cc:    dout(10) << " don't have routed request tid " << m->session_mon_tid << dendl;
./mon/Monitor.cc:    dout(10) << " sending osdmaps from " << m->send_osdmap_first << dendl;
./mon/Monitor.cc:  dout(10) << "resend_routed_requests" << dendl;
./mon/Monitor.cc:      dout(10) << " requeue for self tid " << rr->tid << dendl;
./mon/Monitor.cc:    dout(10) << " dropping routed request " << rr->tid << dendl;
./mon/Monitor.cc:    dout(5) << "waitlisting message " << *m << dendl;
./mon/Monitor.cc:    dout(5) << "discarding message " << *m << " and sending client elsewhere" << dendl;
./mon/Monitor.cc:      dout(5) << __func__ << " setting monitor caps on this connection" << dendl;
./mon/Monitor.cc:    dout(10) << " session closed, dropping " << op->get_req() << dendl;
./mon/Monitor.cc:      dout(5) << __func__ << " ignoring " << op << dendl;
./mon/Monitor.cc:  dout(1) << "dropping unexpected " << *(op->get_req()) << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " reply payload len " << reply->get_payload().length() << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " curr " << timecheck_round << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " there's a timecheck going on" << dendl;
./mon/Monitor.cc:      dout(10) << __func__ << " keep current round going" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " new " << timecheck_round << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " setting up next event" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " curr " << timecheck_round << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " finished to " << timecheck_round << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " send report to mon." << *q << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " send " << *m << " to mon." << *it << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:      dout(1) << __func__ << " drop unexpected msg (not pong)" << dendl;
./mon/Monitor.cc:      dout(1) << __func__ << " drop unexpected msg (not ping or report)" << dendl;
./mon/Monitor.cc:    dout(1) << __func__ << " drop unexpected msg" << dendl;
./mon/Monitor.cc:  dout(10) << "handle_subscribe " << *m << dendl;
./mon/Monitor.cc:      dout(10) << __func__ << ": MDS sub '" << p->first << "'" << dendl;
./mon/Monitor.cc:  dout(10) << "handle_get_version " << *m << dendl;
./mon/Monitor.cc:    dout(10) << " waiting for quorum" << dendl;
./mon/Monitor.cc:  dout(10) << "ms_handle_reset " << con << " " << con->get_peer_addr() << dendl;
./mon/Monitor.cc:  dout(10) << "reset/close on session " << s->name << " " << s->addrs << dendl;
./mon/Monitor.cc:  dout(10) << "ms_handle_refused " << con << " " << con->get_peer_addr() << dendl;
./mon/Monitor.cc:  dout(10) << "handle_mon_get_map" << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << " all versions=" << versions << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " " << *m << dendl;
./mon/Monitor.cc:      dout(10) << __func__ << " inject failure at (" << k << ")" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(1) << __func__ << " restarting scrub" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(1) << __func__ << " new interval = " << interval << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << dendl;
./mon/Monitor.cc:  dout(15) << __func__ << " reset timeout event" << dendl;
./mon/Monitor.cc:  dout(11) << "tick" << dendl;
./mon/Monitor.cc:  dout(10) << __func__ << " proposing cluster_fingerprint " << nf << dendl;
./mon/Monitor.cc:  dout(10) << "check_fsid cluster_uuid contains '" << es << "'" << dendl;
./mon/Monitor.cc:    dout(10) << "extract_save_mon_key moving mon. key to separate keyring" << dendl;
./mon/Monitor.cc:    dout(0) << __func__ << " failed verifying authorizer reply" << dendl;
./mon/Monitor.cc:    dout(20) << __func__ << " building auth_none authorizer" << dendl;
./mon/Monitor.cc:      dout(0) << ss.str() << "\n" << ds.str() << dendl;
./mon/Monitor.cc:    dout(0) << "get_authorizer failed to build service ticket" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " bad authorizer on " << con << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " haven't formed initial quorum, EBUSY" << dendl;
./mon/Monitor.cc:	dout(1) << __func__ << " invalid mode " << (int)mode << dendl;
./mon/Monitor.cc:      dout(1) << __func__ << " failed to decode, " << e.what() << dendl;
./mon/Monitor.cc:	dout(1) << __func__ << " failed to assign global_id" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << " con " << con << " no session" << dendl;
./mon/Monitor.cc:  dout(30) << __func__ << "we have " << monmap->removed_ranks.size() << " removed ranks" << dendl;
./mon/Monitor.cc:    dout(10) << __func__ << "removing rank " << rank << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:    dout(10) << "Engaging stretch mode!" << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << "checking for degraded stretch mode" << dendl;
./mon/Monitor.cc:  dout(20) << "new dead_mon_buckets " << dead_mon_buckets << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./mon/Monitor.cc:    dout(20) << __func__ << "checking OSD session" << s << dendl;
./mon/Monitor.cc:  dout(20) << __func__ << dendl;
./os/FuseStore.cc:  ldout(cct, 10) << __func__ << " path " << path << " -> " << v << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:    ldout(fs->store->cct, 10) << __func__ << " closing last " << o->path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << " size " << size << dendl;
./os/FuseStore.cc:  ldout(fs->store->cct, 10) << __func__ << " " << path << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << " done" << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << " enter" << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << " exit" << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << " enter" << dendl;
./os/FuseStore.cc:  dout(10) << __func__ << " exit" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get index r = " << r << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": path_old: " << path_old << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": path_new: " << path_new << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": path_old: " << path_old << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": path_new: " << path_new << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": get_index failed " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:	dout(25) << __FUNC__ << ": omap clear failed " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:    dout(25) << __FUNC__ << ": index unlink failed " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:    dout(10) << "open_journal at " << journalpath << dendl;
./os/filestore/FileStore.cc:  dout(1) << "mkfs in " << basedir << dendl;
./os/filestore/FileStore.cc:      dout(1) << __FUNC__ << ": generated fsid " << fsid << dendl;
./os/filestore/FileStore.cc:      dout(1) << __FUNC__ << ": using provided fsid " << fsid << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": fsid is " << fsid << dendl;
./os/filestore/FileStore.cc:    dout(1) << __FUNC__ << ": fsid is already set to " << fsid << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": write success, fsid:" << fsid_str << ", ret:" << ret << dendl;
./os/filestore/FileStore.cc:    dout(10) << "mkfs omap fsid is " << fsid << dendl;
./os/filestore/FileStore.cc:    dout(1) << __FUNC__ << ": omap fsid is already set to " << fsid << dendl;
./os/filestore/FileStore.cc:  dout(1) << cct->_conf->filestore_omap_backend << " db exists/created" << dendl;
./os/filestore/FileStore.cc:  dout(1) << "mkfs done in " << basedir << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": created journal on " << journalpath << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": basedir " << basedir << " journal " << journalpath << dendl;
./os/filestore/FileStore.cc:  dout(10) << __func__ << " " << (int)rotational << dendl;
./os/filestore/FileStore.cc:  dout(10) << __func__ << " " << (int)journal_rotational << dendl;
./os/filestore/FileStore.cc:    dout(0) << "limited size xattrs" << dendl;
./os/filestore/FileStore.cc:    dout(0) << "mount ERROR: more than one of filestore journal {writeahead,parallel,trailing} enabled" << dendl;
./os/filestore/FileStore.cc:      dout(0) << "mount WARNING: no btrfs, and no journal in writeahead mode; data may be lost" << dendl;
./os/filestore/FileStore.cc:    dout(0) << "mount WARNING: no journal" << dendl;
./os/filestore/FileStore.cc:  dout(1) << __FUNC__ << ": " << target_version << dendl;
./os/filestore/FileStore.cc:  dout(1) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(5) << "basedir " << basedir << " journal " << journalpath << dendl;
./os/filestore/FileStore.cc:  dout(10) << "mount fsid is " << fsid << dendl;
./os/filestore/FileStore.cc:      dout(0) << __FUNC__ << ": WARNING: no consistent snaps found, store may be in inconsistent state" << dendl;
./os/filestore/FileStore.cc:	  dout(10) << " current/ seq was " << curr_seq << dendl;
./os/filestore/FileStore.cc:	  dout(10) << " current/ missing entirely (unusual, but okay)" << dendl;
./os/filestore/FileStore.cc:	dout(10) << " most recent snap from " << snaps << " is " << cp << dendl;
./os/filestore/FileStore.cc:        dout(10) << __FUNC__ << ": rolling back to consistent snap " << cp << dendl;
./os/filestore/FileStore.cc:  dout(5) << "mount op_seq is " << initial_op_seq << dendl;
./os/filestore/FileStore.cc:  dout(0) << "start omap initiation" << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": enabling WRITEAHEAD journal mode: checkpoint is not enabled" << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": enabling PARALLEL journal mode: fs, checkpoint is enabled" << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": WRITEAHEAD journal mode explicitly enabled in conf" << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": PARALLEL journal mode explicitly enabled in conf" << dendl;
./os/filestore/FileStore.cc:	dout(0) << __FUNC__ << ": TRAILING journal mode explicitly enabled in conf" << dendl;
./os/filestore/FileStore.cc:    dout(0) << __FUNC__ << ": no journal" << dendl;
./os/filestore/FileStore.cc:    dout(0) << __FUNC__ << ": INFO: WbThrottle is disabled" << dendl;
./os/filestore/FileStore.cc:      dout(0) << __FUNC__ << ": INFO: O_DSYNC write is enabled" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(20) << " ls " << ls << dendl;
./os/filestore/FileStore.cc:  dout(20) << " temps " << temps << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": creating " << temp << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": removing stray " << *p << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": " << basedir << dendl;
./os/filestore/FileStore.cc:    dout(5) << __FUNC__ << ": filestore_inject_stall " << orig << ", sleeping" << dendl;
./os/filestore/FileStore.cc:    dout(5) << __FUNC__ << ": done stalling" << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": " << o << " seq " << o->op << " " << *osr << " start" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << o << " seq " << o->op << " " << *osr << " lat " << lat << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": osr " << osr << " " << *osr << dendl;
./os/filestore/FileStore.cc:      dout(5) << __FUNC__ << ": (parallel) " << o->op << " " << o->tls << dendl;
./os/filestore/FileStore.cc:      dout(5) << __FUNC__ << ": (writeahead) " << o->op << " " << o->tls << dendl;
./os/filestore/FileStore.cc:    dout(5) << __FUNC__ << ": (no journal) " << o << " " << tls << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": (trailing journal) " << op << " " << tls << dendl;
./os/filestore/FileStore.cc:  dout(5) << __FUNC__ << ": " << o << " seq " << o->op << " " << *osr << " " << o->tls << dendl;
./os/filestore/FileStore.cc:    dout(10) << " queueing ondisk " << ondisk << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << spos << " done" << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": " << cid << " dne" << dendl;
./os/filestore/FileStore.cc:    dout(20) << __FUNC__ << ": no xattr" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << spos << (in_progress ? " START" : "") << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << spos << " done" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << spos << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << spos << " done" << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": " << cid << " " << oid << " dne" << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": " << cid << " dne" << dendl;
./os/filestore/FileStore.cc:    dout(20) << __FUNC__ << ": no xattr" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": on " << &t << dendl;
./os/filestore/FileStore.cc:          dout(0) << " ENOSPC on setxattrs on " << cid << "/" << oid << dendl;
./os/filestore/FileStore.cc:          dout(10) << "Unrecognized collection hint type: " << type << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "tolerating EEXIST during journal replay since checkpoint is not enabled" << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "tolerating EEXIST during journal replay since checkpoint is not enabled" << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "tolerating EEXIST during journal replay since checkpoint is not enabled" << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "tolerating ERANGE on replay" << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "tolerating ENOENT on replay" << dendl;
./os/filestore/FileStore.cc:	dout(0) << msg << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": (" << cid << "/" << oid << ") pread error: " << cpp_strerror(got) << dendl;
./os/filestore/FileStore.cc:    dout(0) << __func__ << ": inject random EIO" << dendl;
./os/filestore/FileStore.cc:        dout(10) << "failed to lseek: " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:        dout(10) << "failed to lseek: " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:    dout(10) << "read couldn't open " << cid << "/" << oid << ": " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:    dout(15) << "seek_data/seek_hole " << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:    dout(15) << "fiemap ioctl" << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << " = " << r << " num_extents=" << destmap.size() << " " << destmap << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " size " << size << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " size " << size << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": falling back to writing zeros" << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~" << len << " = " << ret << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oldoid << " -> " << cid << "/" << newoid << dendl;
./os/filestore/FileStore.cc:    dout(20) << "objectmap clone" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oldoid << " -> " << cid << "/" << newoid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": copy " << srcoff << "~" << len << " to " << dstoff << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << srcoff << "~" << len << " to " << dstoff << dendl;
./os/filestore/FileStore.cc:    dout(15) << "seek_data/seek_hole " << from << " " << srcoff << "~" << len << dendl;
./os/filestore/FileStore.cc:    dout(15) << "fiemap ioctl" << from << " " << srcoff << "~" << len << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << srcoff << "~" << len << " to " << dstoff << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << srcoff << "~" << len << " to " << dstoff << dendl;
./os/filestore/FileStore.cc:      dout(10) << "  safe_splice read from " << pos << "~" << l << " got " << r << dendl;
./os/filestore/FileStore.cc:      dout(25) << "  read from " << pos << "~" << l << " got " << r << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << srcoff << "~" << len << " to " << dstoff << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << oldcid << "/" << oldoid << " -> " << newcid << "/" << newoid << " " << srcoff << "~" << len << " to " << dstoff << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ":  waiting for max_interval " << max_interval << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ": not waiting, force_sync set" << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ": force_sync set" << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ": stop set" << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ": woke after " << woke << dendl;
./os/filestore/FileStore.cc:      dout(15) << __FUNC__ << ": committing " << cp << dendl;
./os/filestore/FileStore.cc:	  dout(20) << " waiting for checkpoint " << cid << " to complete" << dendl;
./os/filestore/FileStore.cc:	  dout(20) << " done waiting for checkpoint " << cid << " to complete" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": commit took " << lat << ", interval was " << dur << dendl;
./os/filestore/FileStore.cc:	  dout(10) << "removing snap '" << s << "'" << dendl;
./os/filestore/FileStore.cc:      dout(15) << __FUNC__ << ": committed to op_seq " << cp << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": more waiters, committing again" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": journal says we should commit again (probably is/was full)" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:      dout(10) << "sync waiting" << dendl;
./os/filestore/FileStore.cc:  dout(10) << "sync done" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": draining op tp" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": waiting for apply finisher" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": draining ondisk finisher" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": complete" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": done" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << name << dendl;
./os/filestore/FileStore.cc:    dout(0) << __FUNC__ << ": " << name << " failed, not supported" << dendl;
./os/filestore/FileStore.cc:    dout(10) << " -ERANGE, len is " << len << dendl;
./os/filestore/FileStore.cc:    dout(10) << " -ERANGE, got " << len << dendl;
./os/filestore/FileStore.cc:        dout(20) << __FUNC__ << ": " << fd << " getting '" << name << "'" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": init error on " << oid << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": init error on " << oid << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": clear error on " << oid << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": inject error on " << oid << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": inject error on " << oid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " '" << name << "'" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get index r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": get_xattrs err r =" << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": got.size() is 0" << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " '" << name << "' = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": no xattr exists in object_map r = " << r << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": could not get index r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get omap_attrs r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get omap_attrs r = " << r << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not remove_xattrs r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not set_xattrs r = " << r << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " '" << name << "'" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get index r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not remove_xattrs index r = " << r << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " '" << name << "' = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << dendl;
./os/filestore/FileStore.cc:        dout(10) << __FUNC__ << ": could not remove xattr r = " << r << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": no xattr exists in object_map r = " << r << dendl;
./os/filestore/FileStore.cc:    dout(10) << __FUNC__ << ": could not get index r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not get omap_attrs r = " << r << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": could not remove omap_attrs r = " << r << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << fn << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " " << bits << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " " << bits << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << fn << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " = " << bits << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": first checking temp pool" << dendl;
./os/filestore/FileStore.cc:      dout(10) << __FUNC__ << ": start " << start << " >= sep " << sep << dendl;
./os/filestore/FileStore.cc:  dout(20) << "objects: " << *ls << dendl;
./os/filestore/FileStore.cc:    dout(20) << "  next " << *next << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(10) << "pre_hash_collection " << c << " = " << ret << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << fn << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << fn << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << fn << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << o << " from " << oldcid << "/" << o << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << c << "/" << o << " from " << oldcid << "/" << o << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << c << "/" << o << " from " << oldcid << "/" << oldoid << dendl;
./os/filestore/FileStore.cc:    dout(5) << __FUNC__ << ": " << (final+1) << " -> " << final << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << hoid << dendl;
./os/filestore/FileStore.cc:    dout(20) << __FUNC__ << ": get_index got " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ": lfn_find got " << cpp_strerror(r) << dendl;
./os/filestore/FileStore.cc:      dout(20) << __FUNC__ << ":  set " << p.first << dendl;
./os/filestore/FileStore.cc:  dout(20) << __FUNC__ << ": " << cid << "/" << hoid << " = " << r << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << hoid << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << hoid << " [" << first << "," << last << "]" << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << hoid << dendl;
./os/filestore/FileStore.cc:    dout(2) << __FUNC__ << ": " << cid << " DNE" << dendl;
./os/filestore/FileStore.cc:    dout(2) << __FUNC__ << ": " << dest << " DNE" << dendl;
./os/filestore/FileStore.cc:    dout(15) << __FUNC__ << ": " << cid << " bits: " << bits << dendl;
./os/filestore/FileStore.cc:      dout(2) << __FUNC__ << ": " << cid << " DNE" << dendl;
./os/filestore/FileStore.cc:      dout(2) << __FUNC__ << ": " << dest << " DNE" << dendl;
./os/filestore/FileStore.cc:  dout(15) << __FUNC__ << ": " << cid << "/" << oid << " object_size " << expected_object_size << " write_size " << expected_write_size << dendl;
./os/filestore/FileStore.cc:    dout(20) << __FUNC__ << ": hint " << hint << " ret " << ret << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << cid << "/" << oid << " object_size " << expected_object_size << " write_size " << expected_write_size << " = " << ret << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << ": " << file << dendl;
./os/filestore/FileStore.cc:  dout(10) << __FUNC__ << dendl;
./os/filestore/FileStore.cc:    dout(20) << __func__ << " " << o << " already registered" << dendl;
./os/filestore/FileStore.cc:  dout(20) << __func__ << " " << oid << " done" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:	dout(0) << "detect_feature: CLONE_RANGE ioctl is supported" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:	dout(0) << "detect_feature: CLONE_RANGE ioctl is NOT supported: " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: CLONE_RANGE ioctl is DISABLED via 'filestore btrfs clone range' option" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: failed to create simple subvolume " << vol_args.name << ": " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: failed to open " << vol_args.name << ": " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: SNAP_CREATE is supported" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: SNAP_DESTROY is supported" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: SNAP_DESTROY failed: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:	dout(0) << "detect_feature: failed with EPERM as non-root; remount with -o user_subvol_rm_allowed" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: SNAP_CREATE failed: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: snaps enabled, but no SNAP_DESTROY ioctl; DISABLING" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: START_SYNC got " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: START_SYNC is supported (transid " << transid << ")" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: WAIT_SYNC is supported" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: WAIT_SYNC is NOT supported: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: START_SYNC is NOT supported: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: removing old async_snap_test" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:	dout(0) << "detect_feature: failed to remove old async_snap_test: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: SNAP_CREATE_V2 is supported" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:	dout(0) << "detect_feature: SNAP_DESTROY failed: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "detect_feature: SNAP_CREATE_V2 is NOT supported: " << cpp_strerror(err) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "detect_feature: failed to remove " << vol_args.name << ": " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "mount WARNING: btrfs snaps enabled, but no SNAP_CREATE_V2 ioctl (from kernel 2.6.37+)" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "create_current: current/ exists but is not a directory" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "create_current: cannot fstat basedir " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "create_current: cannot statsf basedir " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(2) << "create_current: current appears to be a btrfs subvolume" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(2) << "create_current: created btrfs subvol " << get_current_path() << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "list_checkpoints: cannot fstat basedir " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "list_checkpoints: closedir failed: " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(10) << "create_checkpoint: '" << name << "'" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "create_checkpoint: async snap create '" << name << "' got " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(20) << "create_checkpoint: async snap create '" << name << "' transid " << async_args.transid << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:      dout(0) << "create_checkpoint: snap create '" << name << "' got " << cpp_strerror(r) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(10) << "sync_checkpoint: transid " << transid << " to complete" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "sync_checkpoint: ioctl WAIT_SYNC got " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(20) << "sync_checkpoint: done waiting for transid " << transid << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(10) << "rollback_to: to '" << name << "'" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "rollback_to: error removing old current subvol: " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "rollback_to: error opening '" << s << "': " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "rollback_to: ioctl SNAP_CREATE got " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(10) << "destroy_checkpoint: '" << name << "'" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "destroy_checkpoint: ioctl SNAP_DESTROY got " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(15) << "syncfs" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(0) << "syncfs: btrfs IOC_SYNC got " << cpp_strerror(ret) << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:  dout(20) << "clone_range: " << srcoff << "~" << len << " to " << dstoff << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(20) << "clone_range: using copy" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(20) << "clone_range: using copy, extent too short to align srcoff" << dendl;
./os/filestore/BtrfsFileStoreBackend.cc:    dout(20) << "clone_range: failed CLONE_RANGE call with -EINVAL, using copy" << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "journal_start" << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "journal_stop" << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "journal_replay fs op_seq " << fs_op_seq << dendl;
./os/filestore/JournalingObjectStore.cc:      dout(3) << "journal_replay: end of journal, done." << dendl;
./os/filestore/JournalingObjectStore.cc:      dout(3) << "journal_replay: skipping old op seq " << seq << " <= " << op_seq << dendl;
./os/filestore/JournalingObjectStore.cc:    dout(3) << "journal_replay: applying op seq " << seq << dendl;
./os/filestore/JournalingObjectStore.cc:    dout(3) << "journal_replay: r = " << r << ", op_seq now " << op_seq << dendl;
./os/filestore/JournalingObjectStore.cc:    dout(3) << "journal_replay: total = " << count << dendl;
./os/filestore/JournalingObjectStore.cc:      dout(10) << "op_apply_start blocked, waiting" << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "op_submit_start " << op << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "op_submit_finish " << op << dendl;
./os/filestore/JournalingObjectStore.cc:    dout(10) << "commit_start blocked, all open_ops have completed" << dendl;
./os/filestore/JournalingObjectStore.cc:	dout(10) << "commit_start nothing to do" << dendl;
./os/filestore/JournalingObjectStore.cc:  dout(10) << "commit_finish thru " << committing_seq << dendl;
./os/filestore/JournalingObjectStore.cc:    dout(10) << "op_journal_transactions " << op  << dendl;
./os/filestore/FileJournal.cc:    dout(0) << __func__ << ": failed to read block device size." << dendl;
./os/filestore/FileJournal.cc:    dout(10) << fn << " support discard: " << (int)discard << dendl;
./os/filestore/FileJournal.cc:    dout(10) <<  __func__ << " _open extending to " << newsize << " bytes" << dendl;
./os/filestore/FileJournal.cc:  dout(1) << "check: header looks ok" << dendl;
./os/filestore/FileJournal.cc:  dout(2) << "create " << fn << " fsid " << fsid << dendl;
./os/filestore/FileJournal.cc:  dout(2) << "create done" << dendl;
./os/filestore/FileJournal.cc:  dout(2) << "open " << fn << " fsid " << fsid << " fs_op_seq " << fs_op_seq << dendl;
./os/filestore/FileJournal.cc:    dout(2) << "open journal size " << header.max_size << " > current " << max_size << dendl;
./os/filestore/FileJournal.cc:    dout(2) << "open journal block size " << header.block_size << " != current " << block_size << dendl;
./os/filestore/FileJournal.cc:      dout(10) << "open reached end of journal." << dendl;
./os/filestore/FileJournal.cc:      dout(10) << "open reached seq " << seq << dendl;
./os/filestore/FileJournal.cc:  dout(1) << "close " << fn << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "_fdump" << dendl;
./os/filestore/FileJournal.cc:      dout(2) << "_dump -- not readable" << dendl;
./os/filestore/FileJournal.cc:      dout(25) << ss.str() << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "dump finish" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "header: start " << header.start << dendl;
./os/filestore/FileJournal.cc:  dout(10) << " write_pos " << write_pos << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "read_header" << dendl;
./os/filestore/FileJournal.cc:    dout(0) << "read_header got " << cpp_strerror(err) << dendl;
./os/filestore/FileJournal.cc:  dout(20) << __func__ << " finish" << dendl;
./os/filestore/FileJournal.cc:      dout(10) << " passing half full mark, triggering commit" << dendl;
./os/filestore/FileJournal.cc:    dout(10) << "check_for_full at " << pos << " : " << size << " < " << room << dendl;
./os/filestore/FileJournal.cc:    dout(0) << "JOURNAL TOO SMALL: continuing, but slow: item " << size << " > journal " << max << " (usable)" << dendl;
./os/filestore/FileJournal.cc:          dout(20) << "prepare_multi_write full on first entry, need to wait" << dendl;
./os/filestore/FileJournal.cc:          dout(20) << "prepare_multi_write full on first entry, restarting journal" << dendl;
./os/filestore/FileJournal.cc:  dout(20) << "prepare_multi_write queue_pos now " << queue_pos << dendl;
./os/filestore/FileJournal.cc:    dout(20) << "queue_write_fin seq " << seq << " callback " << fin << dendl;
./os/filestore/FileJournal.cc:    dout(20) << "do_write fsync" << dendl;
./os/filestore/FileJournal.cc:  dout(20) << "do_write latency " << lat << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "do_write queueing finishers through seq " << journaled_seq << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "waiting for completions to empty" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "flush waiting for finisher" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "flush done" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "write_thread_entry start" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry going to sleep" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry woke up" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry woke up" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry full and stopping, throw out queue and finish up" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry full, going to sleep (waiting for commit)" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "write_thread_entry woke up" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "write_thread_entry finish" << dendl;
./os/filestore/FileJournal.cc:    dout(10) << "do_aio_write wrapping, first bit at " << pos << "~" << first.length() << dendl;
./os/filestore/FileJournal.cc:  dout(20) << "write_aio_bl " << pos << "~" << bl.length() << " seq " << seq << dendl;
./os/filestore/FileJournal.cc:      dout(20) << "write_aio_bl io_submit return value: " << r << dendl;
./os/filestore/FileJournal.cc:  dout(10) << __func__ << " enter" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << __func__ << " sleeping" << dendl;
./os/filestore/FileJournal.cc:    dout(20) << __func__ << " waiting for aio(s)" << dendl;
./os/filestore/FileJournal.cc:	dout(0) << "io_getevents got " << cpp_strerror(r) << dendl;
./os/filestore/FileJournal.cc:  dout(10) << __func__ << " exit" << dendl;
./os/filestore/FileJournal.cc:  dout(20) << "check_aio_completion" << dendl;
./os/filestore/FileJournal.cc:	dout(20) << "check_aio_completion queueing finishers through seq " << journaled_seq << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "prepare_entry " << tls << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "commit_start" << dendl;
./os/filestore/FileJournal.cc:    dout(1) << " FULL_WAIT -> FULL_NOTFULL.  journal now active, setting completion plug." << dendl;
./os/filestore/FileJournal.cc:  dout(10) << __func__ << " trim(" << offset << ", " << end << dendl;
./os/filestore/FileJournal.cc:	dout(1) << __func__ << "ioctl(BLKDISCARD) error:" << cpp_strerror(errno) << dendl;
./os/filestore/FileJournal.cc:    dout(5) << "committed_thru " << seq << " < last_committed_seq " << last_committed_seq << dendl;
./os/filestore/FileJournal.cc:    dout(5) << "committed_thru " << seq << " == last_committed_seq " << last_committed_seq << dendl;
./os/filestore/FileJournal.cc:  dout(5) << "committed_thru " << seq << " (last_committed_seq " << last_committed_seq << ")" << dendl;
./os/filestore/FileJournal.cc:      dout(10) << " removing completion plug, queuing completions thru journaled_seq " << journaled_seq << dendl;
./os/filestore/FileJournal.cc:    dout(10) << __func__  << " will trim (" << old_start << ", " << header.start << ")" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << "committed_thru done" << dendl;
./os/filestore/FileJournal.cc:  dout(10) << __func__ << dendl;
./os/filestore/FileJournal.cc:    dout(2) << "read_entry -- not readable" << dendl;
./os/filestore/FileJournal.cc:  dout(2) << __func__ << dendl;
./os/filestore/FileJournal.cc:  dout(2) << __func__ << dendl;
./os/filestore/FileJournal.cc:  dout(2) << __func__ << dendl;
./os/filestore/FileJournal.cc:  dout(2) << __func__ << dendl;
./os/filestore/FileJournal.cc:  dout(2) << __func__ << dendl;
./os/filestore/FileJournal.cc:  dout(20) << __func__ << " journal size=" << size << dendl;
./os/filestore/LFNIndex.cc:	dout(20) << __func__ << " used alt attr for " << full_name << dendl;
./os/filestore/LFNIndex.cc:    dout(20) << __func__ << " removing alt attr from " << full_path << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "ZFSFileStoreBackend: failed to init libzfs" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "ZFSFileStoreBackend: failed to get zfs handler for basedir" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "update_current_zh: zfs_open '" << path << "' got NULL" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "update_current_zh: basedir and current/ on the same filesystem" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "update_current_zh: current/ not exist" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "detect_features: null zfs handle for current/" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:      dout(0) << "create_current: current/ exists but is not a directory" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "create_current: cannot stat current/ " << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "create_current: zfs_create '" << path << "' got " << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:  dout(10) << "list_checkpoints:" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "list_checkpoints: zfs_iter_snapshots_sorted got" << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:  dout(10) << "create_checkpoint: '" << name << "'" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "create_checkpoint: sync_filesystem got" << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "create_checkpoint: zfs_snapshot '" << path << "' got" << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:  dout(10) << "rollback_to: '" << name << "'" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:      dout(0) << "rollback_to: zfs_umount '" << zfs.get_name(current_zh) << "' got" << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "rollback_to: zfs_open '" << path << "' got NULL" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "rollback_to: zfs_rollback '" << zfs.get_name(snap_zh) << "' got" << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:      dout(0) << "update_current_zh: zfs_mount '" << zfs.get_name(current_zh) << "' got " << cpp_strerror(ret) << dendl;
./os/filestore/ZFSFileStoreBackend.cc:  dout(10) << "destroy_checkpoint: '" << name << "'" << dendl;
./os/filestore/ZFSFileStoreBackend.cc:    dout(0) << "destroy_checkpoint: zfs_destroy_snaps '" << name << "' got" << cpp_strerror(ret) << dendl;
./os/filestore/XfsFileStoreBackend.cc:    dout(0) << "set_extsize: fstat: " << cpp_strerror(ret) << dendl;
./os/filestore/XfsFileStoreBackend.cc:    dout(0) << "set_extsize: invalid target file type" << dendl;
./os/filestore/XfsFileStoreBackend.cc:    dout(0) << "set_extsize: FSGETXATTR: " << cpp_strerror(ret) << dendl;
./os/filestore/XfsFileStoreBackend.cc:    dout(0) << "set_extsize: FSSETXATTR: " << cpp_strerror(ret) << dendl;
./os/filestore/XfsFileStoreBackend.cc:      dout(0) << "detect_feature: failed to set test file extsize, assuming extsize is NOT supported" << dendl;
./os/filestore/XfsFileStoreBackend.cc:      dout(0) << __func__ << ": couldn't verify extsize not buggy, disabling extsize" << dendl;
./os/filestore/XfsFileStoreBackend.cc:      dout(0) << __func__ << ": disabling extsize, your kernel < 3.5 and has buggy extsize ioctl" << dendl;
./os/filestore/XfsFileStoreBackend.cc:      dout(0) << __func__ << ": extsize is supported and your kernel >= 3.5" << dendl;
./os/filestore/XfsFileStoreBackend.cc:    dout(0) << "detect_feature: extsize is disabled by conf" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: FIEMAP ioctl is disabled via 'filestore fiemap' config option" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: FIEMAP ioctl is NOT supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:        dout(0) << "detect_features: FIEMAP ioctl is supported, but buggy -- upgrade your kernel" << dendl;
./os/filestore/GenericFileStoreBackend.cc:        dout(0) << "detect_features: FIEMAP ioctl is supported and appears to work" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: SEEK_DATA/SEEK_HOLE is disabled via 'filestore seek data hole' config option" << dendl;
./os/filestore/GenericFileStoreBackend.cc:        dout(0) << "detect_features: lseek SEEK_DATA/SEEK_HOLE is NOT supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: lseek SEEK_DATA/SEEK_HOLE is supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << __func__ << ": splice() is disabled via 'filestore splice' config option" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: splice pipe met error " << cpp_strerror(e) << dendl;
./os/filestore/GenericFileStoreBackend.cc:	dout(0) << "detect_features: splice is supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:	dout(0) << "detect_features: splice is NOT supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syncfs(2) syscall fully supported (by glibc and kernel)" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syncfs(2) syscall supported by glibc BUT NOT the kernel" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syscall(SYS_syncfs, fd) fully supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syscall(SYS_syncfs, fd) supported by libc BUT NOT the kernel" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syscall(__NR_syncfs, fd) fully supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syscall(__NR_syncfs, fd) supported by libc BUT NOT the kernel" << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(0) << "detect_features: syncfs(2) syscall not supported" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: no syncfs(2), but 'filestore fsync flushes journal data = true', so fsync will suffice." << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: no syncfs(2), must use sync(2)." << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "detect_features: WARNING: multiple ceph-osd daemons on the same host will be slow" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "_create_current: current/ exists but is not a directory" << dendl;
./os/filestore/GenericFileStoreBackend.cc:      dout(0) << "_create_current: mkdir " << get_current_path() << " failed: "<< cpp_strerror(ret) << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(15) << "syncfs: doing fsync on " << get_op_fd() << dendl;
./os/filestore/GenericFileStoreBackend.cc:    dout(15) << "syncfs: doing a full sync (syncfs(2) if possible)" << dendl;
./os/filestore/GenericFileStoreBackend.cc:  dout(30) << __func__ << "\n" << ss.str() << dendl;
./os/filestore/GenericFileStoreBackend.cc:  dout(30) << __func__ << "\n" << ss.str() << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " bits " << bits << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " pre-splitting to shared level " << shared << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " path " << path << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " split_rand_factor = " << settings.split_rand_factor << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " start:" << start << " end:" << end << "-" << max_count << " ls.size " << ls->size() << dendl;
./os/filestore/HashIndex.cc:  dout(20) << __func__ << " path=" << path << dendl;
./os/filestore/HashIndex.cc:    dout(20) << __func__ << " prefix " << *i << dendl;
./os/filestore/HashIndex.cc:	  dout(20) << __func__ << " prefix " << *i << " ob " << j->second << dendl;
./os/filestore/DBObjectMap.cc:  dout(1) << __func__ << " start" << dendl;
./os/filestore/DBObjectMap.cc:      dout(20) << __func__ << " key is " << iter->key() << dendl;
./os/filestore/DBObjectMap.cc:	dout(20) << __func__ << " " << iter->key() << " ok" << dendl;
./os/filestore/DBObjectMap.cc:      dout(20) << __func__ << " " << iter->key() << " -> " << newkey << dendl;
./os/filestore/DBObjectMap.cc:      dout(20) << __func__ << " updating " << remove.size() << " keys" << dendl;
./os/filestore/DBObjectMap.cc:  dout(1) << __func__ << " done" << dendl;
./os/filestore/DBObjectMap.cc:  dout(20) << "(init)dbobjectmap: seq is " << state.seq << dendl;
./os/filestore/DBObjectMap.cc:  dout(20) << "dbobjectmap: seq is " << state.seq << dendl;
./os/filestore/DBObjectMap.cc:  dout(20) << "clear_header: clearing seq " << header->seq << dendl;
./os/filestore/DBObjectMap.cc:  dout(20) << "set_header: setting seq " << header->seq << dendl;
./os/filestore/DBObjectMap.cc:    dout(10) << " > header.spos " << header->spos << dendl;
./os/filestore/DBObjectMap.cc:	dout(0) << "Missing: seq " << header.parent << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << dendl;
./os/memstore/MemStore.cc:    dout(20) << __func__ << " coll " << p->first << " " << p->second << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << dendl;
./os/memstore/MemStore.cc:    dout(1) << __func__ << " new fsid " << fsid_str << dendl;
./os/memstore/MemStore.cc:    dout(1) << __func__ << " had fsid " << fsid_str << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << c->get_cid() << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << c->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << c->cid << " " << oid << " " << name << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << c->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " cid " << ch->cid << " got " << ls->size() << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/memstore/MemStore.cc:          dout(10) << "Unrecognized collection hint type: " << type << dendl;
./os/memstore/MemStore.cc:	dout(0) << msg << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << " " << size << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << " " << name << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << oid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << dendl;
./os/memstore/MemStore.cc:  dout(10) << __func__ << " " << cid << " " << ocid << " " << oid << dendl;
./os/memstore/MemStore.cc:      dout(20) << " moving " << p->first << dendl;
./os/memstore/MemStore.cc:      dout(20) << " moving " << p->first << dendl;
./os/bluestore/BlueStore.cc:    dout(LogLevelV) << __func__ << "  " << e << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " " << this << " " << o->oid << " added, num=" << num << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " " << this << " " << " " << o->oid << " removed, num=" << num << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << this << " " << " " << " " << o->oid << " pinned" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << this << " " << " " << " " << o->oid << " unpinned" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " rm " << *b << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " " << when << " start" << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << " move to front of warm " << *b << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << " move to front of hot " << *b << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " " << *b << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " delta " << delta << " on " << *b << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << " buffer_warm_in -> out " << *b << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << " buffer_hot rm " << *b << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << " buffer_warm_out rm " << *b << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " " << when << " start" << dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 20) << __func__ << dendl;
./os/bluestore/BlueStore.cc:      ldout(cache->cct, 20) << __func__ << " discard " << *b << dendl;
./os/bluestore/BlueStore.cc:      ldout(cache->cct, 20) << __func__ << " added " << *b << dendl;
./os/bluestore/BlueStore.cc:      ldout(cache->cct, 30) << __func__ << " cut " << *p->second << dendl;
./os/bluestore/BlueStore.cc:    ldout(cache->cct, 30) << __func__ << " move " << *p->second << dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 20) << __func__ << " " << oid << " " << o << dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 20) << __func__ << " " << oid << " " << dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 30) << __func__ << dendl;
./os/bluestore/BlueStore.cc:      ldout(cache->cct, 30) << __func__ << " " << oid << " miss" << dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 10) << __func__ << " " << onode_map.size()<< dendl;
./os/bluestore/BlueStore.cc:  ldout(cache->cct, 20) << __func__ << dendl;
./os/bluestore/BlueStore.cc:    ldout(cct, LogLevelV) << i.first << " : " << *i.second << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " pruned tail, now " << get_blob() << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << "  src " << e << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "    new " << *cb << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << "  dst " << *ne << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << onode->oid << (force ? " force" : "") << dendl;
./os/bluestore/BlueStore.cc:    dout(30) << " extent " << *e << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << "  new " << new_shard_info << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << "  old " << sv << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << "  fin " << sv << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << " un-spanning " << *p->second << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << " extent " << *e << dendl;
./os/bluestore/BlueStore.cc:	    dout(20) << __func__ << "    adding spanning " << *b << dendl;
./os/bluestore/BlueStore.cc:	  dout(30) << __func__ << "    un-spanning " << *e->blob << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " mark inline shard dirty" << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << "  split " << *ep << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << "     to " << *ne << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << "  adjusted " << *ep << dendl;
./os/bluestore/BlueStore.cc:    ldout(c->store->cct, 20) << __func__ << " cnt:" << flushing_count << dendl;
./os/bluestore/BlueStore.cc:  ldout(c->store->cct, 20) << __func__ << " done" << dendl;
./os/bluestore/BlueStore.cc:  ldout(store->cct, 10) << __func__ << " " << *b << dendl;
./os/bluestore/BlueStore.cc:  ldout(store->cct, 20) << __func__ << " now " << *b << dendl;
./os/bluestore/BlueStore.cc:  ldout(store->cct, 10) << __func__ << " " << *sb << dendl;
./os/bluestore/BlueStore.cc:  ldout(store->cct, 20) << __func__ << " now " << *sb << dendl;
./os/bluestore/BlueStore.cc:    ldout(store->cct, 20) << " r " << r << " v.len " << v.length() << dendl;
./os/bluestore/BlueStore.cc:  ldout(store->cct, 10) << __func__ << " to " << dest << dendl;
./os/bluestore/BlueStore.cc:	ldout(store->cct, 20) << __func__ << "  moving " << *sb << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " path " << path << " label " << label << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " got " << *label << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " initializing freespace" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " opening allocation metadata" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << (int)bluefs->wal_is_rotational() << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " kv_backend = " << kv_backend << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " do_bluefs = " << do_bluefs << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " initializing bluefs" << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " set db_paths to " << db_paths.str() << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " per_pool_omap = " << per_pool_omap << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " per_pool_omap not present" << dendl;
./os/bluestore/BlueStore.cc:      dout(10) << __func__ << " store_statfs is found" << dendl;
./os/bluestore/BlueStore.cc:      dout(10) << __func__ << " store_statfs is corrupt, using empty" << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " per-pool statfs is enabled" << dendl;
./os/bluestore/BlueStore.cc:  dout(30) << __func__ << " statfs " << vstatfs << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " path " << path << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " already created" << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " generated fsid " << fsid << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " using provided fsid " << fsid << dendl;
./os/bluestore/BlueStore.cc:    dout(0) << __func__ << " success" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " path " << dev_path << " id:" << id << dendl;
./os/bluestore/BlueStore.cc:    dout(0) << __func__ << " success" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " id:" << id << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " path " << dev_path << " id:" << id << dendl;
./os/bluestore/BlueStore.cc:  dout(0) << __func__ << " success" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << num << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " path " << path << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " quick-fix on mount" << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " stopping zone cleaner thread" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " stopping kv thread" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " closing" << dendl;
./os/bluestore/BlueStore.cc:  dout(30) << __func__ << " oid " << oid << " extents " << extents << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << "  " << oid << dendl;
./os/bluestore/BlueStore.cc:        dout(20) << __func__ << "    shard " << *s.shard_info << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << "    " << l << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << "fsck converting " << o->oid << " omap to per-pg" << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " debug abort" << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " walking object keyspace" << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " checking shared_blobs" << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << "  " << *sbi.sb << " " << shared_blob << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " sorting out misreferenced extents" << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " checking pool_statfs" << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " checking for stray omap data " << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " checking deferred events" << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " checking freelist vs allocated" << dendl;
./os/bluestore/BlueStore.cc:      dout(5) << __func__ << " fixing per_pg_omap" << dendl;
./os/bluestore/BlueStore.cc:    dout(5) << __func__ << " applying repair results" << dendl;
./os/bluestore/BlueStore.cc:    dout(5) << __func__ << " repair applied" << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " devices span numa nodes " << nodes << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << *buf << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " pool " << pool_id<< dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " not supported in legacy mode " << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << *buf << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c << " " << c->cid << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " " << c << " " << c->cid << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " " << c << " " << c->cid << " done" << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " all reaped" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->get_cid() << " " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << ch->cid << " options " << opts << dendl;
./os/bluestore/BlueStore.cc:    dout(0) << __func__ << ": inject random EIO" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " will do buffered read" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " defaulting to buffered read" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " will bypass cache and do direct read" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " waiting for aio" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " offset " << offset << dendl;
./os/bluestore/BlueStore.cc:    dout(0) << __func__ << ": inject random EIO" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " will do buffered read" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " defaulting to buffered read" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " waiting for aio" << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << oid << " " << name << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << ch->cid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << ch->cid << " = " << (int)(*empty) << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << ch->cid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << ch->cid << " = " << c->cnode.bits << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " temp=" << (int)temp << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " pend " << pend << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " iterator not valid (end of db?)" << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " oid " << it->oid() << " >= " << pend << dendl;
./os/bluestore/BlueStore.cc:	dout(30) << __func__ << " switch to non-temp namespace" << dendl;
./os/bluestore/BlueStore.cc:	dout(30) << __func__ << " pend " << pend << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " oid " << it->oid() << " end " << end << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " reached max " << max << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:        dout(30) << __func__ << "  got header" << dendl;
./os/bluestore/BlueStore.cc:        dout(30) << __func__ << "  reached tail" << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << "  got header" << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << "  no header" << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:	dout(30) << __func__ << "  reached tail" << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->get_cid() << " oid " << oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->get_cid() << " " << oid << dendl;
./os/bluestore/BlueStore.cc:    dout(10) << __func__ << " " << oid << "doesn't exist" <<dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " has_omap = " << (int)o->onode.has_omap() <<dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " old nid_max " << nid_max << dendl;
./os/bluestore/BlueStore.cc:    dout(1) << __func__ << " old blobid_max " << blobid_max << dendl;
./os/bluestore/BlueStore.cc:      dout(1) << __func__ << " freelist_type " << freelist_type << dendl;
./os/bluestore/BlueStore.cc:  dout(1) << __func__ << " done" << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << nid << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << bid << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << txc << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " txc " << txc << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " " << txc << " onodes " << txc->onodes << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " osr " << osr << " q now empty" << dendl;
./os/bluestore/BlueStore.cc:      dout(10) << __func__ << " reaping empty zombie osr " << osr << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << osr << " " << osr->cid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << txc << " osr " << osr << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << osr << " done" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << osr << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << osr << " done" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " osr_set " << s << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " drain " << osr << dendl;
./os/bluestore/BlueStore.cc:	dout(10) << __func__ << " reaping empty zombie osr " << osr << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " done" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " stopping finishers" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " stopped" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " start" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " sleep" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " wake" << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << " committing " << kv_committing << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << " submitting " << kv_submitting << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << " deferred_done " << deferred_done << dendl;
./os/bluestore/BlueStore.cc:      dout(30) << __func__ << " deferred_stable " << deferred_stable << dendl;
./os/bluestore/BlueStore.cc:	  dout(20) << __func__ << " skipping flush (no aios, no deferred_done)" << dendl;
./os/bluestore/BlueStore.cc:	dout(10) << __func__ << " new_nid_max " << new_nid_max << dendl;
./os/bluestore/BlueStore.cc:	dout(10) << __func__ << " new_blobid_max " << new_blobid_max << dendl;
./os/bluestore/BlueStore.cc:	dout(10) << __func__ << " nid_max now " << nid_max << dendl;
./os/bluestore/BlueStore.cc:	dout(10) << __func__ << " blobid_max now " << blobid_max << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " finish" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " start" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " sleep" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " wake" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " kv_committed " << kv_committed << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " deferred_stable " << deferred_stable << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " finish" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " done" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " start" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " sleep" << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " wake" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " finish" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " cleaning zone " << zone_num << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " txc " << txc << " osr " << txc->osr << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "  osr " << osr << " has no pending" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " osr " << osr << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " dequeueing" << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " queuing async deferred_try_submit" << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " leaving queued, more pending" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " start" << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " draining osr" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " completed " << count << " events" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " ch " << c << " " << c->cid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " txc " << txc << dendl;
./os/bluestore/BlueStore.cc:          dout(10) << __func__ << " unknown collection hint " << type << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " ignoring distant " << *b << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " ignoring immutable " << *b << dendl;
./os/bluestore/BlueStore.cc:	dout(20) << __func__ << " ignoring offset-skewed " << *b << dendl;
./os/bluestore/BlueStore.cc:	  dout(20) << __func__ << "  lex old " << *ep << dendl;
./os/bluestore/BlueStore.cc:	  dout(20) << __func__ << "  lex " << *le << dendl;
./os/bluestore/BlueStore.cc:	  dout(20) << __func__ << "  lex " << *le << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << " no deferred" << dendl;
./os/bluestore/BlueStore.cc:          dout(20) << __func__ << " considering " << *ep << dendl;
./os/bluestore/BlueStore.cc:          dout(20) << __func__ << " considering rev " << *prev_ep << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " prealloc " << prealloc << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " blob " << *b << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << "  lex " << *le << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " lex_old " << lo.e << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "  blob " << *b << " release " << r << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "  release " << e << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " will do buffered write" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " defaulting to buffered write" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " will prefer large blob and csum sizes" << dendl;
./os/bluestore/BlueStore.cc:  dout(30) << __func__ << " alloc write" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " perform garbage collection" << dendl;
./os/bluestore/BlueStore.cc:      dout(10) << __func__ << "  request reshard past EOF" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << " ? " << *p.first << " vs " << p.second << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "  unsharing " << *sb << dendl;
./os/bluestore/BlueStore.cc:      dout(20) << __func__ << "  unsharing " << e << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " clearing old omap data" << dendl;
./os/bluestore/BlueStore.cc:    dout(20) << __func__ << " copying omap data" << dendl;
./os/bluestore/BlueStore.cc:	dout(30) << __func__ << "  reached tail" << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << cid << " bits " << bits << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << cid << " bits " << bits << " = " << r << dendl;
./os/bluestore/BlueStore.cc:  dout(15) << __func__ << " " << cid << dendl;
./os/bluestore/BlueStore.cc:        dout(10) << __func__ << " oid " << *it << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << " " << cid << " = " << r << dendl;
./os/bluestore/BlueStore.cc:    dout(30) << __func__ << " Key: " << iter->key() << dendl;
./os/bluestore/BlueStore.cc:  dout(20) << __func__ << " finished in " << duration << " seconds" << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueStore.cc:  dout(0) << "------------" << dendl;
./os/bluestore/StupidAllocator.cc:  ldout(cct, 1) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(10) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:    dout(30) << __func__ << " start" << dendl;
./os/bluestore/ZonedFreelistManager.cc:      dout(30) << __func__ << " end" << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length << dendl;
./os/bluestore/ZonedFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/ZonedFreelistManager.cc:      dout(0) << __func__ << " " << keys[i] << " not found in bdev meta" << dendl;
./os/bluestore/BitmapAllocator.cc:  ldout(cct, 10) << __func__ << " done" << dendl;
./os/bluestore/BitmapAllocator.cc:  ldout(cct, 10) << __func__ << " done" << dendl;
./os/bluestore/BitmapAllocator.cc:  ldout(cct, 10) << __func__ << " done" << dendl;
./os/bluestore/BitmapAllocator.cc:  ldout(cct, 1) << __func__ << dendl;
./os/bluestore/BlueFS.cc:        ldout(bluefs->cct, 1) << __func__ << " cannot register SocketHook" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " bdev " << id << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " bdev " << id << dendl;
./os/bluestore/BlueFS.cc:  dout(1) << __func__ << " uuid " << super.uuid << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " success" << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueFS.cc:    dout(30) << __func__ << " noting alloc for " << p.second->fnode << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << " bluefs layout verified positively" << dendl;
./os/bluestore/BlueFS.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " super block length(encoded): " << bl.length() << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " superblock " << super.version << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " log_fnode " << super.log_fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " superblock " << super.version << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " log_fnode " << super.log_fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << (noop ? " NO-OP" : "") << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " log_fnode " << super.log_fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " done" << dendl;
./os/bluestore/BlueFS.cc:    dout(0) << __func__ << " super to be written to " << dev_target << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " " << ino << " " << file_ref->fnode << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << "  migrating" << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " " << p.first << " " << p.second->fnode << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << "  migrating" << dendl;
./os/bluestore/BlueFS.cc:    dout(30) << __func__ << " ino " << ino << " = " << p->second << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " destroying " << file->fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " got " << ret << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " got " << ret << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " op_init" << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " op_file_update " << file_ref->fnode << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " op_dir_create " << path << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " op_jump_seq " << log_seq << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " need " << need << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " renaming log extents to " << log_dev_new << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " writing super, log fnode: " << super.log_fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " release old log extents " << old_fnode.extents << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " log is currently flushing, waiting" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " log extents " << log_file->fnode.extents << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << " remove old log extent " << e << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << " remove front of old log extent " << e << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << "   kept " << e << " removed " << temp << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " writing super" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " release old log extents " << old_extents << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " log extents " << log_file->fnode.extents << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " " << lsi->second.size() << " dirty_files" << dendl;
./os/bluestore/BlueFS.cc:      dout(20) << __func__ << "   op_file_update " << f.fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << log_t << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << " waiting for async compaction" << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " log_seq_stable " << log_seq_stable << dendl;
./os/bluestore/BlueFS.cc:        dout(20) << __func__ << " done cleaning up dirty files" << dendl;
./os/bluestore/BlueFS.cc:        dout(20) << __func__ << " cleaned file " << file->fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << " file now " << h->file->fnode << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " waiting for previous aio to complete" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " got " << ls->size() << " aios" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << h << " done in " << (ceph_clock_now() - start) << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << "  deleted, no-op" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << h << " " << h->file->fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << dendl;
./os/bluestore/BlueFS.cc:  dout(20) << __func__ << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << "  deleted, no-op" << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " - no pending log events" << dendl;
./os/bluestore/BlueFS.cc:    dout(10) << __func__ << " done in " << (ceph_clock_now() - start) << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << "/" << filename << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " h " << *h << " on " << file->fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << h << " type " << h->writer_type << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " h " << *h << " on " << file->fnode << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << old_dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << new_dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " exists" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " does not exist" << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " not empty" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << " = " << (int)exists << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << "/" << filename << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << "/" << filename << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:      dout(10) << __func__ << " already locked" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << fl << " on " << fl->file->fnode << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << dendl;
./os/bluestore/BlueFS.cc:      dout(20) << __func__ << " dir " << dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:  dout(10) << __func__ << " " << dirname << "/" << filename << dendl;
./os/bluestore/BlueFS.cc:    dout(20) << __func__ << " dir " << dirname << " not found" << dendl;
./os/bluestore/BlueFS.cc:  dout(2) << __func__ << " log file encoded extents length = " << bin_extents.length() << dendl;
./os/bluestore/BlueFS.cc:  dout(2) << __func__ << " valid data in log = " << fixed.length() << dendl;
./os/bluestore/BlueFS.cc:    dout(2) << __func__ << " processing " << get_device_name(dev) << dendl;
./os/bluestore/BlueFS.cc:    dout(5) << __func__ << " " << disk_regions_count << " regions to scan on " << get_device_name(dev) << dendl;
./os/bluestore/BlueFS.cc:	  dout(5) << __func__ << " checking location 0x" << std::hex << pos + (n - chunk_b) << std::dec << dendl;
./os/bluestore/BlueFS.cc:	    dout(5) << __func__ << " extent " << ne << " already refected" <<dendl;
./os/bluestore/BlueFS.cc:	    dout(5) << __func__ << " refusing extent " << ne << dendl;
./os/bluestore/BlueFS.cc:	  dout(5) << __func__ << " checking extent " << ne << dendl;
./os/bluestore/BlueFS.cc:	    dout(5) << __func__ << " failed match" << dendl;
./os/bluestore/BlueFS.cc:	  dout(5) << __func__ << " successful extension of log " << l << "/" << read_len << dendl;
./os/bluestore/BitmapFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BitmapFreelistManager.cc:    dout(1) << __func__ << " fall back to legacy meta repo" << dendl;
./os/bluestore/BitmapFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BitmapFreelistManager.cc:      dout(0) << __func__ << " " << keys[i] << " not found in bdev meta" << dendl;
./os/bluestore/BitmapFreelistManager.cc:  dout(10) << __func__ << " checks if size sync is needed" << dendl;
./os/bluestore/BitmapFreelistManager.cc:    dout(1) << __func__ << " fall back to legacy meta repo" << dendl;
./os/bluestore/BitmapFreelistManager.cc:  dout(1) << __func__ << dendl;
./os/bluestore/BitmapFreelistManager.cc:    dout(10) << __func__ << " start" << dendl;
./os/bluestore/BitmapFreelistManager.cc:    dout(10) << __func__ << " end" << dendl;
./os/bluestore/BitmapFreelistManager.cc:  dout(10) << __func__ << " end" << dendl;
./os/bluestore/ZonedAllocator.cc:    ldout(cct, 10) << __func__ << " failed to allocate" << dendl;
./os/bluestore/ZonedAllocator.cc:  ldout(cct, 10) << __func__ << dendl;
./os/bluestore/ZonedAllocator.cc:  ldout(cct, 1) << __func__ << dendl;
./os/bluestore/AvlAllocator.cc:  ldout(cct, 0) << __func__ << " range_tree: " << dendl;
./os/bluestore/AvlAllocator.cc:  ldout(cct, 0) << __func__ << " range_size_tree: " << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " " << flush_txns << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " done" << dendl;
./os/kstore/KStore.cc:  dout(30) << __func__ << " " << oid << " " << o << dendl;
./os/kstore/KStore.cc:  dout(30) << __func__ << dendl;
./os/kstore/KStore.cc:    dout(30) << __func__ << " " << oid << " miss" << dendl;
./os/kstore/KStore.cc:  dout(30) << __func__ << " " << oid << " hit " << p->second << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << dendl;
./os/kstore/KStore.cc:  dout(30) << __func__ << " " << old_oid << " -> " << new_oid << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " after " << after << dendl;
./os/kstore/KStore.cc:    dout(30) << __func__ << "  trim " << o->oid << dendl;
./os/kstore/KStore.cc:  ldout(store->cct, 20) << " r " << r << " v.len " << v.length() << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " kv_backend = " << kv_backend << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " opened " << cid << dendl;
./os/kstore/KStore.cc:  dout(1) << __func__ << " path " << path << dendl;
./os/kstore/KStore.cc:      dout(1) << __func__ << " generated fsid " << fsid << dendl;
./os/kstore/KStore.cc:      dout(1) << __func__ << " using provided fsid " << fsid << dendl;
./os/kstore/KStore.cc:    dout(1) << __func__ << " already created, fsid is " << fsid << dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " success" << dendl;
./os/kstore/KStore.cc:  dout(1) << __func__ << " path " << path << dendl;
./os/kstore/KStore.cc:  dout(1) << __func__ << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " stopping kv thread" << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " draining finisher" << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " stopping finisher" << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " closing" << dendl;
./os/kstore/KStore.cc:  dout(1) << __func__ << dendl;
./os/kstore/KStore.cc:  dout(1) << __func__ << " finish with " << errors << " errors" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << dendl;
./os/kstore/KStore.cc:    dout(20) << " waiting for kv to commit" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " done" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " " << c->cid << dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " " << c->cid << " done" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " all reaped" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << " taking full stripe" << dendl;
./os/kstore/KStore.cc:	  dout(30) << __func__ << " taking " << stripe_off << "~" << l << dendl;
./os/kstore/KStore.cc:	  dout(30) << __func__ << " adding " << swant - l << " zeros" << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << " generating " << swant << " zeros" << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " " << oid << " " << name << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " = " << (int)(*empty) << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " = " << c->cnode.bits << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " pend " << pretty_binary_string(pend) << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " iterator not valid (end of db?)" << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << " switch to non-temp namespace" << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << " pend " << pretty_binary_string(pend) << dendl;
./os/kstore/KStore.cc:    dout(20) << __func__ << " key " << pretty_binary_string(it->key()) << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " reached max " << max << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " oid " << oid << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << "  got header" << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << "  reached tail" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " oid " << oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " oid " << oid << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << "  got header" << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << "  no header" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " oid " << oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " oid " << oid << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << "  reached tail" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " oid " << oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " oid " << oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " oid " << oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << ch->cid << " oid " << oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " oid " << oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << ch->cid << " " << oid << dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " " << oid << "doesn't exist" <<dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " header = " << o->onode.omap_head <<dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " old nid_max " << nid_max << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " " << o->oid << " nid " << o->onode.nid << dendl;
./os/kstore/KStore.cc:    dout(10) << __func__ << " nid_max now " << nid_max << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " osr " << osr << " = " << txc << dendl;
./os/kstore/KStore.cc:    dout(20) << " onode size is " << bl.length() << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " txc " << txc << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " " << txc << " onodes " << txc->onodes << dendl;
./os/kstore/KStore.cc:  dout(20) << __func__ << " osr " << osr << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " osr " << osr << " q now empty" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " start" << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " sleep" << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " wake" << dendl;
./os/kstore/KStore.cc:      dout(20) << __func__ << " committing " << kv_queue.size() << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << " committing txc " << kv_committing << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " finish" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " ch " << ch.get() << " " << c->cid << dendl;
./os/kstore/KStore.cc:          dout(10) << __func__ << " unknown collection hint " << type << dendl;
./os/kstore/KStore.cc:	dout(0) << msg << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << " full stripe " << offset << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " reuse leading " << p << " bytes" << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " add leading " << offset_rem - p << " zeros" << dendl;
./os/kstore/KStore.cc:    dout(20) << __func__ << " using " << use << " for this stripe" << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " reuse trailing " << l << " bytes" << dendl;
./os/kstore/KStore.cc:	  dout(20) << __func__ << " adding " << len << " of zeros" << dendl;
./os/kstore/KStore.cc:	    dout(20) << __func__ << " keeping tail " << l << " of stripe" << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " rm stripe " << pos << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " rm stripe " << pos << dendl;
./os/kstore/KStore.cc:	dout(20) << __func__ << " clear cached tail" << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " truncate size to " << offset << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:      dout(30) << __func__ << "  stop at " << tail << dendl;
./os/kstore/KStore.cc:    dout(30) << __func__ << "  rm " << pretty_binary_string(it->key()) << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << c->cid << " " << o->oid << dendl;
./os/kstore/KStore.cc:    dout(30) << __func__ << "  rm " << pretty_binary_string(it->key()) << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << c->cid << " " << o->oid << " = " << r << dendl;
./os/kstore/KStore.cc:    dout(20) << __func__ << " clearing old omap data" << dendl;
./os/kstore/KStore.cc:    dout(20) << __func__ << " copying omap data" << dendl;
./os/kstore/KStore.cc:	dout(30) << __func__ << "  reached tail" << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << cid << " bits " << bits << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << cid << " bits " << bits << " = " << r << dendl;
./os/kstore/KStore.cc:  dout(15) << __func__ << " " << cid << dendl;
./os/kstore/KStore.cc:        dout(10) << __func__ << " oid " << *it << dendl;
./os/kstore/KStore.cc:  dout(10) << __func__ << " " << cid << " = " << r << dendl;
./msg/DispatchQueue.cc:  ldout(cct,20) << "done calling dispatch on " << m << dendl;
./msg/DispatchQueue.cc:  ldout(cct,20) << "queue " << m << " prio " << priority << dendl;
./msg/DispatchQueue.cc:	  ldout(cct,10) << " stop flag set, discarding " << m << " " << *m << dendl;
./msg/Message.cc:      ldout(cct, 0) << "can't decode unknown message type " << type << " MSG_AUTH=" << CEPH_MSG_AUTH << dendl;
./msg/async/Stack.cc:      ldout(cct, 10) << __func__ << " starting" << dendl;
./msg/async/Stack.cc:        ldout(cct, 30) << __func__ << " calling event process" << dendl;
./msg/async/Stack.cc:  ldout(cct, 30) << __func__ << dendl;
./msg/async/Stack.cc:  ldout(cct, 30) << __func__ << " started." << dendl;
./msg/async/Stack.cc:  ldout(cct, 30) << __func__ << " end." << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 1) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 1) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 10) << __func__ << " started" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 20) << __func__ << " discard " << *p << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 20) << __func__ << " discard " << *entry.m << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 1) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 1) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 10) << __func__ << " " << seq << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 5) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 5) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 10) << __func__ << " connection is already closed" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 2) << __func__ << " on lossy channel, failing" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " server, going to standby, even though i have stuff queued" << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 1) << __func__ << " server, going to standby" << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 1) << __func__ << " initiating reconnect" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " waiting " << backoff << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " m=" << *m << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " " << e.what() << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 15) << __func__ << " seq=" << seq << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 10) << __func__ << " appending keepalive" << dendl;
./msg/async/ProtocolV2.cc:        ldout(cct, 1) << __func__ << " send msg failed" << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 1) << __func__ << " send msg failed" << dendl;
./msg/async/ProtocolV2.cc:      ldout(cct, 10) << __func__ << " policy.server is false" << dendl;
./msg/async/ProtocolV2.cc:        ldout(cct, 1) << __func__ << " send outcoming bl failed" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " " << e.what() << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " accept peer sent bad banner" << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " " << e.what() << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << "bad auth tag" << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " seg_idx=" << seg_idx << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 25) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " " << e.what() << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << "bad auth tag" << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " decode message failed " << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 10) << __func__ << " blackhole " << *message << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 30) << __func__ << " got KEEPALIVE2 tag ..." << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " got KEEPALIVE_ACK" << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " state changed!" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " state changed!" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " state changed!" << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct,5) << __func__ << " oops, client_ident.addrs() is empty" << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " existing=" << existing << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 1) << __func__ << " reconnect to existing=" << existing << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << " existing=" << existing << dendl;
./msg/async/ProtocolV2.cc:    ldout(cct, 1) << __func__ << " existing=" << existing << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV2.cc:  ldout(cct, 5) << __func__ << " sending reconnect_ok: msg_seq=" << ms << dendl;
./msg/async/net_handler.cc:      ldout(cct, 0) << "couldn't set TCP_NODELAY: " << cpp_strerror(r) << dendl;
./msg/async/net_handler.cc:      ldout(cct, 0) << "couldn't set SO_RCVBUF to " << size << ": " << cpp_strerror(r) << dendl;
./msg/async/net_handler.cc:    ldout(cct,0) << "couldn't set SO_NOSIGPIPE: " << cpp_strerror(r) << dendl;
./msg/async/net_handler.cc:        ldout(cct, 2) << __func__ << " client bind error " << ", " << cpp_strerror(ret) << dendl;
./msg/async/net_handler.cc:    ldout(cct, 10) << __func__ << " connect: " << cpp_strerror(ret) << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 2) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " connection is already closed" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " on lossy channel, failing" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " waiting " << backoff << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 0) << __func__ << " server, going to standby" << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 0) << __func__ << " initiating reconnect" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " m " << *m << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV1.cc:        ldout(cct, 1) << __func__ << " send msg failed" << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 1) << __func__ << " send msg failed" << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 10) << __func__ << " policy.server is false" << dendl;
./msg/async/ProtocolV1.cc:        ldout(cct, 1) << __func__ << " send outcoming bl failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 25) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read tag failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " process tag " << (int)tag << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 20) << __func__ << " got KEEPALIVE" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 20) << __func__ << " begin MSG" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 20) << __func__ << " got CLOSE" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 0) << __func__ << " bad tag " << (int)tag << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read keeplive timespec failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 30) << __func__ << " got KEEPALIVE2 tag ..." << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got KEEPALIVE2 " << kp_t << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read keeplive timespec failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got KEEPALIVE_ACK" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read ack seq failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got ACK" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 15) << __func__ << " got ack seq " << seq << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read message header failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got MSG header" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read message front failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got front " << front.length() << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read message middle failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " got middle " << middle.length() << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " msg_left=" << msg_left << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read data error " << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read footer data error " << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " aborted = " << aborted << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " decode message failed " << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " no session security set" << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 0) << __func__ << " Signature check failed" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " blackhole " << *message << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " started" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " randomize_out_seq " << rand_seq << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 20) << __func__ << " no session security" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " " << seq << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " started" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 20) << __func__ << " discard " << *p << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 20) << __func__ << " discard " << r->second << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 5) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 5) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " write client banner failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:	ldout(cct, 1) << __func__ << " state changed!" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read connect reply failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 1) << __func__ << " state changed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 0) << __func__ << " connect got BADAUTHORIZER" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 0) << __func__ << " connect got RESETSESSION" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " connect got WAIT (connection race)" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " got CEPH_MSGR_TAG_READY " << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read connect ack seq failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " failed to send in_seq " << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " send in_seq done " << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << " write server banner failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read peer banner and addr failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " accept peer addr is " << peer_addr << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read connect msg failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read connect authorizer failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 1) << __func__ << " state changed" << dendl;
./msg/async/ProtocolV1.cc:      ldout(cct, 1) << __func__ << " state changed" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << ": challenging authorizer" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " accept setting up session_security." << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " accept new session" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " state changed" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << __func__ << " accept new session" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << " write connect message reply failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 10) << __func__ << " accept replacing " << existing << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << "accept fault after register" << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 10) << "accept fault after register" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " r=" << r << dendl;
./msg/async/ProtocolV1.cc:    ldout(cct, 1) << __func__ << " read ack seq failed" << dendl;
./msg/async/ProtocolV1.cc:  ldout(cct, 20) << __func__ << " accept done" << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct, 0) << __func__ << " injecting socket failure" << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct, 25) << __func__ << " read_bulk left is " << left << " got " << r << dendl;
./msg/async/AsyncConnection.cc:        ldout(async_msgr->cct, 1) << __func__ << " read failed" << dendl;
./msg/async/AsyncConnection.cc:        ldout(async_msgr->cct, 1) << __func__ << " read failed" << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct, 0) << __func__ << " injecting socket failure" << dendl;
./msg/async/AsyncConnection.cc:    ldout(async_msgr->cct, 1) << __func__ << " send error: " << cpp_strerror(r) << dendl;
./msg/async/AsyncConnection.cc:  ldout(async_msgr->cct, 20) << __func__ << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct, 20) << __func__ << " enter none state" << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct, 20) << __func__ << " socket closed" << dendl;
./msg/async/AsyncConnection.cc:  ldout(async_msgr->cct, 10) << __func__ << dendl;
./msg/async/AsyncConnection.cc:    ldout(async_msgr->cct, 20) << __func__ << " " << *m << " local" << dendl;
./msg/async/AsyncConnection.cc:      ldout(async_msgr->cct,10) << __func__ << " " << av << " -> " << i << dendl;
./msg/async/AsyncConnection.cc:  ldout(async_msgr->cct, 1) << __func__ << dendl;
./msg/async/AsyncConnection.cc:  ldout(async_msgr->cct, 10) << __func__ << dendl;
./msg/async/dpdk/IP.cc:    ldout(cct, 20) << __func__ << " learn mac " << from << " with " << h.src_ip << dendl;
./msg/async/dpdk/IP.cc:        ldout(cct, 20) << " ipv4::get_packet len " << l4p->p.len() << dendl;
./msg/async/dpdk/net.cc:        ldout(cct, 1) << __func__ << " forward to " << fw << dendl;
./msg/async/dpdk/TCP.cc:  ldout(_tcp.cct, 10) << __func__ << " listen: LISTEN -> SYN_RECEIVED" << dendl;
./msg/async/dpdk/TCP.cc:      ldout(_tcp.cct, 20) << __func__ << " syn: SYN_SENT -> ESTABLISHED" << dendl;
./msg/async/dpdk/TCP.cc:      ldout(_tcp.cct, 20) << __func__ << " syn: SYN_SENT -> SYN_RECEIVED" << dendl;
./msg/async/dpdk/TCP.cc:    ldout(_tcp.cct, 10) << __func__ << " dup segment len " << dup << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " SYN_RECEIVED -> ESTABLISHED" << dendl;
./msg/async/dpdk/TCP.cc:          ldout(_tcp.cct, 20) << __func__ << " successfully accepting socket" << dendl;
./msg/async/dpdk/TCP.cc:          ldout(_tcp.cct, 5) << __func__ << " not exist listener or full queue, reset" << dendl;
./msg/async/dpdk/TCP.cc:            ldout(_tcp.cct, 20) << __func__ << " ack: full_ack" << dendl;
./msg/async/dpdk/TCP.cc:            ldout(_tcp.cct, 20) << __func__ << " ack: partial_ack" << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " ack: FIN_WAIT_1 -> FIN_WAIT_2" << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " ack: CLOSING -> TIME_WAIT" << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " ack: LAST_ACK -> CLOSED" << dendl;
./msg/async/dpdk/TCP.cc:      ldout(_tcp.cct, 20) << __func__ << " merged=" << merged << " do_output=" << do_output << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " fin: SYN_RECEIVED or ESTABLISHED -> CLOSE_WAIT" << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " fin: FIN_WAIT_1 -> CLOSING" << dendl;
./msg/async/dpdk/TCP.cc:        ldout(_tcp.cct, 20) << __func__ << " fin: FIN_WAIT_2 -> TIME_WAIT" << dendl;
./msg/async/dpdk/TCP.cc:  ldout(_tcp.cct, 20) << __func__ << dendl;
./msg/async/dpdk/TCP.cc:  ldout(_tcp.cct, 20) << __func__ << " unsent_len=" << _snd.unsent_len << dendl;
./msg/async/dpdk/TCP.cc:    ldout(_tcp.cct, 20) << __func__ << " CLOSE_WAIT -> LAST_ACK" << dendl;
./msg/async/dpdk/TCP.cc:    ldout(_tcp.cct, 20) << __func__ << " ESTABLISHED -> FIN_WAIT_1" << dendl;
./msg/async/dpdk/TCP.cc:  ldout(_tcp.cct, 20) << __func__ << " persist timer fired" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " Device is an Intel's 40G NIC. Enabling 8 fragments hack!" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " Device is a VMWare Virtual NIC. Enabling 16 fragments hack!" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " LRO is on" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " LRO is off" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " RX checksum offload supported" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " TX ip checksum offload supported" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " TSO is supported" << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " TX TCP checksum offload supported" << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 1) << __func__ << " Port " << int(_port_idx) << " init ... " << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 1) << __func__ << " done." << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 1) << __func__ << " port " << int(_port_idx) << ":  HW FC " << _enable_fc << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 1) << __func__ << " port " << int(_port_idx) << ": changing HW FC settings is not supported" << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 5) << __func__ << " created DPDK device" << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/dpdk/DPDK.cc:        ldout(cct, 20) << __func__ << " not ready, continue to wait." << dendl;
./msg/async/dpdk/DPDK.cc:  ldout(cct, 20) << __func__ << " started." << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 0) << __func__ << " failed to get port statistics: " << cpp_strerror(rc) << dendl;
./msg/async/dpdk/DPDK.cc:            // ldout(cct, 0) << __func__ << " len: " << p->len() << " frags: " << p->nr_frags() << dendl;
./msg/async/dpdk/DPDK.cc:        ldout(cct, 1) << __func__ << " get new mbuf failed " << dendl;
./msg/async/dpdk/DPDK.cc:    // ldout(cct, 0) << __func__ << " len " << p->len() << " " << dendl;
./msg/async/dpdk/DPDK.cc:      ldout(cct, 1) << __func__ << " no available mbuf for " << p.frag(0).size << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 1) << __func__ << " no available mbuf for " << p.frag(0).size << dendl;
./msg/async/dpdk/DPDK.cc:      ldout(cct, 1) << __func__ << " no available mbuf for " << p.frag(i).size << dendl;
./msg/async/dpdk/DPDK.cc:    ldout(cct, 10) << __func__ << " ports number: " << int(rte_eth_dev_count_avail()) << dendl;
./msg/async/dpdk/UserspaceEvent.cc:  ldout(cct, 20) << __func__ << " fd=" << fd << dendl;
./msg/async/dpdk/UserspaceEvent.cc:  ldout(cct, 20) << __func__ << " fd=" << fd << " mask=" << mask << dendl;
./msg/async/dpdk/UserspaceEvent.cc:  ldout(cct, 20) << __func__ << " fd=" << fd << dendl;
./msg/async/dpdk/UserspaceEvent.cc:    ldout(cct, 20) << __func__ << " fd=" << fd << " mask=" << masks[count] << dendl;
./msg/async/dpdk/DPDKStack.cc:    ldout(cct, 1) << __func__ << " using " << cores << " cores " << dendl;
./msg/async/dpdk/DPDKStack.cc:  ldout(cct, 10) << __func__ << " addr " << sa << dendl;
./msg/async/dpdk/DPDKStack.cc:  ldout(cct, 10) << __func__ << " addr " << addr << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " destruct." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 20) << __func__ << " handle fake send, wake it up. QP: " << local_qpn << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " tcp_fd: " << tcp_fd << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " start " << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " warnning: logic failed " << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " send handshake msg failed." << r << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " finish " << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " QP: " << local_qpn << " tcp_fd: " << tcp_fd << " notify_fd: " << notify_fd << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 1) << __func__ << " recv handshake msg failed." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " warnning: logic failed: read len: " << r << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 1) << __func__ << " send client ack failed." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:        ldout(cct, 10) << __func__ << " server is already active." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:        ldout(cct, 1) << __func__ << " server ack failed." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 10) << __func__ << " handshake of rdma is done. server connected: " << connected << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " when ib not active. len: " << len << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " when ib not connected. len: " << len <<dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 20) << __func__ << " we do not need last handshake, QP: " << local_qpn << " peer QP: " << peer_qpn << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:        ldout(cct, 20) << __func__ << " got remote close msg..." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 25) << __func__ << " buffers add a chunk: " << chunk->get_offset() << ":" << chunk->get_bound() << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 25) << __func__ << " read over one chunk " << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 25) << __func__ << " got " << read_size  << " bytes, buffers size: " << buffers.size() << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:      ldout(cct, 20) << __func__ << " fake send to upper, QP: " << local_qpn << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " QP: " << local_qpn << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 1) << __func__ << " no enough buffers in worker " << worker << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " finished sending " << total_copied << " bytes." << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " QP: " << local_qpn << " " << tx_buffers[0] << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:    ldout(cct, 25) << __func__ << " sending buffer: " << *current_buffer << " length: " << isge[current_sge].length  << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " qp state is " << get_qp_state() << dendl;
./msg/async/rdma/RDMAConnectedSocketImpl.cc:  ldout(cct, 1) << __func__ << " tcp fd " << tcp_fd << dendl;
./msg/async/rdma/RDMAServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " bind to " << sa.get_sockaddr() << " on port " << sa.get_port()  << dendl;
./msg/async/rdma/RDMAServerSocketImpl.cc:  ldout(cct, 15) << __func__ << dendl;
./msg/async/rdma/RDMAServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " accepted a new QP, tcp_fd: " << sd << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct,1) << __func__ << " using experimental verbs for gid" << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 1) << __func__ << " malformed or no GID supplied, using GID index 0" << dendl;
./msg/async/rdma/Infiniband.cc:      ldout(cct, 1) << __func__ << " found at index " << gid_idx << dendl;
./msg/async/rdma/Infiniband.cc:      ldout(cct, 1) << __func__ << " found active port " << static_cast<int>(port_id) << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 20) << __func__ << " transition to ERROR state successfully." << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " transition to RTS state successfully." << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " Choosing gid_index " << (int)qpa.ah_attr.grh.sgid_index << ", sl " << (int)qpa.ah_attr.sl << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " transition to RTR state successfully." << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " successfully switch to INIT state Queue Pair, qp number: " << qp->qp_num << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " started." << dendl;
./msg/async/rdma/Infiniband.cc:      ldout(cct, 0) << __func__ << " injecting socket failure" << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 10) << __func__ << " got disconnect message " << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 1) << __func__ << " got bad length (" << r << ") " << dendl;
./msg/async/rdma/Infiniband.cc:      ldout(cct, 0) << __func__ << " injecting socket failure" << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " trigger error state Queue Pair, qp number: " << local_cm_meta.local_qpn << " Beacon sent " << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " started." << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 20) << __func__ << " ack aq events." << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " successfully create cq=" << cq << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " started." << dendl;
./msg/async/rdma/Infiniband.cc:   ldout(cct, 20) << __func__ << " ms_async_rdma_enable_hugepage value is: " << cct->_conf->ms_async_rdma_enable_hugepage <<  dendl;
./msg/async/rdma/Infiniband.cc:     ldout(cct, 0) << __func__ << " RDMAV_HUGEPAGES_SAFE is set as: " << getenv("RDMAV_HUGEPAGES_SAFE") <<  dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " constructing Infiniband..." << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 1) << __func__ << " assigning: " << rx_queue_len << " receive buffers" << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 0) << __func__ << " using the max allowed receive buffers: " << rx_queue_len << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 1) << __func__ << " assigning: " << tx_queue_len << " send buffers"  << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 0) << __func__ << " using the max allowed send buffers: " << tx_queue_len << dendl;
./msg/async/rdma/Infiniband.cc:  ldout(cct, 20) << __func__ << " destroy Queue Pair, qp number: " << qp->qp_num << " left SQ WR " << recv_queue.size() << dendl;
./msg/async/rdma/Infiniband.cc:    ldout(cct, 20) << __func__ << " destroy qp=" << qp << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " bind to rdma point" << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " successfully created cm id: " << cm_id << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " fd of cm_channel is " << server_setup_socket << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 15) << __func__ << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " event name: " << rdma_event_str(cm_event->event) << dendl;
./msg/async/rdma/RDMAIWARPServerSocketImpl.cc:  ldout(cct, 20) << __func__ << " accepted a new QP" << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:    ldout(cct, 20) << __func__ << " successfully created cm id: " << cm_id << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:  ldout(cct, 20) << __func__ << " destruct." << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:      ldout(cct, 20) << __func__ << " qp_num=" << cm_id->qp->qp_num << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:  ldout(cct, 30) << __func__ << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:  ldout(cct, 30) << __func__ << dendl;
./msg/async/rdma/RDMAIWARPConnectedSocketImpl.cc:  ldout(cct, 30) << __func__ << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 20) << __func__ << " destructing rdma dispatcher" << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 30) << __func__ << dendl;
./msg/async/rdma/RDMAStack.cc:    ldout(cct, 1) << __func__ << "Event : " << ibv_event_type_str(async_event.event_type) << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 20) << __func__ << " going to poll tx cq: " << tx_cq << " rx cq: " << rx_cq << dendl;
./msg/async/rdma/RDMAStack.cc:          ldout(cct, 10) << __func__ << " finally delete qp = " << qp << dendl;
./msg/async/rdma/RDMAStack.cc:          ldout(cct, 20) << __func__ << " got tx cq event." << dendl;
./msg/async/rdma/RDMAStack.cc:          ldout(cct, 20) << __func__ << " got rx cq event." << dendl;
./msg/async/rdma/RDMAStack.cc:              ldout(cct, 20) << __func__ << " qp state is " << Infiniband::qp_state_string(qp->get_state()) << dendl;
./msg/async/rdma/RDMAStack.cc:              ldout(cct, 20) << __func__ << " outstanding SQ WR is flushed into CQ since QueuePair is dead " << dendl;
./msg/async/rdma/RDMAStack.cc:              ldout(cct, 1) << __func__ << " Disconnected, qp_num = " << response->qp_num << " discard event" << dendl;
./msg/async/rdma/RDMAStack.cc:      ldout(cct, 1) << __func__ << " sending of the disconnect msg completed" << dendl;
./msg/async/rdma/RDMAStack.cc:      ldout(cct, 1) << __func__ << " not tx buffer, chunk " << chunk << dendl;
./msg/async/rdma/RDMAStack.cc:          ldout(cct, 20) << __func__ << " qp state is " << Infiniband::qp_state_string(qp->get_state()) << dendl;
./msg/async/rdma/RDMAStack.cc:          ldout(cct, 20) << __func__ << " outstanding RQ WR is flushed into CQ since QueuePair is dead " << dendl;
./msg/async/rdma/RDMAStack.cc:    ldout(cct, 1) << __func__ << " try connecting failed." << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 30) << __func__ << " need " << bytes << " bytes, reserve " << got << " registered  bytes, inflight " << dispatcher->inflight << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 20) << __func__ << " pending conns " << pending_sent_conns.size() << dendl;
./msg/async/rdma/RDMAStack.cc:    ldout(cct, 20) << __func__ << " sent pending bl socket=" << o << " r=" << r << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 20) << __func__ << " constructing RDMAStack..." << dendl;
./msg/async/rdma/RDMAStack.cc:  ldout(cct, 20) << " creating RDMAStack:" << this << " with dispatcher:" << rdma_dispatcher.get() << dendl;
./msg/async/EventKqueue.cc:  ldout(cct,30) << __func__ << " on kqfd = " << kqfd << dendl;
./msg/async/EventKqueue.cc:  ldout(cct,10) << __func__ << " kqfd = " << kqfd << dendl;
./msg/async/EventKqueue.cc:      ldout(cct,30) << __func__ << " event_wait: " << " NULL" << dendl;
./msg/async/EventKqueue.cc:  ldout(cct,25) << __func__ << " kevent retval: " << retval << dendl;
./msg/async/AsyncMessenger.cc:  ldout(msgr->cct, 10) << __func__ << " " << bind_addrs << dendl;
./msg/async/AsyncMessenger.cc:  ldout(msgr->cct, 10) << __func__ << " bound to " << *bound_addrs << dendl;
./msg/async/AsyncMessenger.cc:  ldout(msgr->cct, 1) << __func__ << dendl;
./msg/async/AsyncMessenger.cc:  ldout(msgr->cct,10) << __func__ << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,10) << __func__ << " " << get_myaddrs() << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,10) << __func__ << " " << get_myaddrs() << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,10) << __func__ << " " << bind_addr << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct,10) << __func__ << " already started" << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,10) << __func__ << " " << bind_addrs << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << " Network Stack is not ready for bind yet - postponed" << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " rebind avoid " << avoid_ports << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << " already started" << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 10) << __func__ << " " << bind_addr << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " bind my_addrs is " << get_myaddrs() << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 10) << __func__ << " new nonce " << nonce << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " start" << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << ": waiting for dispatch queue" << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << ": dispatch queue is stopped" << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 10) << __func__ << ": done." << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 1) << __func__ << " complete." << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << " " << addrs << " limiting to v1 ()" << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << " " << av << " existing " << conn << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 10) << __func__ << " " << av << " new " << conn << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " " << addrs << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " now " << *my_addrs << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct,1) << __func__ << " " << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 5) << __func__ << " accepting_conn " << c << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 5) << __func__ << " mark down " << e << " " << c << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 5) << __func__ << " mark down " << c << dendl;
./msg/async/AsyncMessenger.cc:        ldout(cct, 5) << __func__ << " delete " << c << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 1) << __func__ << " " << addrs << " -- " << conn << dendl;
./msg/async/AsyncMessenger.cc:    ldout(cct, 1) << __func__ << " " << addrs << " -- connection dne" << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 10) << __func__ << " " << conn << " " << *conn->peer_addrs << dendl;
./msg/async/AsyncMessenger.cc:      ldout(cct,10) << __func__ << " had no addrs" << dendl;
./msg/async/AsyncMessenger.cc:	  ldout(cct,10) << __func__ << " " << a << " -> " << t << dendl;
./msg/async/AsyncMessenger.cc:  ldout(cct, 1) << __func__ << " start" << dendl;
./msg/async/AsyncMessenger.cc:      ldout(cct, 5) << __func__ << " delete " << c << dendl;
./msg/async/Event.cc:          ldout(cct, 1) << __func__ << " read notify pipe failed: " << cpp_strerror(ceph_sock_errno()) << dendl;
./msg/async/Event.cc:  ldout(cct, 2) << __func__ << " center_id=" << center_id << " owner=" << owner << dendl;
./msg/async/Event.cc:    ldout(cct, 20) << __func__ << " event count exceed " << nevent << ", expand to " << new_size << dendl;
./msg/async/Event.cc:  ldout(cct, 30) << __func__ << " id=" << id << " trigger after " << microseconds << "us"<< dendl;
./msg/async/Event.cc:  ldout(cct, 30) << __func__ << " id=" << id << dendl;
./msg/async/Event.cc:    ldout(cct, 10) << __func__ << " id=" << id << " not found" << dendl;
./msg/async/Event.cc:  ldout(cct, 20) << __func__ << dendl;
./msg/async/Event.cc:  ldout(cct, 30) << __func__ << " cur time is " << now << dendl;
./msg/async/Event.cc:      ldout(cct, 30) << __func__ << " process time event: id=" << id << dendl;
./msg/async/Event.cc:  ldout(cct, 30) << __func__ << " wait second " << tv.tv_sec << " usec " << tv.tv_usec << dendl;
./msg/async/Event.cc:      ldout(cct, 30) << __func__ << " do " << e << dendl;
./msg/async/Event.cc:  ldout(cct, 30) << __func__ << " " << e << " pending " << num << dendl;
./erasure-code/lrc/ErasureCodeLrc.cc:  dout(10) << "init(" << description_string << ")" << dendl;
./erasure-code/lrc/ErasureCodeLrc.cc:      dout(20) << __func__ << " minimum = " << *minimum << dendl;
./erasure-code/jerasure/ErasureCodeJerasure.cc:  dout(10) << "technique=" << technique << dendl;
./erasure-code/jerasure/ErasureCodePluginJerasure.cc:    dout(20) << __func__ << ": " << profile << dendl;
./erasure-code/isa/ErasureCodeIsa.cc:      dout(0) << "isa_decode: bad matrix" << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:  dout(12) << "[ get table    ] = " << signature << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:    dout(12) << "[ cached table ] = " << signature << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:    dout(12) << "[ cache size   ] = " << decode_tbls_lru->size() << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:  dout(12) << "[ put table    ] = " << signature << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:    dout(12) << "[ shrink lru   ] = " << signature << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:    dout(12) << "[ store table  ] = " << signature << dendl;
./erasure-code/isa/ErasureCodeIsaTableCache.cc:    dout(12) << "[ cache size   ] = " << decode_tbls_lru->size() << dendl;
./erasure-code/shec/ErasureCodeShec.cc:    dout(10) << "(k, m, c) must be chosen" << dendl;
./erasure-code/shec/ErasureCodeShec.cc:    dout(10) << "w default to " << DEFAULT_W << dendl;
./erasure-code/shec/ErasureCodeShec.cc:      dout(10) << "w default to " << DEFAULT_W << dendl;
./erasure-code/shec/ErasureCodeShec.cc:      dout(10) << "w default to " << DEFAULT_W << dendl;
./erasure-code/shec/ErasureCodeShec.cc:      dout(10) << "w set to " << w << dendl;
./erasure-code/shec/ErasureCodeShec.cc:    dout(10) << "matrix = " << dendl;
./erasure-code/shec/ErasureCodeShec.cc:      dout(10) << mat << dendl;
./erasure-code/shec/ErasureCodeShec.cc:    dout(10) << __func__ << ": can't find recover matrix." << dendl;
./erasure-code/shec/ErasureCodePluginShec.cc:    dout(10) << "ErasureCodePluginShec: factory() completed" << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:  dout(20) << "[ get table    ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:  dout(20) << "[ cached table ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:  dout(20) << "[ put table    ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:    dout(20) << "[ already on table ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:    dout(20) << "[ shrink lru   ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:    dout(20) << "[ store table  ] = " << signature << dendl;
./erasure-code/shec/ErasureCodeShecTableCache.cc:    dout(20) << "[ cache size   ] = " << decode_tbls_lru->size() << dendl;
./erasure-code/clay/ErasureCodeClay.cc:    dout(0) << "minimum_to_repair: shouldn't have come here" << dendl;
./mds/MDBalancer.cc:  dout(20) << "export_pin_queue size=" << q.size() << dendl;
./mds/MDBalancer.cc:      dout(20) << " delay export_pin=" << export_pin << " on " << *in << dendl;
./mds/MDBalancer.cc:    dout(20) << " executing export_pin=" << export_pin << " on " << *in << dendl;
./mds/MDBalancer.cc:	  dout(10) << " clear auxsubtree on " << *dir << dendl;
./mds/MDBalancer.cc:	  dout(10) << " create aux subtree on " << *dir << dendl;
./mds/MDBalancer.cc:	  dout(10) << " set auxsubtree bit on " << *dir << dendl;
./mds/MDBalancer.cc:      dout(25) << "auth tree " << *cd << " export_pin=" << export_pin << dendl;
./mds/MDBalancer.cc:    dout(15) << "tick last_sample now " << now << dendl;
./mds/MDBalancer.cc:    dout(20) << "no root, no load" << dendl;
./mds/MDBalancer.cc:  dout(15) << load << dendl;
./mds/MDBalancer.cc:    dout(10) "bal_code=" << bal_code << dendl;
./mds/MDBalancer.cc:    dout(10) << "degraded" << dendl;
./mds/MDBalancer.cc:    dout(10) << "not open" << dendl;
./mds/MDBalancer.cc:  dout(3) << " epoch " << beat_epoch << " load " << load << dendl;
./mds/MDBalancer.cc:    dout(5) << "  import_map from " << rank << " -> " << load << dendl;
./mds/MDBalancer.cc:  dout(25) << "=== got heartbeat " << m->get_beat() << " from " << m->get_source().num() << " " << m->get_load() << dendl;
./mds/MDBalancer.cc:    dout(10) << "opening root on handle_heartbeat" << dendl;
./mds/MDBalancer.cc:    dout(10) << " degraded, ignoring" << dendl;
./mds/MDBalancer.cc:    dout(10) << "receive next epoch " << m->get_beat() << " from mds." << who << " before mds0" << dendl;
./mds/MDBalancer.cc:    dout(20) << " from mds0, new epoch " << m->get_beat() << dendl;
./mds/MDBalancer.cc:      dout(10) << " old heartbeat epoch, ignoring" << dendl;
./mds/MDBalancer.cc:  dout(5) << "   - mds." << ex << " exports " << howmuch << " to mds." << im << dendl;
./mds/MDBalancer.cc:      dout(10) << "drop split on " << df << " because not in cache" << dendl;
./mds/MDBalancer.cc:      dout(10) << "drop split on " << df << " because non-auth" << dendl;
./mds/MDBalancer.cc:    dout(10) << __func__ << " splitting " << *dir << dendl;
./mds/MDBalancer.cc:      dout(10) << "drop merge on " << frag << " because not in cache" << dendl;
./mds/MDBalancer.cc:      dout(10) << "drop merge on " << *dir << " because lost auth" << dendl;
./mds/MDBalancer.cc:    dout(10) << "merging " << *dir << dendl;
./mds/MDBalancer.cc:        dout(10) << "  not all sibs under " << sibfg << " in cache (have " << sibs << ")" << dendl;
./mds/MDBalancer.cc:        dout(10) << "  not all sibs under " << sibfg << " " << sibs << " should_merge" << dendl;
./mds/MDBalancer.cc:      dout(10) << "  all sibs under " << sibfg << " " << sibs << " should merge" << dendl;
./mds/MDBalancer.cc:    dout(20) << " enqueued dir " << *dir << dendl;
./mds/MDBalancer.cc:    dout(20) << " dir already in queue " << *dir << dendl;
./mds/MDBalancer.cc:    dout(7) << "cluster loads are" << dendl;
./mds/MDBalancer.cc:	dout(7) << " mds." << rank << " is underloaded or barely overloaded." << dendl;
./mds/MDBalancer.cc:      dout(7) << "  i am underloaded or barely overloaded, doing nothing." << dendl;
./mds/MDBalancer.cc:      dout(7) << "  i am overloaded, but only for " << (beat_epoch - last_epoch_under) << " epochs" << dendl;
./mds/MDBalancer.cc:    dout(7) << "  i am sufficiently overloaded" << dendl;
./mds/MDBalancer.cc:	dout(15) << "   mds." << it->second << " is importer" << dendl;
./mds/MDBalancer.cc:	  dout(15) << "   mds." << it->second << " is exporter" << dendl;
./mds/MDBalancer.cc:      dout(15) << "  matching exporters to import sources" << dendl;
./mds/MDBalancer.cc:      dout(15) << "  matching big exporters to big importers" << dendl;
./mds/MDBalancer.cc:      dout(15) << "  matching small exporters to big importers" << dendl;
./mds/MDBalancer.cc:  dout(7) << " mantle decided that new targets=" << state.targets << dendl;
./mds/MDBalancer.cc:    dout(15) << "  map: i imported " << *dir << " from " << from << dendl;
./mds/MDBalancer.cc:      dout(7) << " aha, looking through imports from target mds." << target << dendl;
./mds/MDBalancer.cc:	dout(7) << "considering " << *dir << " from " << (*p.first).first << dendl;
./mds/MDBalancer.cc:	  dout(7) << "can't reexport " << *dir << ", too big " << pop << dendl;
./mds/MDBalancer.cc:  dout(7) << "done" << dendl;
./mds/MDBalancer.cc:  dout(7) << "in " << dir_pop << " " << *dir << " need " << need << " (" << needmin << " - " << needmax << ")" << dendl;
./mds/MDBalancer.cc:      dout(15) << "   subdir pop " << pop << " " << *subdir << dendl;
./mds/MDBalancer.cc:  dout(15) << "   sum " << subdir_sum << " / " << dir_pop << dendl;
./mds/MDBalancer.cc:    dout(7) << "   taking smaller " << *(*it).second << dendl;
./mds/MDBalancer.cc:    dout(15) << "   descending into " << *dir << dendl;
./mds/MDBalancer.cc:    dout(7) << "   taking (much) smaller " << it->first << " " << *(*it).second << dendl;
./mds/MDBalancer.cc:    dout(7) << "   descending into replicated " << *dir << dendl;
./mds/MDBalancer.cc:	dout(5) << "replicating dir " << *dir << " pop " << dir_pop << " .. rdp " << rdp << " adj " << rd_adj << dendl;
./mds/MDBalancer.cc:	dout(5) << "unreplicating dir " << *dir << " pop " << dir_pop << dendl;
./mds/MDBalancer.cc:    dout(10) << "no root" << dendl;
./mds/MDSDaemon.cc:      dout(1) << "Can't run that command on an inactive MDS!" << dendl;
./mds/MDSDaemon.cc:  dout(10) << "Dumping misc struct sizes:" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(MDSCacheObject) << "\tMDSCacheObject" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(CInode) << "\tCInode" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(elist<void*>::item) << "\telist<>::item" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(CInode::mempool_inode) << "\tinode" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(CInode::mempool_old_inode) << "\told_inode" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(nest_info_t) << "\tnest_info_t" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(frag_info_t) << "\tfrag_info_t" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(SimpleLock) << "\tSimpleLock" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(ScatterLock) << "\tScatterLock" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(CDentry) << "\tCDentry" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(elist<void*>::item) << "\telist<>::item" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(SimpleLock) << "\tSimpleLock" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(CDir) << "\tCDir" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(elist<void*>::item) << "\telist<>::item" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(fnode_t) << "\tfnode_t" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(nest_info_t) << "\tnest_info_t" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(frag_info_t) << "\tfrag_info_t" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(Capability) << "\tCapability" << dendl;
./mds/MDSDaemon.cc:  dout(10) << sizeof(xlist<void*>::item) << "\txlist<>::item" << dendl;
./mds/MDSDaemon.cc:    dout(4) << __func__ << ": terminated already, dropping out" << dendl;
./mds/MDSDaemon.cc:    dout(4) << __func__ << ": terminated already, dropping out" << dendl;
./mds/MDSDaemon.cc:  dout(1) << "Updating MDS map to version " << epoch << " from " << m->get_source() << dendl;
./mds/MDSDaemon.cc:  dout(10) << "     my compat " << mdsmap_compat << dendl;
./mds/MDSDaemon.cc:  dout(10) << " mdsmap compat " << mdsmap->compat << dendl;
./mds/MDSDaemon.cc:  dout(10) << "my gid is " << myid << dendl;
./mds/MDSDaemon.cc:  dout(10) << "msgr says I am " << addrs << dendl;
./mds/MDSDaemon.cc:      dout(10) << " peer mds gid " << gid << " removed from map" << dendl;
./mds/MDSDaemon.cc:    dout(10) <<  __func__ << ": handling map in rankless mode" << dendl;
./mds/MDSDaemon.cc:        dout(1) << "Monitors have assigned me to become a standby." << dendl;
./mds/MDSDaemon.cc:        dout(5) << "I am still standby" << dendl;
./mds/MDSDaemon.cc:      dout(10) << "not in map yet" << dendl;
./mds/MDSDaemon.cc:  dout(1) << "respawn!" << dendl;
./mds/MDSDaemon.cc:  dout(1) << " e: '" << orig_argv[0] << "'" << dendl;
./mds/MDSDaemon.cc:    dout(1) << " " << i << ": '" << orig_argv[i] << "'" << dendl;
./mds/MDSDaemon.cc:    dout(1) << "respawning with exe " << exe_path << dendl;
./mds/MDSDaemon.cc:    dout(1) << " cwd " << cwd << dendl;
./mds/MDSDaemon.cc:  dout(1) << " exe_path " << exe_path << dendl;
./mds/MDSDaemon.cc:    dout(10) << " stopping, discarding " << *m << dendl;
./mds/MDSDaemon.cc:  dout(5) << "ms_handle_reset on " << con->get_peer_socket_addr() << dendl;
./mds/MDSDaemon.cc:      dout(3) << "ms_handle_reset closing connection for session " << session->info.inst << dendl;
./mds/MDSDaemon.cc:  dout(5) << "ms_handle_remote_reset on " << con->get_peer_socket_addr() << dendl;
./mds/MDSDaemon.cc:      dout(3) << "ms_handle_remote_reset closing connection for session " << session->info.inst << dendl;
./mds/MDSDaemon.cc:      dout(1) << __func__ << ": cannot decode auth caps buffer of length " << info.caps.length() << dendl;
./mds/MDSDaemon.cc:    dout(10) << __func__ << ": parsing auth_cap_str='" << auth_cap_str << "'" << dendl;
./mds/MDSDaemon.cc:      dout(1) << __func__ << ": auth cap parse error: " << cs->strv() << " parsing '" << auth_cap_str << "'" << dendl;
./mds/MDSDaemon.cc:  dout(10) << "ms_handle_accept " << con->get_peer_socket_addr() << " con " << con << " session " << s << dendl;
./mds/SnapRealm.cc:  dout(10) << "build_snap_set on " << *this << dendl;
./mds/SnapRealm.cc:  dout(10) << "get_snap_info snaps " << snaps << dendl;
./mds/SnapRealm.cc:  dout(10) << "resolve_snapname '" << n << "' in [" << first << "," << last << "]" << dendl;
./mds/SnapRealm.cc:      dout(10) << " " << n << " parses to name '" << pname << "' dirino " << pino << dendl;
./mds/SnapRealm.cc:    dout(15) << " ? " << p->second << dendl;
./mds/SnapRealm.cc:      dout(15) << " ? " << *it.second << dendl;
./mds/SnapRealm.cc:    dout(10) << "adjust_parent " << parent << " -> " << newparent << dendl;
./mds/SnapRealm.cc:      dout(20) << " split no-op, no caps to move on file " << *child->inode << dendl;
./mds/SnapRealm.cc:  dout(10) << " open_children are " << open_children << dendl;
./mds/SnapRealm.cc:      dout(20) << " child gets child realm " << *realm << " on " << *realm->inode << dendl;
./mds/SnapRealm.cc:      dout(20) << "    keeping child realm " << *realm << " on " << *realm->inode << dendl;
./mds/SnapRealm.cc:      dout(20) << " child gets " << *in << dendl;
./mds/SnapRealm.cc:      dout(20) << "    keeping " << *in << dendl;
./mds/SnapRealm.cc:  dout(10) << "merge to " << *newparent << " on " << *newparent->inode << dendl;
./mds/SnapRealm.cc:  dout(10) << " open_children are " << open_children << dendl;
./mds/SnapRealm.cc:    dout(20) << " child realm " << *realm << " on " << *realm->inode << dendl;
./mds/SnapRealm.cc:    dout(10) << "build_snap_trace my_snaps " << info.my_snaps << dendl;
./mds/SnapRealm.cc:  dout(10) << "build_snap_trace my_snaps " << info.my_snaps << dendl;
./mds/SnapRealm.cc:  dout(10) << __func__ << dendl;
./mds/SnapRealm.cc:      dout(10) << __func__ << " pruning " << *p << dendl;
./mds/SnapRealm.cc:      dout(10) << __func__ << " keeping " << *p << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:      dout(5) << __func__ << ": read-only FS" << dendl;
./mds/MDSRank.cc:      dout(5) << __func__ << ": MDS not active, no-op" << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(5) << __func__ << ": beginning segment expiry" << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:      dout(5) << __func__ << ": write_head complete, all done!" << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": r=" << r << dendl;
./mds/MDSRank.cc:  dout(20) << "updating export targets, currently " << map_targets.size() << " ranks are targets" << dendl;
./mds/MDSRank.cc:    dout(20) << "export target mds." << rank << " is " << counter << dendl;
./mds/MDSRank.cc:      dout(15) << "export target mds." << rank << " is no longer an export target" << dendl;
./mds/MDSRank.cc:      dout(15) << "export target mds." << rank << " not in map's export_targets" << dendl;
./mds/MDSRank.cc:    dout(15) << "export target map holds stale targets, sending update" << dendl;
./mds/MDSRank.cc:    dout(15) << "updating export_targets, now " << new_map_targets.size() << " ranks are targets" << dendl;
./mds/MDSRank.cc:    dout(15) << "hit export target (new) is " << counter << dendl;
./mds/MDSRank.cc:    dout(15) << "hit export target is " << counter << dendl;
./mds/MDSRank.cc:    dout(1) << __func__ << ": mon command " << cmd << " succeed" << dendl;
./mds/MDSRank.cc:  dout(0) << __func__ << ": sending mon command: " << cmd[0] << dendl;
./mds/MDSRank.cc:    dout(1) << "skipping upkeep work because connection to Monitors appears laggy" << dendl;
./mds/MDSRank.cc:      dout(7) << "shutdown_pass=false" << dendl;
./mds/MDSRank.cc:  dout(1) << __func__ << ": shutting down rank " << whoami << dendl;
./mds/MDSRank.cc:      dout(0) << typeid(*msg).name() << " is not an MMDSOp type" << dendl;
./mds/MDSRank.cc:    dout(5) << " laggy, deferring " << *m << dendl;
./mds/MDSRank.cc:    dout(5) << " there are deferred messages, deferring " << *m << dendl;
./mds/MDSRank.cc:    dout(7) << "mds thrashing exports pass " << (i+1) << "/" << g_conf()->mds_thrash_exports << dendl;
./mds/MDSRank.cc:    dout(7) << "mds thrashing fragments pass " << (i+1) << "/" << g_conf()->mds_thrash_fragments << dendl;
./mds/MDSRank.cc:    dout(0) << "hashing root" << dendl;
./mds/MDSRank.cc:    dout(7) << "mds has " << finished_queue.size() << " queued contexts" << dendl;
./mds/MDSRank.cc:      dout(10) << " finish " << fin << dendl;
./mds/MDSRank.cc:      dout(7) << " processing laggy deferred " << *old << dendl;
./mds/MDSRank.cc:    dout(20) << "get_session dne for " << m->get_source_inst() << dendl;
./mds/MDSRank.cc:    dout(10) << "send_message_mds mds." << mds << " not up, dropping " << *m << dendl;
./mds/MDSRank.cc:    dout(10) << "send_message_client_counted no session for client." << client << " " << *m << dendl;
./mds/MDSRank.cc:    dout(10) << "send_message_client_counted has no session for " << m->get_source_inst() << dendl;
./mds/MDSRank.cc:  dout(10) << "send_message_client " << session->info.inst << " " << *m << dendl;
./mds/MDSRank.cc:  dout(4) << __func__ << ": epoch=" << e << dendl;
./mds/MDSRank.cc:  dout(3) << "request_state " << ceph_mds_state_name(s) << dendl;
./mds/MDSRank.cc:      dout(0) << "boot error forcing transition to read-only; MDS will try to continue" << dendl;
./mds/MDSRank.cc:      dout(0) << "boot_start encountered an error, failing" << dendl;
./mds/MDSRank.cc:        dout(2) << "Booting: " << step << ": opening inotable" << dendl;
./mds/MDSRank.cc:        dout(2) << "Booting: " << step << ": opening sessionmap" << dendl;
./mds/MDSRank.cc:        dout(2) << "Booting: " << step << ": opening mds log" << dendl;
./mds/MDSRank.cc:	  dout(2) << "Booting: " << step << ": opening purge queue" << dendl;
./mds/MDSRank.cc:	  dout(2) << "Booting: " << step << ": opening purge queue (async)" << dendl;
./mds/MDSRank.cc:	  dout(2) << "Booting: " << step << ": loading open file table (async)" << dendl;
./mds/MDSRank.cc:          dout(2) << "Booting: " << step << ": opening snap table" << dendl;
./mds/MDSRank.cc:        dout(2) << "Booting: " << step << ": loading/discovering base inodes" << dendl;
./mds/MDSRank.cc:	dout(2) << "Booting: " << step << ": replaying mds log" << dendl;
./mds/MDSRank.cc:	  dout(2) << "Booting: " << step << ": waiting for purge queue recovered" << dendl;
./mds/MDSRank.cc:        dout(2) << "Booting: " << step << ": positioning at end of old mds log" << dendl;
./mds/MDSRank.cc:  dout(3) << "starting_done" << dendl;
./mds/MDSRank.cc:  dout(1) << " recovery set is " << rs << dendl;
./mds/MDSRank.cc:  dout(1) << "replay_start" << dendl;
./mds/MDSRank.cc:    dout(0) << "standby MDS fell behind active MDS journal's expire_pos, restarting" << dendl;
./mds/MDSRank.cc:    dout(5) << "Restarting replay as standby-replay" << dendl;
./mds/MDSRank.cc:    dout(1) << "standby_replay_restart (final takeover pass)" << dendl;
./mds/MDSRank.cc:      dout(1) << " opening purge_queue (async)" << dendl;
./mds/MDSRank.cc:      dout(1) << " opening open_file_table (async)" << dendl;
./mds/MDSRank.cc:    dout(1) << "Finished replaying journal" << dendl;
./mds/MDSRank.cc:    dout(5) << "Finished replaying journal as standby-replay" << dendl;
./mds/MDSRank.cc:    dout(10) << "setting replay timer" << dendl;
./mds/MDSRank.cc:    dout(10) << " last replay pass was as a standby; making final pass" << dendl;
./mds/MDSRank.cc:        dout(4) << "reformatting journal on standby-replay->replay transition" << dendl;
./mds/MDSRank.cc:  dout(1) << "making mds journal writeable" << dendl;
./mds/MDSRank.cc:    dout(1) << "upgrading snaptable format" << dendl;
./mds/MDSRank.cc:    dout(1) << "wiping out client sessions" << dendl;
./mds/MDSRank.cc:    dout(1) << "wiping out ino prealloc from sessions" << dendl;
./mds/MDSRank.cc:    dout(1) << "skipping " << i << " inodes" << dendl;
./mds/MDSRank.cc:    dout(2) << "i am alone, moving to state reconnect" << dendl;
./mds/MDSRank.cc:    dout(2) << "i am not alone, moving to state resolve" << dendl;
./mds/MDSRank.cc:  dout(1) << "reopen_log" << dendl;
./mds/MDSRank.cc:  dout(1) << "resolve_start" << dendl;
./mds/MDSRank.cc:  dout(1) << "resolve_done" << dendl;
./mds/MDSRank.cc:  dout(1) << "reconnect_start" << dendl;
./mds/MDSRank.cc:  dout(1) << "reconnect_done" << dendl;
./mds/MDSRank.cc:  dout(1) << "rejoin_joint_start" << dendl;
./mds/MDSRank.cc:  dout(1) << "rejoin_start" << dendl;
./mds/MDSRank.cc:  dout(1) << "rejoin_done" << dendl;
./mds/MDSRank.cc:    dout(1) << " waiting for uncommitted fragments" << dendl;
./mds/MDSRank.cc:      dout(1) << " empty cache, no subtrees, leaving cluster" << dendl;
./mds/MDSRank.cc:  dout(1) << "clientreplay_start" << dendl;
./mds/MDSRank.cc:  dout(1) << "clientreplay_done" << dendl;
./mds/MDSRank.cc:  dout(1) << "active_start" << dendl;
./mds/MDSRank.cc:  dout(10) << __func__ << ": initializing metrics handler" << dendl;
./mds/MDSRank.cc:    dout(10) << __func__ << ": initializing metric aggregator" << dendl;
./mds/MDSRank.cc:  dout(1) << "recovery_done -- successful recovery!" << dendl;
./mds/MDSRank.cc:  dout(1)<< "creating_done" << dendl;
./mds/MDSRank.cc:  dout(3) << "boot_create" << dendl;
./mds/MDSRank.cc:  dout(10) << "boot_create creating fresh journal" << dendl;
./mds/MDSRank.cc:    dout(3) << "boot_create creating fresh hierarchy" << dendl;
./mds/MDSRank.cc:  dout(3) << "boot_create creating mydir hierarchy" << dendl;
./mds/MDSRank.cc:  dout(3) << "boot_create creating global snaprealm" << dendl;
./mds/MDSRank.cc:  dout(10) << "boot_create creating fresh inotable table" << dendl;
./mds/MDSRank.cc:    dout(10) << "boot_create creating fresh snaptable" << dendl;
./mds/MDSRank.cc:  dout(2) << "Stopping..." << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << " matched " << victims.size() << " sessions" << dendl;
./mds/MDSRank.cc:  dout(2) << "Finished stopping..." << dendl;
./mds/MDSRank.cc:      dout(1) << "handle_mds_map i am now mds." << whoami << "." << incarnation << dendl;
./mds/MDSRank.cc:        dout(10) << "Monitor activated us! Deactivating replay loop" << dendl;
./mds/MDSRank.cc:      dout(10) << " resolve set is " << resolve << dendl;
./mds/MDSRank.cc:    dout(1) << "cluster recovered." << dendl;
./mds/MDSRank.cc:    dout(0) << "WARNING: inline_data support has been deprecated and will be removed in a future release" << dendl;
./mds/MDSRank.cc:  dout(5) << "handle_mds_recovery mds." << who << dendl;
./mds/MDSRank.cc:    dout(5) << "handle_mds_failure for myself; not doing anything" << dendl;
./mds/MDSRank.cc:  dout(5) << "handle_mds_failure mds." << who << dendl;
./mds/MDSRank.cc:    dout(4) << __func__ << ": possibly waiting for OSD epoch " << target_epoch << dendl;
./mds/MDSRank.cc:      dout(15) << css->strv() << dendl;
./mds/MDSRank.cc:  dout(20) << __func__ << " matched " << victims.size() << " sessions" << dendl;
./mds/MDSRank.cc:  dout(10) << __func__ << " log_to_monitors " << log_to_monitors << dendl;
./mds/MDSRank.cc:  dout(10) << "create_logger" << dendl;
./mds/MDSRank.cc:    dout(1) << css->strv() << dendl;
./mds/MDSRank.cc:  dout(4) << "Preparing blocklist command... (wait=" << wait << ")" << dendl;
./mds/MDSRank.cc:    dout(4) << "Sending mon blocklist command: " << cmd[0] << dendl;
./mds/MDSRank.cc:  dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(10) << "flushing conf change to components: " << changed << dendl;
./mds/MDSRank.cc:  dout(20) << __func__ << dendl;
./mds/MDSRank.cc:  dout(20) << __func__ << dendl;
./mds/MDSRank.cc:    dout(20) << __func__ << ": updating " << status.size() << " status keys" << dendl;
./mds/RecoveryQueue.cc:      dout(10) << "already working on " << *in << ", set need_restart flag" << dendl;
./mds/RecoveryQueue.cc:    dout(10) << "skipping " << pi->size << " " << *in << dendl;
./mds/RecoveryQueue.cc:    dout(10) << "already working on " << *in << dendl;
./mds/RecoveryQueue.cc:    dout(20) << *in << dendl;
./mds/RecoveryQueue.cc:  dout(10) << "not queued " << *in << dendl;
./mds/RecoveryQueue.cc:  dout(15) << "RecoveryQueue::enqueue " << *in << dendl;
./mds/RecoveryQueue.cc:    dout(0) << "recovery error! " << r << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " " << *m << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " " << *m << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " tid " << tid << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " want " << want << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " " << snaps << " -> " << result <<  dendl;
./mds/SnapClient.cc:  dout(10) << __func__ << " snapid " << snapid << " -> " << result <<  dendl;
./mds/SnapClient.cc:    dout(5) << "dump_cache: not synced" << dendl;
./mds/JournalPointer.cc:  dout(4) << "Reading journal pointer '" << object_id << "'" << dendl;
./mds/JournalPointer.cc:    dout(1) << "Journal pointer '" << object_id << "' read failed: " << cpp_strerror(r) << dendl;
./mds/Locker.cc:  dout(10) << __func__ << " " << *mdr << " " << *in << dendl;
./mds/Locker.cc:      dout(20) << " got rdlock on " << t->snaplock << " " << *t << dendl;
./mds/Locker.cc:	dout(20) << " got rdlock on " << t->policylock << " " << *t << dendl;
./mds/Locker.cc:  dout(10) << __func__ << " failed" << dendl;
./mds/Locker.cc:  dout(10) << "acquire_locks " << *mdr << dendl;
./mds/Locker.cc:      dout(20) << " must xlock " << *lock << " " << *object << dendl;
./mds/Locker.cc:      dout(20) << " must wrlock " << *lock << " " << *object << dendl;
./mds/Locker.cc:      dout(20) << " must rdlock " << *lock << " " << *object << dendl;
./mds/Locker.cc:    dout(10) << " must authpin " << *object << dendl;
./mds/Locker.cc:	dout(10) << " ambiguous auth, waiting to authpin " << *object << dendl;
./mds/Locker.cc:	dout(10) << " can't auth_pin (freezing?) " << *object << ", nonblocking" << dendl;
./mds/Locker.cc:      dout(10) << " can't auth_pin (freezing?), waiting to authpin " << *object << dendl;
./mds/Locker.cc:      dout(10) << " already auth_pinned " << *object << dendl;
./mds/Locker.cc:      dout(10) << " auth_pinning " << *object << dendl;
./mds/Locker.cc:      dout(10) << "requesting remote auth_pins from mds." << p.first << dendl;
./mds/Locker.cc:	dout(10) << " mds." << p.first << " is not active" << dendl;
./mds/Locker.cc:	dout(10) << " req remote auth_pin of " << *o << dendl;
./mds/Locker.cc:	dout(10) << " already xlocked " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:      dout(10) << " got xlock on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:	  dout(10) << " already remote_wrlocked " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:	  dout(10) << " already wrlocked " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:	dout(10) << " got wrlock on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:	dout(10) << " already rdlocked " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:      dout(10) << " got rdlock on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(10) << "set_xlocks_done on " << *p.lock << " " << *obj << dendl;
./mds/Locker.cc:      dout(10) << "_drop_non_rdlocks dropping remote locks on mds." << *p << dendl;
./mds/Locker.cc:  dout(10) << "cancel_locking " << *lock << " on " << *mut << dendl;
./mds/Locker.cc:  dout(10) << "invalidate_lock_caches on " << *dir << dendl;
./mds/Locker.cc:  dout(10) << "invalidate_lock_caches " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "create_lock_cache for client." << client << "/" << ceph_mds_op_name(opcode)<< " on " << *diri << dendl;
./mds/Locker.cc:    dout(10) << " dir inode is not auth, noop" << dendl;
./mds/Locker.cc:    dout(10) << " there are peers requests for " << *mdr << ", noop" << dendl;
./mds/Locker.cc:    dout(10) << " there is no cap for client." << client << ", noop" << dendl;
./mds/Locker.cc:      dout(10) << " lock cache already exists for " << ceph_mds_op_name(opcode) << ", noop" << dendl;
./mds/Locker.cc:	dout(10) << " can't auth_pin(freezing?) lock parent " << *p.first << ", noop" << dendl;
./mds/Locker.cc:	  dout(10) << " can't auth_pin(!auth|freezing?) dirfrag " << *dir << ", noop" << dendl;
./mds/Locker.cc:      dout(10) << " can't auth_pin(!auth|freezing?) dirfrag " << *dir << ", noop" << dendl;
./mds/Locker.cc:      dout(10) << " there is freezing/frozen inode in " << *dir << ", noop" << dendl;
./mds/Locker.cc:      dout(10) << " unstable " << *p.lock << " on " << *obj << ", noop" << dendl;
./mds/Locker.cc:      dout(10) << "found lock cache for " << ceph_mds_op_name(opcode) << " on " << *diri << dendl;
./mds/Locker.cc:  dout(10) << "eval_gather " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:	dout(7) << "eval_gather finished gather, but still recovering" << dendl;
./mds/Locker.cc:	dout(7) << "eval_gather finished gather, but need to recover" << dendl;
./mds/Locker.cc:	dout(10) << " finished (local) gather for mix->lock, now gathering from replicas" << dendl;
./mds/Locker.cc:      dout(10) << "  trying to drop loner" << dendl;
./mds/Locker.cc:	dout(10) << "  dropped loner" << dendl;
./mds/Locker.cc:  dout(10) << "eval " << mask << " " << *in << dendl;
./mds/Locker.cc:      dout(10) << "eval set loner: client." << orig_loner << " -> client." << in->get_loner() << dendl;
./mds/Locker.cc:      dout(10) << "eval want loner: client." << in->get_wanted_loner() << " but failed to set it" << dendl;
./mds/Locker.cc:	dout(10) << "eval end set loner to client." << in->get_loner() << dendl;
./mds/Locker.cc:  dout(10) << "eval done" << dendl;
./mds/Locker.cc:    dout(7) << "try_eval ambiguous auth, waiting on " << *p << dendl;
./mds/Locker.cc:    dout(7) << "try_eval frozen, waiting on " << *p << dendl;
./mds/Locker.cc:    dout(7) << "try_eval " << *lock << " ambiguousauth, waiting on " << *p << dendl;
./mds/Locker.cc:    dout(7) << "try_eval " << *lock << " not auth for " << *p << dendl;
./mds/Locker.cc:    dout(7) << "try_eval " << *lock << " frozen, waiting on " << *p << dendl;
./mds/Locker.cc:    dout(7) << "try_eval " << *lock << " freezing, waiting on " << *p << dendl;
./mds/Locker.cc:  dout(10) << "eval_scatter_gathers " << *in << dendl;
./mds/Locker.cc:  dout(7) << "rdlock_try on " << *lock << " on " << *lock->get_parent() << dendl;  
./mds/Locker.cc:  dout(7) << "rdlock_start  on " << *lock << " on " << *lock->get_parent() << dendl;  
./mds/Locker.cc:	dout(10) << "rdlock_start trying head inode " << *head << dendl;
./mds/Locker.cc:  dout(7) << "rdlock_start waiting on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "nudge_log " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "rdlock_finish on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << __func__  << dendl;
./mds/Locker.cc:    dout(20) << " got rdlock on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << __func__ << " failed" << dendl;
./mds/Locker.cc:  dout(10) << __func__  << dendl;
./mds/Locker.cc:  dout(10) << "wrlock_try " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "wrlock_start " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "wrlock_start waiting on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "wrlock_finish on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "remote_wrlock_start mds." << target << " on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(7) << " mds." << target << " is not active" << dendl;
./mds/Locker.cc:  dout(7) << "xlock_start on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:      dout(7) << " mds." << auth << " is not active" << dendl;
./mds/Locker.cc:  dout(10) << "xlock_finish on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(7) << "xlock_finish releasing remote xlock on " << *lock->get_parent()  << dendl;
./mds/Locker.cc:  dout(10) << "xlock_export on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "xlock_import on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "xlock_downgrade on " << *lock << " " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "issue_file_data_version on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "file_update_finish on " << *in << dendl;
./mds/Locker.cc:      dout(10) << " no session for client." << client << " " << *ack << dendl;
./mds/Locker.cc:    dout(10) << " client_snap_caps " << in->client_snap_caps << dendl;
./mds/Locker.cc:  dout(7) << "issue_new_caps for mode " << mode << " on " << *in << dendl;
./mds/Locker.cc:	dout(20) << "  !revoke and new|suppressed|stale, skipping client." << it->first << dendl;
./mds/Locker.cc:	dout(20) << "  revoke stale cap from client." << it->first << dendl;
./mds/Locker.cc:  dout(7) << "issue_truncate on " << *in << dendl;
./mds/Locker.cc:  dout(7) << __func__ << " client." << client << " on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "revoke_stale_caps for " << session->info.inst.name << dendl;
./mds/Locker.cc:    dout(10) << " revoking " << ccap_string(issued) << " on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "resume_stale_caps for " << session->info.inst.name << dendl;
./mds/Locker.cc:    dout(10) << " clearing stale flag on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "remove_stale_leases for " << session->info.inst.name << dendl;
./mds/Locker.cc:    dout(15) << " removing lease on " << *parent << dendl;
./mds/Locker.cc:  dout(7) << "handle_inode_file_caps replica mds." << from << " wants caps " << ccap_string(m->get_caps()) << " on " << *in << dendl;
./mds/Locker.cc:    dout(20) << "check_inode_max_size no-op on " << *in << dendl;
./mds/Locker.cc:    dout(10) << "check_inode_max_size frozen, waiting on " << *in << dendl;
./mds/Locker.cc:      dout(10) << "check_inode_max_size can't wrlock, waiting on " << *in << dendl;
./mds/Locker.cc:    dout(10) << "check_inode_max_size size " << pi.inode->size << " -> " << new_size << dendl;
./mds/Locker.cc:    dout(10) << "check_inode_max_size mtime " << pi.inode->mtime << " -> " << new_mtime << dendl;
./mds/Locker.cc:  dout(10) << "share_inode_max_size on " << *in << dendl;
./mds/Locker.cc:      dout(10) << "share_inode_max_size with client." << client << dendl;
./mds/Locker.cc:    dout(10) << "mark_need_snapflush_inode " << *in << " - added at " << now << dendl;
./mds/Locker.cc:  dout(10) << "_do_null_snapflush client." << client << " on " << *head_in << dendl;
./mds/Locker.cc:      dout(10) << " doing async NULL snapflush on " << snapid << " from client." << client << dendl;
./mds/Locker.cc:      dout(5) << " no session, dropping " << *m << dendl;
./mds/Locker.cc:      dout(7) << " session closed|closing|killing, dropping " << *m << dendl;
./mds/Locker.cc:	dout(20) << __func__ << " " << css->strv() << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_caps on unknown ino " << m->get_ino() << ", dropping" << dendl;
./mds/Locker.cc:  dout(10) << " head inode " << *head_in << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_caps no cap for client." << client << " on " << *head_in << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_caps freezing|frozen on " << *head_in << dendl;
./mds/Locker.cc:      dout(7) << " not auth, ignoring flushsnap on " << *head_in << dendl;
./mds/Locker.cc:    dout(10) << "  flushsnap follows " << follows << " -> snap " << snap << dendl;
./mds/Locker.cc:	dout(10) << " snapped inode " << *in << dendl;
./mds/Locker.cc:      dout(7) << " not expecting flushsnap " << snap << " from client." << client << " on " << *in << dendl;
./mds/Locker.cc:    dout(7) << " ignoring client capid " << m->get_cap_id() << " != my " << cap->get_cap_id() << dendl;
./mds/Locker.cc:	  dout(10) << " updating intermediate snapped inode " << *in << dendl;
./mds/Locker.cc:      dout(10) << " confirming not issued caps " << ccap_string(caps & ~cap->issued()) << dendl;
./mds/Locker.cc:	dout(10) << " revocation in progress, not making any conclusions about null snapflushes" << dendl;
./mds/Locker.cc:	  dout(10) << __func__ << " removing lease on " << *dn << dendl;
./mds/Locker.cc:    dout(7) << " mseq " << mseq << " < " << cap->get_mseq() << ", dropping" << dendl;
./mds/Locker.cc:    dout(7) << " cap_id " << cap_id << " != " << cap->get_cap_id() << ", dropping" << dendl;
./mds/Locker.cc:    dout(7) << " frozen, deferring" << dendl;
./mds/Locker.cc:    dout(10) << " confirming not issued caps " << ccap_string(caps & ~cap->issued()) << dendl;
./mds/Locker.cc:    dout(10) << "kick_issue_caps waiting for unfreeze on " << *in << dendl;
./mds/Locker.cc:    dout(10) << " writing into old inode" << dendl;
./mds/Locker.cc:        dout(10) << "  removing client_range entirely" << dendl;
./mds/Locker.cc:        dout(10) << "  client_range now follows " << snap << dendl;
./mds/Locker.cc:    dout(20) << "inode is file" << dendl;
./mds/Locker.cc:      dout(10) << " i want to change file_max, but lock won't allow it (yet)" << dendl;
./mds/Locker.cc:    dout(10) << "check_access failed, dropping cap update on " << *in << dendl;
./mds/Locker.cc:    dout(7) << " xattrs v" << pi.inode->xattr_version << " -> " << m->head.xattr_version << dendl;
./mds/Locker.cc:  dout(10) << "handle_client_cap_release " << *m << dendl;
./mds/Locker.cc:    dout(7) << "_do_cap_release missing ino " << ino << dendl;
./mds/Locker.cc:    dout(7) << "_do_cap_release no cap for client" << client << " on "<< *in << dendl;
./mds/Locker.cc:  dout(7) << "_do_cap_release for client." << client << " on "<< *in << dendl;
./mds/Locker.cc:    dout(7) << " capid " << cap_id << " != " << cap->get_cap_id() << ", ignore" << dendl;
./mds/Locker.cc:    dout(7) << " mseq " << mseq << " < " << cap->get_mseq() << ", ignore" << dendl;
./mds/Locker.cc:    dout(7) << " freezing|frozen, deferring" << dendl;
./mds/Locker.cc:    dout(7) << " issue_seq " << seq << " != " << cap->get_last_issue() << dendl;
./mds/Locker.cc:  dout(20) << __func__ << " " << revoking_caps.size() << " revoking caps" << dendl;
./mds/Locker.cc:    dout(20) << __func__ << " age = " << age << " client." << cap->get_client() << "." << cap->get_inode()->ino() << dendl;
./mds/Locker.cc:      dout(20) << __func__ << " age below timeout " << mds->mdsmap->get_session_timeout() << dendl;
./mds/Locker.cc:      dout(20) << __func__ << " " << css->strv() << dendl;
./mds/Locker.cc:      dout(20) << __func__ << " silencing log message (backoff) for " << "client." << cap->get_client() << "." << cap->get_inode()->ino() << dendl;
./mds/Locker.cc:  dout(10) << "handle_client_lease " << *m << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_lease don't have ino " << m->get_ino() << "." << m->get_last() << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_lease don't have dn " << m->get_ino() << " " << m->dname << dendl;
./mds/Locker.cc:  dout(10) << " on " << *dn << dendl;
./mds/Locker.cc:    dout(7) << "handle_client_lease didn't have lease for client." << client << " of " << *dn << dendl;
./mds/Locker.cc:      dout(7) << "handle_client_lease release - seq " << l->seq << " != provided " << m->get_seq() << dendl;
./mds/Locker.cc:    dout(20) << "issue_client_lease no/null lease on " << *dn << dendl;
./mds/Locker.cc:	dout(7) << "get_lock don't have dn " << info.dirfrag.ino << " " << info.dname << dendl;
./mds/Locker.cc:	dout(7) << "get_lock don't have ino " << info.ino << dendl;
./mds/Locker.cc:    dout(7) << "get_lock don't know lock_type " << lock_type << dendl;
./mds/Locker.cc:    dout(10) << "don't have object " << m->get_object_info() << ", must have trimmed, dropping" << dendl;
./mds/Locker.cc:    dout(7) << "handle_lock got otype " << m->get_lock_type() << dendl;
./mds/Locker.cc:      dout(7) << "handle_reqrdlock delaying request until lock is stable" << dendl;
./mds/Locker.cc:    dout(7) << "simple_eval not stable and ambiguous auth, waiting on " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(7) << "try_simple_eval not auth for " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(7) << "try_simple_eval can't auth_pin, waiting on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "simple_eval " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:      dout(10) << "simple_eval read-only FS, syncing " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "simple_sync on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "simple_excl on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "simple_lock on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(10) << " doing local stage of mix->lock gather before gathering from replicas" << dendl;
./mds/Locker.cc:  dout(7) << "simple_xlock on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(10) << "scatter_writebehind " << in->get_inode()->mtime << " on " << *lock << " on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "scatter_writebehind_finish on " << *lock << " on " << *in << dendl;
./mds/Locker.cc:  dout(10) << "scatter_eval " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(20) << "  freezing|frozen" << dendl;
./mds/Locker.cc:      dout(10) << "scatter_eval read-only FS, syncing " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:      dout(10) << "scatter_eval no wrlocks|xlocks, not subtree root inode, syncing" << dendl;
./mds/Locker.cc:    dout(10) << "scatter_nudge waiting for unfreeze on " << *p << dendl;
./mds/Locker.cc:    dout(10) << "scatter_nudge waiting for single auth on " << *p << dendl;
./mds/Locker.cc:	  dout(10) << "scatter_nudge auth, propagating " << *lock << " on " << *p << dendl;
./mds/Locker.cc:	    dout(10) << "scatter_nudge auth, read-only FS, syncing " << *lock << " on " << *p << dendl;
./mds/Locker.cc:	dout(10) << "scatter_nudge auth, scatter/unscattering " << *lock << " on " << *p << dendl;
./mds/Locker.cc:	  dout(10) << "scatter_nudge oh, stable after two cycles." << dendl;
./mds/Locker.cc:	dout(10) << "scatter_nudge auth, waiting for stable " << *lock << " on " << *p << dendl;
./mds/Locker.cc:  dout(10) << "scatter_tick" << dendl;
./mds/Locker.cc:      dout(10) << "file_eval read-only FS, syncing " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:    dout(20) << " is excl" << dendl;
./mds/Locker.cc:      dout(20) << " should lose it" << dendl;
./mds/Locker.cc:	dout(10) << " waiting for wrlock to drain" << dendl;
./mds/Locker.cc:  dout(7) << "scatter_mix " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "file_excl " << *lock << " on " << *lock->get_parent() << dendl;  
./mds/Locker.cc:  dout(7) << "file_xsyn on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Locker.cc:  dout(7) << "file_recover " << *lock << " on " << *in << dendl;
./mds/LogEvent.cc:      generic_dout(0) << "failed to decode LogEvent (type maybe " << type << ")" << dendl;
./mds/LogEvent.cc:    generic_dout(0) << "get_type_str: unknown type " << _type << dendl;
./mds/LogEvent.cc:  generic_dout(15) << "decode_log_event type " << type << ", size " << length << dendl;
./mds/LogEvent.cc:    generic_dout(0) << "uh oh, unknown log event type " << type << " length " << length << dendl;
./mds/LogEvent.cc:    generic_dout(0) << "failed to decode LogEvent type " << type << dendl;
./mds/MDSPinger.cc:  dout(10) << ": rank=" << rank << dendl;
./mds/MDSPinger.cc:    dout(20) << ": init ping pong state for rank=" << rank << dendl;
./mds/MDSPinger.cc:  dout(10) << ": rank=" << rank << ", sequence=" << seq << dendl;
./mds/MDSPinger.cc:  dout(10) << ": rank=" << rank << dendl;
./mds/MDSPinger.cc:    dout(10) << ": rank=" << rank << " was never sent ping request." << dendl;
./mds/MDSPinger.cc:  dout(10) << ": rank=" << rank << dendl;
./mds/InoTable.cc:  dout(10) << "project_alloc_id " << id << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "apply_alloc_id " << id << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "project_alloc_ids " << ids << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "apply_alloc_ids " << ids << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "project_release_ids " << ids << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "apply_release_ids " << ids << " to " << projected_free << "/" << free << dendl;
./mds/InoTable.cc:  dout(10) << "replay_alloc_id " << id << dendl;
./mds/InoTable.cc:  dout(10) << "replay_alloc_ids " << ids << dendl;
./mds/InoTable.cc:  dout(10) << "replay_release_ids " << ids << dendl;
./mds/InoTable.cc:  dout(10) << "replay_reset " << free << dendl;
./mds/InoTable.cc:  dout(10) << "skip_inos was " << free << dendl;
./mds/InoTable.cc:  dout(10) << "skip_inos now " << free << dendl;
./mds/InoTable.cc:  dout(10) << "repair: before status. ino = " << id << " pver =" << projected_version << " ver= " << version << dendl;
./mds/InoTable.cc:  dout(10) << "repair: after status. ino = " << id << " pver =" << projected_version << " ver= " << version << dendl;
./mds/MDSTableServer.cc:  dout(7) << "handle_prepare " << *req << dendl;
./mds/MDSTableServer.cc:  dout(7) << "_create_logged " << *req << " tid " << tid << dendl;
./mds/MDSTableServer.cc:  dout(7) << __func__ << " " << *m << dendl;
./mds/MDSTableServer.cc:      dout(0) << "got unexpected notify ack for tid " <<  tid << " from mds." << from << dendl;
./mds/MDSTableServer.cc:  dout(7) << "handle_commit " << *req << dendl;
./mds/MDSTableServer.cc:      dout(0) << "got commit for tid " << tid << ", already committing, waiting." << dendl;
./mds/MDSTableServer.cc:    dout(0) << "got commit for tid " << tid << " > " << version << dendl;
./mds/MDSTableServer.cc:  dout(7) << "_commit_logged, sending ACK" << dendl;
./mds/MDSTableServer.cc:  dout(7) << "handle_rollback " << *req << dendl;
./mds/MDSTableServer.cc:  dout(7) << "_rollback_logged " << *req << dendl;
./mds/MDSTableServer.cc:  dout(10) << "do_server_update len " << bl.length() << dendl;
./mds/MDSTableServer.cc:  dout(10) << "_server_update_logged len " << bl.length() << dendl;
./mds/MDSTableServer.cc:  dout(7) << __func__ << " " << active_clients <<  dendl;
./mds/MDSTableServer.cc:  dout(7) << __func__ << dendl;
./mds/MDSTableServer.cc:  dout(7) << "handle_mds_recovery mds." << who << dendl;
./mds/MDSTableServer.cc:    dout(7) << " still not recovered, delaying" << dendl;
./mds/MDSTableServer.cc:  dout(7) << __func__ << " mds." << who << dendl;
./mds/Server.cc:	dout(5) << "session is closed, dropping " << req->get_reqid() << dendl;
./mds/Server.cc:	dout(3) << "queuing replayed op" << dendl;
./mds/Server.cc:	  dout(3) << "queuing completed op" << dendl;
./mds/Server.cc:      dout(3) << "not active yet, waiting" << dendl;
./mds/Server.cc:    dout(10) << "session not open, dropping this req" << dendl;
./mds/Server.cc:    dout(10) << __func__ << " invalid message (no uuid)" << dendl;
./mds/Server.cc:    dout(10) << __func__ << " unsupported flags" << dendl;
./mds/Server.cc:  dout(3) << __func__ <<  " " << *m << " from " << m->get_source() << dendl;
./mds/Server.cc:    dout(0) << " ignoring sessionless msg " << *m << dendl;
./mds/Server.cc:    dout(0) << " dropping message not allowed for this fs_name: " << *m << dendl;
./mds/Server.cc:  dout(3) << "handle_client_session " << *m << " from " << m->get_source() << dendl;
./mds/Server.cc:    dout(0) << " ignoring sessionless msg " << *m << dendl;
./mds/Server.cc:    dout(0) << " dropping message not allowed for this fs_name: " << *m << dendl;
./mds/Server.cc:      dout(10) << "currently open|opening|stale|killing, dropping this req" << dendl;
./mds/Server.cc:      dout(10) << "mds is stopping, dropping open req" << dendl;
./mds/Server.cc:        dout(2) << css->strv() << dendl;
./mds/Server.cc:	dout(10) << "rejecting blocklisted client " << addr << dendl;
./mds/Server.cc:      dout(20) << __func__ << " CEPH_SESSION_REQUEST_OPEN metadata entries:" << dendl;
./mds/Server.cc:      dout(20) << " features: '" << client_metadata.features << "'" << dendl;
./mds/Server.cc:      dout(20) << " metric specification: [" << client_metadata.metric_spec << "]" << dendl;
./mds/Server.cc:	dout(20) << "  " << p.first << ": " << p.second << dendl;
./mds/Server.cc:      dout(10) << "ignoring renewcaps on non open|stale session (" << session->get_state_name() << ")" << dendl;
./mds/Server.cc:	dout(10) << "already closed|closing|killing, dropping this req" << dendl;
./mds/Server.cc:	dout(10) << "ignoring close req on importing session" << dendl;
./mds/Server.cc:      dout(20) << " killing capability " << ccap_string(cap->issued()) << " on " << *in << dendl;
./mds/Server.cc:      dout(20) << " killing client lease of " << *dn << dendl;
./mds/Server.cc:      dout(20) << " removing client from reconnect set" << dendl;
./mds/Server.cc:        dout(7) << " client " << session->info.inst << " was last reconnect, finishing" << dendl;
./mds/Server.cc:      dout(20) << " removing client from reclaim set" << dendl;
./mds/Server.cc:        dout(7) << " client " << session->info.inst << " was last reclaimed, finishing" << dendl;
./mds/Server.cc:	dout(10) << "force_open_sessions skipping changed " << session->info.inst << dendl;
./mds/Server.cc:	dout(10) << "force_open_sessions opened " << session->info.inst << dendl;
./mds/Server.cc:      dout(10) << "force_open_sessions skipping already-open " << session->info.inst << dendl;
./mds/Server.cc:  dout(10) << __func__ << ": final v " << mds->sessionmap.get_version() << dendl;
./mds/Server.cc:  dout(5) << "terminating all sessions..." << dendl;
./mds/Server.cc:  dout(10) << "find_idle_sessions. last cleared laggy state " << last_cleared_laggy << "s ago" << dendl;
./mds/Server.cc:      dout(10) << "skipping session " << session->info.inst << ", it's being imported" << dendl;
./mds/Server.cc:    dout(10) << "kill_session " << session << dendl;
./mds/Server.cc:    dout(10) << "kill_session importing or already closing/killing " << session << dendl;
./mds/Server.cc:  dout(10) << "apply_blocklist: killed " << victims.size() << dendl;
./mds/Server.cc:    dout(7) << "reconnect_clients -- no sessions, doing nothing." << dendl;
./mds/Server.cc:  dout(1) << "reconnect_clients -- " << client_reconnect_gather.size() << " sessions" << dendl;
./mds/Server.cc:    dout(0) << " ignoring sessionless msg " << *m << dendl;
./mds/Server.cc:    dout(0) << " ignoring msg from not-open session" << *m << dendl;
./mds/Server.cc:    dout(10) << " we're almost in reconnect state (mdsmap delivery race?); waiting" << dendl;
./mds/Server.cc:  dout(10) << " reconnect_start " << reconnect_start << " delay " << delay << dendl;
./mds/Server.cc:      dout(1) << "mds_deny_all_reconnect was set to speed up reboot phase, ignoring reconnect, sending close" << dendl;
./mds/Server.cc:      dout(1) << "no longer in reconnect state, ignoring reconnect, sending close" << dendl;
./mds/Server.cc:      dout(1) << " " << error_str << ", ignoring reconnect, sending close" << dendl;
./mds/Server.cc:	dout(15) << "open snaprealm (w inode) on " << *in << dendl;
./mds/Server.cc:	dout(15) << "open snaprealm (null snaprealm) on " << *in << dendl;
./mds/Server.cc:      dout(10) << "non-auth " << *in << ", will pass off to authority" << dendl;
./mds/Server.cc:      dout(10) << "missing ino " << p.first << ", will load later" << dendl;
./mds/Server.cc:    dout(10) << __func__ << " got '" << client_metadata.features << "'" << dendl;
./mds/Server.cc:  dout(7) << "required_client_features: " << required_client_features << dendl;
./mds/Server.cc:  dout(7) << "reconnect_gather_finish.  failed on " << failed_reconnects << " clients" << dendl;
./mds/Server.cc:    dout(7) << " snaptable cache isn't synced, delaying state transition" << dendl;
./mds/Server.cc:    dout(7) << "reconnect_tick: waiting for evictions" << dendl;
./mds/Server.cc:    dout(1) << "reconnect gives up on " << session->info.inst << dendl;
./mds/Server.cc:    dout(1) << "reconnect will complete once clients are evicted" << dendl;
./mds/Server.cc:        dout(15) << "  session recall threshold (" << recall_max_decay_threshold << ") hit at " << session_recall_throttle << "; skipping!" << dendl;
./mds/Server.cc:        dout(15) << "  session recall 2nd-order threshold (" << 2*recall_max_caps << ") hit at " << session_recall_throttle2o << "; skipping!" << dendl;
./mds/Server.cc:        dout(15) << "  global recall threshold (" << recall_global_max_decay_threshold << ") hit at " << global_recall_throttle << "; skipping!" << dendl;
./mds/Server.cc:      dout(7) << "  recalling " << recall << " caps; session_recall_throttle = " << session_recall_throttle << "; global_recall_throttle = " << global_recall_throttle << dendl;
./mds/Server.cc:  dout(7) << "recalled" << (throttled ? " (throttled)" : "") << " " << caps_recalled << " client caps." << dendl;
./mds/Server.cc:  dout(10) << "force_clients_readonly" << dendl;
./mds/Server.cc:  dout(10) << "journal_and_reply tracei " << in << " tracedn " << dn << dendl;
./mds/Server.cc:      dout(10) << " queued next replay op" << dendl;
./mds/Server.cc:      dout(10) << " journaled last replay op" << dendl;
./mds/Server.cc:      dout(20) << __func__ << " batch head " << *mdr << dendl;
./mds/Server.cc:    dout(10) << "respond_to_request on internal request " << mdr << dendl;
./mds/Server.cc:    dout(10) << "early_reply - flag no_early_reply is set, not allowed." << dendl;
./mds/Server.cc:    dout(10) << "early_reply - there are journaled peers, not allowed." << dendl;
./mds/Server.cc:    dout(10) << "early_reply - allocated ino, not allowed" << dendl;
./mds/Server.cc:    dout(10) << " no early reply on replay op" << dendl;
./mds/Server.cc:  dout(20) << "lat " << lat << dendl;
./mds/Server.cc:    dout(20) << "lat " << lat << dendl;
./mds/Server.cc:    dout(5) << "deliberately skipping trace for " << *reply << dendl;
./mds/Server.cc:  dout(20) << "set_trace_dist snapid " << snapid << dendl;
./mds/Server.cc:    dout(10) << "set_trace_dist snaprealm " << *realm << " len=" << reply->snapbl.length() << dendl;
./mds/Server.cc:    dout(20) << "set_trace_dist added diri " << *diri << dendl;
./mds/Server.cc:    dout(20) << "set_trace_dist added dir  " << *dir << dendl;
./mds/Server.cc:    dout(20) << "set_trace_dist added dn   " << snapid << " " << *dn << dendl;
./mds/Server.cc:    dout(20) << "set_trace_dist added in   " << *in << dendl;
./mds/Server.cc:  dout(4) << "handle_client_request " << *req << dendl;
./mds/Server.cc:    dout(5) << "waiting for root" << dendl;
./mds/Server.cc:      dout(5) << "no session for " << req->get_source() << ", dropping" << dendl;
./mds/Server.cc:      dout(5) << "session closed|closing|killing, dropping" << dendl;
./mds/Server.cc:	dout(5) << "already completed " << req->get_reqid() << dendl;
./mds/Server.cc:    dout(15) << " oldest_client_tid=" << req->get_oldest_client_tid() << dendl;
./mds/Server.cc:	dout(20) << __func__ << " " << css->strv() << dendl;
./mds/Server.cc:    dout(10) << "request " << *mdr << " was killed" << dendl;
./mds/Server.cc:  dout(7) << "dispatch_client_request " << *req << dendl;
./mds/Server.cc:    dout(10) << " read-only FS" << dendl;
./mds/Server.cc:    dout(10) << " got error from peers" << dendl;
./mds/Server.cc:      dout(20) << __func__ << ": full, responding CEPHFS_ENOSPC to op " << ceph_mds_op_name(req->get_op()) << dendl;
./mds/Server.cc:      dout(20) << __func__ << ": full, permitting op " << ceph_mds_op_name(req->get_op()) << dendl;
./mds/Server.cc:    dout(1) << " unknown client op " << req->get_op() << dendl;
./mds/Server.cc:  dout(4) << "handle_peer_request " << m->get_reqid() << " from " << m->get_source() << dendl;
./mds/Server.cc:    dout(3) << "not clientreplay|active yet, waiting" << dendl;
./mds/Server.cc:      dout(10) << "local request " << *mdr << " not peer to mds." << from << dendl;
./mds/Server.cc:    dout(3) << "not active yet, waiting" << dendl;
./mds/Server.cc:    dout(3) << "not clientreplay|active yet, waiting" << dendl;
./mds/Server.cc:      dout(10) << "got remote xlock on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Server.cc:      dout(10) << "got remote wrlock on " << *lock << " on " << *lock->get_parent() << dendl;
./mds/Server.cc:  dout(7) << "dispatch_peer_request " << *mdr << " " << *mdr->peer_request << dendl;
./mds/Server.cc:    dout(7) << " abort flag set, finishing" << dendl;
./mds/Server.cc:	dout(10) << "don't have object, dropping" << dendl;
./mds/Server.cc:  dout(10) << "handle_peer_auth_pin " << *mdr << dendl;
./mds/Server.cc:    dout(10) << " read-only FS" << dendl;
./mds/Server.cc:	dout(10) << " don't have " << oi << dendl;
./mds/Server.cc:	dout(10) << " not auth for " << *obj << dendl;
./mds/Server.cc:	  dout(10) << " can't auth_pin (freezing?) " << *obj << " nonblocking" << dendl;
./mds/Server.cc:	dout(10) << " waiting for authpinnable on " << *obj << dendl;
./mds/Server.cc:      dout(10) << " freezing auth pin on " << *auth_pin_freeze << dendl;
./mds/Server.cc:      dout(10) << "auth_pinning " << *obj << dendl;
./mds/Server.cc:  dout(10) << "handle_peer_auth_pin_ack on " << *mdr << " " << *ack << dendl;
./mds/Server.cc:    dout(10) << " remote has pinned " << *object << dendl;
./mds/Server.cc:      dout(10) << " remote has unpinned " << *object << dendl;
./mds/Server.cc:    dout(10) << "still waiting on peers " << mdr->more()->waiting_on_peer << dendl;
./mds/Server.cc:    dout(10) << "fragment " << *in << " size exceeds " << g_conf()->mds_bal_fragment_size_max << " (CEPHFS_ENOSPC)" << dendl;
./mds/Server.cc:      dout(10) << __func__ << ": " << *straydir << " is frozen, waiting" << dendl;
./mds/Server.cc:    dout(10) << "prepare_new_inode alloc " << mdr->alloc_ino << dendl;
./mds/Server.cc:    dout(0) << "WARNING: client specified " << useino << " and i allocated " << _inode->ino << dendl;
./mds/Server.cc:    dout(10) << "prepare_new_inode prealloc " << mdr->prealloc_inos << dendl;
./mds/Server.cc:  dout(10) << oct << " dir mode 0" << diri->get_inode()->mode << " new mode 0" << mode << dec << dendl;
./mds/Server.cc:    dout(10) << " dir is sticky" << dendl;
./mds/Server.cc:      dout(10) << " new dir also sticky" << dendl;      
./mds/Server.cc:    dout(10) << "prepare_new_inode setting xattrs " << *_xattrs << dendl;
./mds/Server.cc:  dout(10) << "prepare_new_inode " << *in << dendl;
./mds/Server.cc:  dout(10) << "rdlock_path_pin_ref " << *mdr << " " << refpath << dendl;
./mds/Server.cc:      dout(10) << "FAIL on CEPHFS_ESTALE but attempting recovery" << dendl;
./mds/Server.cc:      dout(10) << "FAIL on error " << r << dendl;
./mds/Server.cc:  dout(10) << "ref is " << *ref << dendl;
./mds/Server.cc:      dout(7) << "waiting for !frozen/authpinnable on " << *ref << dendl;
./mds/Server.cc:  dout(10) << "rdlock_path_xlock_dentry " << *mdr << " " << refpath << dendl;
./mds/Server.cc:    dout(7) << "invalid path (zero length)" << dendl;
./mds/Server.cc:    dout(7) << "invalid path (last dot or dot_dot)" << dendl;
./mds/Server.cc:      dout(10) << "FAIL on CEPHFS_ESTALE but attempting recovery" << dendl;
./mds/Server.cc:  dout(10) << "rdlock_two_paths_xlock_destdn " << *mdr << " " << refpath << " " << refpath2 << dendl;
./mds/Server.cc:      dout(10) << "CEPHFS_ESTALE on path, attempting recovery" << dendl;
./mds/Server.cc:      dout(10) << "CEPHFS_ESTALE on path2, attempting recovery" << dendl;
./mds/Server.cc:      dout(7) << "try_open_auth_dirfrag: not open, not inode auth, fw to mds." << inauth << dendl;
./mds/Server.cc:      dout(10) << "try_open_auth_dirfrag: dir inode is frozen, waiting " << *diri << dendl;
./mds/Server.cc:	dout(20) << __func__ << ": LOOKUP op, wait for previous same getattr ops to respond. " << *mdr << dendl;
./mds/Server.cc:	dout(20) << __func__ << ": GETATTR op, wait for previous same getattr ops to respond. " << *mdr << dendl;
./mds/Server.cc:  dout(10) << "reply to stat on " << *req << dendl;
./mds/Server.cc:    dout(10) << "reply to lookup_parent " << *in << dendl;
./mds/Server.cc:      dout(10) << "reply to lookup_name " << *in << dendl;
./mds/Server.cc:      dout(10) << "reply to lookup_ino " << *in << dendl;
./mds/Server.cc:  dout(7) << "lookup_snap_ino " << vino << " parent " << parent_ino << " hash " << hash << dendl;
./mds/Server.cc:    dout(10) << "reply to lookup_snap_ino " << *in << dendl;
./mds/Server.cc:  dout(10) << "_lookup_ino_2 " << mdr.get() << " ino " << ino << " r=" << r << dendl;
./mds/Server.cc:  dout(7) << "open on " << req->get_filepath() << dendl;
./mds/Server.cc:    dout(7) << "read-only FS" << dendl;
./mds/Server.cc:    dout(7) << "not a file or dir " << *cur << dendl;
./mds/Server.cc:    dout(7) << "specified O_DIRECTORY on non-directory " << *cur << dendl;
./mds/Server.cc:    dout(7) << "specified O_TRUNC on !(file|symlink) " << *cur << dendl;
./mds/Server.cc:    dout(7) << "old client cannot open inline data file " << *cur << dendl;
./mds/Server.cc:    dout(7) << "snap " << mdr->snapid << " is read-only " << *cur << dendl;
./mds/Server.cc:  dout(7) << "open w/ O_CREAT on " << req->get_filepath() << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:    dout(10) << " invalid initial file layout" << dendl;
./mds/Server.cc:    dout(10) << " invalid data pool " << layout.pool_id << dendl;
./mds/Server.cc:    dout(10) << "adding created_ino and delegated_inos" << dendl;
./mds/Server.cc:    dout(10) << "adding ino to reply to indicate inode was created" << dendl;
./mds/Server.cc:    dout(10) << "reply to " << *req << " readdir -CEPHFS_ENOTDIR" << dendl;
./mds/Server.cc:    dout(10) << " adjust frag " << fg << " -> " << newfg << " " << diri->dirfragtree << dendl;
./mds/Server.cc:  dout(10) << "handle_client_readdir on " << *dir << dendl;
./mds/Server.cc:      dout(7) << "dir is frozen " << *dir << dendl;
./mds/Server.cc:    dout(10) << " incomplete dir contents for readdir on " << *dir << ", fetching" << dendl;
./mds/Server.cc:  dout(10) << "snapid " << snapid << dendl;
./mds/Server.cc:      dout(20) << "skipping non-overlapping snap " << *dn << dendl;
./mds/Server.cc:	dout(10) << "skipping bad remote ino on " << *dn << dendl;
./mds/Server.cc:      dout(10) << " ran out of room, stopping at " << dnbl.length() << " < " << bytes_left << dendl;
./mds/Server.cc:    dout(12) << "including    dn " << *dn << dendl;
./mds/Server.cc:    dout(12) << "including inode " << *in << dendl;
./mds/Server.cc:      dout(10) << " ran out of room, stopping at " << start_len << " < " << bytes_left << dendl;
./mds/Server.cc:    dout(10) << "handle_client_file_setlock could not get locks!" << dendl;
./mds/Server.cc:  dout(10) << "handle_client_file_setlock: " << set_lock << dendl;
./mds/Server.cc:  dout(10) << " state prior to lock change: " << *lock_state << dendl;
./mds/Server.cc:      dout(10) << " unlock removing waiting lock " << set_lock << dendl;
./mds/Server.cc:      dout(10) << " unlock attempt on " << set_lock << dendl;
./mds/Server.cc:    dout(10) << " lock attempt on " << set_lock << dendl;
./mds/Server.cc:      dout(10) << " was waiting for lock but not anymore, must have been canceled " << set_lock << dendl;
./mds/Server.cc:      dout(10) << " it failed on this attempt" << dendl;
./mds/Server.cc:	dout(10) << " added to waiting list" << dendl;
./mds/Server.cc:  dout(10) << " state after lock change: " << *lock_state << dendl;
./mds/Server.cc:    dout(10) << "handle_client_file_readlock could not get locks!" << dendl;
./mds/Server.cc:    dout(10) << "got unknown lock type " << checking_lock.type << dendl;
./mds/Server.cc:    dout(20) << __func__ << ": full, responding CEPHFS_ENOSPC to setattr with larger size" << dendl;
./mds/Server.cc:  dout(10) << "do_open_truncate " << *in << dendl;
./mds/Server.cc:    dout(10) << "bad layout" << dendl;
./mds/Server.cc:    dout(10) << " invalid data pool " << layout.pool_id << dendl;
./mds/Server.cc:    dout(10) << "bad layout" << dendl;
./mds/Server.cc:    dout(10) << " invalid data pool " << layout.pool_id << dendl;
./mds/Server.cc:  dout(20) << "parse_layout_vxattr name " << name << " value '" << value << "'" << dendl;
./mds/Server.cc:      dout(10) << " parsed " << m << " left '" << left << "'" << dendl;
./mds/Server.cc:	  dout(10) << " unknown pool " << value << dendl;
./mds/Server.cc:      dout(10) << " unknown layout vxattr " << name << dendl;
./mds/Server.cc:    dout(10) << "bad vxattr value, unable to parse int for " << name << dendl;
./mds/Server.cc:    dout(10) << "bad layout" << dendl;
./mds/Server.cc:    dout(10) << " invalid data pool " << layout->pool_id << dendl;
./mds/Server.cc:  dout(20) << "parse_quota_vxattr name " << name << " value '" << value << "'" << dendl;
./mds/Server.cc:      dout(10) << " parsed " << m << " left '" << left << "'" << dendl;
./mds/Server.cc:      dout(10) << " unknown quota vxattr " << name << dendl;
./mds/Server.cc:    dout(10) << "bad vxattr value, unable to parse int for " << name << dendl;
./mds/Server.cc:    dout(10) << "bad quota" << dendl;
./mds/Server.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/Server.cc:      dout(10) << "bad vxattr value, unable to parse bool for " << name << dendl;
./mds/Server.cc:      dout(10) << "bad vxattr value, unable to parse int for " << name << dendl;
./mds/Server.cc:      dout(10) << "bad vxattr value, unable to parse float for " << name << dendl;
./mds/Server.cc:      dout(10) << "bad vxattr value, unable to parse bool for " << name << dendl;
./mds/Server.cc:    dout(10) << " unknown vxattr " << name << dendl;
./mds/Server.cc:  dout(10) << __func__ << " " << name << " on " << *cur << dendl;
./mds/Server.cc:      dout(10) << "can't remove layout policy on the root directory" << dendl;
./mds/Server.cc:      dout(20) << "handler=" << handler.description << dendl;
./mds/Server.cc:  dout(20) << "handler=" << default_xattr_handler->description << dendl;
./mds/Server.cc:        dout(10) << "setxattr '" << xattr_name << "' XATTR_CREATE and CEPHFS_EEXIST on " << *cur << dendl;
./mds/Server.cc:      dout(10) << "setxattr '" << xattr_name << "' XATTR_REPLACE and CEPHFS_ENODATA on " << *cur << dendl;
./mds/Server.cc:      dout(10) << "removexattr '" << xattr_name << "' and CEPHFS_ENODATA on " << *cur << dendl;
./mds/Server.cc:  dout(20) << "parsing name=" << name << ", value=" << value << dendl;
./mds/Server.cc:  dout(20) << " parsed cluster_id=" << cluster_id << ", fs_id=" << fs_id << dendl;
./mds/Server.cc:  dout(10) << "setxattr '" << name << "' len " << len << " on " << *cur << dendl;
./mds/Server.cc:  dout(10) << "removexattr '" << name << "' on " << *cur << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:      dout(15) << " setting a client_range too, since this is a regular file" << dendl;
./mds/Server.cc:  dout(10) << "mknod mode " << _inode->mode << " rdev " << _inode->rdev << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:  dout(12) << " follows " << follows << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:      dout(10) << "CEPHFS_ESTALE on path2, attempting recovery" << dendl;
./mds/Server.cc:	dout(7) << "target has no parent dn, failing..." << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:    dout(7) << "target is a dir, failing..." << dendl;
./mds/Server.cc:  dout(7) << "handle_client_link link " << destdn->get_name() << " in " << *dir << dendl;
./mds/Server.cc:  dout(7) << "target is " << *targeti << dendl;
./mds/Server.cc:    dout(7) << "target has no link, failing..." << dendl;
./mds/Server.cc:    dout(7) << "target is in different subvolume, failing..." << dendl;
./mds/Server.cc:  dout(10) << "_link_local " << *dn << " to " << *targeti << dendl;
./mds/Server.cc:  dout(10) << "_link_local_finish " << *dn << " to " << *targeti << dendl;
./mds/Server.cc:      dout(10) << " targeti auth mds." << linkauth << " is not active" << dendl;
./mds/Server.cc:    dout(10) << " targeti auth must prepare nlink++/--" << dendl;
./mds/Server.cc:  dout(10) << " targeti auth has prepared nlink++/--" << dendl;
./mds/Server.cc:    dout(20) << " noting uncommitted_peers " << mdr->more()->witnessed << dendl;
./mds/Server.cc:  dout(10) << "targeti " << *targeti << dendl;
./mds/Server.cc:  dout(10) << " projected inode " << pi.inode->ino << " v " << pi.inode->version << dendl;
./mds/Server.cc:    dout(10) << " abort flag set, finishing" << dendl;
./mds/Server.cc:  dout(10) << "_committed_peer " << *mdr << dendl;
./mds/Server.cc:  dout(10) << " target is " << *in << dendl;
./mds/Server.cc:  dout(10) << "_link_rollback_finish" << dendl;
./mds/Server.cc:    dout(7) << "handle_client_rmdir on " << *dn << dendl;
./mds/Server.cc:    dout(7) << "handle_client_unlink on " << *dn << dendl;
./mds/Server.cc:  dout(7) << "dn links to " << *in << dendl;
./mds/Server.cc:      dout(7) << "handle_client_unlink on dir " << *in << ", returning error" << dendl;
./mds/Server.cc:      dout(7) << "handle_client_rmdir on non-dir " << *in << ", returning error" << dendl;
./mds/Server.cc:    dout(10) << " straydn is " << *straydn << dendl;
./mds/Server.cc:    dout(10) << " witnesses " << witnesses << ", have " << mdr->more()->witnessed << dendl;
./mds/Server.cc:	dout(10) << " already witnessed by mds." << *p << dendl;
./mds/Server.cc:	dout(10) << " already waiting on witness mds." << *p << dendl;      
./mds/Server.cc:  dout(10) << "_unlink_local " << *dn << dendl;
./mds/Server.cc:    dout(20) << " noting uncommitted_peers " << mdr->more()->witnessed << dendl;
./mds/Server.cc:    dout(10) << " noting renamed (unlinked) dir ino " << in->ino() << " in metablob" << dendl;
./mds/Server.cc:  dout(10) << "_unlink_local_finish " << *dn << dendl;
./mds/Server.cc:    dout(20) << " straydn is " << *straydn << dendl;
./mds/Server.cc:    dout(10) << "_rmdir_prepare_witness mds." << who << " is not active" << dendl;
./mds/Server.cc:  dout(10) << "_rmdir_prepare_witness mds." << who << dendl;
./mds/Server.cc:  dout(10) << " src " << srcpath << dendl;
./mds/Server.cc:  dout(10) << " dn " << *dn << dendl;
./mds/Server.cc:  dout(10) << " straydn " << *straydn << dendl;
./mds/Server.cc:  dout(20) << " rollback is " << mdr->more()->rollback_bl.length() << " bytes" << dendl;
./mds/Server.cc:    dout(10) << " no auth subtree in " << *in << ", skipping journal" << dendl;
./mds/Server.cc:  dout(10) << " noting renamed (unlinked) dir ino " << in->ino() << " in metablob" << dendl;
./mds/Server.cc:  dout(10) << "_logged_peer_rmdir " << *mdr << " on " << *dn << dendl;
./mds/Server.cc:    dout(10) << " abort flag set, finishing" << dendl;
./mds/Server.cc:    dout(10) << "still waiting on peers " << mdr->more()->waiting_on_peer << dendl;
./mds/Server.cc:  dout(10) << "_commit_peer_rmdir " << *mdr << " r=" << r << dendl;
./mds/Server.cc:  dout(10) << "do_rmdir_rollback on " << rollback.reqid << dendl;
./mds/Server.cc:  dout(10) << " dn " << *dn << dendl;
./mds/Server.cc:  dout(10) << " straydn " << *straydn << dendl;
./mds/Server.cc:  dout(10) << " noting renamed (unlinked) dir ino " << in->ino() << " in metablob" << dendl;
./mds/Server.cc:  dout(10) << "_rmdir_rollback_finish " << reqid << dendl;
./mds/Server.cc:  dout(10) << "dir_is_nonempty_unlocked " << *in << dendl;
./mds/Server.cc:  dout(10) << "dir_is_nonempty " << *in << dendl;
./mds/Server.cc:  dout(7) << "handle_client_rename " << *req << dendl;
./mds/Server.cc:    dout(10) << " alternate_name longer than " << alternate_name_max << dendl;
./mds/Server.cc:  dout(10) << " destdn " << *destdn << dendl;
./mds/Server.cc:  dout(10) << " srcdn " << *srcdn << dendl;
./mds/Server.cc:  dout(10) << " srci " << *srci << dendl;
./mds/Server.cc:    dout(7) << "rename src=dest, noop" << dendl;
./mds/Server.cc:    dout(7) << "cannot rename item to be a child of itself" << dendl;
./mds/Server.cc:    //dout(10) << "dest dn exists " << *destdn << dendl;
./mds/Server.cc:    dout(10) << " oldin " << *oldin << dendl;
./mds/Server.cc:      dout(10) << "rename prepending srctrace with " << *pdn << dendl;
./mds/Server.cc:      dout(10) << "rename prepending desttrace with " << *pdn << dendl;
./mds/Server.cc:    dout(10) << "rename src and dest traces now share common ancestor " << *destbase << dendl;
./mds/Server.cc:    dout(10) << " this is a link merge" << dendl;
./mds/Server.cc:    dout(10) << " straydn is " << *straydn << dendl;
./mds/Server.cc:      dout(10) << " renaming between snaprealms, creating snaprealm for " << *srci << dendl;
./mds/Server.cc:    dout(10) << "srci is remote dir, setting stickydirs and opening all frags" << dendl;
./mds/Server.cc:	dout(10) << " opening " << leaf << " under " << *srci << dendl;
./mds/Server.cc:  dout(10) << " witnesses " << witnesses << ", have " << mdr->more()->witnessed << dendl;
./mds/Server.cc:      dout(10) << " preparing ambiguous auth for srci" << dendl;
./mds/Server.cc:      dout(10) << " already witnessed by mds." << *p << dendl;
./mds/Server.cc:      dout(10) << " already waiting on witness mds." << *p << dendl;      
./mds/Server.cc:    dout(10) << " preparing last witness (srcdn auth)" << dendl;
./mds/Server.cc:    dout(20) << " noting uncommitted_peers " << mdr->more()->witnessed << dendl;
./mds/Server.cc:  dout(10) << "_rename_finish " << *mdr << dendl;
./mds/Server.cc:    dout(10) << "_rename_prepare_witness mds." << who << " is not active" << dendl;
./mds/Server.cc:  dout(10) << "_rename_prepare_witness mds." << who << dendl;
./mds/Server.cc:	dout(10) << " frag " << dir->get_frag() << " is auth subtree dirfrag, will force journal" << dendl;
./mds/Server.cc:	dout(20) << " frag " << dir->get_frag() << " is not auth subtree dirfrag" << dendl;
./mds/Server.cc:    dout(10) << " subtrees " << subtrees << " frags " << dirs << dendl;
./mds/Server.cc:	    dout(20) << " frag " << dir->get_frag() << " contains but isn't auth for " << *subtree << dendl;
./mds/Server.cc:	  dout(20) << " frag " << dir->get_frag() << " does not contain " << *subtree << dendl;
./mds/Server.cc:  dout(10) << "_rename_prepare " << *mdr << " " << *srcdn << " " << *destdn << dendl;
./mds/Server.cc:    dout(10) << " straydn " << *straydn << dendl;
./mds/Server.cc:      dout(10) << " we are exporting srci, will force journal destdn" << dendl;
./mds/Server.cc:    dout(10) << " merging remote and primary links to the same inode" << dendl;
./mds/Server.cc:    dout(10) << " reintegrating stray; will avoid changing nlink or dir mtime" << dendl;
./mds/Server.cc:    dout(10) << " forcing journal destdn because we (will) have auth subtrees nested beneath it" << dendl;
./mds/Server.cc:    dout(10) << " forcing journal straydn because we (will) have auth subtrees nested beneath it" << dendl;
./mds/Server.cc:    dout(10) << " noting renamed dir ino " << srci->ino() << " in metablob" << dendl;
./mds/Server.cc:    dout(10) << " noting rename target dir " << oldin->ino() << " in metablob" << dendl;
./mds/Server.cc:      dout(10) << " will merge remote onto primary link" << dendl;
./mds/Server.cc:	  dout(10) << " noting renamed dir open frags " << metablob->renamed_dir_frags << dendl;
./mds/Server.cc:	dout(10) << " forced journaling straydn " << *straydn << dendl;
./mds/Server.cc:      dout(10) << " forced journaling destdn " << *destdn << dendl;
./mds/Server.cc:    dout(10) << " journaling srcdn " << *srcdn << dendl;
./mds/Server.cc:    dout(10) << " NOT journaling srcdn " << *srcdn << dendl;
./mds/Server.cc:  dout(10) << "_rename_apply " << *mdr << " " << *srcdn << " " << *destdn << dendl;
./mds/Server.cc:  dout(10) << " pvs " << mdr->more()->pvmap << dendl;
./mds/Server.cc:      dout(10) << "straydn is " << *straydn << dendl;
./mds/Server.cc:      dout(10) << "merging remote onto primary link" << dendl;
./mds/Server.cc:      dout(10) << "merging primary onto remote link" << dendl;
./mds/Server.cc:    dout(10) << " peer request interrupted, sending noop reply" << dendl;
./mds/Server.cc:  dout(10) << " dest " << destpath << dendl;
./mds/Server.cc:  dout(10) << " destdn " << *destdn << dendl;
./mds/Server.cc:  dout(10) << " src " << srcpath << dendl;
./mds/Server.cc:  dout(10) << " srcdn " << *srcdn << dendl;
./mds/Server.cc:      dout(10) << " freezing srci " << *srcdnl->get_inode() << " with allowance " << allowance << dendl;
./mds/Server.cc:	dout(10) << " set srci ambiguous auth; providing srcdn replica list" << dendl;
./mds/Server.cc:      dout(10) << " witness list insufficient; providing srcdn replica list" << dendl;
./mds/Server.cc:    dout(10) << " witness list sufficient: includes all srcdn replicas" << dendl;
./mds/Server.cc:  dout(20) << " rollback is " << mdr->more()->rollback_bl.length() << " bytes" << dendl;
./mds/Server.cc:    dout(10) << " empty metablob, skipping journal" << dendl;
./mds/Server.cc:  dout(10) << "_logged_peer_rename " << *mdr << dendl;
./mds/Server.cc:    dout(10) << " exported srci " << *srcdnl->get_inode() << dendl;
./mds/Server.cc:    dout(10) << " abort flag set, finishing" << dendl;
./mds/Server.cc:  dout(10) << "_commit_peer_rename " << *mdr << " r=" << r << dendl;
./mds/Server.cc:      dout(10) << " finishing inode export on " << *in << dendl;
./mds/Server.cc:	dout(10) << " reversing inode export of " << *in << dendl;
./mds/Server.cc:      dout(10) << " rollback_bl empty, not rollback back rename (leader failed after getting extra witnesses?)" << dendl;
./mds/Server.cc:  dout(10) << "do_rename_rollback on " << rollback.reqid << dendl;
./mds/Server.cc:    dout(10) << "  srcdir " << *srcdir << dendl;
./mds/Server.cc:      dout(10) << "   srcdn " << *srcdn << dendl;
./mds/Server.cc:      dout(10) << "   srcdn not found" << dendl;
./mds/Server.cc:    dout(10) << "  srcdir not found" << dendl;
./mds/Server.cc:    dout(10) << " destdir " << *destdir << dendl;
./mds/Server.cc:      dout(10) << "  destdn " << *destdn << dendl;
./mds/Server.cc:      dout(10) << "  destdn not found" << dendl;
./mds/Server.cc:    dout(10) << " destdir not found" << dendl;
./mds/Server.cc:      dout(10) << "straydir " << *straydir << dendl;
./mds/Server.cc:	dout(10) << " straydn " << *straydn << dendl;
./mds/Server.cc:	dout(10) << " straydn not found" << dendl;
./mds/Server.cc:      dout(10) << "straydir not found" << dendl;
./mds/Server.cc:    dout(0) << " srcdn back to " << *srcdn << dendl;
./mds/Server.cc:    dout(0) << "  srci back to " << *in << dendl;
./mds/Server.cc:    dout(0) << " destdn back to " << *destdn << dendl;
./mds/Server.cc:    dout(0) << "  desti back to " << *target << dendl;
./mds/Server.cc:    dout(10) << " noting renamed dir ino " << in->ino() << " in metablob" << dendl;
./mds/Server.cc:      dout(10) << " noting renamed dir open frags " << le->commit.renamed_dir_frags << dendl;
./mds/Server.cc:    dout(10) << " noting rename target ino " << target->ino() << " in metablob" << dendl;
./mds/Server.cc:  dout(10) << "_rename_rollback_finish " << mut->reqid << dendl;
./mds/Server.cc:    dout(10) << " peer request interrupted, noop" << dendl;
./mds/Server.cc:    dout(10) << " extra witnesses (srcdn replicas) are " << ack->witnesses << dendl;
./mds/Server.cc:    dout(10) << " got srci import" << dendl;
./mds/Server.cc:    dout(10) << "still waiting on peers " << mdr->more()->waiting_on_peer << dendl;
./mds/Server.cc:  dout(10) << "_peer_rename_sessions_flushed " << *mdr << dendl;
./mds/Server.cc:  dout(10) << "lssnap on " << *diri << dendl;
./mds/Server.cc:    dout(10) << p->first << " -> " << *p->second << dendl;
./mds/Server.cc:    dout(20) << "encode_infinite_lease" << dendl;
./mds/Server.cc:    dout(20) << "mksnap " << snapname << " on " << *diri << " denied to uid " << mdr->client_request->get_caller_uid() << dendl;
./mds/Server.cc:  dout(10) << "mksnap " << snapname << " on " << *diri << dendl;
./mds/Server.cc:  dout(10) << " stid " << stid << " snapid " << snapid << dendl;
./mds/Server.cc:      dout(20) << ": no metadata in payload (old client?)" << dendl;
./mds/Server.cc:  dout(10) << "_mksnap_finish " << *mdr << " " << info << dendl;
./mds/Server.cc:  dout(10) << "snaprealm now " << *diri->snaprealm << dendl;
./mds/Server.cc:    dout(20) << "rmsnap " << snapname << " on " << *diri << " denied to uid " << mdr->client_request->get_caller_uid() << dendl;
./mds/Server.cc:  dout(10) << "rmsnap " << snapname << " on " << *diri << dendl;
./mds/Server.cc:  dout(10) << " snapname " << snapname << " is " << snapid << dendl;
./mds/Server.cc:  dout(10) << " stid is " << stid << ", seq is " << seq << dendl;
./mds/Server.cc:  dout(10) << "_rmsnap_finish " << *mdr << " " << snapid << dendl;
./mds/Server.cc:  dout(10) << "snaprealm now " << *diri->snaprealm << dendl;
./mds/Server.cc:  dout(10) << "renamesnap " << srcname << "->" << dstname << " on " << *diri << dendl;
./mds/Server.cc:  dout(10) << " snapname " << srcname << " is " << snapid << dendl;
./mds/Server.cc:  dout(10) << " stid is " << stid << dendl;
./mds/Server.cc:  dout(10) << "_renamesnap_finish " << *mdr << " " << snapid << dendl;
./mds/Server.cc:  dout(10) << "snaprealm now " << *diri->snaprealm << dendl;
./mds/Mantle.cc:    mantle_dout(0) << "WARNING: mantle script returned a malformed response" << mantle_dendl;
./mds/Mantle.cc:      mantle_dout(0) << "WARNING: mantle script returned a malformed response" << mantle_dendl;
./mds/Mantle.cc:    mantle_dout(0) << "WARNING: mantle could not load Lua state" << mantle_dendl;
./mds/CDentry.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDentry.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDentry.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDentry.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDentry.cc:  dout(10) << "auth_pin by " << by << " on " << *this << " now " << auth_pins << dendl;
./mds/CDentry.cc:  dout(10) << "auth_unpin by " << by << " on " << *this << " now " << auth_pins << dendl;
./mds/CDentry.cc:    dout(10) << __func__ << " first " << first << " -> " << newfirst << dendl;
./mds/CDentry.cc:      dout(10) << __func__ << " replica dentry null -> non-null, must trim" << dendl;
./mds/CDentry.cc:    dout(20) << __func__ << " client." << c << " on " << lock << dendl;
./mds/CDentry.cc:  dout(20) << __func__ << " client." << l->client << " on " << lock << dendl;
./mds/MDLog.cc:  dout(5) << "create empty log" << dendl;
./mds/MDLog.cc:  dout(5) << "open discovering log bounds" << dendl;
./mds/MDLog.cc:  dout(5) << "reopen" << dendl;
./mds/MDLog.cc:  dout(5) << "append positioning at end and marking writeable" << dendl;
./mds/MDLog.cc:  dout(10) << "_submit_thread start" << dendl;
./mds/MDLog.cc:  dout(5) << "cap" << dendl;
./mds/MDLog.cc:  dout(5) << "shutdown" << dendl;
./mds/MDLog.cc:  dout(7) << __func__ << " seq " << seq << dendl;
./mds/MDLog.cc:  dout(7) << __func__ << dendl;
./mds/MDLog.cc:    dout(10) << "trim, ignoring read-only FS" <<  dendl;
./mds/MDLog.cc:      dout(5) << __func__ << ": segment " << ls->seq << " has pending events" << dendl;
./mds/MDLog.cc:    dout(5) << "try_expire expiring segment " << ls->seq << "/" << ls->offset << dendl;
./mds/MDLog.cc:    dout(10) << "try_expire expired segment " << ls->seq << "/" << ls->offset << dendl;
./mds/MDLog.cc:    dout(10) << "_maybe_expired, ignoring read-only FS" <<  dendl;
./mds/MDLog.cc:    dout(10) << "replay - journal empty, done." << dendl;
./mds/MDLog.cc:    dout(1) << "Erasing journal " << jp.back << dendl;
./mds/MDLog.cc:      dout(1) << "Successfully erased journal, updating journal pointer" << dendl;
./mds/MDLog.cc:  dout(4) << "Waiting for journal " << jp.front << " to recover..." << dendl;
./mds/MDLog.cc:  dout(4) << "Journal " << jp.front << " recovered." << dendl;
./mds/MDLog.cc:    dout(4) << "Recovered journal " << jp.front << " in format " << front_journal->get_stream_format() << dendl;
./mds/MDLog.cc:  dout(4) << "Writing new journal header " << jp.back << dendl;
./mds/MDLog.cc:      dout(0) << "_replay journaler got error " << r << ", aborting" << dendl;
./mds/MDLog.cc:  dout(1) << "Transcribed " << events_transcribed << " events, flushing new journal" << dendl;
./mds/MDLog.cc:  dout(1) << "New journal flushed, erasing old journal" << dendl;
./mds/MDLog.cc:  dout(1) << "Journal rewrite complete, continuing with normal startup" << dendl;
./mds/MDLog.cc:  dout(10) << "_replay_thread start" << dendl;
./mds/MDLog.cc:      dout(0) << "_replay journaler got error " << r << ", aborting" << dendl;
./mds/MDLog.cc:            dout(0) << "expire_pos is higher than read_pos, returning CEPHFS_EAGAIN" << dendl;
./mds/MDLog.cc:            dout(0) << "expire_pos is higher than read_pos, returning CEPHFS_EAGAIN" << dendl;
./mds/MDLog.cc:  dout(10) << "_replay_thread kicking waiters" << dendl;
./mds/MDLog.cc:  dout(10) << "_replay_thread finish" << dendl;
./mds/MDLog.cc:  dout(10) << "standby_trim_segments" << dendl;
./mds/MDLog.cc:  dout(10) << " expire_pos=" << expire_pos << dendl;
./mds/MDLog.cc:      dout(10) << " won't remove, not expired!" << dendl;
./mds/MDLog.cc:      dout(10) << " won't remove, last segment!" << dendl;
./mds/MDLog.cc:    dout(10) << " removing segment" << dendl;
./mds/MDLog.cc:    dout(20) << " calling mdcache->trim!" << dendl;
./mds/MDLog.cc:    dout(20) << " removed no segments!" << dendl;
./mds/PurgeQueue.cc:    dout(10) << "skipping activate: PurgeQueue is readonly" << dendl;
./mds/PurgeQueue.cc:    dout(4) << "start work (by drain)" << dendl;
./mds/PurgeQueue.cc:  dout(4) << "opening" << dendl;
./mds/PurgeQueue.cc:      dout(4) << "open complete" << dendl;
./mds/PurgeQueue.cc:	dout(4) << "recovering write_pos" << dendl;
./mds/PurgeQueue.cc:    dout(10) << "cannot wait for recovery: PurgeQueue is readonly" << dendl;
./mds/PurgeQueue.cc:      dout(4) << "write_pos recovered" << dendl;
./mds/PurgeQueue.cc:  dout(4) << "creating" << dendl;
./mds/PurgeQueue.cc:  dout(4) << "pushing inode " << pi.ino << dendl;
./mds/PurgeQueue.cc:    dout(10) << "cannot push inode: PurgeQueue is readonly" << dendl;
./mds/PurgeQueue.cc:    dout(10) << "can't consume: PurgeQueue is readonly" << dendl;
./mds/PurgeQueue.cc:  dout(1) << "going readonly because internal IO failed: " << strerror(-r) << dendl;
./mds/PurgeQueue.cc:      dout(10) << " not readable right now" << dendl;
./mds/PurgeQueue.cc:    dout(20) << " decoding entry" << dendl;
./mds/PurgeQueue.cc:    dout(20) << " executing item (" << item.ino << ")" << dendl;
./mds/PurgeQueue.cc:  dout(10) << " cannot consume right now" << dendl;
./mds/PurgeQueue.cc:    dout(10) << op.item.get_type_str() << dendl;
./mds/PurgeQueue.cc:      dout(10) << " remove dirfrag " << oid << dendl;
./mds/PurgeQueue.cc:  dout(10) << "complete at 0x" << std::hex << expire_to << std::dec << dendl;
./mds/PurgeQueue.cc:    dout(10) << "expiring to 0x" << std::hex << pos << std::dec << dendl;
./mds/PurgeQueue.cc:    dout(10) << "non-sequential completion, not expiring anything" << dendl;
./mds/PurgeQueue.cc:  dout(10) << "completed item for ino " << iter->second.ino << dendl;
./mds/PurgeQueue.cc:  dout(10) << "in_flight.size() now " << in_flight.size() << dendl;
./mds/PurgeQueue.cc:    dout(10) << "skipping; PurgeQueue is readonly" << dendl;
./mds/PurgeQueue.cc:        dout(4) << " data pool " << dp << " not found in OSDMap" << dendl;
./mds/PurgeQueue.cc:    dout(10) << "skipping drain; PurgeQueue is readonly" << dendl;
./mds/SessionMap.cc:  dout(10) << "dump" << dendl;
./mds/SessionMap.cc:      dout(4) << __func__ << ": header missing, loading legacy..." << dendl;
./mds/SessionMap.cc:    dout(10) << __func__ << " loaded version " << version << dendl;
./mds/SessionMap.cc:    dout(10) << __func__ << ": omap load complete" << dendl;
./mds/SessionMap.cc:  dout(10) << "load" << dendl;
./mds/SessionMap.cc:  dout(10) << __func__ << dendl;
./mds/SessionMap.cc:  dout(10) << __func__ << ": needv " << needv << ", v " << version << dendl;
./mds/SessionMap.cc:    dout(4) << __func__ << " erasing legacy sessionmap" << dendl;
./mds/SessionMap.cc:  dout(20) << " updating keys:" << dendl;
./mds/SessionMap.cc:      dout(20) << "  " << name << dendl;
./mds/SessionMap.cc:      dout(20) << "  " << name << " (ignoring)" << dendl;
./mds/SessionMap.cc:  dout(20) << " removing keys:" << dendl;
./mds/SessionMap.cc:    dout(20) << "  " << *i << dendl;
./mds/SessionMap.cc:  dout(10) << "_save_finish v" << v << dendl;
./mds/SessionMap.cc:	  dout(10) << " already had session for " << name << ", recovering" << dendl;
./mds/SessionMap.cc:  dout(1) << "wipe start" << dendl;
./mds/SessionMap.cc:  dout(1) << "wipe result" << dendl;
./mds/SessionMap.cc:  dout(1) << "wipe done" << dendl;
./mds/SessionMap.cc:  dout(10) << __func__ << " s=" << s << " name=" << s->info.inst.name << dendl;
./mds/SessionMap.cc:  dout(10) << __func__ << " s=" << s << " name=" << s->info.inst.name << dendl;
./mds/SessionMap.cc:  dout(10) << __func__ << " s=" << session << " name=" << session->info.inst.name << dendl;
./mds/SessionMap.cc:  dout(4) << __func__ << ": writing " << write_sessions.size() << dendl;
./mds/SessionMap.cc:    dout(20) << __func__ << " stray_prior_path " << path << dendl;
./mds/SessionMap.cc:    dout(20) << __func__ << " path " << path << dendl;
./mds/SessionMap.cc:    dout(10) << __func__ << " client doesn't support FS_FILE_LAYOUT_V2" << dendl;
./mds/SessionMap.cc:    dout(20) << __func__ << " parsing filter '" << s << "'" << dendl;
./mds/SessionMap.cc:    dout(20) << __func__ << " parsed k='" << k << "', v='" << v << "'" << dendl;
./mds/MDSTableClient.cc:  dout(10) << "handle_request " << *m << dendl;
./mds/MDSTableClient.cc:      dout(10) << "got agree on " << reqid << " atid " << tid << dendl;
./mds/MDSTableClient.cc:      dout(10) << "got duplicated agree on " << reqid << " atid " << tid << dendl;
./mds/MDSTableClient.cc:      dout(10) << "got ack on tid " << tid << ", logging" << dendl;
./mds/MDSTableClient.cc:      dout(10) << "got stray ack on tid " << tid << ", ignoring" << dendl;
./mds/MDSTableClient.cc:  dout(10) << "_logged_ack " << tid << dendl;
./mds/MDSTableClient.cc:    dout(15) << "kicking ack waiters on tid " << tid << dendl;
./mds/MDSTableClient.cc:    dout(10) << "tableserver is not ready yet, waiting for request id" << dendl;
./mds/MDSTableClient.cc:  dout(10) << "_prepare " << reqid << dendl;
./mds/MDSTableClient.cc:    dout(10) << "tableserver is not ready yet, deferring request" << dendl;
./mds/MDSTableClient.cc:  dout(10) << "commit " << tid << dendl;
./mds/MDSTableClient.cc:    dout(10) << "tableserver is not ready yet, deferring request" << dendl;
./mds/MDSTableClient.cc:  dout(10) << "got_journaled_agree " << tid << dendl;
./mds/MDSTableClient.cc:  dout(10) << "got_journaled_ack " << tid << dendl;
./mds/MDSTableClient.cc:    dout(10) << "resending commit on " << p->first << dendl;
./mds/MDSTableClient.cc:    dout(10) << "resending prepare on " << p->first << dendl;
./mds/MDSTableClient.cc:  dout(7) << "tableserver mds." << who << " fails" << dendl;
./mds/journal.cc:  dout(6) << "LogSegment(" << seq << "/" << offset << ").try_to_expire" << dendl;
./mds/journal.cc:    dout(20) << " new_dirfrag " << **p << dendl;
./mds/journal.cc:    dout(20) << " dirty_dirfrag " << **p << dendl;
./mds/journal.cc:    dout(20) << " dirty_dentry " << **p << dendl;
./mds/journal.cc:    dout(20) << " dirty_inode " << **p << dendl;
./mds/journal.cc:	dout(15) << "try_to_expire committing " << *dir << dendl;
./mds/journal.cc:	dout(15) << "try_to_expire waiting for unfreeze on " << *dir << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for peers to ack commit on " << *p << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for leader to ack OP_FINISH on " << *p << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for uncommitted fragment " << *p << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for dirlock flush on " << *in << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for dirfragtreelock flush on " << *in << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for nest flush on " << *in << dendl;
./mds/journal.cc:	dout(20) << "try_to_expire requeueing snap needflush inode " << *in << dendl;
./mds/journal.cc:      dout(10) << "try_to_expire waiting for open files to rejournal" << dendl;
./mds/journal.cc:      dout(15) << "try_to_expire waiting for storing backtrace on " << *in << dendl;
./mds/journal.cc:      dout(15) << "try_to_expire waiting for unfreeze on " << *in << dendl;
./mds/journal.cc:    dout(10) << "try_to_expire waiting for truncate of " << **p << dendl;
./mds/journal.cc:  dout(10) << "try_to_expire waiting for purge of " << purging_inodes << dendl;
./mds/journal.cc:    dout(6) << "LogSegment(" << seq << "/" << offset << ").try_to_expire waiting" << dendl;
./mds/journal.cc:    dout(6) << "LogSegment(" << seq << "/" << offset << ").try_to_expire success" << dendl;
./mds/journal.cc:      dout(20) << "EMetaBlob::add_dir_context(" << dir << ") have lump " << dir->dirfrag() << dendl;
./mds/journal.cc:	      dout(0) << "EMetaBlob::add_dir_context unexpected subtree " << *dir << dendl;
./mds/journal.cc:	    dout(20) << "EMetaBlob::add_dir_context(" << dir << ") ambiguous or transient subtree " << dendl;
./mds/journal.cc:	dout(20) << "EMetaBlob::add_dir_context(" << dir << ") already have diri this blob " << *diri << dendl;
./mds/journal.cc:      dout(25) << "EMetaBlob::add_dir_context(" << dir << ")      maybe " << *parent << dendl;
./mds/journal.cc:      dout(25) << "EMetaBlob::add_dir_context(" << dir << ") definitely " << *parent << dendl;
./mds/journal.cc:  dout(20) << "EMetaBlob::add_dir_context final: " << parents << dendl;
./mds/journal.cc:      dout(15) << "random ephemeral pin on " << *in << dendl;
./mds/journal.cc:	    dout(10) << " closing empty non-auth dirfrag " << *dir << dendl;
./mds/journal.cc:  dout(10) << "EMetaBlob.replay " << lump_map.size() << " dirlumps by " << client_name << dendl;
./mds/journal.cc:    dout(10) << "EMetaBlob.replay " << (isnew ? " added root ":" updated root ") << *in << dendl;    
./mds/journal.cc:      dout(10) << "EMetaBlob.replay renamed inode is " << *renamed_diri << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay don't have renamed ino " << renamed_dirino << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay found null dentry in dir " << lp << dendl;
./mds/journal.cc:    dout(10) << "EMetaBlob.replay dir " << lp << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay created base " << *diri << dendl;
./mds/journal.cc:	  dout(0) << "EMetaBlob.replay missing dir ino  " << lp.ino << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay added dir " << *dir << dendl;  
./mds/journal.cc:	dout(10) << "EMetaBlob.replay      dirty nestinfo on " << *dir << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay      clean nestinfo on " << *dir << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay      dirty fragstat on " << *dir << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay      clean fragstat on " << *dir << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay      dirty dirfragtree on " << *dir << dendl;
./mds/journal.cc:    dout(10) << "EMetaBlob.replay updated dir " << *dir << dendl;  
./mds/journal.cc:	dout(10) << "EMetaBlob.replay added (full) " << *dn << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay for [" << fb.dnfirst << "," << fb.dnlast << "] had " << *dn << dendl;
./mds/journal.cc:	    dout(0) << css->strv() << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay added " << *in << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay unlinking " << *in << dendl;
./mds/journal.cc:	      dout(0) << css->strv() << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay linked " << *in << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay for [" << fb.dnfirst << "," << fb.dnlast << "] had " << *in << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay added " << *dn << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay unlinking " << *dn << dendl;
./mds/journal.cc:	    dout(0) << css->strv() << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay for [" << rb.dnfirst << "," << rb.dnlast << "] had " << *dn << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay added (nullbit) " << *dn << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay unlinking " << *dn << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay had " << *dn << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay pushing to bottom of lru " << *dn << dendl;
./mds/journal.cc:	  dout(10) << " already had+adjusted rename import bound " << *dir << dendl;
./mds/journal.cc:	dout(10) << " creating new rename import bound " << *dir << dendl;
./mds/journal.cc:    dout(10) << " unlinked set contains " << unlinked << dendl;
./mds/journal.cc:    dout(10) << "EMetaBlob.replay noting opened inode " << *in << dendl;
./mds/journal.cc:	dout(20) << " (session prealloc " << session->info.prealloc_inos << ")" << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay no session for " << client_name << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay destroyed " << *p << ", dropping " << *in << dendl;
./mds/journal.cc:	  dout(10) << "EMetaBlob.replay unlinked from dentry " << *parent << dendl;
./mds/journal.cc:	dout(10) << "EMetaBlob.replay destroyed " << *p << ", not in cache" << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay request " << p.first << " trim_to " << p.second << dendl;
./mds/journal.cc:      dout(10) << "EMetaBlob.replay flush " << p.first << " trim_to " << p.second << dendl;
./mds/journal.cc:      dout(10) << " opened session " << session->info.inst << dendl;
./mds/journal.cc:	  dout(10) << " removed session " << session->info.inst << dendl;
./mds/journal.cc:	  dout(10) << " reset session " << session->info.inst << " (they reconnected)" << dendl;
./mds/journal.cc:    dout(10) << "EUpdate.replay " << reqid << " had peers, expecting a matching ECommitted" << dendl;
./mds/journal.cc:  dout(10) << "EOpen.replay " << dendl;
./mds/journal.cc:      dout(0) << "EOpen.replay ino " << ino << " not in metablob" << dendl;
./mds/journal.cc:      dout(0) << "EOpen.replay ino " << vino << " not in metablob" << dendl;
./mds/journal.cc:    dout(10) << "ECommitted.replay " << reqid << dendl;
./mds/journal.cc:    dout(10) << "ECommitted.replay " << reqid << " -- didn't see original op" << dendl;
./mds/journal.cc:    dout(10) << "EPeerUpdate.replay commit " << reqid << " for mds." << leader << dendl;
./mds/journal.cc:    dout(10) << "ESubtreeMap.replay -- i already have import map; verifying" << dendl;
./mds/journal.cc:      dout(0) << "journal subtrees: " << subtrees << dendl;
./mds/journal.cc:      dout(0) << "journal ambig_subtrees: " << ambiguous_subtrees << dendl;
./mds/journal.cc:  dout(10) << "ESubtreeMap.replay -- reconstructing (auth) subtree spanning tree" << dendl;
./mds/journal.cc:  dout(10) << "EFragment.replay " << op_name(op) << " " << ino << " " << basefrag << " by " << bits << dendl;
./mds/journal.cc:  dout(10) << "EExport.replay " << base << dendl;
./mds/journal.cc:  dout(10) << "EImportStart.replay " << base << " bounds " << bounds << dendl;
./mds/journal.cc:    dout(10) << "EImportFinish.replay " << base << " success=" << success << dendl;
./mds/journal.cc:  dout(1) << "EResetJournal" << dendl;
./mds/journal.cc:  dout(4) << "ENoOp::replay, " << pad_size << " bytes skipped in journal" << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *dir << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *dir << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " log_seq " << log_seq << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " log_seq " << log_seq << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " log_seq " << log_seq << dendl;
./mds/OpenFileTable.cc:    dout(10) << __func__ << ": load complete" << dendl;
./mds/OpenFileTable.cc:    dout(10) << __func__ << ": load from '" << oid << ":" << key << "'" << dendl;
./mds/OpenFileTable.cc:    dout(10) << __func__ << ": recover journal" << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << ": load complete" << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << " state " << prefetch_state << dendl;
./mds/OpenFileTable.cc:  dout(10) << __func__ << dendl;
./mds/MDSTable.cc:  dout(10) << "save v " << version << dendl;
./mds/MDSTable.cc:    dout(1) << "save error " << r << " v " << v << dendl;
./mds/MDSTable.cc:  dout(10) << "save_2 v " << v << dendl;
./mds/MDSTable.cc:  dout(10) << "load" << dendl;
./mds/MDSTable.cc:  dout(10) << "load_2 got " << bl.length() << " bytes" << dendl;
./mds/MDSTable.cc:    dout(10) << "load_2 loaded v" << version << dendl;
./mds/MetricsHandler.cc:      dout(0) << typeid(*msg).name() << " is not an MMDSOp type" << dendl;
./mds/MetricsHandler.cc:  dout(10) << dendl;
./mds/MetricsHandler.cc:  dout(10) << dendl;
./mds/MetricsHandler.cc:  dout(10) << ": session=" << session << ", client=" << client << dendl;
./mds/MetricsHandler.cc:  dout(20) << ": metrics=" << metrics << dendl;
./mds/MetricsHandler.cc:  dout(10) << ": session=" << session << ", client=" << client << dendl;
./mds/MetricsHandler.cc:  dout(10) << ": last_updated_seq=" << last_updated_seq << dendl;
./mds/MetricsHandler.cc:    dout(10) << ": reset last updated seq for client addr=" << client << dendl;
./mds/MetricsHandler.cc:  dout(5) << ": type=Unknown, session=" << session << ", ignoring unknown payload" << dendl;
./mds/MetricsHandler.cc:  dout(20) << ": session=" << session << dendl;
./mds/MetricsHandler.cc:    dout(10) << ": ignoring session less message" << dendl;
./mds/MetricsHandler.cc:  dout(10) << dendl;
./mds/MetricsHandler.cc:    dout(10) << ": rank0 is unavailable" << dendl;
./mds/MetricsHandler.cc:  dout(10) << ": rank0 is mds." << mdsmap.get_mds_info((mds_rank_t)0).name << dendl;
./mds/MetricsHandler.cc:    dout(10) << ": rank0 addr is now " << new_rank0_addr << dendl;
./mds/MetricsHandler.cc:  dout(20) << dendl;
./mds/MetricsHandler.cc:    dout(20) << ": not yet notified with rank0 address, ignoring" << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << " " << *dn << " " << *in << dendl;
./mds/StrayManager.cc:      dout(10) << " realm " << *realm << dendl;
./mds/StrayManager.cc:      dout(10) << " NO realm, using null context" << dendl;
./mds/StrayManager.cc:  dout(10) << "_purge_stray_purged " << *dn << " " << *in << dendl;
./mds/StrayManager.cc:  dout(10) << "_purge_stray_logged " << *dn << " " << *in << dendl;
./mds/StrayManager.cc:    dout(20) << " dn is new, removing" << dendl;
./mds/StrayManager.cc:  dout(20) << __func__ << ": purging dn: " << *dn << dendl;
./mds/StrayManager.cc:    dout(10) << " can't auth_pin (freezing?) " << *dir << ", waiting" << dendl;
./mds/StrayManager.cc:      dout(4) << __func__ << ": delayed dentry is now null: " << *dn << dendl;
./mds/StrayManager.cc:  dout(10) << "eval_stray " << *dn << dendl;
./mds/StrayManager.cc:  dout(10) << " inode is " << *dnl->get_inode() << dendl;
./mds/StrayManager.cc:      dout(20) << " replicated" << dendl;
./mds/StrayManager.cc:      dout(20) << " caps | leases" << dendl;
./mds/StrayManager.cc:      dout(20) << " pending recovery" << dendl;
./mds/StrayManager.cc:      dout(20) << " too many inode refs" << dendl;
./mds/StrayManager.cc:      dout(20) << " too many dn refs" << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << " " << *remote_dn << dendl;
./mds/StrayManager.cc:    dout(20) << __func__ << ": no inode, cannot evaluate" << dendl;
./mds/StrayManager.cc:    dout(20) << __func__ << ": snap dentry, cannot evaluate" << dendl;
./mds/StrayManager.cc:    dout(20) << __func__ << ": inode's primary dn not stray" << dendl;
./mds/StrayManager.cc:  dout(20) << __func__ << " " << *stray_dn << dendl;
./mds/StrayManager.cc:      dout(20) << __func__ << ": not reintegrating (no remote parents in cache)" << dendl;
./mds/StrayManager.cc:	dout(20) << __func__ << ": not reintegrating (can't authpin remote parent)" << dendl;
./mds/StrayManager.cc:      dout(20) << __func__ << ": not reintegrating" << dendl;
./mds/StrayManager.cc:    dout(20) << __func__ << ": not reintegrating (projected)" << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << " " << *straydn << " to " << *rdn << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << " " << *dn << " to mds." << to << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << ": " << *dn << " " << *in << dendl;
./mds/StrayManager.cc:  dout(10) << " realm " << *realm << dendl;
./mds/StrayManager.cc:  dout(10) << __func__ << ": " << *dn << " " << *in << dendl;
./mds/Migrator.cc:      dout(0) << "waiting for inject_session_race" << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << " inode is auth" << dendl;
./mds/Migrator.cc:    dout(7) << " not auth" << dendl;
./mds/Migrator.cc:    dout(7) << " freezing or frozen" << dendl;
./mds/Migrator.cc:    dout(7) << " not actually empty" << dendl;
./mds/Migrator.cc:    dout(7) << " root" << dendl;
./mds/Migrator.cc:  dout(7) << " really empty, exporting to " << dest << dendl;
./mds/Migrator.cc:  dout(10) << *dir << dendl;
./mds/Migrator.cc:    dout(10) << "export state=locking : dropping locks and removing auth_pin" << dendl;
./mds/Migrator.cc:    dout(10) << "export state=discovering : canceling freeze and removing auth_pin" << dendl;
./mds/Migrator.cc:    dout(10) << "export state=freezing : canceling freeze" << dendl;
./mds/Migrator.cc:    dout(10) << "export state=warning : unpinning bounds, unfreezing, notifying" << dendl;
./mds/Migrator.cc:      dout(10) << "export state=prepping : unpinning bounds, unfreezing" << dendl;
./mds/Migrator.cc:    dout(10) << "export state=exporting : reversing, and unfreezing" << dendl;
./mds/Migrator.cc:    dout(10) << "export state=loggingfinish|notifying : ignoring dest failure, we were successful." << dendl;
./mds/Migrator.cc:  dout(5) << who << dendl;
./mds/Migrator.cc:      dout(10) << "adding temp auth_pin on freezing " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=discovering : clearing state" << dendl;
./mds/Migrator.cc:	dout(10) << "import state=discovered : unpinning inode " << *diri << dendl;
./mds/Migrator.cc:	dout(10) << "import state=prepping : unpinning base+bounds " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=prepped : unpinning base+bounds, unfreezing " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=loggingstart : reversing import on " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=acking : noting ambiguous import " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=finishing : finishing import on " << *dir << dendl;
./mds/Migrator.cc:	dout(10) << "import state=aborting : ignoring repeat failure " << *dir << dendl;
./mds/Migrator.cc:    dout(10) << "removing temp auth_pin on " << *dir << dendl;
./mds/Migrator.cc:  dout(10) << dendl;
./mds/Migrator.cc:  dout(10) << dendl;
./mds/Migrator.cc:  dout(7) << *dir << " to " << dest << dendl;
./mds/Migrator.cc:    dout(7) << "nicely exporting to mds." << dest << " " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": dir is export pinned" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": not active" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": read-only FS, no exports for now" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": destination not active" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": cluster degraded" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": is a system directory" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": is frozen" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": already exporting" << dendl;
./mds/Migrator.cc:    dout(7) << "Cannot export to mds." << dest << " " << *dir << ": in stray directory" << dendl;
./mds/Migrator.cc:	dout(7) << "create aux subtree " << *bd << " under " << *dir << dendl;
./mds/Migrator.cc:  dout(4) << "Starting export to mds." << dest << " " << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *mdr << " " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "export must have aborted " << *mdr << dendl;
./mds/Migrator.cc:    dout(7) << "wouldblock|freezing|frozen, canceling export" << dendl;
./mds/Migrator.cc:    dout(7) << "dest is not yet an export target" << dendl;
./mds/Migrator.cc:      dout(7) << "dest has not been added as export target after three MDSMap epochs, canceling export" << dendl;
./mds/Migrator.cc:    dout(7) << "waiting for dir to become stable before export: " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "subtree is too large, splitting it into: " <<  dendl;
./mds/Migrator.cc:    dout(7) << " sub " << *sub << dendl;
./mds/Migrator.cc:	dout(7) << "child_export_finish requeue " << *origin << dendl;
./mds/Migrator.cc:    dout(7) << "must have aborted" << dendl;
./mds/Migrator.cc:      dout(7) << "peer failed to discover (not active?), canceling" << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "export must have aborted on " << dir << dendl;
./mds/Migrator.cc:  dout(7) << " started to encode dir " << *bound << dendl;
./mds/Migrator.cc:    dout(7) << "  added " << *cur->inode->parent << dendl;
./mds/Migrator.cc:    dout(7) << "  added " << *cur->inode << dendl;
./mds/Migrator.cc:    dout(7) << "  added " << *cur << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "export must have aborted" << dendl;
./mds/Migrator.cc:      dout(10) << "bystander mds." << p.first << dendl;
./mds/Migrator.cc:    dout(7) << "  export bound " << *bound << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "export must have aborted" << dendl;
./mds/Migrator.cc:    dout(7) << "peer couldn't acquire all needed locks or wasn't active, canceling" << dendl;
./mds/Migrator.cc:  dout(7) << *dir << " to " << it->second.peer << dendl;
./mds/Migrator.cc:    dout(7) << "export must have aborted on " << dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << " to " << dest << dendl;
./mds/Migrator.cc:  dout(7) << *in << dendl;
./mds/Migrator.cc:  dout(20) << *in << dendl;
./mds/Migrator.cc:  dout(20) << *in << dendl;
./mds/Migrator.cc:  dout(12) << *in << dendl;
./mds/Migrator.cc:  dout(7) << *dir << " " << dir->get_num_head_items() << " head items" << dendl;
./mds/Migrator.cc:    dout(7) << " exporting " << *dn << dendl;
./mds/Migrator.cc:  dout(10) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:      dout(7) << "not sending MExportDirFinish, dest has failed" << dendl;
./mds/Migrator.cc:  dout(3) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "target must have failed, not sending final commit message.  export succeeded anyway." << dendl;
./mds/Migrator.cc:    dout(7) << "not sending MExportDirFinish last, dest has failed" << dendl;
./mds/Migrator.cc:  dout(7) << "unfreezing" << dendl;
./mds/Migrator.cc:  dout(7) << m->get_path() << dendl;
./mds/Migrator.cc:    dout(7) << " not active, send NACK " << dendl;
./mds/Migrator.cc:      dout(7) << " dropping obsolete message" << dendl;
./mds/Migrator.cc:    dout(10) << " waiting for root" << dendl;
./mds/Migrator.cc:      dout(7) << "failed to discover or not dir " << m->get_path() << ", NAK" << dendl;
./mds/Migrator.cc:  dout(7) << "have " << df << " inode " << *in << dendl;
./mds/Migrator.cc:  dout(7) << " sending export_discover_ack on " << *in << dendl;
./mds/Migrator.cc:  dout(7) << "on " << m->get_dirfrag() << dendl;
./mds/Migrator.cc:  dout(10) << " trace from " << df << " start " << start << dendl;
./mds/Migrator.cc:    dout(10) << "  had " << *cur << dendl;
./mds/Migrator.cc:    dout(10) << "  had " << *in << dendl; 
./mds/Migrator.cc:    dout(10) << "  added " << *cur << dendl;
./mds/Migrator.cc:    dout(10) << "  added " << *dn << dendl;
./mds/Migrator.cc:    dout(10) << "  added " << *in << dendl;
./mds/Migrator.cc:    dout(10) << "  added " << *cur << dendl;
./mds/Migrator.cc:    dout(7) << "on " << *dir << " (first pass)" << dendl;
./mds/Migrator.cc:      dout(7) << "obsolete message, dropping" << dendl;
./mds/Migrator.cc:    dout(7) << "on " << *dir << " (subsequent pass)" << dendl;
./mds/Migrator.cc:    dout(10) << " bound " << bound << dendl;
./mds/Migrator.cc:    dout(7) << "doing assim on " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "bystanders are " << it->second.bystanders << dendl;
./mds/Migrator.cc:      dout(7) << " set stickydirs on bound inode " << *in << dendl;
./mds/Migrator.cc:    dout(7) << " not doing assim on " << *dir << dendl;
./mds/Migrator.cc:      dout(10) << " bound inode " << p->first << " fragset " << p->second << " maps to " << leaves << dendl;
./mds/Migrator.cc:	  dout(7) << "  opening bounding dirfrag " << leaf << " on " << *in << dendl;
./mds/Migrator.cc:	  dout(7) << "  pinning import bound " << *bound << dendl;
./mds/Migrator.cc:	  dout(7) << "  already pinned import bound " << *bound << dendl;
./mds/Migrator.cc:    dout(7) << " all ready, noting auth and freezing import region" << dendl;
./mds/Migrator.cc:      dout(7) << " couldn't acquire all needed locks, failing. " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << " not active, failing. " << *dir << dendl;
./mds/Migrator.cc:  dout(7) << " sending export_prep_ack on " << *dir << dendl;
./mds/Migrator.cc:  dout(7) << "importing " << *dir << " from " << oldauth << dendl;
./mds/Migrator.cc:  dout(10) << " " << m->bounds.size() << " imported bounds" << dendl;
./mds/Migrator.cc:  dout(7) << "did " << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "no bystanders, finishing reverse now" << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "import " << df << " must have aborted" << dendl;
./mds/Migrator.cc:  dout(7) << "sending ack for " << *dir << " to old auth mds." << from << dendl;
./mds/Migrator.cc:  dout(7) << *dir << (m->is_last() ? " last" : "") << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(15) << " on " << *dn << dendl;
./mds/Migrator.cc:    dout(10) << "added " << *in << dendl;
./mds/Migrator.cc:    dout(10) << "  had " << *in << dendl;
./mds/Migrator.cc:    dout(10) << "for client." << it.first << " on " << *in << dendl;
./mds/Migrator.cc:      dout(10) << " no session for client." << it.first << dendl;
./mds/Migrator.cc:  dout(7) << *dir << dendl;
./mds/Migrator.cc:  dout(15) << "doing contents" << dendl;
./mds/Migrator.cc:    dout(15) << " got " << *dn << dendl;
./mds/Migrator.cc:  dout(7) << " done " << *dir << dendl;
./mds/Migrator.cc:    dout(7) << "no ack requested" << dendl;
./mds/Migrator.cc:  dout(7) << "to mds." << dest << " " << *in << dendl;
./mds/Migrator.cc:  dout(10) << *ex << " from " << ex->get_source() << dendl;
./mds/Migrator.cc:  dout(10) << *in << dendl;
./mds/Migrator.cc:    dout(0) << "mds_inject_migrator_session_race is " << inject_session_race << dendl;
./mds/CDir.cc:  dout(25) << "check_rstats on " << this << dendl;
./mds/CDir.cc:    dout(1) << "mismatch between head items and fnode.fragstat! printing dentries" << dendl;
./mds/CDir.cc:    dout(1) << "mismatch between child accounted_rstats and my rstats!" << dendl;
./mds/CDir.cc:    dout(1) << "total of child dentries: " << nest_info << dendl;
./mds/CDir.cc:    dout(1) << "my rstats:              " << fnode->rstat << dendl;
./mds/CDir.cc:    dout(20) << "total of child dentries: " << nest_info << dendl;
./mds/CDir.cc:    dout(20) << "my rstats:              " << fnode->rstat << dendl;
./mds/CDir.cc:	  dout(1) << *dn << " rstat " << in->get_inode()->accounted_rstat << dendl;
./mds/CDir.cc:	  dout(1) << *dn << dendl;
./mds/CDir.cc:  dout(10) << "check_rstats complete on " << this << dendl;
./mds/CDir.cc:  dout(20) << "lookup (" << snap << ", '" << name << "')" << dendl;
./mds/CDir.cc:    dout(20) << "  hit -> " << iter->first << dendl;
./mds/CDir.cc:  dout(20) << "  miss -> " << iter->first << dendl;
./mds/CDir.cc:  dout(20) << __func__ << " (" << last << ", '" << name << "')" << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << " remote " << ino << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *dn << " " << *in << dendl;
./mds/CDir.cc:    dout(12) << __func__ << " " << *dn << " " << *dn->get_linkage()->get_inode() << dendl;
./mds/CDir.cc:    dout(12) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:    dout(10) << __func__ << " " << *dn << " in " << *this << dendl;
./mds/CDir.cc:  dout(12) << __func__ << " " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:    dout(10) << " purging snapped " << *dn << dendl;
./mds/CDir.cc:      dout(10) << " purging snapped " << *in << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << snaps << dendl;
./mds/CDir.cc:  dout(15) << __func__ << " " << *dn << dendl;
./mds/CDir.cc:  dout(10) << "split by " << bits << " bits on " << *this << dendl;
./mds/CDir.cc:  dout(10) << " rstatdiff " << rstatdiff << " fragstatdiff " << fragstatdiff << dendl;
./mds/CDir.cc:    dout(10) << " subfrag " << fg << " " << *f << dendl;
./mds/CDir.cc:    dout(15) << " subfrag " << subfrag << " n=" << n << " for " << p->first << dendl;
./mds/CDir.cc:  dout(10) << "merge " << subs << dendl;
./mds/CDir.cc:    dout(10) << " subfrag " << dir->get_frag() << " " << *dir << dendl;
./mds/CDir.cc:    dout(10) << __func__ << " " << pf->accounted_fragstat << " -> " << pf->fragstat << dendl;
./mds/CDir.cc:    dout(10) << __func__ << " " << pf->accounted_rstat << " -> " << pf->rstat << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " done" << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:      dout(10) << "add_waiter " << std::hex << tag << std::dec << " " << c << " should be ATSUBTREEROOT, " << *this << " is not root, trying parent" << dendl;
./mds/CDir.cc:  dout(11) << __func__ << " mask " << hex << mask << dec << " result " << result << " on " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ <<  " " << pf.get() << dendl;
./mds/CDir.cc:  dout(15) << __func__ << " " << pf.get() << " v" << pf->version << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << projected_version << dendl;
./mds/CDir.cc:    dout(10) << __func__ << " (was clean) " << *this << " version " << get_version() << dendl;
./mds/CDir.cc:    dout(10) << __func__ << " (already dirty) " << *this << " version " << get_version() << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << *this << " version " << get_version() << dendl;
./mds/CDir.cc:  dout(10) << "fetch on " << *this << dendl;
./mds/CDir.cc:      dout(7) << "fetch waiting for authpinnable" << dendl;
./mds/CDir.cc:      dout(7) << "fetch not authpinnable and no context" << dendl;
./mds/CDir.cc:    dout(7) << "fetch dirfrag for unlinked directory, mark complete" << dendl;
./mds/CDir.cc:    dout(7) << "already fetching; waiting" << dendl;
./mds/CDir.cc:  dout(10) << "fetch " << keys.size() << " keys on " << *this << dendl;
./mds/CDir.cc:    dout(7) << "fetch keys waiting for authpinnable" << dendl;
./mds/CDir.cc:    dout(7) << "fetch keys waiting for full fetch" << dendl;
./mds/CDir.cc:      dout(10) << " skipping stale dentry on [" << first << "," << last << "]" << dendl;
./mds/CDir.cc:      dout(12) << "_fetched had " << (dnl->is_null() ? "NEG" : "") << " dentry " << *dn << dendl;
./mds/CDir.cc:	dout(10) << "_fetched  had underwater dentry " << *dn << ", marking clean" << dendl;
./mds/CDir.cc:        dout(12) << "_fetched  got remote link " << ino << " which we have " << *in << dendl;
./mds/CDir.cc:        dout(12) << "_fetched  got remote link " << ino << " (don't have it)" << dendl;
./mds/CDir.cc:      dout(12) << "_fetched had " << (dnl->is_null() ? "NEG" : "") << " dentry " << *dn << dendl;
./mds/CDir.cc:	  dout(10) << "_fetched  had underwater dentry " << *dn << ", marking clean" << dendl;
./mds/CDir.cc:	  dout(10) << "_fetched  had underwater inode " << *dnl->get_inode() << ", marking clean" << dendl;
./mds/CDir.cc:        dout(12) << "_fetched  got " << *dn << " " << *in << dendl;
./mds/CDir.cc:	dout(20) << "hack: adding duplicate dentry for " << *in << dendl;
./mds/CDir.cc:    dout(0) << "_fetched missing object for " << *this << dendl;
./mds/CDir.cc:  dout(10) << "_fetched version " << got_fnode.version << dendl;
./mds/CDir.cc:      dout(10) << " touching wanted dn " << *dn << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << dname << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << frag << dendl;
./mds/CDir.cc:  dout(10) << "commit want " << want << " on " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:  dout(10) << __func__ << dendl;
./mds/CDir.cc:      dout(10) << " rm " << key << dendl;
./mds/CDir.cc:      dout(10) << " rm " << dn->get_name() << " " << *dn << dendl;
./mds/CDir.cc:      dout(10) << " set " << dn->get_name() << " " << *dn << dendl;
./mds/CDir.cc:    dout(14) << " dn '" << dn->get_name() << "' remote ino " << item.ino << dendl;
./mds/CDir.cc:    dout(14) << " dn '" << dn->get_name() << "' inode " << *in << dendl;
./mds/CDir.cc:  dout(10) << "_commit want " << want << " on " << *this << dendl;
./mds/CDir.cc:    dout(10) << "already committed " << committed_version << " >= " << want << dendl;
./mds/CDir.cc:    dout(10) << "already committing " << committing_version << " >= " << want << dendl;
./mds/CDir.cc:    dout(10) << "already committing older " << committing_version << ", waiting for that to finish" << dendl;
./mds/CDir.cc:    dout(10) << "marking committing" << dendl;
./mds/CDir.cc:      dout(1) << "commit error " << r << " v " << v << dendl;
./mds/CDir.cc:  dout(10) << "_committed v " << v << " on " << *this << dendl;
./mds/CDir.cc:	  dout(15) << " dir " << committed_version << " >= inode " << in->get_version() << " now clean " << *in << dendl;
./mds/CDir.cc:	dout(15) << " dir " << committed_version << " < inode " << in->get_version() << " still dirty " << *in << dendl;
./mds/CDir.cc:      dout(15) << " dir " << committed_version << " >= dn " << dn->get_version() << " now clean " << *dn << dendl;
./mds/CDir.cc:      dout(15) << " dir " << committed_version << " < dn " << dn->get_version() << " still dirty " << *dn << dendl;
./mds/CDir.cc:      dout(10) << " there are waiters for " << it->first << ", committing again" << dendl;
./mds/CDir.cc:    dout(10) << " new subtree root, adjusting auth_pins" << dendl;
./mds/CDir.cc:    dout(10) << " old subtree root, adjusting auth_pins" << dendl;
./mds/CDir.cc:  dout(10) << "auth_pin by " << by << " on " << *this << " count now " << auth_pins << dendl;
./mds/CDir.cc:  dout(10) << "auth_unpin by " << by << " on " << *this << " count now " << auth_pins << dendl;
./mds/CDir.cc:    dout(10) << " " << *dn << dendl;
./mds/CDir.cc:      dout(10) << "     " << *dn->inode << dendl;
./mds/CDir.cc:    dout(0) << "verify_fragstat failed " << fnode->fragstat << " on " << *this << dendl;
./mds/CDir.cc:    dout(0) << "               i count " << c << dendl;
./mds/CDir.cc:    dout(0) << "verify_fragstat ok " << fnode->fragstat << " on " << *this << dendl;
./mds/CDir.cc:    dout(10) << "freeze_tree waiting " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDir.cc:      dout(10) << __func__ << " !subtree root and frozen inode, waiting for unfreeze on " << inode << dendl;
./mds/CDir.cc:    dout(10) << "freeze_dir + wait " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDir.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CDir.cc:  dout(20) << __func__ << dendl;
./mds/CDir.cc:  dout(20) << __func__ << dendl;
./mds/Beacon.cc:      dout(20) << "sender thread waiting interval " << interval << "s" << dendl;
./mds/Beacon.cc:    dout(5) << "received beacon reply " << ceph_mds_state_name(m->get_state()) << " seq " << m->get_seq() << " rtt " << rtt << dendl;
./mds/Beacon.cc:      dout(0) << " MDS is no longer laggy" << dendl;
./mds/Beacon.cc:    dout(0) << "Skipping beacon heartbeat to monitors (last acked " << since << "s ago); MDS internal heartbeat is not healthy!" << dendl;
./mds/Beacon.cc:  dout(5) << "Sending beacon " << ceph_mds_state_name(want_state) << " seq " << last_seq << dendl;
./mds/Beacon.cc:      dout(20) << slow << " slow request found" << dendl;
./mds/Beacon.cc:      dout(20) << count << " slow metadata IOs found" << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " client." << client << " snapid " << snapid << " on " << snapin << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " client." << client << " snapid " << snapid << " on " << snapin << dendl;
./mds/CInode.cc:    dout(10) << " snapid not found" << dendl;
./mds/CInode.cc:    dout(10) << " client not found" << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " [" << cowin->first << "," << cowin->last << "] for " << *cowin << dendl;
./mds/CInode.cc:    dout(10) << __func__ << dendl;
./mds/CInode.cc:    dout(10) << __func__ << dendl;
./mds/CInode.cc:  dout(15) << __func__ << " " << pi->ino << dendl;
./mds/CInode.cc:  dout(15) << __func__ << " v" << front.inode->version << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << new_srnode << dendl;
./mds/CInode.cc:      dout(10) << " realm " << *snaprealm << " parent " << *snaprealm->parent << dendl;
./mds/CInode.cc:    dout(10) << __func__ << (early ? " (early) null" : " null") << dendl;
./mds/CInode.cc:  dout(14) << __func__ << " " << fg << dendl;
./mds/CInode.cc:    dout(14) << __func__ << " LEFTOVER dn " << *p.second << dendl;
./mds/CInode.cc:    dout(10) << "pre_dirty " << pv << " (current v " << get_inode()->version << ")" << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << get_version() << dendl;
./mds/CInode.cc:    dout(1) << "store error " << r << " v " << v << " on " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << v << " on " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__  << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " got " << bl.length() << " and " << bl2.length() << dendl;
./mds/CInode.cc:      dout(10) << "_fetched " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " on " << *this << dendl;
./mds/CInode.cc:    dout(20) << __func__ << ": no dirtypool or no old pools" << dendl;
./mds/CInode.cc:    dout(20) << __func__ << ": updating old pool " << p << dendl;
./mds/CInode.cc:    dout(1) << "store backtrace error " << r << " v " << v << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " v " << v <<  dendl;
./mds/CInode.cc:    dout(10) << __func__ << dendl;
./mds/CInode.cc:    dout(10) << __func__ << dendl;
./mds/CInode.cc:  dout(10) << __func__ << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " setting dftlock dirty flag" << dendl;
./mds/CInode.cc:          dout(10) << " forcing frag " << fg << " to leaf (split|merge)" << dendl;
./mds/CInode.cc:          dout(10) << " forcing open dirfrag " << p.first << " to leaf (racing with split|merge)" << dendl;
./mds/CInode.cc:  dout(15) << __func__ << " inode.dirstat is " << get_inode()->dirstat << dendl;
./mds/CInode.cc:      dout(15) << fg << " " << *dir << dendl;
./mds/CInode.cc:      dout(20) << fg << "           fragstat " << pf->fragstat << dendl;
./mds/CInode.cc:      dout(20) << fg << " accounted_fragstat " << pf->accounted_fragstat << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " setting filelock dirty flag" << dendl;
./mds/CInode.cc:    dout(10) << " taking inode dirstat " << dirstat << " for " << *this << dendl;
./mds/CInode.cc:  dout(10) << " ...got " << n << " fragstats on " << *this << dendl;
./mds/CInode.cc:    dout(10) << fg << " [" << fgfirst << ",head] " << dendl;
./mds/CInode.cc:    dout(10) << fg << "           fragstat " << fragstat << dendl;
./mds/CInode.cc:    dout(20) << fg << " accounted_fragstat " << accounted_fragstat << dendl;
./mds/CInode.cc:        dout(10) << fg << " setting filelock updated flag" << dendl;
./mds/CInode.cc:  dout(15) << __func__ << " inode.rstat is " << get_inode()->rstat << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " " << fg << " dir " << *dir << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " " << fg << " rstat " << pf->rstat << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " " << fg << " accounted_rstat " << pf->rstat << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " " << fg << " dirty_old_rstat " << dir->dirty_old_rstat << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " setting nestlock dirty flag" << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " taking inode rstat " << rstat << " for " << *this << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " [" << fgfirst << ",head]" << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " rstat " << rstat << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " accounted_rstat " << accounted_rstat << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " dirty_old_rstat " << dirty_old_rstat << dendl;
./mds/CInode.cc:        dout(10) << fg << " setting nestlock updated flag" << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " first " << first << " -> " << newfirst << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " parent first " << first << " -> " << newfirst << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << type << " on " << *this << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << *lock << " on " << *this << dendl;
./mds/CInode.cc:    dout(20) << fg << " " << *dir << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " frozen, marking " << *lock << " stale " << *dir << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " " << fg << " not loaded, marking " << *lock << " stale " << *dir << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " " << fg << " journaling accounted scatterstat update v" << inode_version << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " on " << *dir << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << type << " on " << *this << dendl;
./mds/CInode.cc:      dout(20) << "  orig dirstat " << pi->dirstat << dendl;
./mds/CInode.cc:	dout(20) << fg << " " << *dir << dendl;
./mds/CInode.cc:	  dout(20) << fg << "           fragstat " << pf->fragstat << dendl;
./mds/CInode.cc:	  dout(20) << fg << " accounted_fragstat " << pf->accounted_fragstat << dendl;
./mds/CInode.cc:	  dout(20) << fg << " skipping STALE accounted_fragstat " << pf->accounted_fragstat << dendl;
./mds/CInode.cc:	  dout(10) << fg << " updated accounted_fragstat " << pf->fragstat << " on " << *dir << dendl;
./mds/CInode.cc:      dout(20) << " final dirstat " << pi->dirstat << dendl;
./mds/CInode.cc:	    dout(20) << " dirstat mismatch, fixing" << dendl;
./mds/CInode.cc:      dout(20) << "  orig rstat " << pi->rstat << dendl;
./mds/CInode.cc:	dout(20) << fg << " " << *dir << dendl;
./mds/CInode.cc:	  dout(20) << fg << "           rstat " << pf->rstat << dendl;
./mds/CInode.cc:	  dout(20) << fg << " accounted_rstat " << pf->accounted_rstat << dendl;
./mds/CInode.cc:	  dout(20) << fg << " dirty_old_rstat " << dir->dirty_old_rstat << dendl;
./mds/CInode.cc:	  dout(20) << fg << " skipping STALE accounted_rstat " << pf->accounted_rstat << dendl;
./mds/CInode.cc:	  dout(10) << fg << " updated accounted_rstat " << pf->rstat << " on " << *dir << dendl;
./mds/CInode.cc:      dout(20) << " final rstat " << pi->rstat << dendl;
./mds/CInode.cc:	    dout(20) << " rstat mismatch, fixing" << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << type << " on " << *this << dendl;
./mds/CInode.cc:    dout(10) << " journaling updated frag accounted_ on " << *dir << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " frag " << fg << " " << c << " on " << *this << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " frag " << fg << " on " << *this << dendl;
./mds/CInode.cc:    dout(15) << "passing waiter up tree" << dendl;
./mds/CInode.cc:  dout(15) << "taking waiter here" << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " dirfrag " << it->first << " on " << *this << dendl;
./mds/CInode.cc:  dout(10) << "maybe_finish_freeze_inode - frozen" << dendl;
./mds/CInode.cc:    dout(10) << "freeze_inode - frozen" << dendl;
./mds/CInode.cc:  dout(10) << "freeze_inode - waiting for auth_pins to drop to " << auth_pin_allowance << dendl;
./mds/CInode.cc:  dout(10) << __func__ << dendl;
./mds/CInode.cc:  dout(10) << "auth_pin by " << by << " on " << *this << " now " << auth_pins << dendl;
./mds/CInode.cc:  dout(10) << "auth_unpin by " << by << " on " << *this << " now " << auth_pins << dendl;
./mds/CInode.cc:    dout(10) << " " << px->size() << " xattrs cowed, " << *px << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " " << snaps << dendl;
./mds/CInode.cc:      dout(10) << " purging old_inode [" << p.second.first << "," << id << "]" << dendl;
./mds/CInode.cc:      dout(10) << __func__ << " snap " << snap << " -> [" << it->second.first << "," << it->first << "]" << dendl;
./mds/CInode.cc:  dout(10) << __func__ << " snap " << snap << " -> nothing" << dendl;
./mds/CInode.cc:      dout(30) << " siblings are " << parent->open_children << dendl;
./mds/CInode.cc:    dout(15) << __func__ << " " << *snaprealm << dendl;
./mds/CInode.cc:    dout(20) << __func__ << " " << *snaprealm << dendl;
./mds/CInode.cc:    dout(20) << __func__ << " " << *snaprealm << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " first cap, joining realm " << *containing_realm << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " last cap, leaving realm " << *containing_realm << dendl;
./mds/CInode.cc:      dout(10) << "including inline version " << inline_version << dendl;
./mds/CInode.cc:      dout(10) << "dropping inline version " << inline_version << dendl;
./mds/CInode.cc:      dout(10) << "including xattrs version " << xattr_version << dendl;
./mds/CInode.cc:      dout(10) << "dropping xattrs version " << xattr_version << dendl;
./mds/CInode.cc:    dout(10) << "    including xattrs v " << i->xattr_version << dendl;
./mds/CInode.cc:	dout(10) << " encoded fragstat/rstat info for " << *dir << dendl;
./mds/CInode.cc:      dout(10) << " skipped fragstat info for " << *dir << dendl;
./mds/CInode.cc:      dout(10) << " took fragstat info for " << *dir << dendl;
./mds/CInode.cc:      dout(10) << " skipped rstat info for " << *dir << dendl;
./mds/CInode.cc:      dout(10) << " took rstat info for " << *dir << dendl;
./mds/CInode.cc:      dout(20) << "ondisk_read_retval: " << results->backtrace.ondisk_read_retval << dendl;
./mds/CInode.cc:        dout(10) << "decoded " << bl.length() << " bytes of backtrace successfully" << dendl;
./mds/CInode.cc:        dout(10) << "scrub: inotable ino = " << in->ino() << dendl;
./mds/CInode.cc:  dout(10) << "scrub starting validate_disk_state on " << *this << dendl;
./mds/CInode.cc:  dout(25) << __func__ << dendl;
./mds/CInode.cc:  dout(20) << __func__ << " with scrub_version " << get_version() << dendl;
./mds/CInode.cc:  dout(20) << __func__ << dendl;
./mds/CInode.cc:  dout(20) << __func__ << dendl;
./mds/CInode.cc:  dout(15) << __func__ << " update=" << update << " " << *this << dendl;
./mds/CInode.cc:    dout(15) << __func__ << " config false: cannot ephemeral random pin " << *this << dendl;
./mds/CInode.cc:    dout(15) << __func__ << " !dir or !normal: cannot ephemeral random pin " << *this << dendl;
./mds/CInode.cc:    dout(15) << __func__ << " unlinked directory: cannot ephemeral random pin " << *this << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " already ephemeral random pinned: requeueing " << *this << dendl;
./mds/CInode.cc:    dout(10) << __func__ << " randomly export pinning " << *this << dendl;
./mds/flock.cc:  ldout(cct,15) << "is_deadlock " << fl << dendl;
./mds/flock.cc:      ldout(cct,15) << " detect deadlock" << dendl;
./mds/flock.cc:    ldout(cct,15) << " conflict lock owner " << *p << dendl;
./mds/flock.cc:  ldout(cct,15) << "add_lock " << new_lock << dendl;
./mds/flock.cc:    ldout(cct,15) << "got overlapping lock, splitting by owner" << dendl;
./mds/flock.cc:        ldout(cct,15) << " blocked by exclusive lock in overlapping_locks" << dendl;
./mds/flock.cc:        ldout(cct,15) << "inserting shared lock" << dendl;
./mds/flock.cc:    ldout(cct,15) << "no conflicts, inserting " << new_lock << dendl;
./mds/flock.cc:    ldout(cct,15) << "splitting by owner" << dendl;
./mds/flock.cc:    ldout(cct,15) << "self overlapping lock " << (*iter)->second << dendl;
./mds/flock.cc:        ldout(cct,15) << "erasing " << (*iter)->second << dendl;
./mds/flock.cc:        ldout(cct,15) << "erasing " << (*iter)->second << dendl;
./mds/flock.cc:        ldout(cct,15) << "erasing " << (*iter)->second << dendl;
./mds/flock.cc:  ldout(cct,15) << "adjust_locks" << dendl;
./mds/flock.cc:    ldout(cct,15) << "adjusting lock: " << *old_lock << dendl;
./mds/flock.cc:      ldout(cct,15) << "one lock extends forever" << dendl;
./mds/flock.cc:        ldout(cct,15) << "same lock type, unifying" << dendl;
./mds/flock.cc:        ldout(cct,15) << "shrinking old lock" << dendl;
./mds/flock.cc:        ldout(cct,15) << "merging locks, they're the same type" << dendl;
./mds/flock.cc:        ldout(cct,15) << "erasing lock " << (*iter)->second << dendl;
./mds/flock.cc:        ldout(cct,15) << "locks aren't same type, changing sizes" << dendl;
./mds/flock.cc:    ldout(cct,15) << "lock to coalesce: " << *old_lock << dendl;
./mds/flock.cc:     ldout(cct,15) << "get_lower_dout(15)eturning end()" << dendl;
./mds/flock.cc:    ldout(cct,15) << "get_last_before returning end()" << dendl;
./mds/flock.cc:  ldout(cct,15) << "get_overlapping_locks" << dendl;
./mds/flock.cc:  ldout(cct,15) << "get_waiting_overlaps" << dendl;
./mds/flock.cc:  ldout(cct,15) << "owner lock: " << owner << dendl;
./mds/flock.cc:    ldout(cct,15) << "comparing to " << (*iter)->second << dendl;
./mds/flock.cc:      ldout(cct,15) << "success, pushing to owned_locks" << dendl;
./mds/MDSContext.cc:  dout(10) << "MDSContext::complete: " << typeid(*this).name() << dendl;
./mds/MDSContext.cc:  dout(10) << "MDSIOContextBase::complete: " << typeid(*this).name() << dendl;
./mds/MDCache.cc:          dout(20) << "upkeep thread trimming cache; last trim " << since << " ago" << dendl;
./mds/MDCache.cc:          dout(10) << "cache not ready for trimming" << dendl;
./mds/MDCache.cc:        dout(10) << "releasing free memory" << dendl;
./mds/MDCache.cc:      dout(20) << "upkeep thread waiting interval " << interval << dendl;
./mds/MDCache.cc:  dout(20) << "config changes: " << changed << dendl;
./mds/MDCache.cc:    dout(10) << "Migrating any ephemeral distributed pinned inodes" << dendl;
./mds/MDCache.cc:    dout(10) << "Migrating any ephemeral random pinned inodes" << dendl;
./mds/MDCache.cc:    dout(7) << "WARNING: mdcache shutdown with non-empty cache" << dendl;
./mds/MDCache.cc:  dout(14) << "remove_inode " << *o << dendl;
./mds/MDCache.cc:  dout(0) << "creating system inode with ino:" << ino << dendl;
./mds/MDCache.cc:  dout(10) << "_create_system_file " << name << " in " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "_create_system_file_finish " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << "open_root" << dendl;
./mds/MDCache.cc:  dout(10) << "populate_mydir " << *mydir << dendl;
./mds/MDCache.cc:    dout(20) << " stray num " << i << " is " << *strays[i] << dendl;
./mds/MDCache.cc:  dout(10) << "populate_mydir done" << dendl;
./mds/MDCache.cc:  dout(7) << " current root is " << *root << dendl;
./mds/MDCache.cc:    dout(10) << "  new subtree at " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << "  claiming child bound " << **p << dendl;
./mds/MDCache.cc:  dout(7) << "try_subtree_merge " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "try_subtree_merge_at " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << "  subtree merge at " << *dir << dendl;
./mds/MDCache.cc:  dout(7) << " current root is " << *root << dendl;
./mds/MDCache.cc:    dout(10) << "  new subtree at " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << "  claiming child bound " << **p << dendl;
./mds/MDCache.cc:	dout(10) << "  new bound " << *bound << ", adjusting auth back to old " << oldauth << dendl;
./mds/MDCache.cc:	dout(10) << "  want bound " << *bound << dendl;
./mds/MDCache.cc:	  dout(10) << "  new bound " << *bound << dendl;
./mds/MDCache.cc:	  dout(10) << "  swallowing intervening subtree at " << *t << dendl;
./mds/MDCache.cc:      dout(10) << "  already have bound " << *bound << dendl;
./mds/MDCache.cc:	dout(10) << "  swallowing extra subtree at " << *stray << dendl;
./mds/MDCache.cc:  dout(10) << "get_force_dirfrag_bound_set " << dfs << dendl;
./mds/MDCache.cc:  dout(10) << " by ino: " << byino << dendl;
./mds/MDCache.cc:    dout(10) << " checking fragset " << p->second.get() << " on " << *diri << dendl;
./mds/MDCache.cc:  dout(10) << "map_dirfrag_set " << dfs << dendl;
./mds/MDCache.cc:  dout(10) << "remove_subtree " << *dir << dendl;
./mds/MDCache.cc:    dout(0) << "verify_subtree_bounds failed" << dendl;
./mds/MDCache.cc:      dout(0) << "  missing bound " << *cd << dendl;
./mds/MDCache.cc:      dout(0) << "    extra bound " << *cd << dendl;
./mds/MDCache.cc:      dout(0) << "verify_subtree_bounds failed: extra bound " << *bd << dendl;
./mds/MDCache.cc:  dout(10) << "adjust_subtree_after_rename " << *diri << " from " << *olddir << dendl;
./mds/MDCache.cc:    dout(10) << "dirfrag " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << " old parent " << *oldparent << dendl;
./mds/MDCache.cc:    dout(10) << " new parent " << *newparent << dendl;
./mds/MDCache.cc:      dout(10) << "parent unchanged for " << *dir << " at " << *oldparent << dendl;
./mds/MDCache.cc:      dout(10) << "moving " << *dir << " from " << *oldparent << " to " << *newparent << dendl;
./mds/MDCache.cc:	dout(10) << "moving bound " << *bound << " from " << *oldparent << " to " << *newparent << dendl;
./mds/MDCache.cc:  dout(10) << "pick_inode_snap follows " << follows << " on " << *in << dendl;
./mds/MDCache.cc:    dout(10) << "pick_inode_snap found " << *p->second << dendl;
./mds/MDCache.cc:  dout(10) << "cow_inode " << *in << " to " << *oldin << dendl;
./mds/MDCache.cc:	dout(10) << " client." << client << " cap " << ccap_string(issued) << dendl;
./mds/MDCache.cc:	dout(10) << "  snaps " << snaps << dendl;
./mds/MDCache.cc:	dout(10) << " ignoring client." << client << " cap follows " << cap->client_follows << dendl;
./mds/MDCache.cc:    dout(10) << "journal_cow_dentry got null CDentry, returning" << dendl;
./mds/MDCache.cc:  dout(10) << "journal_cow_dentry follows " << follows << " on " << *dn << dendl;
./mds/MDCache.cc:	  dout(10) << " olddn " << *olddn << dendl;
./mds/MDCache.cc:      dout(10) << "journal_cow_dentry follows " << follows << " < first on " << *in << dendl;
./mds/MDCache.cc:      dout(10) << "journal_cow_dentry no snapshot follows " << follows << " on " << *in << dendl;
./mds/MDCache.cc:      dout(10) << "journal_cow_dentry follows " << follows << " < first on " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << "journal_cow_dentry no snapshot follows " << follows << " on " << *dn << dendl;
./mds/MDCache.cc:    dout(10) << "    dn " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << " olddn " << *olddn << dendl;
./mds/MDCache.cc:      dout(10) << " olddn " << *olddn << dendl;
./mds/MDCache.cc:  dout(20) << "    frag head is [" << parent->first << ",head] " << dendl;
./mds/MDCache.cc:  dout(20) << " inode update is [" << first << "," << cur->last << "]" << dendl;
./mds/MDCache.cc:  dout(20) << " floor of " << floor << " from parent dn " << *parentdn << dendl;
./mds/MDCache.cc:  dout(10) << "_project_rstat_inode_to_frag [" << ofirst << "," << last << "]" << dendl;
./mds/MDCache.cc:  dout(20) << "  inode           rstat " << inode->rstat << dendl;
./mds/MDCache.cc:  dout(20) << "  inode accounted_rstat " << inode->accounted_rstat << dendl;
./mds/MDCache.cc:  dout(20) << "                  delta " << delta << dendl;
./mds/MDCache.cc:      dout(20) << " projecting to head [" << first << "," << last << "] " << *prstat << dendl;
./mds/MDCache.cc:	dout(20) << "  no dirty_old_rstat with last >= last " << last << dendl;
./mds/MDCache.cc:	  dout(20) << "  last dirty_old_rstat ends at " << parent->dirty_old_rstat.rbegin()->first << dendl;
./mds/MDCache.cc:	    dout(10) << " splitting off left bit [" << it->second.first << "," << first-1 << "]" << dendl;
./mds/MDCache.cc:	    dout(10) << " splitting off right bit [" << last+1 << "," << it->first << "]" << dendl;
./mds/MDCache.cc:	    dout(10) << " staying to the right of [" << it->second.first << "," << it->first << "]..." << dendl;
./mds/MDCache.cc:	  dout(10) << " projecting to new dirty_old_rstat [" << first << "," << last << "]" << dendl;
./mds/MDCache.cc:      dout(20) << " projecting to dirty_old_rstat [" << first << "," << last << "]" << dendl;
./mds/MDCache.cc:    dout(20) << "  project to [" << first << "," << last << "] " << *prstat << dendl;
./mds/MDCache.cc:    dout(20) << "      result [" << first << "," << last << "] " << *prstat << " " << *parent << dendl;
./mds/MDCache.cc:  dout(10) << "project_rstat_frag_to_inode [" << ofirst << "," << last << "]" << dendl;
./mds/MDCache.cc:  dout(20) << "  frag           rstat " << rstat << dendl;
./mds/MDCache.cc:  dout(20) << "  frag accounted_rstat " << accounted_rstat << dendl;
./mds/MDCache.cc:  dout(20) << "                 delta " << delta << dendl;
./mds/MDCache.cc:	dout(20) << "   cloned old_inode rstat is " << old.inode.rstat << dendl;
./mds/MDCache.cc:	  dout(10) << " no old_inode <= " << last << ", done." << dendl;
./mds/MDCache.cc:	  dout(10) << " oldest old_inode is [" << first << "," << it->first << "], done." << dendl;
./mds/MDCache.cc:    dout(20) << " projecting to [" << first << "," << last << "] " << pi->rstat << dendl;
./mds/MDCache.cc:    dout(20) << "        result [" << first << "," << last << "] " << pi->rstat << dendl;
./mds/MDCache.cc:    dout(10) << " no flags/linkunlink, just adding dir context to blob(s)" << dendl;
./mds/MDCache.cc:	dout(10) << "predirty_journal_parents bumping change_attr to " << pf->fragstat.change_attr << " on " << parent << dendl;
./mds/MDCache.cc:	  dout(10) << "predirty_journal_parents updating mtime on " << *parent << dendl;
./mds/MDCache.cc:	  dout(10) << "predirty_journal_parents updating mtime UNDERWATER on " << *parent << dendl;
./mds/MDCache.cc:	dout(10) << "predirty_journal_parents updating size on " << *parent << dendl;
./mds/MDCache.cc:	dout(10) << " taking wrlock on " << pin->nestlock << " on " << *pin << dendl;
./mds/MDCache.cc:      dout(10) << "predirty_journal_parents !auth or ambig or can't authpin on " << *pin << dendl;
./mds/MDCache.cc:	dout(10) << "predirty_journal_parents last prop " << since_last_prop << " ago, continuing" << dendl;
./mds/MDCache.cc:      dout(10) << "predirty_journal_parents stop.  marking nestlock on " << *pin << dendl;
./mds/MDCache.cc:      dout(20) << "predirty_journal_parents add_delta " << pf->fragstat << dendl;
./mds/MDCache.cc:      dout(20) << "predirty_journal_parents         - " << pf->accounted_fragstat << dendl;
./mds/MDCache.cc:      dout(20) << "predirty_journal_parents     gives " << pi.inode->dirstat << " on " << *pin << dendl;
./mds/MDCache.cc:    dout(10) << "predirty_journal_parents frag->inode on " << *parent << dendl;
./mds/MDCache.cc:  dout(10) << "log_leader_commit " << reqid << dendl;
./mds/MDCache.cc:  dout(10) << "_logged_leader_commit " << reqid << dendl;
./mds/MDCache.cc:  dout(10) << "committed_leader_peer mds." << from << " on " << r << dendl;
./mds/MDCache.cc:  dout(10) << "logged_leader_update " << reqid << dendl;
./mds/MDCache.cc:      dout(10) << "finish_committed_leaders " << p->first << dendl;
./mds/MDCache.cc:  dout(10) << "_logged_peer_commit from mds." << from << " " << reqid << dendl;
./mds/MDCache.cc:      dout(10) << " removing " << df << " from " << oldparent << " bounds " << v << dendl;
./mds/MDCache.cc:    dout(10) << " adding " << df << " to " << newparent << " bounds " << v << dendl;
./mds/MDCache.cc:      dout(15) << " ambig subtree " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << " auth subtree " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << "  subtree has " << nbounds << " bounds" << dendl;
./mds/MDCache.cc:        dout(15) << "  subtree bound " << *bound << dendl;
./mds/MDCache.cc:      dout(15) << " adjusting for projected rename of " << *diri << " to " << *newdir << dendl;
./mds/MDCache.cc:	dout(15) << "dirfrag " << dir->dirfrag() << " " << *dir << dendl;
./mds/MDCache.cc:	dout(15) << " old parent " << oldparent->dirfrag() << " " << *oldparent << dendl;
./mds/MDCache.cc:	dout(15) << " new parent " << newparent->dirfrag() << " " << *newparent << dendl;
./mds/MDCache.cc:	    dout(10) << " creating subtree for " << dir->dirfrag() << dendl;
./mds/MDCache.cc:	dout(10) << "simplify: " << frag << " swallowing " << b << " with bounds " << bb << dendl;
./mds/MDCache.cc:  dout(15) << " subtrees " << le->subtrees << dendl;
./mds/MDCache.cc:  dout(15) << " ambiguous_subtrees " << le->ambiguous_subtrees << dendl;
./mds/MDCache.cc:  dout(10) << "resolve_start" << dendl;
./mds/MDCache.cc:    dout(10) << "send_resolves waiting for snapclient cache to sync" << dendl;
./mds/MDCache.cc:  dout(10) << "send_peer_resolves" << dendl;
./mds/MDCache.cc:	dout(10) << " including uncommitted " << *mdr << dendl;
./mds/MDCache.cc:    dout(10) << "sending peer resolve to mds." << p.first << dendl;
./mds/MDCache.cc:  dout(10) << "send_subtree_resolves" << dendl;
./mds/MDCache.cc:    dout(7) << "send_subtree_resolves waiting, imports/exports still in progress" << dendl;
./mds/MDCache.cc:      dout(10) << " ambig " << dir->dirfrag() << " " << dfls << dendl;
./mds/MDCache.cc:      dout(10) << " claim " << dir->dirfrag() << " " << dfls << dendl;
./mds/MDCache.cc:    dout(10) << " ambig " << p->first << " " << p->second << dendl;
./mds/MDCache.cc:	dout(10) << " simplify: " << p->first << " swallowing " << b << " with bounds " << bb << dendl;
./mds/MDCache.cc:    dout(10) << "sending subtee resolve to mds." << p.first << dendl;
./mds/MDCache.cc:  dout(7) << "handle_mds_failure mds." << who << dendl;
./mds/MDCache.cc:  dout(1) << "handle_mds_failure mds." << who << " : recovery peers are " << recovery_set << dendl;
./mds/MDCache.cc:  dout(10) << " resolve_gather " << resolve_gather << dendl;
./mds/MDCache.cc:  dout(10) << " resolve_ack_gather " << resolve_ack_gather << dendl;
./mds/MDCache.cc:  dout(10) << " rejoin_sent " << rejoin_sent << dendl;
./mds/MDCache.cc:  dout(10) << " rejoin_gather " << rejoin_gather << dendl;
./mds/MDCache.cc:  dout(10) << " rejoin_ack_gather " << rejoin_ack_gather << dendl;
./mds/MDCache.cc:	dout(10) << " peer request " << *mdr << " uncommitted, will resolve shortly" << dendl;
./mds/MDCache.cc:	dout(10) << " peer request " << *mdr << " has no prepare, finishing up" << dendl;
./mds/MDCache.cc:	dout(10) << " peer request " << *mdr << " uncommitted, will resolve shortly" << dendl;
./mds/MDCache.cc:    dout(10) << "cleaning up peer request " << *finish.front() << dendl;
./mds/MDCache.cc:    dout(10) << "cancelling fragment " << df << " bit " << info.bits << dendl;
./mds/MDCache.cc:  dout(7) << "handle_mds_recovery mds." << who << dendl;
./mds/MDCache.cc:  dout(7) << "set_recovery_set " << s << dendl;
./mds/MDCache.cc:  dout(7) << "handle_resolve from " << m->get_source() << dendl;
./mds/MDCache.cc:	dout(10) << " still have pending updates, delay processing peer resolve" << dendl;
./mds/MDCache.cc:	  dout(10) << " already committing peer request " << p << " noop "<< dendl;
./mds/MDCache.cc:	  dout(10) << " ambiguous peer request " << p << " will COMMIT" << dendl;
./mds/MDCache.cc:	dout(10) << " ambiguous peer request " << p << " will ABORT" << dendl;
./mds/MDCache.cc:    dout(10) << "delay processing subtree resolve" << dendl;
./mds/MDCache.cc:      dout(10) << "checking ambiguous import " << *dir << dendl;
./mds/MDCache.cc:	  dout(7) << "ambiguous import failed on " << *dir << dendl;
./mds/MDCache.cc:	  dout(7) << "ambiguous import succeeded on " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << "peer claims " << p.first << " bounds " << p.second << dendl;
./mds/MDCache.cc:    dout(10) << "noting ambiguous import on " << p.first << " bounds " << p.second << dendl;
./mds/MDCache.cc:  dout(10) << "process_delayed_resolve" << dendl;
./mds/MDCache.cc:  dout(10) << "maybe_resolve_finish got all resolves+resolve_acks, done." << dendl;
./mds/MDCache.cc:  dout(10) << "handle_resolve_ack " << *ack << " from " << ack->get_source() << dendl;
./mds/MDCache.cc:    dout(10) << " commit on peer " << p.first << dendl;
./mds/MDCache.cc:    dout(10) << " abort on peer " << metareq << dendl;
./mds/MDCache.cc:  dout(10) << "disambiguate_other_imports" << dendl;
./mds/MDCache.cc:    dout(10) << "ambiguous imports for mds." << who << dendl;
./mds/MDCache.cc:      dout(10) << " ambiguous import " << q->first << " bounds " << q->second << dendl;
./mds/MDCache.cc:	dout(10) << "  mds." << who << " did import " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << "  mds." << who << " did not import " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "disambiguate_my_imports" << dendl;
./mds/MDCache.cc:      dout(10) << "ambiguous import auth known, must not be me " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << "  subtree root is " << *root << dendl;
./mds/MDCache.cc:      dout(10) << "ambiguous import auth unclaimed, must be me " << *dir << dendl;
./mds/MDCache.cc:      dout(0) << "disambiguate_imports uh oh, dir_auth is still ambiguous for " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "remove_inode_recursive " << *in << dendl;
./mds/MDCache.cc:    dout(10) << " removing dirfrag " << *subdir << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << ":" << *in << dendl;
./mds/MDCache.cc:      dout(10) << __func__ << ": stray still has subtree " << *in << dendl;
./mds/MDCache.cc:          dout(10) << __func__ << ": stray still has linkage " << *tin << dendl;
./mds/MDCache.cc:        dout(10) << __func__ << ": stray dn is not expireable " << *dn << dendl;
./mds/MDCache.cc:  dout(7) << "trim_unlinked_inodes" << dendl;
./mds/MDCache.cc:      dout(7) << " will trim from " << *in << dendl;
./mds/MDCache.cc:  dout(7) << "recalc_auth_bits " << (replay ? "(replay)" : "") <<  dendl;
./mds/MDCache.cc:    dout(10) << " subtree auth=" << auth << " for " << *p->first << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_start" << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_send_rejoins with recovery_set " << recovery_set << dendl;
./mds/MDCache.cc:    dout(7) << "rejoin_send_rejoins still processing imported caps, delaying" << dendl;
./mds/MDCache.cc:	  dout(10) << " sending scatterlock state on root " << *root << dendl;
./mds/MDCache.cc:	  dout(10) << " sending scatterlock state on root " << *root << dendl;
./mds/MDCache.cc:	  dout(15) << " " << *mdr << " authpin on " << *q.first << dendl;
./mds/MDCache.cc:	  dout(15) << " " << *mdr << " xlock on " << *lock << " " << *obj << dendl;
./mds/MDCache.cc:	  dout(15) << " " << *mdr << " wrlock on " << *lock << " " << *obj << dendl;
./mds/MDCache.cc:    dout(10) << "nothing to rejoin" << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_walk " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << " add_weak_primary_dentry " << *dn << dendl;
./mds/MDCache.cc:	dout(10) << " sending scatterlock state on " << *in << dendl;
./mds/MDCache.cc:    dout(15) << " add_strong_dirfrag " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << " add_strong_dentry " << *dn << dendl;
./mds/MDCache.cc:	dout(15) << " add_strong_inode " << *in << dendl;
./mds/MDCache.cc:	  dout(10) << " sending scatterlock state on " << *in << dendl;
./mds/MDCache.cc:    dout(10) << "i am a surivivor, and will ack immediately" << dendl;
./mds/MDCache.cc:	dout(10) << " claiming cap import " << p->first << " client." << q->first << " on " << *in << dendl;
./mds/MDCache.cc:	dout(10) << " claiming cap import " << p->first << " client." << q->first << dendl;
./mds/MDCache.cc:      dout(0) << " missing dir ino " << p.ino << dendl;
./mds/MDCache.cc:	dout(0) << " missing dir for " << p.frag << " (which maps to " << leaf << ") on " << *diri << dendl;
./mds/MDCache.cc:	dout(10) << " already have " << p.frag << " -> " << leaf << " " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << " have " << p.frag << " -> " << leaf << " " << *dir << dendl;
./mds/MDCache.cc:      dout(0) << " missing dir ino " << p.first << dendl;
./mds/MDCache.cc:	  dout(0) << " missing dir frag " << fg << " on " << *diri << dendl;
./mds/MDCache.cc:      dout(10) << " have " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << " have " << *in << dendl;
./mds/MDCache.cc:    dout(10) << " have base " << *in << dendl;
./mds/MDCache.cc:      dout(10) << " including base inode (due to potential scatterlock update) " << *in << dendl;
./mds/MDCache.cc:      dout(7) << "still need rejoin from (" << rejoin_gather << ")" << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_scour_survivor_replicas from mds." << from << dendl;
./mds/MDCache.cc:      dout(10) << " rem " << *in << dendl;
./mds/MDCache.cc:	dout(10) << " rem " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << " rem " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << " invented " << *in << dendl;
./mds/MDCache.cc:  dout(10) << " invented " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " have " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " frag " << dirfrag << " doesn't match dirfragtree " << *diri << dendl;
./mds/MDCache.cc:      dout(10) << " maps to frag(s) " << leaves << dendl;
./mds/MDCache.cc:	  dout(10) << " have(approx) " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << " invented " << *dn << dendl;
./mds/MDCache.cc:	      dout(10) << " dn authpin by " << r << " on " << *dn << dendl;
./mds/MDCache.cc:	    dout(10) << " dn xlock by " << r << " on " << *dn << dendl;
./mds/MDCache.cc:        dout(10) << " have " << *dn << dendl;
./mds/MDCache.cc:	      dout(7) << " sender has primary dentry but wrong inode" << dendl;
./mds/MDCache.cc:	    dout(7) << " sender doesn't have primay dentry" << dendl;
./mds/MDCache.cc:	    dout(7) << " sender has primary dentry but we don't" << dendl;
./mds/MDCache.cc:    dout(10) << " have " << *in << dendl;
./mds/MDCache.cc:	dout(10) << " inode authpin by " << r << " on " << *in << dendl;
./mds/MDCache.cc:	dout(10) << " inode xlock by " << q.second << " on " << *lock << " on " << *in << dendl;
./mds/MDCache.cc:	dout(10) << " inode wrlock by " << r << " on " << *lock << " on " << *in << dendl;
./mds/MDCache.cc:    dout(7) << "still need rejoin from (" << rejoin_gather << ")" << dendl;
./mds/MDCache.cc:  dout(7) << "handle_cache_rejoin_ack from " << ack->get_source() << dendl;
./mds/MDCache.cc:	  dout(10) << " add inode " << *diri << dendl;
./mds/MDCache.cc:	  dout(10) << " unconnected dirfrag " << p.first << dendl;
./mds/MDCache.cc:      dout(10) << " add dirfrag " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << " got " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << " adjust dn.first " << dn->first << " -> " << q.second.first << " on " << *dn << dendl;
./mds/MDCache.cc:	    dout(10) << " had bad linkage for " << *dn << ", unlinking " << *in << dendl;
./mds/MDCache.cc:	    dout(10) << " had bad linkage for " << *dn <<  dendl;
./mds/MDCache.cc:	    dout(10) << " had bad linkage for " << *dn <<  dendl;
./mds/MDCache.cc:	      dout(10) << " add inode " << *in << dendl;
./mds/MDCache.cc:        dout(10) << " got " << *dn << dendl;
./mds/MDCache.cc:    dout(10) << " got dir replica " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << " got inode base " << *in << dendl;
./mds/MDCache.cc:  //dout(10) << "inode_locks len " << ack->inode_locks.length() << " is " << ack->inode_locks << dendl;
./mds/MDCache.cc:    dout(10) << " got inode locks " << *in << dendl;
./mds/MDCache.cc:      dout(10) << " exporting caps for client." << q->first << " ino " << p->first << dendl;
./mds/MDCache.cc:	dout(10) << " no session for client." << p->first << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_trim_undef_inodes" << dendl;
./mds/MDCache.cc:	  dout(10) << " trimming " << *dn << dendl;
./mds/MDCache.cc:	dout(10) << " trimming " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " trimming " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << " trimming " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_gather_finish" << dendl;
./mds/MDCache.cc:  dout(10) << "open_caps_inode_finish ino " << ino << " ret " << ret << dendl;
./mds/MDCache.cc:  dout(10) << "rejoin_open_sessions_finish" << dendl;
./mds/MDCache.cc:    dout(10) << __func__ << " ino " << ino << " ret " << ret << dendl;
./mds/MDCache.cc:  dout(10) << "process_imported_caps" << dendl;
./mds/MDCache.cc:    dout(10) << "  opening missing ino " << p.first << dendl;
./mds/MDCache.cc:  dout(10) << "rebuild_need_snapflush " << snap_follows << " on " << *head_in << dendl;
./mds/MDCache.cc:    dout(10) << " need snapflush from client." << client << " on " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "choose_lock_states_and_reconnect_caps" << dendl;
./mds/MDCache.cc:    dout(15) << " chose lock states on " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "send_snaps" << dendl;
./mds/MDCache.cc:      dout(10) << " no session for client." << p.first << dendl;
./mds/MDCache.cc:  dout(10) << "clean_open_file_lists" << dendl;
./mds/MDCache.cc:	dout(10) << " unlisting unwanted/capless inode " << *in << dendl;
./mds/MDCache.cc:	  dout(10) << " unlisting flushed snap inode " << *in << dendl;
./mds/MDCache.cc:    dout(10) << " no session for client." << client << dendl;
./mds/MDCache.cc:  dout(10) << "export_remaining_imported_caps" << dendl;
./mds/MDCache.cc:      dout(15) << " chose lock states on " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "do_cap_import " << session->info.inst.name << " mseq " << cap->get_mseq() << " on " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "do_delayed_cap_imports" << dendl;
./mds/MDCache.cc:  dout(10) << "open_snaprealms" << dendl;
./mds/MDCache.cc:    dout(5) << "open_snaprealms has unconnected snaprealm:" << dendl;
./mds/MDCache.cc:      dout(5) << css->strv() << dendl;
./mds/MDCache.cc:  dout(10) << "open_snaprealms - all open" << dendl;
./mds/MDCache.cc:  dout(10) << "opened_undef_inode " << *in << dendl;
./mds/MDCache.cc:  dout(7) << "rejoin_send_acks" << dendl;
./mds/MDCache.cc:      dout(7) << " unlinked inode " << *in << dendl;
./mds/MDCache.cc:    dout(10) << "subtree " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "reissue_all_caps" << dendl;
./mds/MDCache.cc:  dout(10) << "queue_file_recover " << *in << dendl;
./mds/MDCache.cc:  dout(10) << " snaps in [" << in->first << "," << in->last << "] are " << s << dendl;
./mds/MDCache.cc:  dout(10) << "identify_files_to_recover" << dendl;
./mds/MDCache.cc:	  dout(10) << " client." << p.first << " has range " << p.second << " but no cap on " << *in << dendl;
./mds/MDCache.cc:    dout(10) << " realm " << *realm << dendl;
./mds/MDCache.cc:    dout(10) << " NO realm, using null context" << dendl;
./mds/MDCache.cc:  dout(10) << "_truncate_inode  snapc " << snapc << " on " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "truncate_inode_finish " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "truncate_inode_logged " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "start_recovered_truncates" << dendl;
./mds/MDCache.cc:  dout(10) << "start_purge_inodes" << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " purging inos " << inos << " logseg " << ls->seq << dendl;
./mds/MDCache.cc:  dout(7) << "trim_lru trimmed " << trimmed << " items" << dendl;
./mds/MDCache.cc:            dout(20) << "trimming empty pinned subtree " << *dir << dendl;
./mds/MDCache.cc:    dout(20) << __func__ << ": try expiring " << *mdsdir_in << " for stopping mds." << mds <<  dendl;
./mds/MDCache.cc:      dout(20) << __func__ << ": successfully expired mdsdir" << dendl;
./mds/MDCache.cc:      dout(20) << __func__ << ": some unexpirable contents in mdsdir" << dendl;
./mds/MDCache.cc:        dout(20) << __func__ << ": maybe trimming base: " << *base_in << dendl;
./mds/MDCache.cc:    dout(7) << "sending cache_expire to " << p.first << dendl;
./mds/MDCache.cc:  dout(12) << "trim_dentry " << *dn << dendl;
./mds/MDCache.cc:    dout(12) << " in container " << *con << dendl;
./mds/MDCache.cc:    dout(12) << " no container; under a not-yet-linked dir" << dendl;
./mds/MDCache.cc:      dout(12) << "  sending expire to mds." << a << " on " << *dn << dendl;
./mds/MDCache.cc:  dout(15) << "trim_dirfrag " << *dir << dendl;
./mds/MDCache.cc:      dout(12) << " subtree root, container is " << *dir << dendl;
./mds/MDCache.cc:      dout(12) << "  sending expire to mds." << a << " on   " << *dir << dendl;
./mds/MDCache.cc:  dout(15) << "trim_inode " << *in << dendl;
./mds/MDCache.cc:      dout(12) << "  sending expire to mds." << a << " on " << *in << dendl;
./mds/MDCache.cc:  dout(7) << "trim_non_auth" << dendl;
./mds/MDCache.cc:      dout(10) << " removing " << *dn << dendl;
./mds/MDCache.cc:	dout(10) << " removing " << *in << dendl;
./mds/MDCache.cc:	  dout(10) << " removing " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << " removing " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "trim_non_auth_subtree(" << dir << ") " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << "trim_non_auth_subtree(" << dir << ") Checking dentry " << dn << dendl;
./mds/MDCache.cc:            dout(10) << "trim_non_auth_subtree(" << dir << ") keeping " << *subdir << dendl;
./mds/MDCache.cc:        dout(20) << "trim_non_auth_subtree(" << dir << ") removing inode " << in << " with dentry" << dn << dendl;
./mds/MDCache.cc:        dout(20) << "trim_non_auth_subtree(" << dir << ") keeping inode " << in << " with dentry " << dn <<dendl;
./mds/MDCache.cc:      dout(20) << "trim_non_auth_subtree(" << dir << ") keeping dentry " << dn <<dendl;
./mds/MDCache.cc:      dout(20) << "trim_non_auth_subtree(" << dir << ") removing dentry " << dn << dendl;
./mds/MDCache.cc:  dout(10) << "try_trim_nonauth_subtree " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " closing empty non-auth child subtree " << *bd << dendl;
./mds/MDCache.cc:	  dout(10) << " closing empty non-auth subtree " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << " removing " << *diri << dendl;
./mds/MDCache.cc:      dout(10) << " parent subtree is " << *psub << dendl;
./mds/MDCache.cc:      dout(10) << " closing empty non-auth subtree " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " parent subtree also non-auth: " << *psub << dendl;
./mds/MDCache.cc:  dout(7) << "cache_expire from mds." << from << dendl;
./mds/MDCache.cc:	dout(7) << "delaying nonauth|warned expires for " << *parent_dir << dendl;
./mds/MDCache.cc:      dout(7) << "expires for " << *parent_dir << dendl;
./mds/MDCache.cc:      dout(7) << "containerless expires (root, stray inodes)" << dendl;
./mds/MDCache.cc:      dout(20) << __func__ << ": expiring inode " << *in << dendl;
./mds/MDCache.cc:		dout(7) << " dir expire on " << *dir << " from mds." << from << dendl;
./mds/MDCache.cc:      dout(20) << __func__ << ": expiring dirfrag " << *dir << dendl;
./mds/MDCache.cc:      dout(10) << " dn expires in dir " << pd.first << dendl;
./mds/MDCache.cc:	    dout(0) << "  missing dentry for " << p.first.first << " snap " << p.first.second << " in " << *dir << dendl;
./mds/MDCache.cc:	    dout(0) << "  missing dentry for " << p.first.first << " snap " << p.first.second << dendl;
./mds/MDCache.cc:	  dout(7) << "  dentry_expire on " << *dn << " from mds." << from << dendl;
./mds/MDCache.cc:  dout(7) << "process_delayed_expire on " << *dir << dendl;
./mds/MDCache.cc:  dout(7) << "discard_delayed_expire on " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "trim_client_leases" << dendl;
./mds/MDCache.cc:      dout(10) << " expiring client." << r->client << " lease of " << *dn << dendl;
./mds/MDCache.cc:  dout(0) << "shutdown_check at " << ceph_clock_now() << dendl;
./mds/MDCache.cc:  dout(0) << "lru size now " << lru.lru_get_size() << "/" << bottom_lru.lru_get_size() << dendl;
./mds/MDCache.cc:  dout(0) << "log len " << mds->mdlog->get_num_events() << dendl;
./mds/MDCache.cc:    dout(0) << "objecter still active" << dendl;
./mds/MDCache.cc:  dout(5) << "shutdown_start" << dendl;
./mds/MDCache.cc:  dout(7) << "shutdown_pass" << dendl;
./mds/MDCache.cc:    dout(7) << " already shut down" << dendl;
./mds/MDCache.cc:  dout(5) << "lru size now " << lru.lru_get_size() << "/" << bottom_lru.lru_get_size() << dendl;
./mds/MDCache.cc:    dout(7) << "looking for subtrees to export" << dendl;
./mds/MDCache.cc:      dout(10) << "  examining " << *dir << " bounds " << bounds << dendl;
./mds/MDCache.cc:      dout(7) << "sending " << *dir << " back to mds." << dest << dendl;
./mds/MDCache.cc:    dout(7) << "waiting for strays to migrate" << dendl;
./mds/MDCache.cc:    dout(7) << "still have " << num_auth_subtree << " auth subtrees" << dendl;
./mds/MDCache.cc:    dout(7) << "still >1 segments, waiting for log to trim" << dendl;
./mds/MDCache.cc:    dout(7) << "still have " << num_subtrees() << " subtrees" << dendl;
./mds/MDCache.cc:    dout(7) << "still have replicated objects" << dendl;
./mds/MDCache.cc:    dout(7) << "still have auth pinned objects" << dendl;
./mds/MDCache.cc:    dout(7) << "capping the log" << dendl;
./mds/MDCache.cc:    dout(7) << "writing header for (now-empty) journal" << dendl;
./mds/MDCache.cc:    dout(7) << "objecter still active" << dendl;
./mds/MDCache.cc:    dout(7) << "there's still stuff in the cache: " << lru.lru_get_size() << "/" << bottom_lru.lru_get_size()  << dendl;
./mds/MDCache.cc:      dout(7) << "there's still reference to mydir " << *mydir << dendl;
./mds/MDCache.cc:  dout(5) << "shutdown done." << dendl;
./mds/MDCache.cc:	  dout(10) << "already exporting/purging " << *dn << dendl;
./mds/MDCache.cc:  dout(7) << "traverse: opening base ino " << path.get_ino() << " snap " << snapid << dendl;
./mds/MDCache.cc:      dout(7) << "traverse: " << *cur << " not a dir " << dendl;
./mds/MDCache.cc:      dout(10) << "traverse: snapdir" << dendl;
./mds/MDCache.cc:      dout(10) << "traverse: snap " << path[depth] << " -> " << snapid << dendl;
./mds/MDCache.cc:          dout(7) << "traverse: " << *cur << " is frozen, waiting" << dendl;
./mds/MDCache.cc:	dout(10) << "traverse: need dirfrag " << fg << ", doing discover from " << *cur << dendl;
./mds/MDCache.cc:      dout(7) << "traverse: " << *curdir << " is frozen, waiting" << dendl;
./mds/MDCache.cc:	dout(10) << "waiting for single auth on " << *curdir << dendl;
./mds/MDCache.cc:	dout(10) << "fw to auth for " << *curdir << dendl;
./mds/MDCache.cc:	  dout(10) << "traverse: failed to rdlock " << dn->lock << " " << *dn << dendl;
./mds/MDCache.cc:	dout(10) << "traverse: non-readable dentry at " << *dn << dendl;
./mds/MDCache.cc:	dout(10) << "traverse: null+readable dentry at " << *dn << dendl;
./mds/MDCache.cc:	  dout(7) << "linking in remote in " << *in << dendl;
./mds/MDCache.cc:          dout(7) << "remote link to " << dnl->get_remote_ino() << ", which i don't have" << dendl;
./mds/MDCache.cc:	  dout(10) << "traverse: failed to rdlock " << cur->snaplock << " " << *cur << dendl;
./mds/MDCache.cc:    dout(12) << "traverse: miss on dentry " << path[depth] << " in " << *curdir << dendl;
./mds/MDCache.cc:	    dout(20) << " didn't traverse full path; not returning pdnvec" << dendl;
./mds/MDCache.cc:	    dout(20) << " not adding null for snapid " << snapid << dendl;
./mds/MDCache.cc:	    dout(7) << "traverse: " << *curdir << " is frozen, waiting" << dendl;
./mds/MDCache.cc:	    dout(20) << " added null " << *dn << dendl;
./mds/MDCache.cc:		dout(10) << "traverse: failed to rdlock " << dn->lock << " " << *dn << dendl;
./mds/MDCache.cc:        dout(7) << "traverse: incomplete dir contents for " << *cur << ", fetching" << dendl;
./mds/MDCache.cc:	dout(7) << "traverse: discover from " << path[depth] << " from " << *curdir << dendl;
./mds/MDCache.cc:        dout(7) << "traverse: not auth for " << path << " in " << *curdir << dendl;
./mds/MDCache.cc:	  dout(7) << "traverse: waiting for single auth in " << *curdir << dendl;
./mds/MDCache.cc:	dout(7) << "traverse: forwarding, not auth for " << *curdir << dendl;
./mds/MDCache.cc:      dout(10) << "waiting for single auth on " << *cur << dendl;
./mds/MDCache.cc:      dout(10) << "fw to auth for " << *cur << dendl;
./mds/MDCache.cc:  dout(10) << "path_traverse finish on snapid " << snapid << dendl;
./mds/MDCache.cc:  dout(10) << "cache_traverse " << fp << dendl;
./mds/MDCache.cc:    dout(20) << " " << depth << " " << dname << " frag " << fg << " from " << *in << dendl;
./mds/MDCache.cc:  dout(10) << " got " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "open_remote_dir on " << *diri << dendl;
./mds/MDCache.cc:    dout(7) << "get_dentry_inode linking in remote in " << *in << dendl;
./mds/MDCache.cc:    dout(10) << "get_dentry_inode on remote dn, opening inode for " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << "open_remote_dentry " << *dn << dendl;
./mds/MDCache.cc:      dout(0) << "open_remote_dentry_finish bad remote dentry " << *dn << dendl;
./mds/MDCache.cc:  dout(15) << "make_trace adding " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << "_open_ino_backtrace_fetched ino " << ino << " errno " << err << dendl;
./mds/MDCache.cc:    dout(10) << " found cached " << *in << dendl;
./mds/MDCache.cc:      dout(10) << " got empty backtrace " << dendl;
./mds/MDCache.cc:	dout(10) << " got same parents " << info.ancestors[0] << " 2 times" << dendl;
./mds/MDCache.cc:    dout(0) << " failed to open ino " << ino << " err " << err << "/" << info.last_err << dendl;
./mds/MDCache.cc:  dout(10) << " got backtrace " << backtrace << dendl;
./mds/MDCache.cc:  dout(10) << "_open_ino_parent_opened ino " << ino << " ret " << ret << dendl;
./mds/MDCache.cc:    dout(10) << " found cached " << *in << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << ": ino " << ino << " ret " << ret << dendl;
./mds/MDCache.cc:    dout(10) << " found cached " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "open_ino_traverse_dir ino " << ino << " " << ancestors << dendl;
./mds/MDCache.cc:      dout(10) << " " << *diri << " is not dir" << dendl;
./mds/MDCache.cc:	  dout(10) << " " << *diri << " is frozen, waiting " << dendl;
./mds/MDCache.cc:	  dout(10) << " fetching undef " << *dnl->get_inode() << dendl;
./mds/MDCache.cc:	  dout(10) << " fetching incomplete " << *dir << dendl;
./mds/MDCache.cc:	dout(10) << " no ino " << next_ino << " in " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << " null " << *dn << " is not readable, waiting" << dendl;
./mds/MDCache.cc:	dout(10) << " no ino " << next_ino << " in " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "open_ino_finish ino " << ino << " ret " << ret << dendl;
./mds/MDCache.cc:      dout(10) << " waiting for more peers to be active" << dendl;
./mds/MDCache.cc:      dout(10) << " all MDS peers have been checked " << dendl;
./mds/MDCache.cc:  dout(10) << "handle_open_ino " << *m << " err " << err << dendl;
./mds/MDCache.cc:    dout(10) << " have " << *in << dendl;
./mds/MDCache.cc:  dout(10) << "handle_open_ino_reply " << *m << dendl;
./mds/MDCache.cc:      dout(10) << " found cached " << *in << dendl;
./mds/MDCache.cc:      dout(10) << " found ino " << ino << " on mds." << from << dendl;
./mds/MDCache.cc:      dout(10) << " error " << m->error << " from mds." << from << dendl;
./mds/MDCache.cc:  dout(10) << "kick_open_ino_peers mds." << who << dendl;
./mds/MDCache.cc:      dout(10) << "  kicking ino " << p->first << " who was checking mds." << who << dendl;
./mds/MDCache.cc:      dout(10) << "  kicking ino " << p->first << " who was waiting" << dendl;
./mds/MDCache.cc:  dout(5) << "find_ino_peers " << ino << " hint " << hint << dendl;
./mds/MDCache.cc:      dout(10) << "_do_find_ino_peer waiting for more peers to be active" << dendl;
./mds/MDCache.cc:      dout(10) << "_do_find_ino_peer failed on " << fip.ino << dendl;
./mds/MDCache.cc:  dout(10) << "handle_find_ino " << *m << dendl;
./mds/MDCache.cc:    dout(10) << " have " << r->path << " " << *in << dendl;
./mds/MDCache.cc:    dout(10) << "handle_find_ino_reply " << *m << dendl;
./mds/MDCache.cc:      dout(10) << "handle_find_ino_reply successfully found " << fip.ino << dendl;
./mds/MDCache.cc:    dout(10) << "handle_find_ino_reply tid " << m->tid << " dne" << dendl;
./mds/MDCache.cc:      dout(10) << "kicking find_ino_peer " << fip.tid << " who was checking mds." << who << dendl;
./mds/MDCache.cc:      dout(10) << "kicking find_ino_peer " << fip.tid << " who was waiting" << dendl;
./mds/MDCache.cc:      dout(10) << "request_start already had " << *mdr << ", waiting for finish" << dendl;
./mds/MDCache.cc:      dout(10) << "request_start already processing " << *mdr << ", dropping new msg" << dendl;
./mds/MDCache.cc:  dout(7) << "request_start " << *mdr << dendl;
./mds/MDCache.cc:  dout(7) << "request_start_peer " << *mdr << " by mds." << by << dendl;
./mds/MDCache.cc:  dout(7) << "request_start_internal " << *mdr << " op " << op << dendl;
./mds/MDCache.cc:  dout(7) << "request_get " << rid << " " << *p->second << dendl;
./mds/MDCache.cc:  dout(7) << "request_finish " << *mdr << dendl;
./mds/MDCache.cc:    dout(10) << "request_forward on internal op; cancelling" << dendl;
./mds/MDCache.cc:  dout(15) << "request_cleanup " << *mdr << dendl;
./mds/MDCache.cc:      dout(10) << "request_kill " << *mdr << " -- waiting for peer reply, delaying" << dendl;
./mds/MDCache.cc:      dout(10) << "request_kill " << *mdr << " -- already started peer prep, no-op" << dendl;
./mds/MDCache.cc:    dout(10) << "request_kill " << *mdr << " -- already committing, remove it from sesssion requests" << dendl;
./mds/MDCache.cc:    dout(10) << "request_kill " << *mdr << dendl;
./mds/MDCache.cc:  dout(10) << "do_realm_invalidate_and_update_notify " << *in->snaprealm << " " << *in << dendl;
./mds/MDCache.cc:    dout(10) << " realm " << *realm << " on " << *realm->inode << dendl;
./mds/MDCache.cc:    dout(10) << " " << realm << " open_children are " << realm->open_children << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *in << " stid " << stid << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *m << " from mds." << from << dendl;
./mds/MDCache.cc:  dout(10) << "scan_stray_dir " << next << dendl;
./mds/MDCache.cc:  dout(7) << "discover_base_ino " << want_ino << " from mds." << from << dendl;
./mds/MDCache.cc:    dout(10) << " waiting for single auth on " << *base << dendl;
./mds/MDCache.cc:    dout(7) << " waiting for single auth on " << *base << dendl;
./mds/MDCache.cc:      dout(0) << "discover_reply not yet active(|still rejoining), delaying" << dendl;
./mds/MDCache.cc:    dout(10) << "added base " << *cur << dendl;
./mds/MDCache.cc:      dout(7) << *cur << " not a dir" << dendl;
./mds/MDCache.cc:	  dout(7) << " not dirfrag auth, setting dir_auth_hint for " << *curdir << dendl;
./mds/MDCache.cc:	  dout(7) << *cur << " is frozen, non-empty reply, stopping" << dendl;
./mds/MDCache.cc:	dout(7) << *cur << " is frozen, empty reply, waiting" << dendl;
./mds/MDCache.cc:	dout(7) << *curdir << " is frozen, non-empty reply, stopping" << dendl;
./mds/MDCache.cc:	dout(7) << *curdir << " is frozen, dirfrag mismatch, stopping" << dendl;
./mds/MDCache.cc:      dout(7) << *curdir << " is frozen, empty reply, waiting" << dendl;
./mds/MDCache.cc:      dout(7) << "handle_discover not adding unwanted base dir " << *curdir << dendl;
./mds/MDCache.cc:      dout(7) << "handle_discover added dir " << *curdir << dendl;
./mds/MDCache.cc:	dout(7) << "incomplete dir contents for " << *curdir << ", fetching" << dendl;
./mds/MDCache.cc:	dout(7) << "handle_discover allowing discovery of xlocked " << *dn << dendl;
./mds/MDCache.cc:	dout(7) << "handle_discover blocking on xlocked " << *dn << dendl;
./mds/MDCache.cc:	dout(7) << "handle_discover non-empty reply, xlocked tail " << *dn << dendl;
./mds/MDCache.cc:	dout(7) << "handle_discover allowing discovery of frozen tail " << *dnl->get_inode() << dendl;
./mds/MDCache.cc:	dout(7) << *dnl->get_inode() << " is frozen, empty reply, waiting" << dendl;
./mds/MDCache.cc:	dout(7) << *dnl->get_inode() << " is frozen, non-empty reply, stopping" << dendl;
./mds/MDCache.cc:    dout(7) << "handle_discover added dentry " << *dn << dendl;
./mds/MDCache.cc:    dout(7) << "handle_discover added inode " << *next << dendl;
./mds/MDCache.cc:  dout(7) << "handle_discover sending result back to asker mds." << from << dendl;
./mds/MDCache.cc:    dout(0) << "discover_reply NOT ACTIVE YET" << dendl;
./mds/MDCache.cc:  dout(7) << "discover_reply " << *m << dendl;
./mds/MDCache.cc:    dout(7) << " flag error, dir" << dendl;
./mds/MDCache.cc:    dout(7) << " flag error, dentry = " << m->get_error_dentry() << dendl;
./mds/MDCache.cc:      dout(10) << " found tid " << m->get_tid() << dendl;
./mds/MDCache.cc:      dout(10) << " tid " << m->get_tid() << " not found, must be dup reply" << dendl;
./mds/MDCache.cc:    dout(7) << "discover_reply got base inode " << *cur << dendl;
./mds/MDCache.cc:      dout(7) << " dir_auth_hint is " << m->get_dir_auth_hint() << dendl;
./mds/MDCache.cc:	dout(7) << " doing nothing, nobody is waiting for dir" << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " had " << *dir << " nonce " << dir->replica_nonce << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " added " << *dir << " nonce " << dir->replica_nonce << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " had " << *dn << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " added " << *dn << dendl;
./mds/MDCache.cc:    dout(10) << __func__ << " added " << *in << dendl;
./mds/MDCache.cc:    dout(10) << __func__ << " had " << *in << dendl;
./mds/MDCache.cc:      dout(10) << __func__ << " different linkage in dentry " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << "replica inode is random ephemeral pinned" << dendl;
./mds/MDCache.cc:  dout(7) << "sending dir_update on " << *dir << " bcast " << bcast << " to " << who << dendl;
./mds/MDCache.cc:    dout(7) << "sending dir_update on " << *dir << " to " << *it << dendl;
./mds/MDCache.cc:    dout(5) << "dir_update on " << df << ", don't have it" << dendl;
./mds/MDCache.cc:      dout(5) << "trying discover on dir_update for " << path << dendl;
./mds/MDCache.cc:    dout(5) << "dir_update on " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << "  remote " << ino << " " << d_type << dendl;
./mds/MDCache.cc:  dout(7) << __func__ << " " << *dn << dendl;
./mds/MDCache.cc:      dout(10) << __func__ << "  primary " << *dnl->get_inode() << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " don't have dirfrag " << m->get_dirfrag() << dendl;
./mds/MDCache.cc:      dout(7) << __func__ << " don't have dentry " << *dir << " dn " << m->get_dn() << dendl;
./mds/MDCache.cc:      dout(7) << __func__ << " on " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *dn << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " don't have dirfrag " << m->get_dirfrag() << dendl;
./mds/MDCache.cc:      dout(7) << __func__ << " don't have dentry " << *dir << " dn " << m->get_dn() << dendl;
./mds/MDCache.cc:      dout(7) << __func__ << " on " << *dn << dendl;
./mds/MDCache.cc:  dout(10) << "force_dir_fragment " << fg << " on " << *diri << dendl;
./mds/MDCache.cc:      dout(10) << " splitting parent by " << split << " " << *pdir << dendl;
./mds/MDCache.cc:	dout(10) << "force_dir_fragment result " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << " " << last << " parent is " << parent << dendl;
./mds/MDCache.cc:      dout(10) << "force_dir_fragment no frags under " << fg << dendl;
./mds/MDCache.cc:      dout(10) << " will combine frags under " << fg << ": " << src << dendl;
./mds/MDCache.cc:      dout(10) << "force_dir_fragment result " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << " new fragtree is " << diri->dirfragtree << dendl;
./mds/MDCache.cc:	dout(10) << " taking srcfrag subtree bounds from " << *dir << dendl;
./mds/MDCache.cc:    dout(7) << "can_fragment: read-only FS, no fragmenting for now" << dendl;
./mds/MDCache.cc:    dout(7) << "can_fragment: cluster degraded, no fragmenting for now" << dendl;
./mds/MDCache.cc:    dout(7) << "can_fragment: i won't merge|split anything in stray" << dendl;
./mds/MDCache.cc:    dout(7) << "can_fragment: i won't fragment mdsdir or .ceph" << dendl;
./mds/MDCache.cc:      dout(7) << "can_fragment: scrub in progress " << *dir << dendl;
./mds/MDCache.cc:      dout(7) << "can_fragment: already fragmenting " << *dir << dendl;
./mds/MDCache.cc:      dout(7) << "can_fragment: not auth on " << *dir << dendl;
./mds/MDCache.cc:      dout(7) << "can_fragment: bad dirfrag " << *dir << dendl;
./mds/MDCache.cc:      dout(7) << "can_fragment: can't merge, freezing|frozen.  wait for other exports to finish first." << dendl;
./mds/MDCache.cc:  dout(7) << __func__ << " " << *dir << " bits " << bits << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " cannot fragment right now, dropping" << dendl;
./mds/MDCache.cc:    dout(7) << __func__ << " frag bits > 24, dropping" << dendl;
./mds/MDCache.cc:  dout(7) << "merge_dir to " << frag << " on " << *diri << dendl;
./mds/MDCache.cc:    dout(7) << "don't have all frags under " << frag << " for " << *diri << dendl;
./mds/MDCache.cc:    dout(10) << " " << frag << " already a leaf for " << *diri << dendl;
./mds/MDCache.cc:  dout(10) << " we are merging by " << bits << " bits" << dendl;
./mds/MDCache.cc:    dout(7) << "fragment_mark_and_complete " << basedirfrag << " must have aborted" << dendl;
./mds/MDCache.cc:  dout(10) << "fragment_mark_and_complete " << info.dirs << " on " << *diri << dendl;
./mds/MDCache.cc:      dout(15) << " fetching incomplete " << *dir << dendl;
./mds/MDCache.cc:	dout(15) << " waiting until new dir gets journaled " << *dir << dendl;
./mds/MDCache.cc:	dout(15) << " committing new " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << " marking " << *dir << dendl;
./mds/MDCache.cc:      dout(15) << " already marked " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "fragment_unmark_unfreeze_dirs " << dirs << dendl;
./mds/MDCache.cc:    dout(10) << " frag " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "find_stale_fragment_freeze" << dendl;
./mds/MDCache.cc:      dout(10) << " cancel fragmenting " << df << " bit " << info.bits << dendl;
./mds/MDCache.cc:    dout(7) << "fragment_frozen " << basedirfrag << " must have aborted" << dendl;
./mds/MDCache.cc:    dout(7) << "dispatch_fragment_dir " << basedirfrag << " must have aborted" << dendl;
./mds/MDCache.cc:    dout(10) << " storing result frag " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << " result frag " << *dir << dendl;
./mds/MDCache.cc:  dout(10) << "fragment_committed " << basedirfrag << dendl;
./mds/MDCache.cc:      dout(10) << " truncate orphan dirfrag " << oid << dendl;
./mds/MDCache.cc:      dout(10) << " removing orphan dirfrag " << oid << dendl;
./mds/MDCache.cc:  dout(10) << "fragment_old_purged " << basedirfrag << dendl;
./mds/MDCache.cc:  dout(10) << "handle_fragment_notify_ack " << *ack << " from " << ack->get_source() << dendl;
./mds/MDCache.cc:    dout(10) << "handle_fragment_notify_ack obsolete message, dropping" << dendl;
./mds/MDCache.cc:  dout(10) << "handle_fragment_notify " << *notify << " from " << notify->get_source() << dendl;
./mds/MDCache.cc:  dout(10) << "add_uncommitted_fragment: base dirfrag " << basedirfrag << " bits " << bits << dendl;
./mds/MDCache.cc:  dout(10) << "rollback_uncommitted_fragments: " << uncommitted_fragments.size() << " pending" << dendl;
./mds/MDCache.cc:    dout(10) << " rolling back " << p->first << " refragment by " << uf.bits << " bits" << dendl;
./mds/MDCache.cc:	  dout(10) << "    dirty nestinfo on " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << "    dirty fragstat on " << *dir << dendl;
./mds/MDCache.cc:	  dout(10) << "    dirty dirfragtree on " << *dir << dendl;
./mds/MDCache.cc:  dout(1) << "force file system read-only" << dendl;
./mds/MDCache.cc:  //dout(10) << "show_subtrees" << dendl;
./mds/MDCache.cc:  //dout(15) << "show_subtrees, base dirfrags " << basefrags << dendl;
./mds/MDCache.cc:  dout(15) << "show_subtrees" << dendl;
./mds/MDCache.cc:    //dout(25) << "saw depth " << d << " " << *dir << dendl;
./mds/MDCache.cc:    if (seen.count(dir)) dout(0) << "aah, already seen " << *dir << dendl;
./mds/MDCache.cc:	//dout(25) << " saw sub " << **p << dendl;
./mds/MDCache.cc:    dout(10) << "*** stray/lost entry in subtree map: " << *p->first << dendl;
./mds/MDCache.cc:  dout(7) << "show_cache" << dendl;
./mds/MDCache.cc:      dout(7) << " unlinked " << *in << dendl;
./mds/MDCache.cc:      dout(7) << "  dirfrag " << *dir << dendl;
./mds/MDCache.cc:	dout(7) << "   dentry " << *dn << dendl;
./mds/MDCache.cc:	  dout(7) << "    inode " << *dnl->get_inode() << dendl;
./mds/MDCache.cc:    dout(1) << "dump_cache to " << path << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << path << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *dir << dendl;
./mds/MDCache.cc:    dout(10) << __func__ << " no corruption found" << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *diri << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *diri << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " start dirfrags : " << *diri << dendl;
./mds/MDCache.cc:    dout(10) << __func__ << ": read-only FS" << dendl;
./mds/MDCache.cc:  dout(10) << "flush_dentry " << path << dendl;
./mds/MDCache.cc:  dout(10) << __func__ << " " << *diri << dendl;
./mds/MDCache.cc:    dout(10) << "Checking ephemerally pinned directories for redistribute due to max_mds change." << dendl;
./mds/ScrubStack.cc:  dout(20) << "dequeue " << *obj << " from ScrubStack" << dendl;
./mds/ScrubStack.cc:      dout(10) << __func__ << " with {" << *in << "}" << ", already in scrubbing" << dendl;
./mds/ScrubStack.cc:    dout(10) << __func__ << " with {" << *in << "}" << ", top=" << top << dendl;
./mds/ScrubStack.cc:      dout(10) << __func__ << " with {" << *dir << "}" << ", already in scrubbing" << dendl;
./mds/ScrubStack.cc:    dout(10) << __func__ << " with {" << *dir << "}" << ", top=" << top << dendl;
./mds/ScrubStack.cc:  dout(20) << "enqueue " << *obj << " to " << (top ? "top" : "bottom") << " of ScrubStack" << dendl;
./mds/ScrubStack.cc:  dout(20) << __func__ << ": state=" << state << dendl;
./mds/ScrubStack.cc:      dout(20) << __func__ << " examining " << *in << dendl;
./mds/ScrubStack.cc:	  dout(20) << __func__ << " dir inode, done" << dendl;
./mds/ScrubStack.cc:	dout(20) << __func__ << " dirfrag, done" << dendl;
./mds/ScrubStack.cc:      dout(10) << __func__ << " can't auth pin" << dendl;
./mds/ScrubStack.cc:      dout(10) << __func__ << " ambiguous auth" << dendl;
./mds/ScrubStack.cc:      dout(20) << __func__ << " cluster degraded" << dendl;
./mds/ScrubStack.cc:      dout(10) << __func__ << " forward to mds." << auth << dendl;
./mds/ScrubStack.cc:  dout(10) << __func__ << " " << *in << dendl;
./mds/ScrubStack.cc:  dout(20) << __func__ << "recursive mode, frags " << frags << dendl;
./mds/ScrubStack.cc:	dout(20) << __func__ << " ambiguous auth " << *dir  << dendl;
./mds/ScrubStack.cc:	dout(20) << __func__ << " cluster degraded" << dendl;
./mds/ScrubStack.cc:      dout(20) << __func__ << " freezing/frozen " << *dir  << dendl;
./mds/ScrubStack.cc:      dout(20) << __func__ << " barebones " << *dir  << dendl;
./mds/ScrubStack.cc:      dout(20) << __func__ << " forward " << p.second  << " to mds." << p.first << dendl;
./mds/ScrubStack.cc:  dout(10) << __func__ << " done" << dendl;
./mds/ScrubStack.cc:  dout(20) << __func__ << " " << *in << dendl;
./mds/ScrubStack.cc:  dout(10) << __func__ << " " << *dir << dendl;
./mds/ScrubStack.cc:    dout(10) << __func__ << " incomplete, fetching" << dendl;
./mds/ScrubStack.cc:  dout(10) << __func__ << " done" << dendl;
./mds/ScrubStack.cc:    dout(10) << __func__ << " scrub passed on inode " << *in << dendl;
./mds/ScrubStack.cc:  dout(20) << __func__ << ": state=" << state << dendl;
./mds/ScrubStack.cc:  dout(20) << __func__ << ": state=" << state << dendl;
./mds/ScrubStack.cc:  dout(10) << __func__ << " " << *m << " from mds." << from << dendl;
./mds/ScrubStack.cc:	  dout(10) << __func__ << " no frag " << fg << dendl;
./mds/ScrubStack.cc:	  dout(10) << __func__ << " not auth " << *dir << dendl;
./mds/ScrubStack.cc:	  dout(10) << __func__ << " can't auth pin " << *dir <<  dendl;
./mds/ScrubStack.cc:  dout(7) << __func__ << " " << *m << " from mds." << from << dendl;
./mds/SnapServer.cc:	dout(10) << "prepare v" << version << " create " << info << dendl;
./mds/SnapServer.cc:	dout(10) << "prepare v" << version << " noop" << dendl;
./mds/SnapServer.cc:      dout(10) << "prepare v" << version << " destroy " << snapid << " seq " << last_snap << dendl;
./mds/SnapServer.cc:      dout(10) << "prepare v" << version << " update " << info << dendl;
./mds/SnapServer.cc:    dout(7) << "commit " << tid << " " << opname << " " << info << dendl;
./mds/SnapServer.cc:    dout(7) << "commit " << tid << " destroy " << sn << " seq " << seq << dendl;
./mds/SnapServer.cc:    dout(7) << "commit " << tid << " noop" << dendl;
./mds/SnapServer.cc:    dout(7) << "rollback " << tid << " " << opname << " " << info << dendl;
./mds/SnapServer.cc:    dout(7) << "rollback " << tid << " destroy " << pending_destroy[tid] << dendl;
./mds/SnapServer.cc:    dout(7) << "rollback " << tid << " noop" << dendl;
./mds/SnapServer.cc:  dout(7) << "_server_update purged " << purge << dendl;
./mds/SnapServer.cc:    dout(10) << "check_osd_map - version unchanged" << dendl;
./mds/SnapServer.cc:  dout(10) << "check_osd_map need_to_purge=" << need_to_purge << dendl;
./mds/SnapServer.cc:	    dout(10) << " osdmap marks " << q << " as removed" << dendl;
./mds/SnapServer.cc:    dout(10) << "requesting removal of " << all_purge << dendl;
./mds/SnapServer.cc:  dout(10) << __func__ << " " << *m << dendl;
./mds/SnapServer.cc:	dout(10) << " mon reports " << q << " is removed" << dendl;
./mds/SnapServer.cc:  dout(10) << __func__ << " " << num << " now removed" << dendl;
./mds/MDSMap.cc:      dout(0) << "removed non-existant data pool " << *it << " from MDSMap" << dendl;
./mds/MetricAggregator.cc:  dout(10) << ": pinging " << active_rank_addrs.size() << " active mds(s)" << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": pinging rank=" << rank << " addr=" << addr << dendl;
./mds/MetricAggregator.cc:  dout(10) << dendl;
./mds/MetricAggregator.cc:  dout(10) << dendl;
./mds/MetricAggregator.cc:      dout(0) << typeid(*msg).name() << " is not an MMDSOp type" << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": performance_counter_descriptor=" << d << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": sub_key_descriptor=" << d << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": match_string=" << match_string << dendl;
./mds/MetricAggregator.cc:  dout(20) << ": client=" << client << ", rank=" << rank << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": sub_key_descriptor=" << d << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": match_string=" << match_string << dendl;
./mds/MetricAggregator.cc:        dout(10) << ": removed metric for key=" << key << dendl;
./mds/MetricAggregator.cc:  dout(20) << ": rank=" << rank << dendl;
./mds/MetricAggregator.cc:  dout(10) << ": culled " << p.size() << " clients" << dendl;
./mds/MetricAggregator.cc:  dout(10) << dendl;
./mds/MetricAggregator.cc:    dout(10) << ": mds rank=" << rank << " removed from mdsmap" << dendl;
./mds/MetricAggregator.cc:  dout(10) << ": active set=["  << active_rank_addrs << "]" << dendl;
./mds/MetricAggregator.cc:  dout(10) << ": setting " << queries.size() << " queries" << dendl;
./mds/MetricAggregator.cc:    dout(20) << ": descriptors=" << descriptors << dendl;
./log/test.cc:  ldout(cct, 20) << "Log depth=" << depth << " x=" << x << dendl;
./log/test.cc:  ldout(cct, 20) << "Preparing recursion string" << dendl;
./log/test.cc:    ldout(cct, 20) << "End " << recursion(cct) << "x=" << x << dendl;
./log/test.cc:    ldout(cct, 20) << "End x=" << x << dendl;
./log/test.cc:    ldout(g_ceph_context, 20) << "Iteration " << i << dendl;
./log/test.cc:    ldout(g_ceph_context, 20) << "Iteration " << i << dendl;
./log/test.cc:  ldout(g_ceph_context, 0) << long_message << dendl;
./log/test.cc:  ldout(g_ceph_context, 0) << "Prologue" << (std::streambuf*)nullptr << long_message << dendl;
./log/test.cc:  ldout(g_ceph_context, 0) << "Epitaph" << long_message << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 10) << "set snap read " << snap_seq << " -> " << s << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 20) << "complete_aio_write " << c << dendl;
./librados/IoCtxImpl.cc:    ldout(client->cct, 20) << " waking waiters on seq " << waiters->first << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 20) << "flush_aio_writes" << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 10) << ceph_osd_op_name(op) << " oid=" << oid << " nspace=" << oloc.nspace << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 20) << "aio_write " << oid << " " << off << "~" << len << " snapc=" << snapc << " snap_seq=" << snap_seq << dendl;
./librados/IoCtxImpl.cc:      ldout(cdata->client->cct, 10) << "IoCtxImpl::getxattrs: xattr=" << p->first << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 10) << "Objecter returned from read r=" << r << dendl;
./librados/IoCtxImpl.cc:      ldout(client->cct, 10) << "IoCtxImpl::getxattrs: xattr=" << p->first << dendl;
./librados/IoCtxImpl.cc:  ldout(client->cct, 10) << __func__ << " issued linger op " << linger_op << dendl;
./librados/RadosClient.cc:    ldout(cct, 10) << __func__ << " build monmap" << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "starting msgr at " << messenger->get_myaddrs() << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "starting objecter" << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "setting wanted keys" << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "calling monclient init" << dendl;
./librados/RadosClient.cc:    ldout(cct, 0) << conf->name << " initialization error " << cpp_strerror(-err) << dendl;
./librados/RadosClient.cc:    ldout(cct, 0) << conf->name << " authentication error " << cpp_strerror(-err) << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "init done" << dendl;
./librados/RadosClient.cc:  ldout(cct, 1) << "shutdown" << dendl;
./librados/RadosClient.cc:  ldout(cct, 10) << __func__ << " enter" << dendl;
./librados/RadosClient.cc:  ldout(cct, 10) << __func__ << " exit" << dendl;
./librados/RadosClient.cc:  ldout(cct, 10) << __func__ << " enter" << dendl;
./librados/RadosClient.cc:  ldout(cct, 10) << __func__ << " exit" << dendl;
./librados/RadosClient.cc:    ldout(cct, 10) << "disconnected, discarding " << *m << dendl;
./librados/RadosClient.cc:      ldout(cct, 10) << __func__ << " waiting" << dendl;
./librados/RadosClient.cc:      ldout(cct, 10) << __func__ << " done waiting" << dendl;
./librados/RadosClient.cc:    ldout(cct, 10) << __func__ << " invalid level " << level << dendl;
./librados/RadosClient.cc:  ldout(cct, 10) << __func__ << " version " << m->version << dendl;
./librados/RadosClient.cc:        ldout(cct, 20) << __func__ << " delivering " << ss.str() << dendl;
./librados/RadosClient.cc:  ldout(cct,10) << __func__ << " " << service << "." << name << dendl;
./librados/snap_set_diff.cc:	ldout(cct, 20) << "  start, after " << start << dendl;
./librados/snap_set_diff.cc:	ldout(cct, 20) << "  start" << dendl;
./librados/snap_set_diff.cc:      ldout(cct, 20) << " past end " << end << ", end object does not exist" << dendl;
./librados/snap_set_diff.cc:      ldout(cct, 20) << " end" << dendl;
./librados/snap_set_diff.cc:    ldout(cct, 20) << "  diff_to_next " << diff_to_next << dendl;
./librados/snap_set_diff.cc:    ldout(cct, 20) << "  diff now " << *diff << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 5) << "_maybe_remove_last_instance removing bucket " << item << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 5) << "_maybe_remove_last_instance removing name for item " << item << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 5) << __func__ << " " << id << " " << loc << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 20) << " id is at " << id_loc << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 5) << "check_item_loc item " << item << " loc " << loc << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 5) << "check_item_loc bucket " << q->second << " dne" << dendl;
./crush/CrushWrapper.cc:	ldout(cct, 2) << "check_item_loc " << item << " exists in bucket " << b->id << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 2) << __func__ << " item " << item << " loc " << loc << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 10) << __func__ << " step " << step << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 5) << "insert_item creating bucket " << q->second << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 1) << "insert_item doesn't have bucket " << id << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 5) << "update_item " << item << " already at " << loc << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 5) << __func__ << " " << id << " weight " << weight << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 5) << "reweight root bucket " << id << dendl;
./crush/CrushWrapper.cc:        ldout(cct, 20) << __func__ << " not in root subtree " << root_bucket << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 20) << __func__ << " underfull_buckets " << underfull_buckets << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 10) << __func__ << " end of orig, break 0" << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 10) << " from " << from << dendl;
./crush/CrushWrapper.cc:		ldout(cct, 20) << __func__ << "   in used " << used << dendl;
./crush/CrushWrapper.cc:		ldout(cct, 20) << __func__ << "   not in subtree " << from << dendl;
./crush/CrushWrapper.cc:		ldout(cct, 20) << __func__ << "   in orig " << orig << dendl;
./crush/CrushWrapper.cc:		  ldout(cct, 20) << __func__ << "   in used " << used << dendl;
./crush/CrushWrapper.cc:		  ldout(cct, 20) << __func__ << "   not in subtree " << from << dendl;
./crush/CrushWrapper.cc:		  ldout(cct, 20) << __func__ << "   in orig " << orig << dendl;
./crush/CrushWrapper.cc:	    ldout(cct, 10) << __func__ << " end of orig, break 1" << dendl;
./crush/CrushWrapper.cc:	ldout(cct, 10) << __func__ << " end of orig, break 2" << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 10) << __func__ << "  w <- " << o << " was " << w << dendl;
./crush/CrushWrapper.cc:    ldout(cct, 10) << __func__ << " step " << step << " w " << w << dendl;
./crush/CrushWrapper.cc:	ldout(cct, 10) << __func__ << " take " << w << dendl;
./crush/CrushWrapper.cc:	ldout(cct, 1) << " bad take value " << curstep->arg1 << dendl;
./crush/CrushWrapper.cc:      ldout(cct, 10) << " emit " << w << dendl;
./crush/CrushWrapper.cc:  ldout(cct, 5) << __func__ << " " << id << " weight " << weight << dendl;
./crush/CrushLocation.cc:  lgeneric_dout(cct, 10) << "crush_location is " << loc << dendl;
./crush/CrushLocation.cc:  lgeneric_dout(cct, 10) << "crush_location is (default) " << loc << dendl;
./test/objectstore_bench.cc:  dout(0) << "objectstore " << g_conf()->osd_objectstore << dendl;
./test/objectstore_bench.cc:  dout(0) << "data " << g_conf()->osd_data << dendl;
./test/objectstore_bench.cc:  dout(0) << "journal " << g_conf()->osd_journal << dendl;
./test/objectstore_bench.cc:  dout(0) << "size " << cfg.size << dendl;
./test/objectstore_bench.cc:  dout(0) << "block-size " << cfg.block_size << dendl;
./test/objectstore_bench.cc:  dout(0) << "repeats " << cfg.repeats << dendl;
./test/objectstore_bench.cc:  dout(0) << "threads " << cfg.threads << dendl;
./test/objectstore_bench.cc:  dout(10) << "created objectstore " << os.get() << dendl;
./test/libcephsqlite/main.cc:  ldout(cct, 1) << "sqlite3 version: " << sqlite3_libversion() << dendl;
./test/fio/fio_ceph_objectstore.cc:      dout(0) << "FIO plugin perf dump:" << dendl;
./test/fio/fio_ceph_objectstore.cc:      dout(0) << ostr.str() << dendl;
./test/fio/fio_ceph_messenger.cc:    dout(0) <<  ostr.str() << dendl;
./test/TestSignalHandlers.cc:  generic_dout(-1) << "triggering SIGSEGV..." << dendl;
./test/TestSignalHandlers.cc:  generic_dout(0) << "triggering SIGSEGV with infinite recursion..." << dendl;
./test/librados_test_stub/TestWatchNotify.cc:  ldout(cct, 20) << "enter" << dendl;
./test/librados_test_stub/TestWatchNotify.cc:  ldout(cct, 20) << "handle=" << handle << dendl;
./test/librados_test_stub/TestWatchNotify.cc:    ldout(cct, 1) << "oid=" << oid << ": not found" << dendl;
./test/librados_test_stub/TestWatchNotify.cc:  ldout(cct, 20) << "oid=" << oid << ": notify_id=" << notify_id << dendl;
./test/librados_test_stub/TestWatchNotify.cc:    ldout(cct, 1) << "oid=" << oid << ": not found" << dendl;
./test/librados_test_stub/TestWatchNotify.cc:  ldout(cct, 20) << "oid=" << oid << ", notify_id=" << notify_id << dendl;
./test/librados_test_stub/TestWatchNotify.cc:    ldout(cct, 1) << "oid=" << oid << ": not found" << dendl;
./test/librados_test_stub/LibradosTestStub.cc:      dout(ceph::dout::need_dynamic(level)) << buf << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << "length=" << bl.length() << ", snapc=" << snapc << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << "snapc=" << snapc << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << "snapc=" << snapc << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << "size=" << size << ", snapc=" << snapc << dendl;
./test/librados_test_stub/TestMemIoCtxImpl.cc:  ldout(cct, 20) << "length=" << bl.length() << ", snapc=" << snapc << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 10) << "received scores " << oct << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 6) << "receive ping from " << from_rank << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 6) << "timeout ping from " << from_rank << dendl;
./test/mon/test_election.cc:      ldout(g_ceph_context, 30) << "rank " << i.first << " has timer value " << i.second->timer_steps << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 10) << "all_agree_on_leader on " << leader << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:  ldout(g_ceph_context, 5) << "mangled the scores to be different" << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 10) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_election.cc:    ldout(g_ceph_context, 1) << "removed rank " << deletee << " from set" << dendl;
./test/mon/test_election.cc:      ldout(g_ceph_context, 1) << "ran in " << steps << " timesteps" << dendl;
./test/mon/test_mon_workloadgen.cc:      generic_dout(20) << "C_Tick::" << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(20) << __func__ << " adding tick timer" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(20) << __func__ << " disable tick" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << "client::" << __func__ << " " << *m << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << "client::" << __func__ << " " << con << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << "client::" << __func__ << " " << con << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << "client::" << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << "ClientStub::" << __func__ << " done" << dendl;
./test/mon/test_mon_workloadgen.cc:      generic_dout(20) << "C_CreatePGs::" << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << " public addr " << g_conf()->public_addr << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << " name " << g_conf()->name << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << " creating osd superblock" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(20) << __func__ << " " << sb << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(20) << __func__ << " osdmap " << osdmap << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << " boot?" << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(1) << __func__ << " backoff and try again later." << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << " boot!" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << " send " << *mstats << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << " pg " << pgid << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(20) << __func__ << " pg at pos " << at << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(1) << __func__ << " wait for osdmap" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << "up_thru: " << osdmap.get_up_thru(whoami) << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(1) << __func__ << " wait for osdmap" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(0) << monc.get_monmap() << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(5) << __func__ << " no new maps here; dropping" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(10) << __func__ << " done" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << " " << *m << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << " " << con << dendl;
./test/mon/test_mon_workloadgen.cc:      dout(10) << __func__ << " on mon" << dendl;
./test/mon/test_mon_workloadgen.cc:    dout(1) << __func__ << dendl;
./test/mon/test_mon_workloadgen.cc:    generic_dout(10) << "main::shutdown time has ran out" << dendl;
./test/mon/test-mon-msg.cc:    dout(1) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(1) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(1) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(0) << __func__ << " finished" << dendl;
./test/mon/test-mon-msg.cc:    dout(0) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(0) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(0) << __func__ << dendl;
./test/mon/test-mon-msg.cc:    dout(1) << __func__ << " " << *m << dendl;
./test/mon/test-mon-msg.cc:      dout(10) << __func__ << " not wanted" << dendl;
./test/mon/test-mon-msg.cc:    dout(20) << __func__ << " " << *m << " type " << m->get_type() << dendl;
./test/mon/test-mon-msg.cc:    dout(20) << __func__ << " type " << t << dendl;
./test/mon/test-mon-msg.cc:    dout(20) << __func__ << " type " << t << dendl;
./test/mon/test-mon-msg.cc:    dout(15) << __func__ << " " << *m << dendl;
./test/mon/test-mon-msg.cc:      dout(20) << __func__ << " took " << (e-s) << " seconds" << dendl;
./test/mon/test-mon-msg.cc:      dout(20) << __func__ << " error: " << cpp_strerror(ETIMEDOUT) << dendl;
./test/mon/test-mon-msg.cc:      dout(20) << __func__ << " reply_msg is nullptr" << dendl;
./test/mon/test-mon-msg.cc:      dout(20) << __func__ << " reply_msg " << *reply_msg << dendl;
./test/testcrypto.cc:    dout(0) << "couldn't encode! error " << error << dendl;
./test/testcrypto.cc:    dout(0) << "couldn't decode! error " << error << dendl;
./test/testcrypto.cc:  dout(0) << "decoded len: " << dec_out.length() << dendl;
./test/testcrypto.cc:  dout(0) << "decoded msg: " << dec_out.c_str() << dendl;
./test/testkeys.cc:  generic_dout(0) << "server created" << dendl;
./test/testkeys.cc:  dout(0) << "decoded len: " << dec_out.length() << dendl;
./test/testkeys.cc:  dout(0) << "decoded msg: " << dec_out.c_str() << dendl;
./test/rbd_mirror/random_write.cc:  dout(5) << "connecting to cluster" << dendl;
./test/test_trans.cc:    dout(0) << "foo started" << dendl;
./test/test_trans.cc:    dout(0) << "foo asserting 0" << dendl;
./test/test_trans.cc:  dout(0) << "starting thread" << dendl;
./test/test_trans.cc:  dout(0) << "starting op" << dendl;
./test/testmsgr.cc:    dout(0) << "got ping from " << m->get_source() << dendl;
./test/testmsgr.cc:  dout(0) << "i am mon " << args[0] << dendl;
./test/testmsgr.cc:      dout(0) << "wait r " << received << " s " << sent << " is " << isend << dendl;
./test/testmsgr.cc:      dout(0) << "mark_down " << t << dendl;
./test/testmsgr.cc:    dout(0) << "pinging " << t << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] got op from Test" << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] connected: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] accepted: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[!TestPeer] accepted(stale event): " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] reset: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] remote reset: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:    ldout(cct, 0) << "[!TestPeer] refused: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:    ldout(cct, 0) << "[TestPeer] connect_peer(" << test_addr << ")" << dendl;
./test/crimson/test_messenger_peer.cc:        ldout(cct, 0) << "[TestPeer] this is not a new session " << conn.get() << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] this is a new session " << conn.get() << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] send_peer()" << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[TestPeer] send_peer() (pending " << pending_send << ")" << dendl;
./test/crimson/test_messenger_peer.cc:    ldout(cct, 0) << "[TestPeer] keepalive_peer()" << dendl;
./test/crimson/test_messenger_peer.cc:    ldout(cct, 0) << "[TestPeer] markdown()" << dendl;
./test/crimson/test_messenger_peer.cc:       ldout(cct, 0) << "[CmdSrv] got PING, sending PONG ..." << dendl;
./test/crimson/test_messenger_peer.cc:        ldout(cct, 0) << "All tests succeeded" << dendl;
./test/crimson/test_messenger_peer.cc:          ldout(cct, 0) << "[CmdSrv] shutdown ..." << dendl;
./test/crimson/test_messenger_peer.cc:          ldout(cct, 0) << "[CmdSrv] nonstop set ..." << dendl;
./test/crimson/test_messenger_peer.cc:        ldout(cct, 0) << "[CmdSrv] got cmd " << cmd << dendl;
./test/crimson/test_messenger_peer.cc:        ldout(cct, 0) << "[CmdSrv] done, send cmd reply ..." << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[CmdSrv] accepted: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[!CmdSrv] accepted(stale event): " << conn << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "[CmdSrv] reset: " << conn << dendl;
./test/crimson/test_messenger_peer.cc:        ldout(cct, 0) << "--------  suite stopped (force)  --------\n\n" << dendl;
./test/crimson/test_messenger_peer.cc:      ldout(cct, 0) << "--------  suite stopped  --------\n\n" << dendl;
./test/crimson/test_messenger_peer.cc:    ldout(cct, 0) << "[CmdSrv] ready" << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "init " << colls << " colls " << objs << " objs" << dendl;
./test/objectstore/TestObjectStoreState.cc:    dout(5) << "give collection hint, number of objects per collection: " << num_objs << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "init has " << m_in_flight.load() << "in-flight transactions" << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "init finished" << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "get_coll id " << cid << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "get_coll_at pos " << pos << dendl;
./test/objectstore/TestObjectStoreState.cc:    dout(5) << "get_coll_at pos " << pos << " non-existent" << dendl;
./test/objectstore/TestObjectStoreState.cc:  dout(5) << "touch_obj coll id " << m_cid << " name " << buf << dendl;
./test/objectstore/Allocator_bench.cc:  ldout(g_ceph_context, 0) << ostr.str() << dendl;
./test/objectstore/test_idempotent_sequence.cc:      dout(0) << "diff found an difference" << dendl;
./test/objectstore/test_idempotent_sequence.cc:      dout(0) << "no diff" << dendl;
./test/objectstore/DeterministicOpSequence.cc:  dout(0) << ss.str() << dendl;
./test/objectstore/DeterministicOpSequence.cc:    dout(0) << "generate seq " << txn << " op " << op << dendl;
./test/objectstore/DeterministicOpSequence.cc:  dout(10) << __func__ << " " << txn << dendl;
./test/objectstore/DeterministicOpSequence.cc:      dout(0) << "do_touch new object in collection and exists in another" << dendl;
./test/objectstore/DeterministicOpSequence.cc:  dout(0) << "do_touch " << entry->m_cid << "/" << obj << dendl;
./test/objectstore/DeterministicOpSequence.cc:    dout(0) << "do_remove no objects in collection" << dendl;
./test/objectstore/DeterministicOpSequence.cc:  dout(0) << "do_remove " << entry->m_cid << "/" << obj << dendl;
./test/objectstore/DeterministicOpSequence.cc:    dout(0) << "do_set_attrs no objects in collection" << dendl;
./test/objectstore/DeterministicOpSequence.cc:  dout(0) << "do_set_attrs " << out.size() << " entries" << dendl;
./test/objectstore/DeterministicOpSequence.cc:    dout(0) << "do_write no objects in collection" << dendl;
./test/osdc/FakeWriteback.cc:      ldout(m_cct, 20) << "finished read " << m_off << "~" << r << dendl;
./test/osdc/MemWriteback.cc:  dout(1) << "writing " << oid << " " << off << "~" << len  << dendl;
./test/osdc/MemWriteback.cc:  dout(1) << oid << " final size " << obj_bl.length() << dendl;
./test/osdc/MemWriteback.cc:  dout(1) << "reading " << oid << " " << off << "~" << len << dendl;
./test/osdc/MemWriteback.cc:    dout(1) << oid << "DNE!" << dendl;
./test/osdc/MemWriteback.cc:  dout(1) << "reading " << oid << " from total size " << obj_bl.length() << dendl;
./cls/cephfs/cls_cephfs_client.cc:    //dout(4) << "Invalid size attr on '" << oid << "'" << dendl;
./cls/cephfs/cls_cephfs_client.cc:    //dout(4) << "Invalid size attr on '" << oid << "'" << dendl;
./cls/cephfs/cls_cephfs_client.cc:    //dout(4) << "Invalid size attr on '" << oid << "'" << dendl;
./cls/cephfs/cls_cephfs_client.cc:      //dout(4) << "Corrupt backtrace on '" << oid << "': " << e << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 20) << "split " << *left << " at " << off << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 20) << "split    left is " << *left << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 20) << "split   right is " << *right << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 10) << "merge_left " << *left << " + " << *right << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 10) << "merge_left result " << *left << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 10) << "try_merge_bh " << *bh << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read miss+complete+zero " << left << " left, " << *n << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read miss " << left << " left, " << *n << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read hit " << *e << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read rx " << *e << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read error " << *e << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read gap+complete+zero " << *n << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 20) << "map_read gap " << *n << dendl;
./osdc/ObjectCacher.cc:        ldout(oc->cct, 10) << "map_write adding trailing bh " << *final << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) << "cur is " << cur << ", p is " << *p->second << dendl;
./osdc/ObjectCacher.cc:      ldout(oc->cct, 10) << "map_write bh " << *bh << " intersected" << dendl;
./osdc/ObjectCacher.cc:      ldout(oc->cct, 10) << "map_write gap " << cur << "~" << glen << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 10) << "map_write final is " << *final << dendl;
./osdc/ObjectCacher.cc:  ldout(oc->cct, 10) << "truncate " << *this << " to " << s << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) <<  "restarting reads post-truncate" << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) << " setting exists on " << *this << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) << " clearing complete on " << *this << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) << "discard " << *this << " bh " << *bh << dendl;
./osdc/ObjectCacher.cc:    ldout(oc->cct, 10) <<  "restarting reads post-discard" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "close_object " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 7) << "bh_read_finish no object cache" << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 20) << "checking bh " << *bh << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "bh_read_finish skipping non-rx " << *bh << dendl;
./osdc/ObjectCacher.cc:	  ldout(cct, 10) << "bh_read_finish removing " << *bh << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << "bh_read_finish read " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 20) << "finishing waiters " << ls << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 7) << "bh_write_scattered " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 7) << "bh_write " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 20) << " tid " << tid << " on " << bh->ob->get_oid() << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 7) << "bh_write_commit no object cache" << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << "bh_write_commit marking exists on " << *ob << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "bh_write_commit skipping non-tx " << *bh << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "bh_write_commit newer tid on " << *bh << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "bh_write_commit clean " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flush " << amount << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "trim trimming " << *bh << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << "trim clearing complete on " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "trim trimming " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "is_cached " << *ex_it << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "readx " << *ex_it << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << "readx  object !exists, 1 extent..." << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 20) << "readx  may copy on write" << dendl;
./osdc/ObjectCacher.cc:	    ldout(cct, 10) << "readx  flushing " << *bh << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 20) << "readx  ob has bh " << *bh_it->second << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "readx hit bh " << *bh << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 20) << "readx defer " << rd << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "readx has all buffers" << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "readx  result is " << rd->bl->length() << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "readx  no bufferlist ptr (readahead?), done." << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 20) << "readx done " << rd << " " << ret << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << __func__ << " woke up" << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << "wait_for_write woke up, ret " << ret << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flusher start" << dendl;
./osdc/ObjectCacher.cc:	ldout(cct, 10) << "flusher flushing aged dirty bh " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flusher finish" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "purge " << *ob << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flush " << *ob << " " << offset << "~" << length << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 20) << "flush  " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flush_set has no dirty|tx bhs" << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "flush_set on " << oset << " dne" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flush_set " << oset << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "flush_set on " << oset << " dne" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "flush_all " << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "purge_set on " << oset << " dne" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "purge_set " << oset << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "release trimming " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "release clearing complete on " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "release setting exists on " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << "release_set on " << oset << " dne" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "release_set " << oset << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "release_all" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "clear_nonexistence() " << oset << dendl;
./osdc/ObjectCacher.cc:      ldout(cct, 10) << " setting exists and complete on " << *ob << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << __func__ << " on " << oset << " dne" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << __func__ << " " << oset << dendl;
./osdc/ObjectCacher.cc:    ldout(cct, 10) << __func__ << " " << oset << " ex " << ex << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 10) << "verify_stats" << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 30) << "bh_add " << *ob << " " << *bh << dendl;
./osdc/ObjectCacher.cc:  ldout(cct, 30) << "bh_remove " << *ob << " " << *bh << dendl;
./osdc/Filer.cc:    ldout(cct, 10) << "_probe  probing " << p->oid << dendl;
./osdc/Filer.cc:	  ldout(cct, 10) << "_probed found size at " << end << dendl;
./osdc/Filer.cc:    ldout(cct, 10) << "_probed probing further" << dendl;
./osdc/Filer.cc:    ldout(cct, 10) << "_probed found mtime " << probe->max_mtime << dendl;
./osdc/Filer.cc:    ldout(cct, 10) << "_probed found mtime " << probe->max_mtime << dendl;
./osdc/Filer.cc:    ldout(cct, 10) << "purge_range removing " << oid << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << "set_readonly" << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << "set_writeable" << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << "recover start" << dendl;
./osdc/Journaler.cc:    ldout(cct, 1) << "recover - already recovering" << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << "read_head" << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "reread_head" << dendl;
./osdc/Journaler.cc:    ldout(cct, 0) << "error getting journal off disk" << dendl;
./osdc/Journaler.cc:      ldout(cct, 0) << "Corrupt header (bad offsets): " << h << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << "probing for end of the log" << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "reprobe" << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "write_head " << last_written << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "_finish_write_head " << wrote << dendl;
./osdc/Journaler.cc:    ldout(cct, 10) << "write_buf_throttle wait, delta " << delta << dendl;
./osdc/Journaler.cc:  ldout(cct, 20) << "write_buf_throttle get, delta " << delta << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "_do_flush flushing " << flush_pos << "~" << len << dendl;
./osdc/Journaler.cc:  ldout(cct, 20) << "write_buf_throttle put, len " << len << dendl;
./osdc/Journaler.cc:    ldout(cct, 0) << "_finish_read got error " << r << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "_prefetch" << dendl;
./osdc/Journaler.cc:    ldout(cct, 10) << "_prefetch temp_fetch_len " << temp_fetch_len << dendl;
./osdc/Journaler.cc:  ldout(cct, 10) << "_is_readable: not readable, returning false" << dendl;
./osdc/Journaler.cc:  ldout(cct, 1) << __func__ << dendl;
./osdc/Objecter.cc:  ldout(cct, 20) << __func__ << " clearing up homeless session..." << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " linger_op " << i->first << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " op " << i->first << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " command_op " << i->first << dendl;
./osdc/Objecter.cc:      ldout(cct, 10) <<  " successfully canceled tick" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "_linger_commit " << info->linger_id << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " PAUSERD" << dendl;
./osdc/Objecter.cc:    ldout(cct, 20) << " ignoring old gen" << dendl;
./osdc/Objecter.cc:  ldout(cct, 20) << __func__ << " linger_id=" << info->linger_id << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << __func__ << " cookie " << m->cookie << " dne" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " " << *m << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " " << cct << " " << *m << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " checking linger op " << op->linger_id << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " checking op " << op->tid << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " checking command " << c->tid << dendl;
./osdc/Objecter.cc:	  ldout(cct, 3) << "handle_osd_map decoding full epoch " << e << dendl;
./osdc/Objecter.cc:      ldout(cct, 10) << __func__ << "  checking op " << p->first << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "close_session for osd." << s->osd << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " linger_op " << i->first << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " op " << i->first << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << " command_op " << i->first << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " latest " << newest << ", have it" << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " latest " << newest << ", waiting" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "tick" << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " raced with shutdown" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "resend_mon_ops" << dendl;
./osdc/Objecter.cc:    ldout(cct, 20) << " note: not requesting reply" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " op " << op << dendl;
./osdc/Objecter.cc:  ldout(cct, 5) << num_in_flight << " in flight" << dendl;
./osdc/Objecter.cc:  ldout(cct,10) << __func__ << " " << tids << dendl;
./osdc/Objecter.cc:    ldout(cct, 4) << __func__ << ": DNE pool " << pool_id << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << __func__ << " " << to->osd << " " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << __func__ << " " << from->osd << " " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << __func__ << " " << from->osd << " " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << __func__ << " " << to->osd << " " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << "cancel_op " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << __func__ << " " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "in handle_osd_op_reply" << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << __func__ << " no session on con " << con << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << "retrying write after first reply: " << tid << dendl;
./osdc/Objecter.cc:    ldout(cct, 5) << " got redirect reply; redirecting" << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << " got -EAGAIN, resubmitting" << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << "handle_osd_op_reply completed tid " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 5) << num_in_flight << " in flight" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " " << *m << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << __func__ << " no session on con " << con << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " unrecognized op " << (int)m->op << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "list_nobjects_seek " << list_context << dendl;
./osdc/Objecter.cc:      ldout(cct, 10) << " pg_num changed; restarting with " << pg_num << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " " << list_context << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "allocate_selfmanaged_snap; pool: " << pool << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "create_pool name=" << name << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "delete_pool " << pool << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "delete_pool " << pool_name << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "pool_op_submit " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "handle_pool_op_reply " << *m << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << "unknown request " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "done" << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " tid " << tid << " dne" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " tid " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "get_pool_stats " << pools << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "_poolstat_submit " << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "handle_get_pool_stats_reply " << *m << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << "have request " << tid << " at " << op << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << "unknown request " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "done" << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " tid " << tid << " dne" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " tid " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "get_fs_stats" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "fs_stats_submit" << op->tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "handle_fs_stats_reply " << *m << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << "have request " << tid << " at " << op << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << "unknown request " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "done" << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " tid " << tid << " dne" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " tid " << tid << dendl;
./osdc/Objecter.cc:  ldout(cct, 15) << "_sg_read_finish" << dendl;
./osdc/Objecter.cc:    ldout(cct, 15) << "  only one frag" << dendl;
./osdc/Objecter.cc:  ldout(cct, 7) << "_sg_read_finish " << bytes_read << " bytes" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "ms_handle_connect " << con << dendl;
./osdc/Objecter.cc:	ldout(cct, 1) << "ms_handle_reset aborted,initialized=" << initialized << dendl;
./osdc/Objecter.cc:      ldout(cct, 1) << "ms_handle_refused on osd." << osd << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "blocklist_self " << (set ? "add" : "rm") << dendl;
./osdc/Objecter.cc:    ldout(cct, 7) << __func__ << " no session on con " << con << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "_submit_command " << tid << " " << c->cmd << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << "_send_command " << c->tid << dendl;
./osdc/Objecter.cc:    ldout(cct, 10) << __func__ << " tid " << tid << " dne" << dendl;
./osdc/Objecter.cc:  ldout(cct, 10) << __func__ << " tid " << tid << dendl;
./osdc/Striper.cc:  ldout(cct, 30) << " be " << tofs << "~" << tlen << dendl;
./osdc/Striper.cc:      ldout(cct, 20) << "  s at end" << dendl;
./osdc/Striper.cc:    ldout(cct, 30) << "  s " << s->first << "~" << s->second << dendl;
./osdc/Striper.cc:      ldout(cct, 30) << "  s len 0, skipping" << dendl;
./osdc/Striper.cc:      ldout(cct, 20) << "  s gap " << gap << ", skipping" << dendl;
./osdc/Striper.cc:      ldout(cct, 20) << "  s has " << actual << ", copying" << dendl;
./osdc/Striper.cc:      ldout(cct, 30) << "  s advancing" << dendl;
./osdc/Striper.cc:  ldout(cct, 10) << "file_to_extents " << offset << "~" << len << dendl;
./osdc/Striper.cc:    ldout(cct, 20) << " sc is one, reset su to os" << dendl;
./osdc/Striper.cc:        ldout(cct, 20) << " added new " << *ex << dendl;
./osdc/Striper.cc:      ldout(cct, 20) << " adding in to " << *ex << dendl;
./osdc/Striper.cc:    ldout(cct, 15) << "file_to_extents  " << *ex << dendl;
./osdc/Striper.cc:  ldout(cct, 20) << " stripes_per_object " << stripes_per_object << dendl;
./osdc/Striper.cc:  ldout(cct, 10) << "get_file_offset " << objectno << " " << off  << dendl;
./osdc/Striper.cc:  ldout(cct, 20) << " stripes_per_object " << stripes_per_object << dendl;
./osdc/Striper.cc:  ldout(cct, 10) << "assemble_result(" << this << ")" << dendl;
dout(SLEEP_LEVEL) << "Sleeping for "        << std::chrono::duration_cast<std::chrono::microseconds>(sleep_for).count()        << " microseconds" << dendl;
ldout(cct,10) << __func__ << " cluster_methods " << cluster_methods  << " service_methods " << service_methods  << " client_methods " << client_methods  << dendl;
ldout(cct,10) << __func__ << " mon_cluster_modes " << mon_cluster_modes  << " mon_service_modes " << mon_service_modes  << " mon_client_modes " << mon_client_modes  << ";
cluster_modes " << cluster_modes  ldout(cct,1) << "failed to pick con mode from client's " << preferred_modes        << " and our " << allowed_modes << dendl;
ldout(cct,20) << __func__ << " peer_type " << peer_type << " method " << method  << " cluster_methods " << cluster_methods  << " service_methods " << service_methods  << " client_methods " << client_methods  << dendl;
ldout(cct, 20)       << "KrbClientHandler::build_authorizer(): Service: "       << ceph_entity_type_name(service_id) << dendl;
ldout(cct, 20)       << "KrbClientHandler::build_request() " << dendl;
ldout(cct, 20)         << "KrbClientHandler::build_request() : Token Blob: " << "\n";
ldout(cct, 20)       << "KrbClientHandler::handle_response() " << dendl;
ldout(cct, 0)             << "ERROR: KrbClientHandler::handle_response() "               "[gss_import_name(gss_client_name)] failed! "             << gss_major_status << " "             << gss_minor_status << " "             << status_str             << dendl;
ldout(cct, 20)           << "ERROR: KrbClientHandler::handle_response() "             "[gss_acquire_cred()] failed! "           << gss_major_status << " "           << gss_minor_status << " "           << status_str           << dendl;
ldout(cct, 0)           << "ERROR: KrbClientHandler::handle_response() "             "[gss_import_name(gss_service_name)] failed! "           << gss_major_status << " "           << gss_minor_status << " "           << status_str           << dendl;
ldout(cct, 20)         << "KrbClientHandler::handle_response() : Token Blob: " << "\n";
ldout(cct, 20)           << "KrbClientHandler::handle_response() : "             "[gss_init_sec_context(GSS_S_CONTINUE_NEEDED)] " << dendl;
ldout(cct, 20)           << "KrbClientHandler::handle_response() : "             "[gss_init_sec_context(GSS_S_COMPLETE)] " << dendl;
ldout(cct, 0)           << "ERROR: KrbClientHandler::handle_response() "             "[gss_init_sec_context()] failed! "           << gss_major_status << " "           << gss_minor_status << " "           << status_str           << dendl;
ldout(ceph_ctx, 0)         << "Error: KrbAuthorizeHandler::verify_authorizer() failed!" << dendl;
ldout(cct, 20)       << "KrbServiceHandler::handle_request() " << dendl;
ldout(cct, 20)       << "KrbClientHandler::handle_request() : Token Blob: "       << "\n";
ldout(cct, 20)             << "KrbServiceHandler::handle_response() : "               "[KrbServiceHandler(GSS_S_CONTINUE_NEEDED)] " << dendl;
ldout(cct, 20)             << "KrbServiceHandler::handle_response() : "               "[KrbServiceHandler(GSS_S_COMPLETE)] " << dendl;
ldout(cct, 0)              << "KrbServiceHandler::handle_response() : "                 "ERROR: Could not get MONITOR CAPS : " << entity_name << dendl;
ldout(cct, 0)                << "KrbServiceHandler::handle_response() : "                   "ERROR: MONITOR CAPS invalid : " << entity_name << dendl;
ldout(cct, 0)             << "ERROR: KrbServiceHandler::handle_response() "               "[gss_accept_sec_context()] failed! "             << gss_major_status << " "             << gss_minor_status << " "             << status_str             << dendl;
ldout(cct, 20)         << "KrbServiceHandler::handle_request() : Token Blob: " << "\n";
ldout(cct, 0)         << "ERROR: KrbServiceHandler::start_session() "           "[gss_import_name(gss_client_name)] failed! "         << gss_major_status << " "         << gss_minor_status << " "         << status_str         << dendl;
ldout(cct, 0)         << "ERROR: KrbServiceHandler::start_session() "           "[gss_acquire_cred()] failed! "         << gss_major_status << " "         << gss_minor_status << " "         << status_str         << dendl;
ldout(cct, 10) << "get auth session key: client_challenge "     << std::hex << req.client_challenge << std::dec << dendl;
ldout(cct, 1) << __func__ << " failed to decode CephXServerChallenge: "      << e.what() << dendl;
ldout(cct, 10) << " got initial server challenge "     << std::hex << server_challenge << std::dec << dendl;
ldout(cct, 1) << __func__ << " failed to decode CephXResponseHeader: "    << e.what() << dendl;
ldout(cct, 1) << __func__ << " failed to decode tickets: "   << e.what() << dendl;
ldout(cct, 10) << " got connection bl " << cbl.length()         << " and extra tickets " << extra_tickets.length()         << dendl;
ldout(cct, 10) << " got connection_secret "        << connection_secret->size() << " bytes" << dendl;
ldout(cct, 0) << "could not set rotating key: decode_decrypt failed. error:"     << error << dendl;
ldout(cct, 10) << "validate_tickets: want=" << want << " need=" << need   << " have=" << have << dendl;
ldout(cct, 10) << "want=" << want << " need=" << need << " have=" << have   << dendl;
ldout(cct, 20) << "need_tickets: want=" << want   << " have=" << have   << " need=" << need   << dendl;
ldout(cct, 10) << "start_session server_challenge "   << hex << server_challenge << dec << dendl;
ldout(cct, 0) << __func__ << " failed to decode CephXRequestHeader: "    << e.what() << dendl;
ldout(cct, 10) << "handle_request get_auth_session_key for "       << entity_name << dendl;
ldout(cct, 0) << __func__ << " failed to decode CephXAuthenticate: "        << e.what() << dendl;
ldout(cct, 20) << " checking key: req.key=" << hex << req.key        << " expected_key=" << expected_key << dec << dendl;
ldout(cct, 0) << " unexpected key: req.key=" << hex << req.key  << " expected_key=" << expected_key << dec << dendl;
ldout(cct, 10) << "decoded old_ticket with global_id=" << *global_id         << dendl;
ldout(cct,10) << __func__ << " auth ticket global_id " << *global_id      << dendl;
ldout(cct, 10) << " adding key for service "        << ceph_entity_type_name(service_id) << dendl;
ldout(cct, 0) << __func__        << " failed to decode CephXServiceTicketRequest: "        << e.what() << dendl;
ldout(cct, 10) << " adding key for service "    << ceph_entity_type_name(service_id) << dendl;
ldout(cct, 10) << "   missing key for service "      << ceph_entity_type_name(service_id) << dendl;
ldout(cct, 10) << "handle_request getting rotating secret for "       << entity_name << dendl;
ldout(cct, 10) << "build_service_ticket service "   << ceph_entity_type_name(info.service_id)   << " secret_id " << info.secret_id   << " ticket_info.ticket.name="   << ticket_info.ticket.name.to_str()   << " ticket.global_id " << info.ticket.global_id << dendl;
ldout(cct, -1) << "cephx_build_service_ticket_blob failed with error "   << error << dendl;
ldout(cct, 10) << "build_service_ticket_reply encoding " << num    << " tickets with secret " << principal_secret << dendl;
ldout(cct, 0) << __func__ << " failed decode_decrypt, error is: " << error      << dendl;
ldout(cct, 10) << __func__ << " decode_decrypt failed "         << "with " << error << dendl;
ldout(cct, 10) << __func__ << " ticket.secret_id=" <<  ticket.secret_id     << dendl;
ldout(cct, 10) << __func__ << " service "     << ceph_entity_type_name(service_id)     << " secret_id " << ticket.secret_id     << " session_key " << msg_a.session_key     << " validity=" << msg_a.validity << dendl;
ldout(cct, 10) << __func__ << " ticket expires=" << expires       << " renew_after=" << renew_after << dendl;
ldout(cct, 10) << "set_have_need_key no handler for service "     << ceph_entity_type_name(service_id) << dendl;
//ldout(cct, 10) << "set_have_need_key service " << ceph_entity_type_name(service_id)  //<< " (" << service_id << ")"  //<< " need=" << iter->second.need_key() << " have=" << iter->second.have_key() << dendl;
ldout(cct, 10) << __func__ << " failed to decode ticket v or count: "     << e.what() << dendl;
ldout(cct, 10) << __func__ << " failed to decode ticket type: " << e.what()       << dendl;
ldout(cct, 0) << "no TicketHandler for service "    << ceph_entity_type_name(service_id) << dendl;
ldout(cct, 10) << "validate_tickets want " << mask << " have " << have   << " need " << need << dendl;
ldout(cct, 0) << "ceph_decode_ticket could not get general service secret for service_id="       << ceph_entity_type_name(service_id) << " secret_id=" << secret_id << dendl;
ldout(cct, 0) << "ceph_decode_ticket could not get service secret for service_id="        << ceph_entity_type_name(service_id) << " secret_id=" << secret_id << dendl;
ldout(cct, 0) << "ceph_decode_ticket could not decrypt ticket info. error:"  << error << dendl;
ldout(cct, 10) << "verify_authorizer decrypted service "    << ceph_entity_type_name(service_id)    << " secret_id=" << ticket.secret_id << dendl;
ldout(cct, 0) << "verify_authorizer could not get general service secret for service "       << ceph_entity_type_name(service_id) << " secret_id=" << ticket.secret_id << dendl;
ldout(cct, 0) << "verify_authorizer could not get service secret for service "       << ceph_entity_type_name(service_id) << " secret_id=" << ticket.secret_id << dendl;
ldout(cct, 0) << "verify_authorizer could not decrypt ticket info: error: "      << error << dendl;
ldout(cct, 0) << "verify_authorizer global_id mismatch: declared id=" << global_id     << " ticket_id=" << ticket_info.ticket.global_id << dendl;
ldout(cct, 0) << "verify_authorizercould not decrypt authorize request with error: "      << error << dendl;
ldout(cct,10) << __func__ << " adding server_challenge " << c->server_challenge      << dendl;
ldout(cct, 10) << __func__ << " got server_challenge+1 "     << auth_msg.server_challenge_plus_one     << " expecting " << c->server_challenge + 1 << dendl;
ldout(cct, 10) << "verify_authorizer ok nonce " << hex << auth_msg.nonce << dec    << " reply_bl.length()=" << reply_bl->length() <<  dendl;
ldout(cct, 0) << "verify_authorizer_reply bad nonce got " << reply.nonce_plus_one << " expected " << expect     << " sent " << nonce << dendl;
ldout(cct, 0) << "failed to decrypt challenge (" << challenge.length() << " bytes): "      << error << dendl;
ldout(cct, 30) << "get_service_secret service " << ceph_entity_type_name(service_id)    << " id " << secret_id << " " << secret << dendl;
ldout(cct, 10) << "get_service_secret service " << ceph_entity_type_name(service_id)      << " secret " << secret_id << " not found" << dendl;
ldout(cct, 30) << "service " << ceph_entity_type_name(iter->first)              << " id " << mapiter->first              << " key " << mapiter->second << dendl;
ldout(cct, 30) << "_rotate_secret adding " << ceph_entity_type_name(service_id)            << " id " << secret_id << " " << ek            << dendl;
ldout(cct, 10) << __func__ << " seq " << m->get_seq()   << " front_crc_ = " << footer.front_crc   << " middle_crc = " << footer.middle_crc   << " data_crc = " << footer.data_crc   << " sig = " << *psig   << dendl;
ldout(cct, 20) << "Putting signature in client message(seq # " << m->get_seq()   << "): sig = " << sig << dendl;
ldout(cct, 0) << "do not have service " << ceph_entity_type_name(service_id_)     << ", i am " << ceph_entity_type_name(this->service_id) << dendl;
ldout(cct, 10) << "jni: link: oldpath " << c_oldpath <<  " newpath " << c_newpath << dendl;
ldout(cct, 10) << "jni: symlink: oldpath " << c_oldpath <<  " newpath " << c_newpath << dendl;
ldout(cct, 10) << "jni: open: path " << c_path << " flags " << flags  << " mode " << (int)j_mode << dendl;
ldout(cct, 10) << "jni: open_layout: path " << c_path << " flags " << flags  << " mode " << (int)j_mode << " stripe_unit " << stripe_unit  << " stripe_count " << stripe_count << " object_size " << object_size  << " data_pool " << (c_data_pool ? c_data_pool : "<NULL>") << dendl;
ldout(cct, 10) << "jni: lseek: fd " << (int)j_fd << " offset "  << (long)j_offset << " whence " << whence << dendl;
ldout(cct, 10) << "jni: read: fd " << (int)j_fd << " len " << (long)j_size <<  " offset " << (long)j_offset << dendl;
ldout(cct, 10) << "jni: write: fd " << (int)j_fd << " len " << (long)j_size <<  " offset " << (long)j_offset << dendl;
ldout(cct, 10) << "jni: ftruncate: fd " << (int)j_fd <<  " size " << (loff_t)j_size << dendl;
ldout(cct, 10) << "jni: fsync: fd " << (int)j_fd <<  " dataonly " << (j_dataonly ? 1 : 0) << dendl;
ldout(cct, 10) << "jni: flock: fd " << (int)j_fd <<  " operation " << j_operation << " owner " << j_owner << dendl;
ldout(cct, 10) << "jni: getxattr: path " << c_path << " name " << c_name <<  " len " << buf_size << dendl;
ldout(cct, 10) << "jni: lgetxattr: path " << c_path << " name " << c_name <<  " len " << buf_size << dendl;
ldout(cct, 10) << "jni: setxattr: path " << c_path << " name " << c_name  << " len " << j_size << " flags " << flags << dendl;
ldout(cct, 10) << "jni: lsetxattr: path " << c_path << " name " << c_name  << " len " << j_size << " flags " << flags << dendl;
ldout(m->cct, 20) << __func__ << " " << i->job << " pool " << i->pool                    << " [" << i->begin << "," << i->end << ")"                    << " pgs " << i->pgs                    << dendl;
ldout(cct, 20) << __func__ << " " << job << " " << p.first << " [" << ps       << "," << ps_end << ")" << dendl;
lgeneric_subdout(cct, refs, 5) << "PG::get " << this << " "     << "tag " << (tag ? tag : "(none") << " "     << (after - 1) << " -> " << after << dendl;
lgeneric_subdout(local_cct, refs, 5) << "PG::put " << this << " "           << "tag " << (tag ? tag : "(none") << " "           << (after + 1) << " -> " << after           << dendl;
lgeneric_subdout(cct, refs, 5) << "PG::get " << this << " " << info.pgid     << " got id " << id << " "     << (ref - 1) << " -> " << ref     << dendl;
lgeneric_subdout(cct, refs, 5) << "PG::put " << this << " " << info.pgid     << " put id " << id << " "     << (newref + 1) << " -> " << newref     << dendl;
dout(20) << "op_has_sufficient_caps "           << "session=" << session           << " pool=" << pool.id << " (" << pool.name           << " " << req->get_hobj().nspace    << ")"    << " pool_app_metadata=" << pool.info.application_metadata    << " need_read_cap=" << op->need_read_cap()    << " need_write_cap=" << op->need_write_cap()    << " classes=" << op->classes()    << " -> " << (cap ? "yes" : "NO")    << dendl;
dout(15) << __func__ << " finish_sync_event? " << finish_sync_event << " clean? "   << is_clean() << dendl;
dout(10) << "start_recovery_op " << soid#ifdef DEBUG_RECOVERY_OIDS    << " (" << recovering_oids << ")"#endif    << dendl;
dout(10) << "finish_recovery_op " << soid#ifdef DEBUG_RECOVERY_OIDS    << " (" << recovering_oids << ")"#endif    << dendl;
dout(10) << __func__ << " from " << sources << " split_bits " << split_bits    << dendl;
dout(20) << __func__ << " ? " << r << " " << p->first        << " " << p->second << dendl;
dout(20) << __func__ << " checking " << p->first        << " " << p->second << dendl;
dout(0) << __func__ << " " << info_struct_v << " -> " << pg_latest_struct_v   << dendl;
dout(20) << __func__ << " " << op << " (waiting_for_map " << p->first << ")"      << dendl;
dout(20) << __func__ << " " << p->first << " front op "        << p->second.front() << " must still wait, doing nothing"        << dendl;
dout(15) << __func__ << " pg(" << info.pgid   << (is_active() ? ") <active>" : ") <not-active>")   << (is_clean() ? " <clean>" : " <not-clean>") << dendl;
dout(15) << __func__ << ": time_for_deep=" << planned.time_for_deep      << " deep_coin_flip=" << deep_coin_flip << dendl;
dout(20) << __func__ << ": auto repair with scrubbing, rescrub if errors found"   << dendl;
dout(20) << __func__ << " updated flags: " << planned    << " allow_regular_scrub: " << allow_regular_scrub << dendl;
dout(10) << __func__ << " new removed_snaps " << i->second      << ", snap_trimq now " << snap_trimq << dendl;
dout(10) << __func__ << " new purged_snaps " << j->second      << ", now " << recovery_state.get_info().purged_snaps << dendl;
dout(10) << __func__ << " snap " << snap << " - not active and primary"      << dendl;
dout(20) << __func__ << " snap " << snap      << ", trimq now " << snap_trimq      << ", repeat " << snap_trimq_repeat << dendl;
dout(20) << __func__ << " snap " << snap      << " already in trimq " << snap_trimq << dendl;
dout(10) << __func__ << " flushes in progress, moving "        << waiting_for_peered.size() << " items to waiting_for_flush"        << dendl;
lgeneric_dout(cct, 20) << __func__ << " Adjust local usage "    << (local_bytes >> 10) << "KiB"    << " primary usage " << (bf_bytes >> 10)    << "KiB" << dendl;
dout(10) << __func__ << " primary_bytes " << (primary_bytes >> 10)      << "KiB"      << " local " << (local_bytes >> 10) << "KiB"      << " pending_adjustments " << (pending_adjustment >> 10) << "KiB"      << dendl;
dout(10) << "backfill reservation rejected: failure injection"      << dendl;
dout(10) << "backfill reservation rejected: backfill full"      << dendl;
dout(10) << __func__ << "osd." << osd->whoami        << " pg " << info.pgid        << " found obsolete rollback obj "        << *i << " generation < trimmed_to "        << trimmed_to        << "...repaired" << dendl;
dout(10) << "repair_object " << soid    << " bad_peers osd.{" << bad_peers << "},"    << " ok_peers osd.{" << ok_shards << "}" << dendl;
dout(0) << __func__ << ": Need version of replica, bad object_info_t: "     << soid << dendl;
dout(5) << __func__ << " refusing to forward. " << (is_clean() ? "(clean) " : "(not clean) ") <<            (is_active() ? "(active) " : "(not active) ") <<  dendl;
dout(10) << __func__ << " queued at: " << epoch_queued    << (is_primary() ? " (primary)" : " (replica)") << dendl;
dout(10) << "old_peering_msg reply_epoch " << reply_epoch << " query_epoch "      << query_epoch << " last_peering_reset " << last_reset << dendl;
dout(7) << " changed after " << m->get_map_epoch()     << ", dropping " << *m << dendl;
dout(7) << __func__ << " sent before last_force_op_resend "  << pool.info.last_force_op_resend  << ", dropping" << *m << dendl;
dout(7) << __func__ << " sent before last_force_op_resend_prenautilus "  << pool.info.last_force_op_resend_prenautilus  << ", dropping" << *m << dendl;
dout(7) << __func__ << " pg split in "       << info.history.last_epoch_split << ", dropping" << dendl;
dout(7) << __func__ << " sent before last_force_op_resend_preluminous "       << pool.info.last_force_op_resend_preluminous       << ", dropping" << *m << dendl;
dout(10) << "can_discard_replica_op pg changed " << info.history      << " after " << m->map_epoch      << ", dropping" << dendl;
dout(10) << __func__ << ": " << get_osdmap()->get_epoch()    << dendl;
dout(20) << __func__ << " wake up at "                 << ceph_clock_now()          << ", re-queuing delete" << dendl;
dout(0) << __func__ << " additional unexpected onode list"              <<" (new onodes has appeared since PG removal started"              << olist << dendl;
dout(20) << __func__ << " reserved_num_bytes " << (reserved_num_bytes >> 10) << "KiB"             << " Before kb_used " << new_stat.statfs.kb_used() << "KiB" << dendl;
ldout(cct, 10) << __func__ << " from " << new_pool.first << " to "                       << tier_pool << dendl;
ldout(cct, 10) << __func__ << " removing pg_temp " << pg.first       << " for nonexistent pool " << pg.first.pool() << dendl;
ldout(cct, 10) << __func__ << "  removing pg_temp " << pg.first       << " with all down osds" << pg.second << dendl;
ldout(cct, 10) << __func__ << "  removing pg_temp " << pg.first << " "       << pg.second << " that matches raw_up mapping" << dendl;
ldout(cct, 10) << __func__ << "  removing pg_temp " << pg.first << " "       << pg.second << " exceeds pool size" << dendl;
ldout(cct, 10) << __func__ << "  removing primary_temp " << pg.first       << " to down " << pg.second << dendl;
ldout(cct, 10) << __func__ << "  removing primary_temp "       << pgid << " -> " << real_primary       << " (unnecessary/redundant)" << dendl;
ldout(cct, 0) << __func__ << " pg " << pg << " is gone or merge source"      << dendl;
ldout(cct, 0) << __func__ << " pg " << pg << " is pending merge"      << dendl;
ldout(cct, 0) << __func__ << " verify_upmap of pg " << pg                    << " returning " << r                    << dendl;
ldout(cct, 10) << __func__ << " pg " << pg                   << " weight_map " << weight_map                   << dendl;
ldout(cct, 10) << __func__ << " pg " << pg << ": osd " << osd << " is gone or has "               << "been moved out of the specific crush-tree"        << dendl;
ldout(cct, 10) << __func__ << " pg " << pg << ": osd " << osd               << " is out/crush-out"      << dendl;
ldout(cct, 10) << " removing redundant pg_upmap "                     << i->first << " " << i->second                     << dendl;
ldout(cct, 10) << " removing no-op pg_upmap_items "                       << j->first << " " << j->second                       << dendl;
ldout(cct, 10) << " simplifying partially no-op pg_upmap_items "                       << j->first << " " << j->second                       << " -> " << newmap                       << dendl;
ldout(cct, 10) << __func__ << " cancel invalid pending "                     << "pg_upmap entry "                     << i->first << "->" << i->second                     << dendl;
ldout(cct, 10) << __func__ << " cancel invalid pg_upmap entry "                     << j->first << "->" << j->second                     << dendl;
ldout(cct, 10) << __func__ << " cancel invalid pending "                     << "pg_upmap_items entry "                     << p->first << "->" << p->second                     << dendl;
ldout(cct, 10) << __func__ << " cancel invalid "                     << "pg_upmap_items entry "                     << q->first << "->" << q->second                     << dendl;
ldout(cct, 10) << "build_simple on " << nosd   << " osds" << dendl;
ldout(cct,20) << __func__ << " pool " << i.first                  << " ruleno " << ruleno                  << " weight-map " << pmap                  << dendl;
ldout(cct, 20) << " osd." << i.first << " weight " << i.second       << " pgs " << pgs << dendl;
ldout(cct, 20) << " osd." << i.first                   << "\tpgs " << i.second.size()                   << "\ttarget " << target                   << "\tdeviation " << deviation                   << dendl;
ldout(cct, 10) << __func__ << " distribution is almost perfect"                   << dendl;
ldout(cct, 10) << " overfull " << overfull                   << " underfull " << underfull                   << dendl;
ldout(cct, 10) << " hitting underfull osds now"                       << " when trying to remap overfull osds"                       << dendl;
ldout(cct, 10) << " Overfull search osd." << osd                       << " target " << target                       << " deviation " << deviation         << dendl;
ldout(cct, 10) << " osd." << osd                       << " target " << target                       << " deviation " << deviation                       << " < max deviation " << max_deviation                       << dendl;
ldout(cct, 10) << " will try dropping existing"                           << " remapping pair "                           << q.first << " -> " << q.second                           << " which remapped " << pg                           << " into overfull osd." << osd                           << dendl;
ldout(cct, 10) << " existing pg_upmap_items " << p->second                         << " remapped " << pg << " into overfull osd." << osd                         << ", will try cancelling it entirely"                         << dendl;
ldout(cct, 10) << " existing pg_upmap_items " << p->second                         << " remapped " << pg << " into overfull osd." << osd                         << ", new_pg_upmap_items now " << new_upmap_items                         << dendl;
ldout(cct, 10) << " " << pg << " already has pg_upmap "                         << temp_it->second << ", skipping"                         << dendl;
ldout(cct, 10) << " " << pg << " already has full-size pg_upmap_items "                         << it->second << ", skipping"                         << dendl;
ldout(cct, 10) << " " << pg << " already has pg_upmap_items "                         << it->second                         << dendl;
ldout(cct, 10) << " will try adding new remapping pair "                         << orig[i] << " -> " << out[i] << " for " << pg    << (orig[i] != osd ? " NOT selected osd" : "")                         << dendl;
ldout(cct, 10) << " failed to find any changes for overfull osds"                   << dendl;
ldout(cct, 10) << " osd." << osd                       << " target " << target                       << " deviation " << deviation                       << " -> absolute " << fabsf(deviation)                       << " < max " << max_deviation                       << dendl;
ldout(cct, 10) << " will try dropping existing"                           << " remapping pair "                           << j.first << " -> " << j.second                           << " which remapped " << pg                           << " out from underfull osd." << osd                           << dendl;
ldout(cct, 10) << " existing pg_upmap_items " << i.second                         << " remapped " << pg                         << " out from underfull osd." << osd                         << ", will try cancelling it entirely"                         << dendl;
ldout(cct, 10) << " existing pg_upmap_items " << i.second                         << " remapped " << pg                         << " out from underfull osd." << osd                         << ", new_pg_upmap_items now " << new_upmap_items                         << dendl;
ldout(cct, 10) << " failed to find any changes for underfull osds"                   << dendl;
ldout(cct, 10) << " break due to not being able to find any"                     << " further optimizations"                     << dendl;
ldout(cct, 20) << " osd." << i.first                     << "\tpgs " << i.second.size()                     << "\ttarget " << target                     << "\tdeviation " << deviation                     << dendl;
ldout(cct, 10) << " break because stddev is not decreasing"                       << " and aggressive mode is not enabled"                       << dendl;
ldout(cct, 10) << " hit local_fallback_retries "                       << local_fallback_retries                       << dendl;
ldout(cct, 20) << " local_fallback_retried " << local_fallback_retried                     << " to_skip " << to_skip                     << dendl;
ldout(cct, 10) << " upmap pg " << i.first                     << " new pg_upmap_items " << i.second                     << dendl;
ldout(cct, 10) << __func__ << " Optimization plan is almost perfect"                     << dendl;
ldout(cct, 10) << __func__ << ": adding sources in batch "       << sources.size() << dendl;
ldout(cct, 10) << __func__ << " " << soid       << " delete, ignoring source" << dendl;
ldout(cct, 10) << "search_for_missing " << soid << " " << need       << " also missing on osd." << fromosd       << " (last_update " << oinfo.last_update       << " < needed " << need << ")" << dendl;
ldout(cct, 10) << "search_for_missing " << soid << " " << need       << " also missing on osd." << fromosd       << " (past last_backfill " << oinfo.last_backfill       << ")" << dendl;
ldout(cct, 10) << "search_for_missing " << soid << " " << need       << " also missing on osd." << fromosd << dendl;
ldout(cct, 10) << "search_for_missing " << soid << " " << need     << " is on osd." << fromosd << dendl;
ldout(cct, 20) << "needs_recovery_map missing " << needs_recovery_map   << dendl;
ldout(cct, 10) << __func__ << " sources osds " << now_down << " now down, remaining sources are "         << missing_loc_sources << dendl;
dout(10) << "maybe_complete_notify -- "    << watchers.size()    << " in progress watchers " << dendl;
dout(10) << __func__ << " " << notif->notify_id        << " last_ping " << last_ping << " < cutoff " << cutoff        << ", disconnecting" << dendl;
dout(20) << __func__        << " prior_readable_until_ub " << prior_readable_until_ub        << " (mnow " << mnow << " + "        << info.history.prior_readable_until_ub << ")" << dendl;
psdout(10) << "purge_strays " << stray_set << " but premerge, doing nothing"        << dendl;
psdout(10) << " got dup osd." << from << " info "        << oinfo << ", identical to ours" << dendl;
psdout(10) << " got info " << oinfo << " from down osd." << from      << " discarding" << dendl;
psdout(10) << "handle_advance_map "     << newup << "/" << newacting     << " -- " << up_primary << "/" << acting_primary     << dendl;
psdout(20) << __func__ << ": Dirtying info: last_persisted is "       << last_persisted_osdmap       << " while current is " << osdmap_ref->get_epoch() << dendl;
psdout(20) << __func__ << ": Not dirtying info: last_persisted is "       << last_persisted_osdmap       << " while current is " << osdmap_ref->get_epoch() << dendl;
psdout(20) << "new interval newup " << newup        << " newacting " << newacting << dendl;
psdout(10) << __func__ << " osd transitioned from down -> up"        << dendl;
psdout(10) << __func__ << ": check_new_interval output: "        << debug.str() << dendl;
psdout(1) << __func__ << " up " << oldup << " -> " << up     << ", acting " << oldacting << " -> " << acting     << ", acting_primary " << old_acting_primary << " -> "     << new_acting_primary     << ", up_primary " << old_up_primary << " -> " << new_up_primary     << ", role " << oldrole << " -> " << role     << ", features acting " << acting_features     << " upacting " << upacting_features     << dendl;
psdout(10) << oldacting << " -> " << acting        << ", acting primary "        << old_acting_primary << " -> " << get_primary()        << dendl;
psdout(10) << oldacting << " -> " << acting   << ", replicas changed" << dendl;
psdout(20) << __func__ << " upacting_features 0x" << std::hex      << upacting_features << std::dec      << " from " << acting << "+" << up << dendl;
psdout(20) << __func__ << " checking missing set deletes flag. missing = "      << get_pg_log().get_missing() << dendl;
psdout(10) << __func__ << " prior_readable_until_ub "      << prior_readable_until_ub << " (mnow " << mnow << " + "      << info.history.prior_readable_until_ub << ")" << dendl;
psdout(20) << __func__ << " state " << get_current_state()      << dendl;
psdout(20) << __func__ << " state " << get_current_state()      << dendl;
psdout(20) << " peer_clock_delta_ub " << *hb_stamps[0]->peer_clock_delta_ub        << " -> ru " << ru << dendl;
psdout(20) << " peer_clock_delta_lb " << *hb_stamps[0]->peer_clock_delta_lb        << " -> ruub " << ruub << dendl;
psdout(20) << __func__ << " readable_until_ub now " << readable_until_ub        << dendl;
dout(20) << __func__ << " peer osd." << acting[i]      << " ruub " << acting_readable_until_ub[i] << dendl;
dout(20) << __func__ << " readable_until[_ub] " << readable_until    << " (sent " << readable_until_ub_sent << ")" << dendl;
dout(10) << __func__ << " prior_readable_down_osds osd." << *p        << " is dead as of epoch " << map->get_epoch()        << dendl;
psdout(10) << "adjust_need_up_thru now "        << up_thru << ", need_up_thru now false" << dendl;
psdout(10) << "up_thru " << get_osdmap()->get_up_thru(pg_whoami.osd)        << " < same_since " << info.history.same_interval_since        << ", must notify monitor" << dendl;
psdout(10) << "up_thru " << get_osdmap()->get_up_thru(pg_whoami.osd)        << " >= same_since " << info.history.same_interval_since        << ", all is well" << dendl;
psdout(10) << __func__ << " primary has " << missing.num_missing()        << " missing" << dendl;
psdout(10) << __func__ << " osd." << peer << " doesn't have missing set"   << dendl;
psdout(10) << __func__ << " osd." << peer << " has "   << pm->second.num_missing() << " missing" << dendl;
psdout(10) << __func__ << " osd." << peer   << " has last_backfill " << pi->second.last_backfill << dendl;
psdout(10) << "all_unfound_are_queried_or_lost all of might_have_unfound "      << might_have_unfound      << " have been queried or are marked lost" << dendl;
psdout(10) << __func__ << " prefer osd." << p->first               << " because it is complete while best has missing"               << dendl;
psdout(10) << __func__ << " skipping osd." << p->first               << " because it has missing while best is complete"               << dendl;
psdout(10) << "calc_acting prefer osd." << p->first   << " because it is current primary" << dendl;
psdout(20) << __func__ << " candidates by cost are: " << candidates_by_cost      << dendl;
psdout(20) << __func__ << " result want=" << *want      << " async_recovery=" << *async_recovery << dendl;
psdout(20) << __func__ << " candidates by cost are: " << candidates_by_cost      << dendl;
psdout(20) << __func__ << " result want=" << *want      << " async_recovery=" << *async_recovery << dendl;
psdout(10) << __func__ << " all_info osd." << p->first << " "   << p->second << dendl;
psdout(10) << __func__ << " no suitable info found (incomplete backfills?),"   << " reverting to up" << dendl;
psdout(10) << __func__ << " evicting osd." << want.back()               << " from oversized want " << want << dendl;
psdout(10) << __func__ << " want " << want << " != acting " << acting        << ", requesting pg_temp change" << dendl;
psdout(10) << "acting_recovery_backfill is "      << acting_recovery_backfill << dendl;
psdout(10) << "choose_acting want=" << want << " backfill_targets="           << want_backfill << " async_recovery_targets="           << async_recovery_targets << dendl;
psdout(10) << __func__ << " "      << missing.num_missing() << " missing, "      << unfound << " unfound"      << dendl;
psdout(20) << __func__ << ": osd." << peer   << ": we already have pg_missing_t" << dendl;
psdout(20) << __func__ << ": osd." << peer   << ": in peer_log_requested" << dendl;
psdout(20) << __func__ << ": osd." << peer   << ": in peer_missing_requested" << dendl;
psdout(10) << __func__ << ": osd." << peer << ": requesting pg_missing_t"        << dendl;
psdout(10) << "activate - no missing, moving last_complete " << info.last_complete      << " -> " << info.last_update << dendl;
dout(20) << "activate - purged_snaps " << info.purged_snaps        << " removed_snaps " << p->second        << dendl;
psdout(10) << "activate peer osd." << peer       << " is up to date, queueing in pending_activators" << dendl;
psdout(10) << "activate peer osd." << peer       << " is up to date, but sending pg_log anyway" << dendl;
dout(10) << "activate peer osd." << peer << " sending " << m->log   << dendl;
psdout(10) << "activate peer osd." << peer << " " << pi     << " uptodate" << dendl;
psdout(10) << "activate peer osd." << peer << " " << pi     << " missing " << pm << dendl;
psdout(20) << __func__ << " setting up missing_loc from shard " << *i   << " " << dendl;
psdout(10) << __func__ << " updating purged_snaps to "        << oinfo.purged_snaps        << dendl;
psdout(10) << "proc_master_log for osd." << from << ": "      << olog << " " << omissing << dendl;
psdout(10) << " peer osd." << from << " now " << oinfo      << " " << omissing << dendl;
psdout(10) << "proc_replica_log for osd." << from << ": "      << oinfo << " " << olog << " " << omissing << dendl;
psdout(10) << " peer osd." << from << " now "      << oinfo << " " << omissing << dendl;
psdout(20) << " after missing " << i->first        << " need " << i->second.need        << " have " << i->second.have << dendl;
psdout(10) << " sending info+missing+log since " << query.since        << dendl;
psdout(10) << __func__ << " target doesn't match expected parent "   << last_pg_merge_meta.source_pgid.get_parent()   << " of source_pgid " << last_pg_merge_meta.source_pgid   << dendl;
psdout(10) << __func__ << " target version doesn't match expected "        << last_pg_merge_meta.target_version << dendl;
psdout(10) << __func__ << " source " << source->pg_whoami   << " incomplete"   << dendl;
dout(10) << __func__ << " source " << source->info.pgid.pgid   << " doesn't match expected source pgid "   << last_pg_merge_meta.source_pgid << dendl;
dout(10) << __func__ << " source version doesn't match expected "   << last_pg_merge_meta.target_version << dendl;
psdout(10) << __func__        << " set les/c to " << last_pg_merge_meta.last_epoch_started << "/"        << last_pg_merge_meta.last_epoch_clean        << " from pool last_dec_*, source pg history was "        << sources.begin()->second->info.history        << dendl;
dout(10) << __func__ << " both merge target and source are placeholders,"               << " set sis to lec " << info.history.last_epoch_clean               << dendl;
psdout(10) << __func__ << " last_epoch_clean "   << info.history.last_epoch_clean << " < past_interval start "   << pib.first << ", adjusting start backwards" << dendl;
psdout(10) << __func__ << " last_epoch_started "   << info.history.last_epoch_started << " < same_interval_since "   << info.history.same_interval_since   << ", adjusting pg_history backwards" << dendl;
psdout(0) << __func__ << " negative num_objects = "              << info.stats.stats.sum.num_objects << " setting it to 0 "              << dendl;
psdout(20) << __func__ << " actingset " << actingset << " upset "        << upset << " acting_recovery_backfill " << acting_recovery_backfill << dendl;
psdout(20) << __func__ << " shard " << pg_whoami   << " primary objects " << num_objects   << " missing " << missing   << dendl;
psdout(20) << __func__ << " no peer_missing found for "       << peer.first << dendl;
psdout(20) << __func__ << " shard " << peer.first   << " objects " << peer_num_objects   << " missing " << missing   << dendl;
psdout(30) << __func__ << " " << ml.first << " object_location_counts["   << ml.second << "]=" << info.stats.object_location_counts[ml.second]   << dendl;
psdout(30) << __func__ << " object_location_counts["        << upset << "]=" << info.stats.object_location_counts[upset]        << dendl;
psdout(20) << __func__ << " object_location_counts "        << info.stats.object_location_counts << dendl;
psdout(20) << __func__ << " ml " << ml.second         << " upset size " << upset.size()         << " up " << ml.first.up << dendl;
psdout(20) << __func__         << " shard " << sml.first         << " ml " << ml.second         << " missing shards " << missing_shards << dendl;
psdout(20) << __func__ << " missing based degraded "   << degraded << dendl;
psdout(20) << __func__ << " missing based misplaced "   << misplaced << dendl;
psdout(20) << __func__ << " missing shard " << std::get<1>(item)   << " missing= " << std::get<0>(item) << dendl;
psdout(20) << __func__ << " acting shard " << std::get<1>(item)   << " missing= " << std::get<0>(item) << dendl;
psdout(20) << __func__ << " extra acting misplaced " << extra_misplaced   << dendl;
psdout(20) << __func__ << " degraded " << degraded        << (estimate ? " (est)": "") << dendl;
psdout(20) << __func__ << " misplaced " << misplaced        << (estimate ? " (est)": "")<< dendl;
psdout(20) << __func__ << " reporting purged_snaps "      << pre_publish.purged_snaps << dendl;
psdout(15) << "publish_stats_to_osd " << pg_stats_publish->reported_epoch        << ": no change since " << info.stats.last_fresh << dendl;
psdout(15) << "publish_stats_to_osd " << pre_publish.reported_epoch        << ":" << pre_publish.reported_seq << dendl;
psdout(10) << "init role " << role << " up "      << newup << " acting " << newacting      << " history " << history      << " past_intervals " << pi      << dendl;
psdout(20) << __func__ << " trim_to bool = " << bool(trim_to)      << " trim_to = " << (trim_to ? *trim_to : eversion_t()) << dendl;
psdout(20) << __func__ << " peer_missing for " << peer        << " = " << pmissing << dendl;
psdout(10) << __func__ << " approx pg log length =  "      << pg_log.get_log().approx_size() << dendl;
psdout(10) << __func__ << " transaction_applied = "      << transaction_applied << dendl;
psdout(10) << __func__ << " " << pg_whoami        << " is async_recovery or backfill target" << dendl;
psdout(10) << "last_complete now " << info.last_complete               << " while log is empty" << dendl;
psdout(10) << "last_complete now " << info.last_complete        << " log.complete_to " << pg_log.get_log().complete_to->version        << dendl;
psdout(10) << "last_complete now " << info.last_complete        << " log.complete_to at end" << dendl;
psdout(25) << __func__ << " primary " << updated_stats.stats.sum.num_bytes        << " local " << info.stats.stats.sum.num_bytes << dendl;
psdout(20) << __func__ << " final " << updated_stats.stats.sum.num_bytes        << " replaces local " << info.stats.stats.sum.num_bytes << dendl;
psdout(30) << __func__ << " missing_loc before: "   << missing_loc.get_locations(entry.soid) << dendl;
psdout(30) << __func__ << " missing_loc after: "   << missing_loc.get_locations(entry.soid) << dendl;
psdout(10) << __func__ << " version " << version      << " now ondisk" << dendl;
psdout(10) << __func__ << " approx pg log length =  "             << pg_log.get_log().approx_size() << dendl;
psdout(10) << "should_restart_peering, transitioning to Reset"         << dendl;
psdout(10) << "should restart peering, calling start_peering_interval again"         << dendl;
psdout(10) << "Active stray osd." << osd << " in want_acting is down"                   << dendl;
psdout(10) << "Active need acting change, call choose_acting again"                << dendl;
psdout(20) << "reporting stats to osd after " << (advmap.osdmap->get_epoch() - ps->info.stats.reported_epoch)         << " epochs" << dendl;
psdout(10) << "Active: got notify from " << notevt.from         << ", already have info from that osd, ignoring"         << dendl;
psdout(10) << "Active: got notify from " << notevt.from         << ", already purged that peer, ignoring"         << dendl;
psdout(10) << "Active: got notify from " << notevt.from         << ", calling proc_replica_info and discover_all_missing"         << dendl;
psdout(10) << "Active: got notify from previous acting member "                 << notevt.from << ", requesting pg_temp change"                 << dendl;
psdout(10) << " peer osd." << infoevt.from        << " activated and committed" << dendl;
psdout(10) << "searching osd." << logevt.from       << " log for unfound items" << dendl;
psdout(10) << "_activate_committed " << evt.epoch      << " peer_activated now " << ps->peer_activated      << " last_interval_started "      << ps->info.history.last_interval_started      << " last_epoch_started "      << ps->info.history.last_epoch_started      << " same_interval_since "      << ps->info.history.same_interval_since      << dendl;
psdout(10) << " waiting for prior_readable_until_ub "        << ps->prior_readable_until_ub << " > mnow " << mnow << dendl;
psdout(10) << " mnow " << mnow << " >= prior_readable_until_ub "        << ps->prior_readable_until_ub << dendl;
psdout(10) << __func__ << " delete priority changed, resetting"     << dendl;
psdout(10) << " no prior_set down osds, clearing prior_readable_until_ub"        << dendl;
psdout(20) << "Adding osd: " << infoevt.from.osd << " peer features: "         << hex << infoevt.features << dec << dendl;
psdout(10) << "GetLog: auth_log_shard osd."         << auth_log_shard.osd << " went down" << dendl;
psdout(10) << "GetLog: discarding log from "         << "non-auth_log_shard osd." << logevt.from << dendl;
psdout(10) << "GetLog: received master log from osd."       << logevt.from << dendl;
psdout(10) << " requesting fulllog+missing from osd." << *i    << " (want since " << since << " < log.tail "    << pi.log_tail << ")" << dendl;
psdout(10) << " still need up_thru update before going active"    << dendl;
psdout(10) << " still need up_thru update before going active"    << dendl;
psdout(10) << "Got last missing, don't need missing "    << "posting Activate" << dendl;
dout(10) << "check_recovery_sources resetting pulls from osd." << i->first        << ", osdmap has it marked down" << dendl;
dout(7) << __func__ << ": tid " << ip_op.tid << " op " //<< *m       << " ack_type " << (int)r->ack_type       << " from " << from       << dendl;
dout(7) << __func__ << ": tid " << ip_op.tid << " (no op) "       << " ack_type " << (int)r->ack_type       << " from " << from       << dendl;
dout(20) << __func__ << "  " << poid << " got "        << r << " on read, read_error" << dendl;
dout(20) << __func__ << "  " << poid << " more data, digest so far 0x"        << std::hex << pos.data_hash.digest() << std::dec << dendl;
dout(20) << __func__ << "  " << poid << " done with data, digest 0x"      << std::hex << o.digest << std::dec << dendl;
dout(20) << __func__ << "  " << poid << " got "        << r << " on omap header read, read_error" << dendl;
dout(25) << __func__ << "  " << poid        << " on omap scan, db status error" << dendl;
dout(25) << __func__ << " " << poid      << " large omap object detected. Object has " << pos.omap_keys      << " keys and size " << pos.omap_bytes << " bytes" << dendl;
dout(20) << __func__ << " done with " << poid << " omap_digest "    << std::hex << o.omap_digest << std::dec << dendl;
dout(25) << __func__ << " adding " << pos.omap_keys << " keys and "             << pos.omap_bytes << " bytes to pg_stats sums" << dendl;
dout(10) << __func__ << " " << soid           << " v " << m->version    << (m->logbl.length() ? " (transaction)" : " (parallel exec")    << " " << m->logbl.length()    << dendl;
dout(10) << __func__ << ": removing object " << m->discard_temp_oid        << " since we won't get the transaction" << dendl;
dout(10) << __func__ << " on op " << *m    << ", sending commit to osd." << rm->ackerosd    << dendl;
dout(10) << "calc_head_subsets " << head    << " clone_overlap " << snapset.clone_overlap << dendl;
dout(10) << "calc_head_subsets " << head    << " data_subset " << data_subset << dendl;
dout(10) << "calc_head_subsets " << head << " has prev " << c        << " overlap " << prev << dendl;
dout(10) << "calc_head_subsets " << head << " does not have prev " << c      << " overlap " << prev << dendl;
dout(10) << "calc_head_subsets " << head    << "  data_subset " << data_subset    << "  clone_subsets " << clone_subsets << dendl;
dout(10) << "calc_clone_subsets " << soid    << " clone_overlap " << snapset.clone_overlap << dendl;
dout(10) << "calc_clone_subsets " << soid << " has prev " << c        << " overlap " << prev << dendl;
dout(10) << "calc_clone_subsets " << soid << " does not have prev " << c      << " overlap " << prev << dendl;
dout(10) << "calc_clone_subsets " << soid << " has next " << c        << " overlap " << next << dendl;
dout(10) << "calc_clone_subsets " << soid << " does not have next " << c      << " overlap " << next << dendl;
dout(10) << "calc_clone_subsets " << soid    << "  data_subset " << data_subset    << "  clone_subsets " << clone_subsets << dendl;
dout(7) << "pull " << soid   << " v " << v   << " on osds " << q->second   << " from osd." << fromshard   << dendl;
dout(10) << "pulling soid " << soid << " from osd " << fromshard      << " at version " << pmissing.get_items().find(soid)->second.have      << " rather than at version " << v << dendl;
dout(10) << __func__ << ": " << soid << " v" << oi.version    << " size " << size << " to osd." << peer << dendl;
dout(10) << __func__ << ": Adding oid "        << target_oid << " in the temp collection" << dendl;
dout(10) << __func__ << " " << recovery_info.soid               << " backfill size " << recovery_info.oi.size               << " previous size " << size               << " net size " << recovery_info.oi.size - size               << dendl;
dout(15) << " clone_range " << recovery_info.soid << " "                  << q.get_start() << "~" << q.get_len() << dendl;
dout(20) << __func__ <<" recovering object " << recovery_info.soid             << " copy_subset: " << recovery_info.copy_subset             << " intervals_included: " << intervals_included             << " data_zeros: " << data_zeros << dendl;
dout(10) << __func__ << ": Removing oid "               << target_oid << " from the temp collection" << dendl;
dout(15) << " clone_range " << p->first << " "        << q.get_start() << "~" << q.get_len() << dendl;
dout(10) << "handle_pull_response "    << pop.recovery_info    << pop.after_progress    << " data.size() is " << data.length()    << " data_included: " << data_included    << dendl;
dout(10) << "new recovery_info " << pi.recovery_info           << ", new progress " << pi.recovery_progress           << dendl;
dout(10) << "handle_push "    << pop.recovery_info    << pop.after_progress    << dendl;
dout(20) << __func__ << ": sending push " << *j   << " to osd." << i->first << dendl;
dout(20) << __func__ << ": sending pulls " << i->second      << " to osd." << i->first << dendl;
dout(7) << __func__ << " " << recovery_info.soid   << " v " << recovery_info.version   << " size " << recovery_info.size   << " recovery_info: " << recovery_info          << dendl;
dout(10) << __func__ << " some extents get pruned "             << out_op->data_included.size() << "/" << origin_size             << dendl;
dout(0) << __func__ << " " << coll << std::hex                         << " full-object read crc 0x" << crc                         << " != expected 0x" << oi.data_digest                         << std::dec << " on " << recovery_info.soid << dendl;
dout(10) << "huh, i wasn't pushing " << soid << " to osd." << peer      << ", or anybody else"      << dendl;
dout(10) << "huh, i wasn't pushing " << soid << " to osd." << peer      << dendl;
dout(10) << " pushing more from, "        << pi->recovery_progress.data_recovered_to        << " of " << pi->recovery_info.copy_subset << dendl;
dout(10) << "pushed " << soid << ", still waiting for push ack from "   << pushing[soid].size() << " others" << dendl;
ldpp_dout(dpp, 20) << __func__ << ": " << oid       << " new_size "       << offset + bl.length()       << dendl;
ldpp_dout(dpp, 20) << "generate_transactions: "    << opair.first    << ", current size is "    << hinfo->get_total_logical_size(sinfo)    << " buffers are "    << op.buffer_updates    << dendl;
ldpp_dout(dpp, 20) << "generate_transactions: "      << " truncate is "      << *(op.truncate)      << dendl;
ldpp_dout(dpp, 20) << __func__ << ": new_size truncate down "      << new_size << dendl;
ldpp_dout(dpp, 20) << __func__ << ": saving extent "        << make_pair(restore_from, restore_len)        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": truncating to "        << new_size        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": not saving extents, fresh object"        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": adding buffer_update "      << make_pair(off, len)      << dendl;
ldpp_dout(dpp, 20) << __func__ << ": prepending zeroes to align "        << off << "->" << new_size        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": appending zeroes to align end "        << end << "->" << end+tail        << ", len: " << len << "->" << len+tail        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": truncating out to "      << truncate_to      << dendl;
ldpp_dout(dpp, 20) << __func__ << ": to_overwrite: "    << to_overwrite    << dendl;
ldpp_dout(dpp, 20) << __func__ << ": overwriting "        << restore_from << "~" << restore_len        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": to_append: "    << to_append    << dendl;
ldpp_dout(dpp, 20) << __func__ << ": appending "      << extent.get_off() << "~" << extent.get_len()      << dendl;
ldpp_dout(dpp, 20) << __func__ << ": " << oid    << " resetting hinfo to logical size "    << new_size    << dendl;
ldpp_dout(dpp, 20) << __func__ << ": " << oid        << " marking rollback extents "        << rollback_extents        << dendl;
ldpp_dout(dpp, 20) << __func__ << ": marking append "      << append_after      << dendl;
ldout(cct, 0) << __func__ << " could not stat class " << fname        << ": " << cpp_strerror(r) << dendl;
ldout(cct, 0) << "_load_class could not open class " << fname        << " (dlopen failed): " << dlerror() << dendl;
dout(20) << __func__ << " " << pgid << " " << id << " [" << begin << ","      << end << ") pg not found" << dendl;
dout(20) << __func__ << " " << pgid << " " << id << " [" << begin << ","      << end << ") begin not found" << dendl;
dout(10) << __func__ << " session " << this << " has backoff " << *b      << " for " << *m << dendl;
dout(10) << __func__ << " aborting. incoming epoch: " << epoch_to_verify    << " vs last-aborted: " << m_last_aborted << dendl;
dout(10) << __func__ << " planned: must? " << request_flags.must_scrub << " need-auto? "    << request_flags.need_auto << " stamp: " << m_pg->info.history.last_scrub_stamp    << dendl;
dout(15) << __func__ << " pg(" << m_pg_id << ") must: " << must    << " required:" << m_flags.required << " flags: " << request_flags    << " stamp: " << reg_stamp << dendl;
dout(15) << __func__ << " pg(" << m_pg_id << ") register next scrub, scrub time "    << m_scrub_reg_stamp << ", must = " << (int)must << dendl;
dout(10) << __func__ << " existing-" << m_scrub_reg_stamp << ". was registered? "    << is_scrub_registered() << dendl;
dout(10) << __func__ << (scrub_level == scrub_level_t::deep ? " deep " : " shallow ")    << (scrub_type == scrub_type_t::do_repair ? " repair-scrub " : " not-repair ")    << " prev stamp: " << m_scrub_reg_stamp << " " << is_scrub_registered()    << dendl;
dout(10) << __func__ << " existing-" << m_scrub_reg_stamp << ". was registered? "    << is_scrub_registered() << dendl;
dout(10) << __func__ << " recovery last: " << last_applied    << " vs. scrub's: " << m_subset_last_update << dendl;
dout(10) << __func__ << " Min: " << min_idx << " Max: " << max_idx    << " Div: " << preemption_data.chunk_divisor() << dendl;
dout(10) << __func__ << ": scrub blocked somewhere in range "      << "[" << m_start << ", " << candidate_end << ")" << dendl;
dout(15) << __func__ << " range selected: " << m_start << " //// " << m_end << " //// "    << m_max_end << dendl;
dout(20) << __func__ << " " << soid << " can preempt? "    << preemption_data.is_preemptable() << " already preempted? "    << preemption_data.was_preempted() << dendl;
dout(15) << __func__ << " sleep: " << sleep_time.count() << "ms. needed? "    << m_needs_sleep << dendl;
lgeneric_subdout(g_ceph_context, osd, 10)   << "scrub_requeue_callback: Could not find "   << "PG " << pgid << " can't complete scrub requeue after sleep" << dendl;
lgeneric_dout(scrbr->get_pg_cct(), 7) << "scrub_requeue_callback: slept for " << ceph_clock_now() - scrbr->m_sleep_started_at << ", re-queuing scrub" << dendl;
dout(10) << __func__ << " started in epoch/interval: " << m_epoch_start << "/"    << m_interval_start    << " pg same_interval_since: " << m_pg->info.history.same_interval_since    << dendl;
dout(10) << __func__ << " epoch_start: " << m_interval_start    << " from pg: " << m_pg->get_history().same_interval_since << dendl;
dout(10) << __func__ << " scrubmap from osd." << replica    << (deep ? " deep" : " shallow") << dendl;
dout(10) << __func__ << " interval start: " << m_interval_start    << " epoch: " << m_epoch_start << " deep: " << m_is_deep << dendl;
dout(10) << __func__ << " [" << start << "," << end << ") "    << " pos " << pos << " Deep: " << deep << dendl;
dout(10) << __func__ << " pg:" << m_pg->pg_id << " Msg: map_epoch:" << msg->map_epoch    << " min_epoch:" << msg->min_epoch << " deep?" << msg->deep << dendl;
dout(10) << "replica_scrub_op discarding old replica_scrub from " << msg->map_epoch      << " < " << m_pg->info.history.same_interval_since << dendl;
dout(2) << __func__ << " replica " << i << " has "     << m_received_maps[i].objects.size() << " items" << dendl;
dout(2) << __func__ << m_pg->get_primary() << " has "     << m_primary_scrubmap.objects.size() << " items" << dendl;
dout(10) << __func__ << " discarding old from " << m->map_epoch << " < "      << m_pg->info.history.same_interval_since << dendl;
dout(10) << "scrub requesting " << op_text << " from osd." << p << " Epoch: " << epch      << dendl;
dout(20) << __func__ << " deep_scrub: " << deep_scrub << " m_is_deep: " << m_is_deep    << " repair: " << repair << dendl;
dout(10) << __func__ << " before flags: " << m_flags    << " deep_scrub_on_error: " << m_flags.deep_scrub_on_error << dendl;
dout(20) << __func__ << " Current 'required': " << m_flags.required        << " Planned 'req_scrub': " << m_pg->m_planned_scrub.req_scrub << dendl;
dout(10) << __func__ << " " << (m_shallow_errors + m_deep_errors)        << " error(s) present with no repair possible" << dendl;
dout(25) << "scrub_finish shard " << m_pg_whoami     << " num_omap_bytes = " << stats.stats.sum.num_omap_bytes     << " num_omap_keys = " << stats.stats.sum.num_omap_keys << dendl;
dout(10) << "scrub_finish " << m_pg->info.stats.stats.sum.num_scrub_errors       << " error(s) still present after re-scrub" << dendl;
dout(10) << __func__ << " #pending: " << num_digest_updates_pending << " pending? "    << num_digest_updates_pending    << (m_end.is_max() ? " <last chunk> " : " <mid chunk> ") << dendl;
: m_pg{pg} // holding the "whole PG" for dout() sake    , m_osds{osds}{  if (!m_osds->inc_scrubs_local()) {    // the failure is signalled by not having m_holding_local_reservation set    return;
dout(10) << __func__ << ": Read error " << hoid << " r="    << res.r << " errors=" << res.errors << dendl;
dout(10) << __func__ << ": canceling recovery op for obj " << hoid    << dendl;
dout(10) << __func__ << ": Adding oid "        << tobj.hobj << " in the temp collection" << dendl;
dout(10) << __func__ << " " << op.soid             << " add new actual data by " << op.data.length()             << " add new num_bytes by " << op.data.length() * get_ec_data_chunk_count()             << dendl;
dout(10) << __func__ << ": Removing oid "      << tobj.hobj << " from the temp collection" << dendl;
dout(10) << __func__ << " " << op.soid                  << " sub actual data by " << st.st_size                  << " sub num_bytes by " << st.st_size * get_ec_data_chunk_count()                  << dendl;
dout(10) << __func__ << ": returned " << hoid << " "    << "(" << to_read.get<0>()    << ", " << to_read.get<1>()    << ", " << to_read.get<2>()    << ")"    << dendl;
dout(10) << __func__ << ": canceling recovery op for obj " << op.hoid   << dendl;
dout(10) << __func__ << ": before_progress=" << op.recovery_progress   << ", after_progress=" << after_progress   << ", pop.data.length()=" << pop.data.length()   << ", size=" << op.obc->obs.oi.size << dendl;
dout(10) << __func__ << ": on_peer_recover on " << *i         << ", obj " << op.hoid << dendl;
dout(10) << __func__ << ": removing object " << *i        << " since we won't get the transaction" << dendl;
dout(5) << __func__ << ": Error " << r    << " reading " << i->first << ", fast read, probably ok"    << dendl;
dout(5) << __func__ << ": Error " << r    << " reading " << i->first << dendl;
dout(5) << __func__ << ": Bad hash for " << i->first << " digest 0x"      << hex << h.digest() << " expected 0x" << hinfo->get_chunk_hash(shard) << dec << dendl;
dout(10) << __func__ << ": fulfilling attr request on "      << *i << dendl;
dout(10) << __func__ << " Error(s) ignored for " << iter->first       << " enough copies available" << dendl;
dout(10) << __func__ << ": canceling " << req      << "  for obj " << *i << dendl;
dout(0) << __func__ << " not enough shards left to try for " << hoid     << " read result was " << result << dendl;
dout(0) << __func__ << ": Mismatch of total_chunk_size "          << hinfo.get_total_chunk_size() << dendl;
dout(20) << __func__ << ": blocking " << *op      << " because it requires an rmw and the cache is invalid "      << pipeline_state      << dendl;
dout(20) << __func__ << ": invalidating cache after this op"      << dendl;
dout(20) << __func__ << ": clearing pipeline_state "      << pipeline_state      << dendl;
ldpp_dout(dpp, 20) << "objects_read_async_cb: got: " << results    << dendl;
ldpp_dout(dpp, 20) << "objects_read_async_cb: cache: " << ec->cache    << dendl;
dout(20) << __func__ << "  " << poid << " got "      << r << " on read, read_error" << dendl;
dout(20) << __func__ << "  " << poid << " got "      << r << " on read, not chunk size " << sinfo.get_chunk_size() << " aligned"      << dendl;
dout(0) << "_scan_list  " << poid << " got incorrect size on read 0x"  << std::hex << pos  << " expected 0x" << hinfo->get_total_chunk_size() << std::dec  << dendl;
dout(0) << "_scan_list  " << poid << " got incorrect hash on read 0x"  << std::hex << pos.data_hash.digest() << " !=  expected 0x"  << hinfo->get_chunk_hash(get_parent()->whoami_shard().shard)  << std::dec << dendl;
dout(10) << " got old revert version " << recovery_info.version        << " for " << *latest << dendl;
dout(10) << __func__ << " issue_repop shipping empty opt to osd." << peer             << ", object " << hoid             << " beyond std::max(last_backfill_started "             << ", peer_info[peer].last_backfill "             << recovery_state.get_peer_info(peer).last_backfill      << ")" << dendl;
dout(10) << __func__ << " issue_repop shipping empty opt to osd." << peer             << ", object " << hoid             << " which is pending recovery in async_recovery_targets" << dendl;
dout(20) << __func__ << ": blocking object " << oid    << " on full cache" << dendl;
dout(20) << __func__ << ": blocking object " << oid    << " on primary repair" << dendl;
dout(20) << __func__ << ": blocking object " << oid.get_head()    << " on snap promotion " << obc->obs.oi.soid << dendl;
dout(20) << __func__ << ": blocking object " << snap.get_head()    << " on degraded snap " << snap << dendl;
dout(20) << __func__ << " peer " << peer << " min_version " << min_obj->first               << " oid " << min_obj->second << dendl;
dout(10) << __func__      << " mnow " << mnow      << " > readable_until " << ru << dendl;
dout(10) << __func__ << " still wait (mnow " << mnow        << " < prior_readable_until_ub " << prior_readable_until_ub        << ")" << dendl;
dout(10) << __func__ << " no longer wait (mnow " << mnow        << " >= prior_readable_until_ub " << prior_readable_until_ub        << ")" << dendl;
dout(10) << __func__ << " still laggy (mnow " << mnow        << ", readable_until zero)" << dendl;
dout(10) << __func__ << " still laggy (mnow " << mnow        << " >= readable_until " << ru << ")" << dendl;
dout(10) << __func__ << " no longer laggy (mnow " << mnow        << " < readable_until " << ru << ")" << dendl;
dout(10) << " pgnls pg=" << m->get_pg()   << " " << get_osdmap()->raw_pg_to_pg(m->get_pg())   << " != " << info.pgid << dendl;
dout(10) << " pgnls pg=" << m->get_pg() << " count " << list_size   << dendl;
dout(10) << " pgnls lower_bound " << lower_bound   << " pg_end " << pg_end << dendl;
dout(10) << "outside of PG bounds " << pg_start << " .. "     << pg_end << dendl;
dout(10) << " pgnls candidate 0x" << std::hex << candidate.get_hash()     << " vs lower bound 0x" << lower_bound.get_hash()     << std::dec << dendl;
dout(20) << "pgnls item 0x" << std::hex            << candidate.get_hash()            << ", rev 0x" << hobject_t::_reverse_bits(candidate.get_hash())            << std::dec << " "            << candidate.oid.name << dendl;
dout(10) << " pgnls result=" << result << " outdata.length()="   << osd_op.outdata.length() << dendl;
dout(10) << " pgls pg=" << m->get_pg()   << " " << get_osdmap()->raw_pg_to_pg(m->get_pg())   << " != " << info.pgid << dendl;
dout(10) << " pgls result=" << result << " outdata.length()="   << osd_op.outdata.length() << dendl;
dout(10) << __func__ << " backoff ack id " << m->id    << " [" << begin << "," << end << ")" << dendl;
dout(20) << __func__ << " waiting_for_map "      << p->first << " not empty, queueing" << dendl;
dout(20) << __func__ << " min " << op->min_epoch      << ", queue on waiting_for_map " << op->get_source() << dendl;
dout(4) << "do_op name is longer than "     << cct->_conf->osd_max_object_name_len     << " bytes" << dendl;
dout(4) << "do_op locator is longer than "     << cct->_conf->osd_max_object_name_len     << " bytes" << dendl;
dout(4) << "do_op namespace is longer than "     << cct->_conf->osd_max_object_namespace_len     << " bytes" << dendl;
dout(4) << "do_op object " << head << " invalid for backing store: "     << r << dendl;
dout(10) << __func__ << " discarding op sent before full " << m << " "      << *m << dendl;
dout(10) << "do_op " << *m    << (op->may_write() ? " may_write" : "")    << (op->may_read() ? " may_read" : "")    << (op->may_cache() ? " may_cache" : "")    << " -> " << (write_ordered ? "write-ordered" : "read-ordered")    << " flags " << ceph_osd_flag_string(m->get_flags())    << dendl;
dout(3) << __func__ << " dup " << m->get_reqid()       << " version " << version << dendl;
dout(20) << __func__               << ": unstable write on replica, bouncing to primary "        << *m << dendl;
dout(20) << __func__ << ": serving replica read on oid " << oid             << dendl;
dout(10) << __func__ << ": clone " << obc->obs.oi.soid        << " is unreadable, waiting" << dendl;
dout(10) << __func__ << ": clone " << obc->obs.oi.soid        << " is degraded, waiting" << dendl;
dout(10) << " provided locator " << m->get_object_locator()      << " != object's " << obc->obs.oi.soid << dendl;
dout(20) << __func__ << ": object " << obc->obs.oi.soid      << " is lost" << dendl;
dout(25) << __func__ << " " << obc->obs.oi << " "      << (obc->obs.exists ? "exists" : "DNE")      << " missing_oid " << missing_oid      << " must_promote " << (int)must_promote      << " in_hit_set " << (int)in_hit_set      << dendl;
dout(25) << __func__ << " (no obc)"      << " missing_oid " << missing_oid      << " must_promote " << (int)must_promote      << " in_hit_set " << (int)in_hit_set      << dendl;
dout(20) << __func__ << " missing_oid " << missing_oid    << "  in_hit_set " << in_hit_set << dendl;
dout(10) << "sending redirect to pool " << pool.info.tier_of << " for op "    << op << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(10) << __func__ << " tid " << tid << " != prdop " << prdop      << " tid " << prdop->objecter_tid << dendl;
dout(10) << __func__ << " oid " << oid << " != prdop " << prdop      << " soid " << prdop->soid << dendl;
dout(10) << __func__ << " " << p->first << " requeuing " << ls.size()        << " requests" << dendl;
dout(20) << __func__ << " chunk_index: " << chunks->first       << " next_length: " << chunks->second << " cursor: "       << p.first << dendl;
dout(10) << __func__ << ": clone " << cid        << " is unreadable, waiting" << dendl;
dout(10) << __func__ << " Start refcount from " << src_soid           << " to " << tgt_soid << dendl;
dout(10) << __func__ << " Start do chunk proxy read for " << *m    << " index: " << op_index << " oid: " << soid.oid.name << " req_offset: " << req_offset    << " req_length: " << req_length << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(20) << __func__ << " " << oid << " tid " << tid            << " in_progress_op size: "            << in_progress_op.size() << dendl;
dout(10) << __func__ << " " << hoid      << " blocked by scrub" << dendl;
dout(10) << __func__ << " " << hoid        << " placing op in waiting_for_scrub" << dendl;
dout(10) << __func__ << " " << hoid        << " no op, dropping on the floor" << dendl;
dout(10) << " ORDERSNAP flag set and snapc seq " << ctx->snapc.seq        << " < snapset seq " << obc->ssc->snapset.seq        << " on " << obc->obs.oi.soid << dendl;
dout(10) << __func__ << " " << soid << " " << *ctx->ops      << " ov " << obc->obs.oi.version << " av " << ctx->at_version      << " snapc " << ctx->snapc      << " snapset " << obc->ssc->snapset      << dendl;
dout(10) << __func__ << " " << soid << " " << *ctx->ops      << " ov " << obc->obs.oi.version      << dendl;
dout(20) << __func__ << " alloc reply " << ctx->reply    << " result " << result << dendl;
dout(15) << "log_op_stats " << *m    << " inb " << inb    << " outb " << outb    << " lat " << latency << dendl;
dout(10) << __func__ << " bi.begin=" << bi.begin << " bi.end=" << bi.end               << " bi.objects.size()=" << bi.objects.size() << dendl;
dout(0) << __func__ << " " << ghobject_t(p.first, ghobject_t::NO_GEN, pg_whoami.shard)                    << " can't get object info" << dendl;
dout(10) << __func__ << " " << ghobject_t(p.first, ghobject_t::NO_GEN, pg_whoami.shard)                 << " sub actual data by " << st.st_size                 << " sub num_bytes by " << usersize                 << dendl;
dout(10) << coid << " old_snaps " << old_snaps    << " old snapset " << snapset << dendl;
dout(10) << coid << " snaps " << old_snaps << " -> "      << new_snaps << " ... deleting" << dendl;
dout(10) << coid << " new snapset " << snapset << " on "    << head_obc->obs.oi << dendl;
dout(10) << coid << " writing updated snapset on " << head_oid      << ", snapset is " << snapset << dendl;
dout(5) << "tmapup warning: key '" << key << "' < previous key '" << last_in_key  << "', falling back to an inefficient (unsorted) update" << dendl;
dout(20) << "  keep trailing " << rest.length()        << " at " << newkeydata.length() << dendl;
ldpp_dout(dpp, 10) << __func__ << " "      << "osd_max_object_size: " << max      << ";
Hard limit of object size is 4GB." << dendl;
dout(10) << __func__ << ": length required when chunk size provided"        << dendl;
dout(10) << __func__ << ": length (trimmed to 0x"               << std::hex << op.checksum.length               << ") not aligned to chunk size 0x"               << op.checksum.chunk_size << std::dec               << dendl;
dout(10) << __func__ << ": unknown crc type ("      << static_cast<uint32_t>(op.checksum.type) << ")" << dendl;
dout(10) << " read got " << r << " / " << op.extent.length      << " bytes from obj " << soid << dendl;
dout(10) << " sparse_read got " << r << " bytes from object "      << soid << dendl;
dout(10) << " munging ZERO " << op.extent.offset << "~" << op.extent.length        << " -> TRUNCATE " << op.extent.offset << " (old size is " << oi.size << ")" << dendl;
dout(10) << "CEPH_OSD_OP_CMPXATTR name=" << name << " val=" << val       << " op=" << (int)op.xattr.cmp_op << " mode=" << (int)op.xattr.cmp_mode << dendl;
dout(10) << "CEPH_OSD_OP_CMPXATTR name=" << name << " val=" << u64val       << " op=" << (int)op.xattr.cmp_op << " mode=" << (int)op.xattr.cmp_mode << dendl;
dout(20) << "key cookie=" << oi_iter->first.first               << " entity=" << oi_iter->first.second << " "               << oi_iter->second << dendl;
dout(10) << " old truncate_seq " << op.extent.truncate_seq << " < current " << seq     << ", adjusting write length to " << op.extent.length << dendl;
dout(10) << " truncate_seq " << op.extent.truncate_seq << " > current " << seq       << ", truncating to " << op.extent.truncate_size << dendl;
dout(10) << " truncate_seq " << op.extent.truncate_seq << " > current " << seq       << ", but object is new" << dendl;
dout(10) << " truncate seq " << op.extent.truncate_seq << " <= current " << oi.truncate_seq       << ", no-op" << dendl;
dout(10) << " truncate seq " << op.extent.truncate_seq << " > current " << oi.truncate_seq     << ", truncating" << dendl;
dout(10) << "watch " << ceph_osd_watch_op_name(op.watch.op)   << ": ctx->obc=" << (void *)obc.get() << " cookie=" << cookie   << " oi.version=" << oi.version.version << " ctx->at_version=" << ctx->at_version << dendl;
dout(10) << "watch: peer_addr="   << ctx->op->get_req()->get_connection()->get_peer_addr() << dendl;
dout(10) << " removed watch " << oi_iter->second << " by "       << entity << dendl;
dout(20) << __func__ << " overlapped !! offset: " << src_offset << " length: " << src_length      << " chunk_info: " << p << dendl;
dout(10) << "set-chunked oid:" << oi.soid << " user_version: " << oi.user_version   << " chunk_info: " << chunk_info << dendl;
dout(20) << "invalid copy-from2 flags 0x"    << std::hex << (int)op.copy_from.flags << std::dec << dendl;
dout(1) << "unrecognized osd op " << op.op       << " " << ceph_osd_op_name(op.op)       << dendl;
dout(20) << "unsuccessful at decoding tmap for " << ctx->new_obs.oi.soid      << dendl;
dout(20) << "successful at decoding tmap for " << ctx->new_obs.oi.soid    << dendl;
dout(20) << __func__ << " verifying clones are absent "    << ss << dendl;
dout(10) << __func__ << " cannot evict head before clone "        << clone_oid << dendl;
dout(10) << __func__ << " cannot evict head, pending promote on clone "        << clone_oid << dendl;
dout(20) << __func__ << " has or will have clones but no_whiteout=1"        << dendl;
dout(20) << __func__ << " " << soid << " whiteout=" << (int)whiteout    << " no_whiteout=" << (int)no_whiteout    << " try_no_whiteout=" << (int)try_no_whiteout    << dendl;
dout(20) << "_rollback_to attempted to roll back to a missing or backfilling clone "      << missing_oid << " (requested snapid: ) " << snapid << dendl;
dout(20) << "_rollback_to deleting head on " << soid.oid      << " because got ENOENT|whiteout on find_object_context" << dendl;
dout(20) << "_rollback_to attempted to roll back to a degraded object "        << rollback_to_sobject << " (requested snapid: ) " << snapid << dendl;
dout(10) << "_rollback_to deleting " << soid.oid        << " and rolling back to old snap" << dendl;
dout(20) << "make_writeable " << soid << " snapset=" << ctx->new_snapset    << "  snapc=" << snapc << dendl;
dout(10) << " cloning v " << ctx->obs->oi.version      << " to " << coid << " v " << ctx->at_version      << " snaps=" << snaps      << " snapset=" << ctx->new_snapset << dendl;
dout(20) << "make_writeable " << soid    << " done, snapset=" << ctx->new_snapset << dendl;
dout(10) << "do_osd_op_effects disconnect failed to find watcher "        << watcher << dendl;
dout(15) << "do_osd_op_effects applying watch connect on session "      << session.get() << " watcher " << watcher << dendl;
dout(15) << "do_osd_op_effects found existing watch watcher " << watcher        << dendl;
dout(15) << "do_osd_op_effects new watcher " << watcher        << dendl;
dout(20) << __func__ << " full, but proceeding due to FULL_FORCE or MDS"        << dendl;
dout(20) << __func__ << " " << soid << " " << ctx    << " op " << pg_log_entry_t::get_op_name(log_op_type)    << dendl;
dout(10) << " final snapset " << ctx->new_snapset        << " in " << soid << dendl;
dout(20) << __func__ << " op_returns " << ctx->log.back().op_returns      << dendl;
dout(20) << __func__ << " encoding snaps from " << ctx->new_snapset        << dendl;
dout(20) << __func__ << "  extra_reqids " << ctx->extra_reqids << " "             << ctx->extra_reqid_return_codes << dendl;
dout(20) << " cursor.is_complete=" << cursor.is_complete()    << " " << out_attrs.size() << " attrs"    << " " << bl.length() << " bytes"    << " " << reply_obj.omap_header.length() << " omap header bytes"    << " " << reply_obj.omap_data.length() << " omap data bytes in "    << omap_keys << " keys"    << " " << reply_obj.reqids.size() << " reqids"    << dendl;
dout(10) << __func__ << " " << dest    << " from " << src << " " << oloc << " v" << version    << " flags " << flags    << (mirror_snapset ? " mirror_snapset" : "")    << dendl;
dout(20) << __func__ << " oid " << obc->obs.oi.soid << " num_chunks: " << num_chunks   << " start_offset: " << start_offset << " chunks_size: " << chunks_size   << " last_offset: " << last_offset << dendl;
dout(20) << __func__ << " tgt_oid: " << soid.oid << " tgt_offset: "     << manifest->chunk_map[iter->first].offset     << " length: " << length << " pool id: " << oloc.pool     << " tid: " << tid << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(10) << __func__ << " tid " << tid << " != cop " << cop      << " tid " << cop->objecter_tid << dendl;
dout(10) << __func__ << " clone snap " << *p << " has been deleted"   << dendl;
dout(20) << __func__ << std::hex      << " got digest: rx data 0x" << cop->results.data_digest      << " omap 0x" << cop->results.omap_digest      << ", source: data 0x" << cop->results.source_data_digest      << " omap 0x" <<  cop->results.source_omap_digest      << std::dec      << " flags " << cop->results.flags      << dendl;
dout(20) << "fill_in_final_tx: writing "   << "directly to final object" << dendl;
dout(10) << __func__ << " deleting partial temp object "      << cop->results.temp_oid << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(10) << __func__ << " tid " << tid << " != cop " << chunk_cop      << " tid " << chunk_cop->objecter_tid << dendl;
dout(20) << __func__ << " offset: " << p.second->cursor.data_offset       << " length: " << sub_chunk.outdata.length() << dendl;
dout(20) << __func__ << " " << cop    << " " << cop->attrs.size() << " attrs"    << " " << cop->data.length() << " bytes"    << " " << cop->omap_header.length() << " omap header bytes"    << " " << cop->omap_data.length() << " omap data bytes"    << dendl;
dout(10) << __func__ << " " << soid << " r=" << r    << " uv" << results->user_version << dendl;
dout(20) << __func__        << " snaps are empty, clone is invalid,"        << " setting r to ENOENT" << dendl;
dout(10) << __func__      << ": enoent while trying to promote clone, " << soid      << " must have been trimmed, removing from snapset"      << dendl;
dout(10) << __func__ << " " << soid << " r=" << r    << " uv" << results->user_version << dendl;
dout(10) << __func__ << " " << cop->obc->obs.oi.soid    << " from " << cop->src << " " << cop->oloc    << " v" << cop->results.user_version << dendl;
dout(10) << __func__ << " oid: " << soid << " tid: " << tid     << " target: " << target << " offset: " << p.first     << " length: " << p.second.length() << dendl;
dout(0) << __func__ << " read fail " << oi.soid            << " len: " << oi.size << " r: " << r << dendl;
dout(0) << __func__ << " bl.length: " << bl.length() << " != oi.size: "     << oi.size << " during chunking " << dendl;
dout(10) << __func__ << " oid: " << oi.soid << " len: " << bl.length()     << " oi.size: " << oi.size       << " chunk_size: " << chunk_size << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(10) << __func__ << " " << soid    << " v" << oi.version    << " uv" << oi.user_version    << " " << (blocking ? "blocking" : "non-blocking/best-effort")    << dendl;
dout(20) << __func__ << " next oldest clone is " << older_obc->obs.oi   << dendl;
dout(10) << __func__ << " next oldest clone is dirty: "     << older_obc->obs.oi << dendl;
dout(20) << __func__ << " next oldest clone " << next   << " is not present;
implicitly clean" << dendl;
dout(10) << __func__ << " " << oid << " tid " << tid    << " " << cpp_strerror(r) << dendl;
dout(10) << __func__ << " tid " << tid << " != fop " << fop      << " tid " << fop->objecter_tid << dendl;
dout(10) << __func__ << " flushed_version " << fop->flushed_version        << " != current " << obc->obs.oi.user_version        << dendl;
dout(10) << __func__ << " waiting on write lock " << fop->op << " "      << fop->dup_ops << dendl;
dout(20) << __func__ << " offset: " << p.second.offset  << " length: " << p.second.length << dendl;
dout(10) << __func__ << " " << fop->obc->obs.oi.soid << " tid "    << fop->objecter_tid << dendl;
dout(10) << __func__ << ": repop tid " << repop->rep_tid << " all committed "    << dendl;
dout(10) << "eval_repop " << *repop    << (repop->op && repop->op->get_req<MOSDOp>() ? "" : " (no op)") << dendl;
dout(7) << "issue_repop rep_tid " << repop->rep_tid          << " o " << soid          << dendl;
dout(30) << "watch: Found oid=" << owi.obj << " addr=" << owi.wi.addr      << " name=" << owi.wi.name << " cookie=" << owi.wi.cookie << dendl;
dout(10) << "handle_watch_timeout waiting for degraded on obj "      << obc->obs.oi.soid      << dendl;
dout(10) << "handle_watch_timeout waiting for scrub on obj "      << obc->obs.oi.soid      << dendl;
dout(10) << __func__ << ": found obc in cache: " << obc      << dendl;
dout(10) << __func__ << ": no obc for soid "     << soid << " and !can_create"     << dendl;
dout(10) << __func__ << ": no obc for soid "   << soid << " but can_create"   << dendl;
dout(10) << __func__ << ": " << obc << " " << soid   << " " << obc->rwstate   << " oi: " << obc->obs.oi   << " ssc: " << obc->ssc   << " snapset: " << obc->ssc->snapset << dendl;
dout(10) << __func__ << ": creating obc from disk: " << obc      << dendl;
dout(10) << __func__ << ": " << obc << " " << soid    << " " << obc->rwstate    << " oi: " << obc->obs.oi    << " exists: " << (int)obc->obs.exists    << " ssc: " << obc->ssc    << " snapset: " << obc->ssc->snapset << dendl;
dout(10) << __func__ << " " << oid       << " @" << oid.snap       << " oi=" << obc->obs.oi       << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap      << " snapset " << ssc->snapset      << " map_snapid_to_clone=true" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap        << " snapset " << ssc->snapset        << " maps to head" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap   << " snapset " << ssc->snapset   << " maps to nothing" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap        << " snapset " << ssc->snapset        << " maps to " << oid << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap   << " snapset " << ssc->snapset   << " " << oid << " is missing" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap   << " snapset " << ssc->snapset   << " " << oid << " is not present" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap        << " snapset " << ssc->snapset        << " " << oid << " HIT" << dendl;
dout(10) << __func__ << " " << oid << " @" << oid.snap    << " snapset " << ssc->snapset << dendl;
dout(10) << __func__ << " " << head      << " want " << oid.snap << " > snapset seq " << ssc->snapset.seq      << " -- HIT " << obc->obs      << dendl;
dout(10) << __func__ << " no clones with last >= oid.snap "      << oid.snap << " -- DNE" << dendl;
dout(20) << __func__ << " " << soid << " missing, try again later"      << dendl;
dout(20) << __func__ << " " << soid    << " snapset " << obc->ssc->snapset    << dendl;
dout(20) << __func__ << " " << soid << " clone_snaps " << p->second      << " does not contain " << oid.snap << " -- DNE" << dendl;
dout(20) << __func__ << " " << soid << " snap " << oid.snap      << " in removed_snaps_queue" << " -- DNE" << dendl;
dout(20) << __func__ << " " << soid << " clone_snaps " << p->second    << " contains " << oid.snap << " -- HIT " << obc->obs << dendl;
dout(7) << __func__ << " " << soid     << " v " << v     << " but it is unfound" << dendl;
dout(10) << __func__      << " pg has changed, not touching last_complete_ondisk" << dendl;
dout(0) << __func__ << " " << soid << " from shard " << from   << ", reps on " << recovery_state.get_missing_loc().get_locations(soid)   << " unfound? " << recovery_state.get_missing_loc().is_unfound(soid)   << dendl;
dout(20) << __func__    << " op_trim_to = " << op_trim_to << " op_roll_forward_to = " << op_roll_forward_to << dendl;
dout(20) << __func__ << " got reply from "    << m->get_from() << dendl;
dout(10) << "clear ctx: "             << "OpRequestRef " << i.first             << " OpContext " << i.second             << dendl;
dout(10) << __func__ << " flushes in progress, moving "      << waiting_for_peered.size()      << " items to waiting_for_flush"      << dendl;
dout(5) << __func__ << ": bft=" << get_backfill_targets()    << " from " << last_backfill_started << dendl;
dout(5) << "target shard " << *i      << " from " << recovery_state.get_peer_info(*i).last_backfill      << dendl;
dout(10) << __func__ << " requeuing full waiters (not in writeback) "      << dendl;
dout(10) << __func__ << " needs_recovery: "    << recovery_state.get_missing_loc().get_needs_recovery()    << dendl;
dout(10) << __func__ << " missing_loc: "    << recovery_state.get_missing_loc().get_missing_locs()    << dendl;
dout(10) << __func__ << " recovering " << recovering.size()           << " in pg,"           << " missing " << missing << dendl;
dout(10) << __func__ << " "             << soid << " " << item.need      << (missing.is_missing(soid) ? " (missing)":"")      << (missing.is_missing(head) ? " (missing head)":"")             << (recovering.count(soid) ? " (recovering)":"")      << (recovering.count(head) ? " (recovering head)":"")             << dendl;
dout(10) << " will pull " << alternate_need << " or " << need       << " from one of "       << recovery_state.get_missing_loc().get_locations(soid)       << dendl;
dout(20) << "replica delete delayed on " << soid        << ";
could not get rw_manager lock" << dendl;
dout(20) << "replica delete got recovery read lock on " << soid        << dendl;
dout(20) << "recovery delayed on " << soid      << ";
could not get rw_manager lock" << dendl;
dout(20) << "recovery got recovery read lock on " << soid      << dendl;
dout(10) << __func__ << ": " << soid.get_head()   << " still missing on primary" << dendl;
dout(10) << __func__ << " (" << max << ")"           << " bft=" << get_backfill_targets()    << " last_backfill_started " << last_backfill_started    << (new_backfill ? " new_backfill":"")    << dendl;
dout(10) << "peer osd." << *i    << " info " << recovery_state.get_peer_info(*i)    << " interval " << peer_backfill_info[*i].begin    << "-" << peer_backfill_info[*i].end    << " " << peer_backfill_info[*i].objects.size() << " objects"    << dendl;
dout(20) << " BACKFILL removing " << check        << " from peers " << check_targets << dendl;
dout(20) << " BACKFILL keeping " << check   << " with ver " << obj_v   << " on peers " << keep_ver_targs << dendl;
dout(20) << " BACKFILL replacing " << check     << " with ver " << obj_v     << " to peers " << need_ver_targs << dendl;
dout(20) << " BACKFILL pushing " << backfill_info.begin          << " with ver " << obj_v          << " to peers " << missing_targs << dendl;
dout(20) << "backfill blocking on " << backfill_info.begin     << ";
could not get rw_manager lock" << dendl;
dout(20) << "need_ver_targs=" << need_ver_targs        << " keep_ver_targs=" << keep_ver_targs << dendl;
dout(20) << "backfill_targets=" << get_backfill_targets()        << " missing_targs=" << missing_targs        << " skip_targs=" << skip_targs << dendl;
dout(10) << " peer " << bt        << " num_objects now " << pinfo.stats.stats.sum.num_objects        << " / " << info.stats.stats.sum.num_objects << dendl;
dout(10) << __func__<< ": bi is old, rescanning local backfill_info"      << dendl;
dout(10) << __func__<< ": bi is old, (" << bi->version      << ") can be updated with log to projected_last_update "      << projected_last_update << dendl;
dout(10) << __func__ << ": updating from version " << e.version               << dendl;
dout(10) << __func__ << ": " << e.soid << " updated to version "     << e.version << dendl;
dout(10) << " checking " << p->soid        << " at " << p->version << dendl;
dout(20) << __func__ << " previous set had approx " << unique        << " unique items over " << dur << " seconds" << dendl;
dout(10) << __func__ << " target_size " << p->target_size      << " fpp " << p->get_fpp() << dendl;
dout(10) << __func__ << " backfill target osd." << *p        << " last_backfill has not progressed past pgid ps"        << dendl;
dout(10) << __func__ << " allocated new state, position "      << agent_state->position << dendl;
dout(10) << __func__    << " max " << start_max    << ", flush " << agent_state->get_flush_mode_name()    << ", evict " << agent_state->get_evict_mode_name()    << ", pos " << agent_state->position    << dendl;
dout(20) << __func__ << " start pos " << agent_state->position    << " next start pos " << next    << " started " << total_started << dendl;
dout(10) << __func__ << " loading " << p->begin << "-"   << p->end << dendl;
dout(10) << __func__ << " start_flush() failed " << obc->obs.oi      << " with " << result << dendl;
dout(20) << __func__      << " temp " << temp      << " pos " << temp_lower << "-" << temp_upper      << ", evict_effort " << agent_state->evict_effort      << dendl;
dout(10) << __func__    << " flush_mode: "    << TierAgentState::get_flush_mode_name(agent_state->flush_mode)    << " evict_mode: "    << TierAgentState::get_evict_mode_name(agent_state->evict_mode)    << " num_objects: " << info.stats.stats.sum.num_objects    << " num_bytes: " << info.stats.stats.sum.num_bytes    << " num_objects_dirty: " << info.stats.stats.sum.num_objects_dirty    << " num_objects_omap: " << info.stats.stats.sum.num_objects_omap    << " num_dirty: " << num_dirty    << " num_user_objects: " << num_user_objects    << " num_user_bytes: " << num_user_bytes    << " num_overhead_bytes: " << num_overhead_bytes    << " pool.info.target_max_bytes: " << pool.info.target_max_bytes    << " pool.info.target_max_objects: " << pool.info.target_max_objects    << dendl;
dout(20) << __func__ << " dirty " << ((float)dirty_micro / 1000000.0)    << " full " << ((float)full_micro / 1000000.0)    << dendl;
dout(5) << __func__ << " flush_mode "     << TierAgentState::get_flush_mode_name(agent_state->flush_mode)     << " -> "     << TierAgentState::get_flush_mode_name(flush_mode)     << dendl;
dout(5) << __func__ << " evict_mode "     << TierAgentState::get_evict_mode_name(agent_state->evict_mode)     << " -> "     << TierAgentState::get_evict_mode_name(evict_mode)     << dendl;
dout(5) << __func__ << " evict_effort "     << ((float)agent_state->evict_effort / 1000000.0)     << " -> "     << ((float)evict_effort / 1000000.0)     << dendl;
dout(20) << __func__ << ": " << **i        << " version is empty" << dendl;
dout(20) << __func__ << ": " << **i        << " (*i)->v past v" << dendl;
dout(20) << __func__ << ": " << **i        << " not committed, returning false"        << dendl;
dout(10) << __func__ << ": scrub delayed, "        << next.first << " is blocked"        << dendl;
dout(10) << __func__ << " " << soid    << " peers osd.{" << get_acting_recovery_backfill() << "}" << dendl;
ldout(pg->cct, 10) << "NotTrimming: trimming "       << pg->snap_trimq.range_start()       << dendl;
ldout(pg->cct, 10) << "adding snap " << snap_to_trim    << " to purged_snaps"    << dendl;
ldout(pg->cct, 10) << "purged_snaps now "    << pg->info.purged_snaps << ", snap_trimq now "    << pg->snap_trimq << dendl;
ldout(pg->cct, 10) << "could not get write lock on obj "      << object << dendl;
ldout(pg->cct, 10) << "waiting for it to clear"      << dendl;
dout(10) << "WaitPushes::react(const ActivePushesUpd&) pending_active_pushes: "    << scrbr->pending_active_pushes() << dendl;
dout(15) << "DrainReplMaps::react(const GotReplicas&): still draining incoming maps: "    << scrbr->dump_awaited_maps() << dendl;
dout(10) << "ReplicaWaitUpdates::react(const ReplicaPushesUpd&): "    << scrbr->pending_active_pushes() << dendl;
dout(10) << "ActiveReplica::react(const SchedReplica&). is_preemptable? "    << scrbr->get_preemptor().is_preemptable() << dendl;
dout(1) << "Error! Aborting. ActiveReplica::react(SchedReplica) Ret: " << ret     << dendl;
lgeneric_subdout(cct, osd, 20) << " moving complete_to to "                                       << log.begin()->version << dendl;
dout(10) << "proc_replica_log for osd." << from << ": "    << oinfo << " " << olog << " " << omissing << dendl;
dout(10) << __func__ << ": osd." << from << " does not overlap, not looking "      << "for divergent objects" << dendl;
dout(10) << __func__ << ": osd." << from << " same log head, not looking "      << "for divergent objects" << dendl;
dout(20) << " before missing " << i->first << " need " << i->second.need      << " have " << i->second.have << dendl;
dout(20) << "merge_log point (usually last shared) is "        << *first_non_divergent << dendl;
dout(10) << "rewind_divergent_log truncate divergent future " <<    newhead << dendl;
dout(10) << "merge_log " << olog << " from osd." << fromosd           << " into " << log << dendl;
dout(20) << "merge_log cut point (usually last shared) is "      << lower_bound << dendl;
dout(10) << "merge_log result " << log << " " << missing <<    " changed=" << changed << dendl;
dout(10) << "merge_log copying olog dups to log " << olog.dups.front().version << " to " << olog.dups.back().version << dendl;
dout(10) << "merge_log extending dups tail to " <<   olog.dups.back().version << dendl;
dout(10) << "merge_log extending dups head to " <<   olog.dups.front().version << dendl;
dout(10) << "merge_log removed dups overlapping log entries (" <<      log.tail << "," << log.dups.back().version << "]" << dendl;
dout(6) << "write_log_and_missing with: "      << "dirty_to: " << dirty_to      << ", dirty_from: " << dirty_from      << ", writeout_from: " << writeout_from      << ", trimmed: " << trimmed      << ", trimmed_dups: " << trimmed_dups      << ", clear_divergent_priors: " << clear_divergent_priors      << dendl;
dout(20) << __func__ << " extra missing entry: " << p.first        << " " << p.second << dendl;
ldpp_dout(dpp, 20) << "read_log_and_missing " << divergent_priors.size()                           << " divergent_priors" << dendl;
ldpp_dout(dpp, 20) << "read_log_and_missing coll "                     << ch->get_cid()                     << " " << pgmeta_oid << dendl;
dout(20) << __func__ << " will remove " << oid << " " << v << " from "        << shard << dendl;
dout(20) << __func__ << ": sending recovery delete << " << it->first   << " " << it->second << " to osd." << shard << dendl;
dout(20) << __func__ << " " << oid << " still missing on at least "   << shard << dendl;
dout(20) << __func__ << " completed recovery, local_missing = "        << get_parent()->get_local_missing() << dendl;
dout(10) << __func__ << ": Removing oid "      << *i << " from the temp collection" << dendl;
dout(25) << __func__ << "  " << poid << " got " << r      << ", skipping" << dendl;
dout(25) << __func__ << "  " << poid << " got " << r      << ", stat_error" << dendl;
dout(10) << __func__ << " digest_match = false, " << obj << " data_digest 0x" << std::hex << i->second.digest      << " != data_digest 0x" << auth->second->objects[obj].digest << std::dec      << dendl;
dout(10) << __func__ << ": selecting osd " << auth->first    << " for obj " << obj    << " with oi " << *auth_oi    << dendl;
dout(20) << __func__ << (repair ? " repair " : " ") << (parent->get_pool().is_replicated() ? "replicated " : "")  << (j == auth ? "auth" : "") << "shards " << shard_map.size() << (digest_match ? " digest_match " : " ")  << (shard_map[j->first].only_data_digest_mismatch_info() ? "'info mismatch info'" : "")  << dendl;
dout(20) << __func__ << " missing digest but age " << age     << " < " << cct->_conf->osd_deep_scrub_update_digest_min_age     << " on " << *k << dendl;
dout(1) << __func__ << " #op shards: " << num_shards          << " max osd capacity(iops) per shard: " << max_osd_capacity << dendl;
dout(1) << __func__ << " osd_mclock_cost_per_io: "          << std::fixed << osd_mclock_cost_per_io << dendl;
dout(1) << __func__ << " osd_mclock_cost_per_byte: "          << std::fixed << osd_mclock_cost_per_byte << dendl;
lgeneric_subdout(cct, osd, 20)       << "copy_up_to/copy_after copy dup version "       << d->version << dendl;
lgeneric_subdout(cct, osd, 20)  << "copy_up_to/copy_after copy dup from log version "  << i->version << dendl;
dout(20) << __func__ << " " << oid << " " << new_snaps    << " was " << (old_snaps_check ? *old_snaps_check : set<snapid_t>())    << dendl;
dout(20) << __func__ << " get_next(" << pos << ") returns " << r        << " " << next << dendl;
dout(20) << __func__ << " pool " << pool << " snap " << snap      << " key '" << k << "' lower_bound not found" << dendl;
dout(20) << __func__ << " pool " << pool << " snap " << snap      << " key '" << k << "' lower_bound got mismatched prefix '"      << it->key() << "'" << dendl;
dout(20) << __func__ << " pool " << pool << " snap " << snap      << " found [" << *begin << "," << *end << "), no overlap" << dendl;
dout(10) << __func__     << " [" << begin << "," << end << ") - joins ["     << before_begin << "," << before_end << ") and ["     << after_begin << "," << after_end << ")" << dendl;
dout(10) << __func__     << " [" << begin << "," << end << ") - join with earlier ["     << before_begin << "," << before_end << ")" << dendl;
dout(10) << __func__     << " [" << begin << "," << end << ") - join with later ["     << after_begin << "," << after_end << ")" << dendl;
dout(10) << __func__ << " rm " << rm.size() << " keys, set " << m.size()    << " keys" << dendl;
dout(20) << __func__ << " purged_snaps pool " << pool    << " [" << begin << "," << end << ")" << dendl;
dout(20) << __func__ << " mapping pool " << mapping.hoid.pool    << " snap " << mapping.snap    << " shard " << shard    << " " << mapping.hoid << dendl;
dout(10) << __func__ << " passed final purged_snaps interval, rest ok"        << dendl;
dout(20) << __func__ << " ok " << mapping.hoid        << " snap " << mapping.snap        << " precedes pool " << pool        << " purged_snaps [" << begin << "," << end << ")" << dendl;
dout(10) << __func__ << " stray " << mapping.hoid        << " snap " << mapping.snap        << " in pool " << pool        << " shard " << shard        << " purged_snaps [" << begin << "," << end << ")" << dendl;
dout(1) << __func__ << " converted " << n << " keys in "   << timespan_str(end - start) << dendl;
dout(10) << __func__    << " info stats: " << (info.stats.stats_invalid ? "invalid" : "valid")    << dendl;
dout(10) << mode << " got " << m_scrub_cstat.sum.num_objects << "/"    << info.stats.stats.sum.num_objects << " objects, "    << m_scrub_cstat.sum.num_object_clones << "/"    << info.stats.stats.sum.num_object_clones << " clones, "    << m_scrub_cstat.sum.num_objects_dirty << "/"    << info.stats.stats.sum.num_objects_dirty << " dirty, "    << m_scrub_cstat.sum.num_objects_omap << "/"    << info.stats.stats.sum.num_objects_omap << " omap, "    << m_scrub_cstat.sum.num_objects_pinned << "/"    << info.stats.stats.sum.num_objects_pinned << " pinned, "    << m_scrub_cstat.sum.num_objects_hit_set_archive << "/"    << info.stats.stats.sum.num_objects_hit_set_archive << " hit_set_archive, "    << m_scrub_cstat.sum.num_bytes << "/" << info.stats.stats.sum.num_bytes    << " bytes, " << m_scrub_cstat.sum.num_objects_manifest << "/"    << info.stats.stats.sum.num_objects_manifest << " manifest objects, "    << m_scrub_cstat.sum.num_bytes_hit_set_archive << "/"    << info.stats.stats.sum.num_bytes_hit_set_archive << " hit_set_archive bytes."    << dendl;
dout(20) << func << " " << mode << " " << pgid << " " << *head << " skipped "      << missing << " clone(s) in cache tier" << dendl;
dout(10) << __func__ << " num stat obj " << m_pl_pg->info.stats.stats.sum.num_objects    << dendl;
dout(10) << __func__ << " " << mode << " " << info.pgid << " new object " << soid   << " while processing " << *head << dendl;
dout(10) << __func__ << " " << mode << " " << info.pgid      << " No more objects while processing " << *head << dendl;
dout(20) << __func__ << " - " << missing << " (" << missing_digest.size() << ") missing"    << dendl;
dout(15) << __func__ << " soid: " << soid << " scrub is active? " << is_scrub_active()    << dendl;
dout(20) << __func__ << " " << soid << " < [" << m_start << "," << m_end << ")"        << dendl;
dout(20) << __func__ << " " << soid << " >= [" << m_start << "," << m_end << ")"        << dendl;
dout(20) << __func__ << " " << pgid << " e" << old_map->get_epoch()    << " to e" << new_map->get_epoch()    << " pg_nums " << p->second << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first       << " pg_num " << pgnum << " -> " << q->second       << " children " << children << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first     << " pg_num " << pgnum << " -> " << q->second     << " is a child" << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first     << " pg_num " << pgnum << " -> " << q->second     << " is post-split, skipping" << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first         << " pg_num " << pgnum << " -> " << q->second         << " is merge source, target " << parent         << ", source(s) " << children << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first       << " pg_num " << pgnum << " -> " << q->second       << " is beyond old pgnum, skipping" << dendl;
dout(20) << __func__ << " " << cur << " e" << q->first       << " pg_num " << pgnum << " -> " << q->second       << " is merge target, source " << children << dendl;
dout(10) << __func__      << " tiers " << agent_queue.size()      << ", top is " << level      << " with pgs " << top.size()      << ", ops " << agent_ops << "/"      << cct->_conf->osd_agent_max_ops      << (agent_active ? " active" : " NOT ACTIVE")      << dendl;
dout(10) << "high_count " << flush_mode_high_count      << " agent_ops " << agent_ops      << " flush_quota " << agent_flush_quota << dendl;
dout(10) << __func__ << " " << pg->pg_id << " no agent_work, delay for " << cct->_conf->osd_agent_delay_time << " seconds" << dendl;
dout(10) << __func__ << " " << attempts << " attempts, promoted "    << obj << " objects and " << byte_u_t(bytes) << ";
target "    dout(20) << __func__ << "  po " << po << " pb " << pb << " avg_size "      << avg_size << dendl;
dout(10) << __func__ << "  actual " << actual    << ", actual/prob ratio " << ratio    << ", adjusted new_prob " << new_prob    << ", prob " << promote_probability_millis << " -> " << prob    << dendl;
dout(20) << __func__ << " cur ratio " << ratio           << ", physical ratio " << pratio    << ", new state " << get_full_state_name(new_state)    << " " << inject    << dendl;
dout(10) << __func__ << " " << get_full_state_name(cur_state)      << " -> " << get_full_state_name(new_state) << dendl;
ldpp_dout(dpp, 10) << __func__ << " Injected " << get_full_state_name(type) << " OSD ("             << (injectfull < 0 ? "set" : std::to_string(injectfull)) << ")"             << dendl;
ldpp_dout(dpp, 10) << __func__ << " current usage is " << cur_ratio                       << " physical " << physical_ratio << dendl;
dout(0) << __func__ << " fake total " << cct->_conf->fake_statfs_for_testing            << " adjust available " << avail            << dendl;
dout(20) << __func__ << " time out heartbeat for osd " << i.first        << " last_update " << i.second.last_update << dendl;
dout(10) << __func__ << " " << old_wanted << " + " << old_pending << " -> "    << pg_temp_wanted.size() << dendl;
dout(20) << __func__ << " == true " << scrubs_local << " local + " << scrubs_remote      << " remote < max " << cct->_conf->osd_max_scrubs << dendl;
dout(20) << __func__ << " == false " << scrubs_local << " local + " << scrubs_remote      << " remote >= max " << cct->_conf->osd_max_scrubs << dendl;
dout(20) << __func__ << " " << scrubs_local << " -> " << (scrubs_local+1)      << " (max " << cct->_conf->osd_max_scrubs << ", remote " << scrubs_remote << ")" << dendl;
dout(20) << __func__ << " " << scrubs_local << " -> " << (scrubs_local-1)    << " (max " << cct->_conf->osd_max_scrubs << ", remote " << scrubs_remote << ")" << dendl;
dout(20) << __func__ << " " << scrubs_remote << " -> " << (scrubs_remote+1)      << " (max " << cct->_conf->osd_max_scrubs << ", local " << scrubs_local << ")" << dendl;
dout(20) << __func__ << " " << scrubs_remote << " -> " << (scrubs_remote-1)    << " (max " << cct->_conf->osd_max_scrubs << ", local " << scrubs_local << ")" << dendl;
dout(10) << __func__ << " oldest map " << max_oldest_map << " > since "      << since << ", starting with full map" << dendl;
dout(10) << "send_incremental_map " << since << " -> " << to           << " to " << con << " " << con->get_peer_addr() << dendl;
dout(10) << "  " << (to - since) << " > max " << cct->_conf->osd_map_share_max_epochs        << ", only sending most recent" << dendl;
dout(7) << __func__ << ": " << *pg << " no longer have map for "       << m->get_map_epoch() << ", dropping" << dendl;
dout(7) << __func__ << ": " << *pg << " primary changed since "       << m->get_map_epoch() << ", dropping" << dendl;
dout(20) << __func__    << " ready_to_merge_source " << ready_to_merge_source        << " not_ready_to_merge_source " << not_ready_to_merge_source    << " ready_to_merge_target " << ready_to_merge_target        << " not_ready_to_merge_target " << not_ready_to_merge_target    << " sent_ready_to_merge_source " << sent_ready_to_merge_source    << dendl;
dout(1) << __func__ << " public network " << front_iface << " numa node "            << front_node << dendl;
dout(1) << __func__ << " cluster network " << back_iface << " numa node "       << back_node << dendl;
dout(1) << __func__ << " public and cluster network numa nodes do not match"                << dendl;
dout(1) << __func__ << " objectstore and network numa nodes do not match"  << dendl;
dout(1) << __func__ << " cluster network " << back_iface              << " ports numa nodes do not match" << dendl;
dout(1) << __func__ << " public network " << front_iface            << " ports numa nodes do not match" << dendl;
dout(1) << __func__ << " unable to determine numa node " << numa_node       << " CPUs" << dendl;
dout(1) << __func__ << " setting numa affinity to node " << numa_node       << " cpus "       << cpu_set_to_str_list(numa_cpu_set_size, &numa_cpu_set)       << dendl;
dout(1) << "finished manual compaction in "            << duration            << " seconds" << dendl;
dout(1) << " bench count " << count            << " bsize " << byte_u_t(bsize) << dendl;
dout(2) << "init " << dev_path   << " (looks like " << (store_is_rotational ? "hdd" : "ssd") << ")"   << dendl;
dout(2) << "journal looks like " << (journal_is_rotational ? "hdd" : "ssd")          << dendl;
dout(1) << __func__ << " upgrade snap_mapper (first start as octopus)"       << dendl;
dout(10) << "load_pgs " << *it        << " removing, legacy or flagged for removal pg" << dendl;
dout(20) << __func__ << "  dropping " << pgid        << "create, pool does not have CREATING flag set" << dendl;
dout(1) << __func__ << " withhold creation of pg " << pgid   << ": " << num_pgs << " >= "<< max_pgs_per_osd << dendl;
dout(20) << __func__ << " pending_creates_from_mon "        << pending_creates_from_mon << dendl;
dout(4) << __func__ << ": resolicit pg creates from mon since "       << last_pg_create_epoch << dendl;
dout(4) << __func__ << ": resolicit osdmap from mon since "       << start << dendl;
dout(4) << __func__ << ": re-subscribe osdmap(onetime) since "       << start << dendl;
dout(10) << __func__ << " " << *h << " " << *pi    << " [" << (pi->empty() ? pair<epoch_t,epoch_t>(0,0) :         pi->get_bounds()) << ")"    << dendl;
dout(10) << "_add_heartbeat_peer: new peer osd." << p      << " " << hi->con_back->get_peer_addr()      << " " << hi->con_front->get_peer_addr()      << dendl;
dout(20) << " removing heartbeat peer osd." << n    << " " << q->second.con_back->get_peer_addr()    << " " << (q->second.con_front ? q->second.con_front->get_peer_addr() : entity_addr_t())    << dendl;
dout(20) << "handle_osd_ping from " << m->get_source_inst()      << " bad fsid " << m->fsid << " != " << superblock.cluster_fsid      << dendl;
dout(5) << "Dropping heartbeat from " << from      << ", " << heartbeat_drop->second      << " remaining to drop" << dendl;
dout(5) << "Dropping heartbeat from " << from    << ", " << heartbeat_drop->second    << " remaining to drop" << dendl;
dout(10) << "internal heartbeat not healthy, dropping ping request"   << dendl;
dout(25) << "handle_osd_ping got reply from osd." << from                     << " first_tx " << i->second.first_tx                     << " last_tx " << i->second.last_tx                     << " last_rx_back " << i->second.last_rx_back       << " -> " << now                     << " last_rx_front " << i->second.last_rx_front                     << dendl;
dout(25) << "handle_osd_ping got reply from osd." << from                     << " first_tx " << i->second.first_tx                     << " last_tx " << i->second.last_tx                     << " last_rx_back " << i->second.last_rx_back                     << " last_rx_front " << i->second.last_rx_front       << " -> " << now                     << dendl;
dout(25) << "handle_osd_ping got all replies from osd." << from                     << " , erase pending ping(sent at " << m->ping_stamp << ")"                     << " and older pending ping(s)"                     << dendl;
dout(10) << "handle_osd_ping canceling queued "                       << "failure report for osd." << from << dendl;
dout(10) << "handle_osd_ping canceling in-flight "                       << "failure report for osd." << from << dendl;
dout(10) << "handle_osd_ping no pending ping(sent at " << m->ping_stamp                   << ") is found, treat as covered by newly sent pings "                   << "and ignore"                   << dendl;
dout(10) << "handle_osd_ping " << m->get_source_inst()      << " says i am down in " << m->map_epoch << dendl;
dout(25) << "heartbeat_check we haven't sent ping to osd." << p->first               << " yet, skipping" << dendl;
dout(25) << "heartbeat_check osd." << p->first      << " first_tx " << p->second.first_tx      << " last_tx " << p->second.last_tx      << " last_rx_back " << p->second.last_rx_back      << " last_rx_front " << p->second.last_rx_front      << dendl;
dout(10) << "heartbeat_reset failed hb con " << con << " for osd." << p->second.peer        << ", reopening" << dendl;
dout(10) << "heartbeat_reset failed hb con " << con << " for osd." << p->second.peer   << ", raced with osdmap update, closing out peer" << dendl;
dout(20) << __func__ << " last_purged_snaps_scrub " << last        << " next " << next << " ... now" << dendl;
dout(20) << __func__ << " last_purged_snaps_scrub " << last        << " next " << next << dendl;
dout(20) << __func__ << " max_waiting_epoch " << max_waiting_epoch        << ", requesting new map" << dendl;
dout(10) << " new session (outgoing) " << s << " con=" << s->con          << " addr=" << s->con->get_peer_addr() << dendl;
dout(10) << "new session (incoming)" << s << " con=" << con          << " addr=" << con->get_peer_addr()          << " must have raced with connect" << dendl;
dout(10) << "start_boot - have maps " << superblock.oldest_map    << ".." << superblock.newest_map << dendl;
dout(10) << __func__ << " _preboot mon has osdmaps "    << oldest << ".." << newest << dendl;
dout(10) << __func__ << " purged_snaps_last " << superblock.purged_snaps_last      << " < newest_map " << superblock.current_epoch << dendl;
dout(10) << __func__ << " waiting for peering work to drain"       << dendl;
dout(10) << __func__ << " purged_snaps_last " << superblock.purged_snaps_last    << ", newest_map " << superblock.current_epoch << dendl;
dout(5) << __func__ << " force returning true since last markdown"               << " was " << cct->_conf->osd_max_markdown_period               << "s ago" << dendl;
dout(1) << "is_healthy false -- only " << up << "/" << num << " up peers (less than "       << int(cct->_conf->osd_heartbeat_min_healthy_ratio * 100.0) << "%)" << dendl;
dout(20) << " initial client_addrs " << client_addrs    << ", cluster_addrs " << cluster_addrs    << ", hb_back_addrs " << hb_back_addrs    << ", hb_front_addrs " << hb_front_addrs    << dendl;
dout(10) << " assuming cluster_addrs match client_addrs "      << client_addrs << dendl;
dout(10) << " assuming hb_back_addrs match cluster_addrs "      << cluster_addrs << dendl;
dout(10) << " assuming hb_front_addrs match client_addrs "      << client_addrs << dendl;
dout(10) << " final client_addrs " << client_addrs    << ", cluster_addrs " << cluster_addrs    << ", hb_back_addrs " << hb_back_addrs    << ", hb_front_addrs " << hb_front_addrs    << dendl;
dout(10) << "queue_want_up_thru now " << want << " (was " << up_thru_wanted << ")"      << ", currently " << cur      << dendl;
dout(10) << "queue_want_up_thru want " << want << " <= queued " << up_thru_wanted      << ", currently " << cur      << dendl;
dout(10) << __func__ << " " << first << ".." << last    << ", previously requested "    << requested_full_first << ".." << requested_full_last << dendl;
dout(10) << __func__ << " " << e << ", requested " << requested_full_first      << ".." << requested_full_last      << ", ignoring" << dendl;
dout(10) << __func__ << " " << e << ", requested " << requested_full_first      << ".." << requested_full_last << ", resetting" << dendl;
dout(10) << __func__ << " " << e << ", requested " << requested_full_first           << ".." << requested_full_last           << ", still need more" << dendl;
dout(10) << __func__ << " " << old_queue << " + " << old_pending << " -> "    << failure_queue.size() << dendl;
dout(10) << __func__ << " canceling in-flight failure report for osd."             << it->first << dendl;
dout(20) << __func__ << " pg " << spgid << " snap " << snap        << " already queued" << dendl;
dout(10) << __func__ << " requeue pg " << spgid << " " << pg << " snap "      << snap << dendl;
dout(10) << __func__ << " no unique id for dev " << dev << " ("        << err << "), skipping" << dendl;
dout(10) << __func__ << " con " << con      << " " << con->get_peer_addr()      << " map epoch " << session->last_sent_epoch      << " -> " << peer_epoch_lb << " (as per caller)" << dendl;
dout(10) << __func__ << " con " << con      << " " << con->get_peer_addr()      << " map epoch " << session->last_sent_epoch      << " -> " << last_sent_epoch << " (shared)" << dendl;
dout(10) << __func__ << " new session " << s << " con " << s->con      << " entity " << s->entity_name      << " addr " << con->get_peer_addrs() << dendl;
dout(10) << __func__ << " existing session " << s << " con " << s->con      << " entity " << s->entity_name      << " addr " << con->get_peer_addrs() << dendl;
dout(10) << __func__ << " session " << s << " " << s->entity_name        << " failed to decode caps string" << dendl;
dout(10) << __func__ << " session " << s   << " " << s->entity_name   << " has caps " << s->caps << " '" << str << "'" << dendl;
dout(10) << __func__ << " session " << s << " " << s->entity_name   << " failed to parse caps '" << str << "'" << dendl;
dout(0) << "handle_scrub fsid " << m->fsid << " != " << monc->get_fsid()     << dendl;
dout(0) << __func__ << " fsid " << m->fsid << " != " << monc->get_fsid()     << dendl;
dout(20) << __func__ << " should run between week day " << cct->_conf->osd_scrub_begin_week_day            << " - " << cct->_conf->osd_scrub_end_week_day            << " now " << bdt.tm_wday << " = no" << dendl;
dout(20) << __func__ << " should run between " << cct->_conf->osd_scrub_begin_hour            << " - " << cct->_conf->osd_scrub_end_hour            << " now " << bdt.tm_hour << " = yes" << dendl;
dout(20) << __func__ << " should run between " << cct->_conf->osd_scrub_begin_hour            << " - " << cct->_conf->osd_scrub_end_hour            << " now " << bdt.tm_hour << " = no" << dendl;
dout(20) << __func__ << " loadavg per cpu " << loadavg_per_cpu      << " < max " << cct->_conf->osd_scrub_load_threshold      << " = yes" << dendl;
dout(20) << __func__ << " loadavg " << loadavgs[0]      << " < daily_loadavg " << daily_loadavg      << " and < 15m avg " << loadavgs[2]      << " = yes" << dendl;
dout(20) << __func__ << " loadavg " << loadavgs[0]    << " >= max " << cct->_conf->osd_scrub_load_threshold    << " and ( >= daily_loadavg " << daily_loadavg    << " or >= 15m avg " << loadavgs[2]    << ") = no" << dendl;
dout(10) << __func__             << " will only schedule explicitly requested repair due to active recovery"             << dendl;
dout(20) << "sched_scrub " << scrub_job.pgid << " scheduled at " << scrub_job.sched_time   << " > " << now << dendl;
dout(15) << __func__ << " not scheduling scrub for " << scrub_job.pgid << " due to "                 << (!time_permit ? "time not permit" : "high load") << dendl;
dout(10) << __func__ << " skip " << scrub_job.pgid                 << " because repairing is not explicitly requested on it"                 << dendl;
dout(15) << "sched_scrub scrubbing " << scrub_job.pgid << " at " << scrub_job.sched_time        << (pg->get_must_scrub() ? ", explicitly requested" :     (load_is_low ? ", load_is_low" : " deadline < now"))        << dendl;
dout(10) << __func__ << " waiting for pgs to catch up (need " << need        << " max_lag " << max_lag << ")" << dendl;
dout(10) << __func__ << " waiting for pgs to consume " << need     << " (shard " << shard->shard_id << " min " << min     << ", map cache is " << cct->_conf->osd_map_cache_size     << ", max_lag_factor " << m_osd_pg_epoch_max_lag_factor     << ")" << dendl;
dout(0) << "handle_osd_map fsid " << m->fsid << " != "     << monc->get_fsid() << dendl;
dout(10) << "got osd map from Session " << session             << " which we can't take maps from (not a mon or osd)" << dendl;
dout(3) << "handle_osd_map epochs [" << first << "," << last << "], i have "   << superblock.newest_map   << ", src has [" << m->oldest_map << "," << m->newest_map << "]"   << dendl;
dout(10) << "handle_osd_map message skips epochs "      << superblock.newest_map + 1 << ".." << (first-1) << dendl;
dout(2) << "got incremental " << e  << " but failed to encode full with correct crc;
requesting"    dout(10) << __func__ << " still missing full maps " << requested_full_first      << ".." << requested_full_last << dendl;
dout(10) << __func__ << " can't get previous map " << i.first - 1                 << " probably first start of this osd" << dendl;
dout(10) << __func__ << " recording final pg_pool_t for pool "   << j.first << dendl;
dout(10) << __func__ << " recording pool " << j.first << " pg_num "   << j.second.get_pg_num() << " -> " << new_pg_num << dendl;
dout(10) << __func__ << " recording new pool " << j.first << " pg_num "   << j.second.get_pg_num() << dendl;
dout(10) << __func__ << " superblock purged_snaps_last is "      << superblock.purged_snaps_last      << ", not recording new purged_snaps" << dendl;
dout(10) << " advance to epoch " << cur      << " (<= last " << last      << " <= newest_map " << superblock.newest_map      << ")" << dendl;
dout(10) << __func__ << " NOUP flag changed in " << newmap->get_epoch()        << dendl;
dout(10) << " msg say newest map is " << m->newest_map      << ", requesting more" << dendl;
dout(0) << "crush map has features " << features       << ", adjusting msgr requires for clients" << dendl;
dout(0) << "crush map has features " << features       << " was " << p.features_required       << ", adjusting msgr requires for mons" << dendl;
dout(0) << "crush map has features " << features       << ", adjusting msgr requires for osds" << dendl;
dout(1) << __func__ << " require_osd_release " << last_require_osd_release     << " -> " << to_string(osdmap->require_osd_release) << dendl;
dout(10) << __func__ << " added merge_waiter " << src->pg_id    << " for " << target  << ", have " << p.size() << "/" << need    << dendl;
dout(1) << __func__ << " " << pg->pg_id    << " is merge source, target is " << parent     << dendl;
dout(20) << __func__ << " " << pg->pg_id     << " is merge target, sources are " << children     << dendl;
dout(20) << __func__ << " have " << s.size() << "/"       << need << dendl;
dout(20) << __func__        << " new pool opts " << newpool->second.opts        << " old pool opts " << oldpool->second.opts        << dendl;
dout(10) << __func__ << " pg " << pg->first << " doesn't map here, "   << "discarding pending_create_from_osd" << dendl;
dout(0) << "require_mon_peer received from non-mon "     << m->get_connection()->get_peer_addr()     << " " << *m << dendl;
dout(0) << "require_mon_or_mgr_peer received from non-mon, non-mgr "     << m->get_connection()->get_peer_addr()     << " " << *m << dendl;
dout(0) << "require_osd_peer received from non-osd "     << m->get_connection()->get_peer_addr()     << " " << *m << dendl;
dout(5) << "from dead osd." << from << ", marking down, "     << " msg was " << m->get_source_inst().addr     << " expected "     << (map->is_up(from) ?  map->get_cluster_addrs(from) : entity_addrvec_t())     << dendl;
dout(15) << "require_same_or_newer_map " << epoch    << " (i am " << osdmap->get_epoch() << ") " << m << dendl;
dout(7) << "waiting for newer map epoch " << epoch     << " > my " << osdmap->get_epoch() << " with " << m << dendl;
dout(10) << " pg_num is " << pg_num      << ", m_seed " << i->ps()      << ", split_bits is " << split_bits << dendl;
dout(10) << "mkpg " << on << "  not acting_primary (" << acting_primary        << "), my role=" << role << ", skipping" << dendl;
dout(10) << __func__ << ": got obsolete pg create on pgid "        << pgid << " from epoch " << m->epoch        << ", primary changed in " << history.same_primary_since        << dendl;
dout(20) << __func__ << " skipping osd." << osd << " (NULL con)"   << dendl;
dout(20) << __func__ << " " << pgid << " e" << created        << "@" << created_stamp        << " (no history or past_intervals)" << dendl;
dout(20) << __func__ << " " << pgid << " e" << created        << "@" << created_stamp        << " history " << q->second.first        << " pi " << q->second.second << dendl;
dout(10) << __func__ << " starting " << to_start      << ", recovery_ops_reserved " << recovery_ops_reserved      << " -> " << (recovery_ops_reserved + to_start) << dendl;
dout(15) << __func__ << " active " << recovery_ops_active      << " + reserved " << recovery_ops_reserved      << " >= max " << max << dendl;
dout(20) << "do_recovery wake up at "                 << ceph_clock_now()          << ", re-queuing recovery" << dendl;
dout(20) << "Recovery event scheduled at "               << service.recovery_schedule_time << dendl;
dout(10) << "do_recovery started " << started << "/" << reserved_pushes      << " on " << *pg << dendl;
dout(10) << "start_recovery_op " << *pg << " " << soid    << " (" << recovery_ops_active << "/"    << osd->get_recovery_max_active() << " rops)"    << dendl;
dout(10) << "finish_recovery_op " << *pg << " " << soid    << " dequeue=" << dequeue    << " (" << recovery_ops_active << "/"    << osd->get_recovery_max_active() << " rops)"    << dendl;
dout(10) << __func__ << "(" << pushes << "), recovery_ops_reserved "    << recovery_ops_reserved << " -> " << (recovery_ops_reserved-pushes)    << dendl;
dout(15) << "enqueue_op " << op << " prio " << priority           << " type " << type    << " cost " << cost    << " latency " << latency    << " epoch " << epoch    << " " << *(op->get_req()) << dendl;
dout(10) << "dequeue_op " << op << " prio " << m->get_priority()    << " cost " << m->get_cost()    << " latency " << latency    << " " << *m    << " pg " << *pg << dendl;
dout(1) << queries.size() - supported_queries.size()            << " unsupported queries" << dendl;
dout(30) << "min was " << pg_slots_by_epoch.begin()->epoch    << " on " << pg_slots_by_epoch.begin()->pg->pg_id << dendl;
dout(30) << "min is now " << pg_slots_by_epoch.begin()->epoch    << " on " << pg_slots_by_epoch.begin()->pg->pg_id << dendl;
dout(10) << need << " waiting on "        << pg_slots_by_epoch.begin()->epoch << dendl;
dout(10) << new_osdmap->get_epoch()           << " (was " << (old_osdmap ? old_osdmap->get_epoch() : 0) << ")"    << dendl;
dout(20) << __func__ << "  " << pgid        << " waiting for split " << slot->waiting_for_split << dendl;
dout(20) << __func__ << "  " << pgid        << " waiting for merge by epoch " << slot->waiting_for_merge_epoch        << dendl;
dout(20) << __func__ << "  " << pgid   << " pending_peering first epoch " << first   << " <= " << new_osdmap->get_epoch() << ", requeueing" << dendl;
dout(20) << __func__ << "  " << pgid << " maps to us, keeping"   << dendl;
dout(20) << __func__ << "  " << pgid   << " waiting item " << qi   << " epoch " << qi.get_map_epoch()   << " <= " << new_osdmap->get_epoch()   << ", "   << (qi.get_map_epoch() < new_osdmap->get_epoch() ? "stale" :       "misdirected")   << ", dropping" << dendl;
dout(20) << __func__ << " " << pgid    << " to_process " << slot->to_process    << " waiting " << slot->waiting    << " waiting_peering " << slot->waiting_peering << dendl;
dout(20) << __func__ << " slot " << pgid   << " has no pg and waiting_for_split " << dendl;
dout(10) << "as_of_osdmap " << as_of_osdmap->get_epoch() << " < shard "      << shard_osdmap->get_epoch() << ", new children " << newer_children      << dendl;
dout(10) << "priming (existing) slot " << p->first << " e" << p->second   << dendl;
dout(20) << __func__ << " checking shard " << shard_id    << " for remaining merge pgs " << merge_pgs << dendl;
dout(20) << __func__ << "  have merge participant pg " << pgid        << " " << slot->pg << dendl;
dout(20) << __func__ << "  pending split on merge participant pg " << pgid        << " " << slot->waiting_for_split << dendl;
dout(20) << __func__ << "  creating empty merge participant " << pgid        << " for merge in " << epoch << dendl;
dout(20) << pg->pg_id << " waiting_for_split " << slot->waiting_for_split      << dendl;
dout(10) << __func__ << " still waiting for split on "        << slot->waiting_for_split << dendl;
dout(10) << __func__ << " parent " << parent << " clearing " << i.first        << dendl;
dout(20) << __func__ << " " << pgid      << " peering, item epoch is "      << qi.get_map_epoch()      << ", will wait on " << qi << dendl;
dout(20) << __func__ << " " << pgid      << " item epoch is "      << qi.get_map_epoch()      << ", will wait on " << qi << dendl;
dout(20) << __func__ << " " << token    << (r.second ? " (new)" : "")    << " to_process " << slot->to_process    << " waiting " << slot->waiting    << " waiting_peering " << slot->waiting_peering    << dendl;
dout(20) << __func__ << " " << slot->to_process.back()    << " queued" << dendl;
dout(20) << __func__ << " " << token        << " nothing queued" << dendl;
dout(20) << __func__ << " " << token        << " requeue_seq " << slot->requeue_seq << " > our "        << requeue_seq << ", we raced with _wake_pg_slot"        << dendl;
dout(20) << __func__ << " slot " << token << " no longer attached to "        << pg << dendl;
dout(20) << __func__ << " " << token    << " to_process " << slot->to_process    << " waiting " << slot->waiting    << " waiting_peering " << slot->waiting_peering << dendl;
dout(20) << __func__ << " " << token        << " splitting " << slot->waiting_for_split << dendl;
dout(20) << __func__ << " " << token        << " map " << qi.get_map_epoch() << " > "        << osdmap->get_epoch() << dendl;
dout(20) << __func__ << " " << token       << " no pg, no longer primary, ignoring mon create on "       << qi << dendl;
dout(20) << __func__ << " " << token       << " no pg, should create on " << qi << dendl;
dout(20) << __func__ << " " << token     << " no pg, peering, !create, discarding " << qi << dendl;
dout(20) << __func__ << " " << token   << " no pg, peering, doesn't map here e" << osdmap->get_epoch()   << ", discarding " << qi   << dendl;
dout(20) << __func__ << " " << token        << " no pg, should exist e" << osdmap->get_epoch()        << ", will wait on " << qi << dendl;
dout(20) << __func__ << " " << token        << " no pg, shouldn't exist e" << osdmap->get_epoch()        << ", dropping " << qi << dendl;
dout(20) << __func__      << " " << p->second->to_process.front()      << " shuffled w/ " << item << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__                      << ": completing flush" << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__       << ": completing flush" << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__       << ": completing shut down" << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << ": watcher="                     << watcher << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << ": handle="       << handle << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__         << ": completing unregister" << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << ": handle="       << handle << ", watcher=" << watcher << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__ << ": handle="       << handle << ", watcher=" << watcher << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__         << ": completing unregister" << dendl;
ldout(m_cct, 20) << "ImageUpdateWatchers::" << __func__         << ": completing shut down" << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__ << ": watcher="                     << watcher << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__                       << ": completing unregister " << handle << dendl;
ldout(m_cct, 10) << "QuiesceWatchers::" << __func__ << ": watcher "                         << handle << " failed" << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__ << " event: "                     << event_type << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__ << ": handle="                         << handle << ", event_type=" << event_type << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__                               << ": skip for failed watcher" << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__ << ": r=" << r                     << dendl;
ldout(m_cct, 20) << "QuiesceWatchers::" << __func__                         << ": completing unregister " << it.first << dendl;
ldout(cct, 20) << __func__ << ": refresh_seq = " << m_refresh_seq << ", "   << "last_refresh = " << m_last_refresh << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "snap_id=" << action_contexts.first.snap_id << dendl;
ldout(ictx->cct, 20) << "C_OpenAfterCloseComplete::finish: r=" << r    << dendl;
ldout(ictx->cct, 10) << "Image::aio_read() buf=" << (void *)bl.c_str() << "~"    << (void *)(bl.c_str() + len - 1) << dendl;
ldout(ictx->cct, 10) << "Image::aio_read() buf=" << (void *)bl.c_str() << "~"    << (void *)(bl.c_str() + len - 1) << dendl;
ldout(cct, 20) << "detect format of " << name << " : "     << (old_format ? (*old_format ? "old" : "new") :         "don't care")  << dendl;
ldout(cct, 20) << __func__ << " "  << &io_ctx << " name = " << imgname     << " size = " << size << " order = " << order << dendl;
ldout(cct, 10) << __func__ << " name=" << image_name << ", "     << "id= " << id << ", "     << "size=" << size << ", opts=" << opts << dendl;
ldout(cct, 10) << __func__ << " "     << "c_name=" << c_name << ", "     << "c_id= " << clone_id << ", "     << "c_opts=" << c_opts << dendl;
ldout(cct, 20) << "rename " << &io_ctx << " " << srcname << " -> "     << dstname << dendl;
ldout(cct, 20) << __func__ << ": ictx=" << ictx << ", "                   << "lock_mode=" << lock_mode << dendl;
ldout(cct, 20) << __func__ << ": ictx=" << ictx << ", "                   << "lock_mode=" << lock_mode << ", "                   << "lock_owner=" << lock_owner << dendl;
ldout(cct, 20) << "copy " << src->name     << (src->snap_name.length() ? "@" + src->snap_name : "")     << " -> " << destname << " opts = " << opts << dendl;
ldout(ictx->cct, 20) << "lock image " << ictx << " exclusive=" << exclusive    << " cookie='" << cookie << "' tag='" << tag << "'"    << dendl;
ldout(ictx->cct, 20) << "unlock image " << ictx    << " cookie='" << cookie << "'" << dendl;
ldout(ictx->cct, 20) << "break_lock image " << ictx << " client='" << client    << "' cookie='" << cookie << "'" << dendl;
ldout(ictx->cct, 20) << "read_iterate " << ictx << " off = " << off    << " len = " << len << dendl;
ldout(cct, 20) << __func__ << " " << ictx << " numcomp = " << numcomp                   << dendl;
ldout(m_cct, 20) << "sector size: " << sector_size << ", data alignment: "                   << data_alignment << dendl;
ldout(m_cct, 20) << "sector size: " << get_sector_size() << ", data offset: "                   << get_data_offset() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << *extents << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << write_data.length()                 << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << "reset required for non-pipelined response: "                     << "work=" << work.get() << dendl;
ldout(cct, 15) << "current_state=" << current_state << ", "                   << "next_state=" << next_state << ", "                   << "r=" << r << dendl;
ldout(m_cct, 20) << "bytes=" << byte_offset << "~" << byte_length << ", "                   << "r=" << r << dendl;
ldout(m_cct, 15) << "source_spec=" << source_spec << ", "                   << "source_snap_id=" << m_src_snap_id << ", "                   << "import_only=" << import_only << dendl;
ldout(m_cct, 10) << "r=" << r << ", "                   << "image_size=" << m_image_size << dendl;
ldout(m_cct, 10) << "adding snap: ns=" << snap_info.snap_namespace << ", "                     << "name=" << snap_info.name << ", "                     << "id=" << snap_id << dendl;
ldout(m_cct, 15) << "read snap id: " << m_src_snap_id << ", "                   << "write snapc={"                   << "seq=" << snapc.seq << ", "                   << "snaps=" << snapc.snaps << "}" << dendl;
ldout(m_cct, 10) << "url=" << m_url << ", "                   << "access_key=" << m_access_key << dendl;
ldout(m_cct, 20) << "string_to_sign=" << string_to_sign << ", "                   << "authorization=" << authorization << dendl;
ldout(cct, 20) << "image_offset=" << image_offset << ", "                     << "image_length=" << image_length << ", "                     << "cluster_length=" << cluster_length << dendl;
ldout(cct, 20) << "cluster_offset=" << cluster->cluster_offset << ", "                   << "stream_offset=" << stream_offset << ", "                   << "stream_length=" << stream_length << dendl;
ldout(cct, 20) << "r=" << r << ", "                   << "cluster_offset=" << cluster->cluster_offset << dendl;
ldout(cct, 20) << "image_offset=" << image_offset << ", "                   << "l1_table_index=" << l1_table_index << ", "                   << "l2_table_offset=" << l2_table_offset << ", "                   << "l2_table_index=" << l2_table_index << dendl;
ldout(cct, 20) << "image_offset=" << image_offset << ", "                     << "cluster_offset=DNE" << dendl;
ldout(cct, 20) << "l2_table_offset=" << request.l2_table_offset << ", "                       << "l2_table_index=" << request.l2_table_index << ", "                       << "cluster_offset=zeroed" << dendl;
ldout(cct, 20) << "l2_table_offset=" << request.l2_table_offset << ", "                       << "l2_table_index=" << request.l2_table_index << ", "                       << "cluster_offset=" << *request.cluster_offset                       << dendl;
ldout(cct, 20) << "l2_offset=" << l2_offset << ", "                         << "index=" << idx << " (in-flight)" << dendl;
ldout(cct, 20) << "l2_offset=" << l2_offset << ", "                         << "index=" << idx << " (error): "                         << cpp_strerror(l2_cache.ret_val) << dendl;
ldout(cct, 20) << "l2_offset=" << l2_offset << ", " << "index=" << idx                       << dendl;
ldout(cct, 20) << "l2_offset=" << l2_offset << ", "                     << "index=DNE (cache busy)" << dendl;
ldout(cct, 20) << "l2_offset=" << l2_offset << ", "                   << "index=" << min_idx << " (loading)" << dendl;
ldout(cct, 20) << "r=" << r << ", "                   << "l2_offset=" << l2_offset << ", "                   << "index=" << index << dendl;
ldout(cct, 20) << "r=" << r << ", "                   << "image_offset=" << cluster_extent.image_offset << ", "                   << "cluster_offset=" << cluster_extent.cluster_offset                   << dendl;
ldout(cct, 20) << "r=" << r << ", "                   << "image_offset=" << image_offset << ", "                   << "image_length=" << image_length << dendl;
ldout(cct, 20) << "l1_table_index=" << l1_table_index << ", "                     << "snap_id=" << snap_id << ": DNE" << dendl;
ldout(cct, 20) << "l1_table_index=" << l1_table_index << ", "                   << "snap_id=" << snap_id << ", "                   << "l2_table_offset=" << l2_table_offset << dendl;
ldout(cct, 20) << "r=" << r << ", "                   << "snap_id=" << snap_id << dendl;
ldout(cct, 20) << "l1_table_index=" << l1_table_index << ", "                     << "snap_id=" << snap_id << ", "                     << "image_offset=" << cluster_extent.image_offset << ", "                     << "l2_table_index=" << l2_table_index << ", "                     << "cluster_offset=" << cluster_offset << ", "                     << "prev_cluster_offset=" << prev_cluster_offset << dendl;
ldout(cct, 20) << "l1_table_index=" << l1_table_index << ", "                   << "snap_id=" << snap_id << ", "                   << "sparse_extents=" << sparse_extents << dendl;
ldout(cct, 15) << "size=" << m_size << ", "                 << "cluster_bits=" << m_cluster_bits << ", "                 << "l2_bits=" << m_l2_bits << dendl;
ldout(cct, 15) << "size=" << m_size << ", "                 << "cluster_bits=" << m_cluster_bits << ", "                 << "l1_table_offset=" << m_l1_table_offset << ", "                 << "snapshot_count=" << m_snapshot_count << ", "                 << "snapshots_offset=" << m_snapshots_offset << dendl;
ldout(cct, 10) << "snap_id=" << (m_snapshots.size() + 1) << ", "                 << "offset=" << m_snapshots_offset << dendl;
ldout(cct, 10) << "r=" << r << ", "                 << "index=" << m_snapshots.size() << dendl;
ldout(cct, 10) << "snap_id=" << m_snapshots.size() << ", "                 << "id_str_len=" << snapshot.id.size() << ", "                 << "name_str_len=" << snapshot.name.size() << ", "                 << "l1_table_offset=" << snapshot.l1_table_offset << ", "                 << "l1_size=" << snapshot.l1_table.size << ", "                 << "extra_data_size=" << snapshot.extra_data_size << dendl;
ldout(cct, 10) << "snap_id=" << m_snapshots.size() << ", "                 << "offset=" << m_snapshots_offset << ", "                 << "length=" << length << dendl;
ldout(cct, 10) << "r=" << r << ", "                 << "snap_id=" << m_snapshots.size() << dendl;
ldout(cct, 10) << "snap_id=" << m_snapshots.size() << ", "                 << "name=" << snapshot.name << ", "                 << "size=" << snapshot.size << dendl;
ldout(cct, 10) << "snap_id=" << m_snapshots.size() << ", "                 << "l1_table_offset=" << snapshot.l1_table_offset                 << dendl;
ldout(cct, 10) << "r=" << r << ", "                 << "snap_id=" << m_snapshots.size() << dendl;
ldout(cct, 20) << "snap_id=" << snap_id << ", "                 << "image_extents=" << image_extents << dendl;
ldout(cct, 20) << "r=" << r << ", "                 << "snapshot_delta=" << *snapshot_delta << dendl;
ldout(cct, 20) << "snap_id=" << snap_id << ", "                 << "image_extents=" << image_extents << dendl;
ldout(cct, 20) << "r=" << r << ", "                 << "snapshot_delta=" << snapshot_delta << dendl;
ldout(cct, 10) << "r=" << r << ", "                   << "image_size=" << raw_snapshot->m_snap_info.size << dendl;
ldout(cct, 20) << "snapshot resize " << **previous_size << " -> "                   << new_size << dendl;
ldout(cct, 20) << "zeroing extent " << image_offset << "~"                       << image_length << " at snapshot " << snap_id << dendl;
ldout(cct, 5) << operation << " not supported by current lock owner"                    << dendl;
ldout(m_image_ctx.cct, 20) << "lock owner lost, restarting"                                         << dendl;
ldout(cct, 5) << this << " " << __func__ << ": dest_name=" << dstname                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": dest_name=" << dest_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": "                << "size=" << m_image_ctx.size << ", "                << "new_size=" << size << dendl;
ldout(cct, 5) << this << " " << __func__ << ": "                << "size=" << m_image_ctx.size << ", "                << "new_size=" << size << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": "                << "snap_name=" << srcname << ", "                << "new_snap_name=" << dstname << dendl;
ldout(cct, 5) << this << " " << __func__ << ": "                << "snap_id=" << src_snap_id << ", "                << "new_snap_name=" << dest_snap_name << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_name=" << snap_name                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": limit=" << limit                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": features=" << features                << ", enabled=" << enabled << dendl;
ldout(cct, 5) << this << " " << __func__ << ": features=" << features                << ", enabled=" << enabled << dendl;
ldout(cct, 5) << this << " " << __func__ << ": key=" << key << ", value="                << value << dendl;
ldout(cct, 5) << this << " " << __func__ << ": key=" << key << ", value="                << value << dendl;
ldout(cct, 20) << "list_snaps failed: " << m_image_offset << "~"                     << m_image_length << ": " << cpp_strerror(r) << dendl;
ldout(cct, 20) << "image extent " << m_image_offset << "~"                     << m_image_length << ": list_snaps complete" << dendl;
ldout(cct, 20) << "off=" << snapshot_extent.get_off() << ", "                     << "len=" << snapshot_extent.get_len() << ", "                     << "state=" << snapshot_extent.get_val().state << dendl;
ldout(ictx->cct, 20) << "diff_iterate " << ictx << " off = " << off         << " len = " << len << dendl;
ldout(cct, 5) << "diff_iterate from " << from_snap_id << " to "                << end_snap_id << " size from " << from_size                << " to " << end_size << dendl;
ldout(m_cct, 20) << "m_in_flight_state_updates="                     << m_in_flight_state_updates << dendl;
ldout(cct, 10) << "trying to open image by name " << io_ctx.get_pool_name()                 << "/" << image_name << dendl;
ldout(cct, 20) << "trying to open v1 image by name "                     << other_io_ctx.get_pool_name() << "/"                     << other_image_name << dendl;
ldout(cct, 20) << "trying to open v2 image by id "                     << other_io_ctx.get_pool_name() << "/"                     << other_image_id << dendl;
ldout(cct, 20) << other_image_type << " migration spec: "                   << *other_migration_spec << dendl;
ldout(cct, 10) << io_ctx.get_pool_name() << "/" << image_name << " -> "                 << dest_io_ctx.get_pool_name() << "/" << dest_image_name                 << ", opts=" << opts << dendl;
ldout(cct, 10) << source_spec << " -> "                 << dest_io_ctx.get_pool_name() << "/"                 << dest_image_name << ", opts=" << opts << dendl;
ldout(m_cct, 1) << "failed to open destination image: " << cpp_strerror(r)                    << dendl;
ldout(m_cct, 1) << image_ctx->name << "@" << snap.name                      << " has children" << dendl;
ldout(m_cct, 10) << "mirroring is not enabled for destination pool"                     << dendl;
ldout(m_cct, 10) << from_snap.name << " " << child_image.pool_name << "/"                   << child_image.pool_namespace << "/"                   << child_image.image_name << " (migration_abort="                   << migration_abort << ", reattach_child=" << reattach_child                   << ")" << dendl;
ldout(m_cct, 20) << "src_snap_id_start=" << src_snap_id_start << ", "                   << "src_snap_id_end=" << src_snap_id_end << ", "                   << "dst_snap_id_start=" << dst_snap_id_start << ", "                   << "snap_seqs=" << snap_seqs << dendl;
ldout(cct, 5) << "insufficient permissions to get peer-client-id "                    << "config-key" << dendl;
ldout(cct, 5) << "insufficient permissions to update peer-client-id "                    << "config-key" << dendl;
ldout(cct, 20) << "ictx=" << ictx << " mode=" << mode                 << " relax_same_pool_parent_check="                 << relax_same_pool_parent_check <<  dendl;
ldout(cct, 20) << "ignoring disable command: mirroring is not enabled for "                   << "this image" << dendl;
ldout(cct, 20) << "ictx=" << ictx << ", "                 << "force=" << force << dendl;
ldout(cct, 20) << "pool_id=" << io_ctx.get_id() << ", image_id=" << image_id                 << dendl;
ldout(cct, 20) << "name=" << site_name << ", "                 << "client=" << client_name << dendl;
ldout(cct, 20) << "uuid=" << uuid << ", "                 << "client=" << client_name << dendl;
ldout(cct, 20) << "uuid=" << uuid << ", "                 << "name=" << site_name << dendl;
ldout(cct, 20) << "uuid=" << uuid << ", "                 << "direction=" << mirror_peer_direction << dendl;
ldout(cct, 20) << "uuid=" << uuid << ", "                 << "attributes=" << attributes << dendl;
ldout(cct, 20) << "pool=" << io_ctx.get_pool_name() << ", mode_filter="                 << (mode_filter ? stringify(*mode_filter) : "null")                 << ", start_id=" << start_id << ", max=" << max << dendl;
ldout(cct, 20) << "listing images in group name "   << group_name << " group id " << group_header_oid << dendl;
ldout(cct, 20) << "removing image " << image_id   << " image id " << image_header_oid << dendl;
ldout(cct, 20) << "Opened participating images. " <<      "Deleting snapshots themselves." << dendl;
ldout(cct, 20) << "removing individual snapshot from image " << ictx->name                     << dendl;
ldout(cct, 20) << "Removed images snapshots removing snapshot record."                 << dendl;
ldout(cct, 20) << "rolling back to individual snapshot for image " << ictx->name                     << dendl;
ldout(cct, 20) << "io_ctx=" << &group_ioctx    << " group name " << group_name << " image "    << &image_ioctx << " id " << image_id << dendl;
ldout(cct, 20) << "removing image from group name " << group_name    << " group id " << group_id << dendl;
ldout(cct, 20) << "io_ctx=" << &group_ioctx   << " group name " << group_name << " image "   << &image_ioctx << " name " << image_name << dendl;
ldout(cct, 20) << "adding image to group name " << group_name   << " group id " << group_header_oid << dendl;
ldout(cct, 20) << "adding image " << image_name   << " image id " << image_header_oid << dendl;
ldout(cct, 20) << "io_ctx=" << &group_ioctx  << " group name " << group_name << " image "  << &image_ioctx << " name " << image_name << dendl;
ldout(cct, 20) << "removing image from group name " << group_name    << " group id " << group_id << dendl;
ldout(cct, 20) << "io_ctx=" << &group_ioctx   << " group name " << group_name << dendl;
ldout(cct, 20) << "group_rename " << &io_ctx << " " << src_name                 << " -> " << dest_name << dendl;
ldout(cct, 20) << "Waiting for completion on on_finish: " <<      on_finishes[i] << dendl;
ldout(cct, 20) << "Couldn't find created snapshot with namespace: "                       << ne << dendl;
ldout(cct, 20) << "Removing individual snapshot with name: " <<      ind_snap_name << dendl;
ldout(cct, 20) << src->name                 << (src->snap_name.length() ? "@" + src->snap_name : "")                 << " -> " << destname << " opts = " << opts << dendl;
ldout(ictx->cct, 20) << "snap_set " << ictx << " snap = "                       << (snap_name ? snap_name : "NULL") << dendl;
ldout(ictx->cct, 20) << "snap_set " << ictx << " "                       << "snap_id=" << snap_id << dendl;
ldout(cct, 1) << "namespace support requires nautilus or later OSD"                  << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", off=" << off << ", "                 << "len = " << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", off=" << off << ", "                 << "len = " << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", off=" << off << ", "                 << "len = " << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", off=" << off << ", "                 << "len = " << len << ", data_len " << bl.length() << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", off=" << off << ", "                 << "len = " << len << dendl;
ldout(cct, 20) << "compare_and_write ictx=" << &image_ctx << ", off="                 << off << ", " << "len = " << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << ", " << "flags=" << op_flags << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << ", flags=" << op_flags << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << ", data_len = " << bl.length() << ", "                 << "flags=" << op_flags << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << dendl;
ldout(cct, 20) << "prepend_offset=" << prepend_offset << ", "                   << "prepend_length=" << prepend_length << ", "                   << "write_same_offset=" << write_same_offset << ", "                   << "write_same_length=" << write_same_length << ", "                   << "append_offset=" << append_offset << ", "                   << "append_length=" << append_length << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << ", off=" << off << ", "                 << "len=" << len << dendl;
ldout(cct, 20) << "ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << dendl;
ldout(cct, 20) << &io_ctx << " name=" << image_name << ", id=" << image_id                 << dendl;
ldout(ictx->cct, 10) << "mirroring is not enabled for this image"                           << dendl;
ldout(cct, 15) << "derived image id " << image_id << " from existing "                   << "trash entry" << dendl;
ldout(cct, 10) << "pool usage is lower than or equal to "                     << (threshold * 100)                     << "%" << dendl;
ldout(cct, 5) << "image has snapshots - these must be deleted "                      << "with 'rbd snap purge' before the image can be "                      << "removed." << dendl;
ldout(cct, 5) << "error: image still has watchers" << std::endl                      << "This means the image is still open or the client "                      << "using it crashed. Try again after closing/unmapping "                      << "it or waiting 30s for the crashed client to timeout."                      << dendl;
ldout(cct, 5) << "Image is not in the expected state. Ensure moving "                      << "the image to the trash completed successfully."                      << dendl;
ldout(cct, 5) << "Remove the image from the group and try again."                      << dendl;
ldout(cct, 20) << "trash_remove " << &io_ctx << " " << image_id                 << " " << force << dendl;
ldout(cct, 20) << "trash_restore " << &io_ctx << " " << image_id << " "                 << image_new_name << dendl;
ldout(cct, 20) << "restoring image id " << image_id << " with name "                   << image_name << dendl;
ldout(ictx->cct, 20) << "snap_create " << ictx << " " << snap_name                       << " flags: " << flags << dendl;
ldout(ictx->cct, 20) << "snap_is_protected " << ictx << " " << snap_name         << dendl;
ldout(ictx->cct, 20) << "get_snap_namespace " << ictx << " " << snap_name                       << dendl;
ldout(m_ictx->cct, 10) << "may_copy_on_write " << oid << " " << read_off                         << "~" << read_len << " = " << may << dendl;
ldout(m_ictx->cct, 20) << __func__ << ": " << oid << " "                         << off << "~" << len << " "                         << "journal_tid=" << original_journal_tid << ", "                         << "new_journal_tid=" << new_journal_tid << dendl;
ldout(m_ictx->cct, 20) << "complete_writes() completing " << result                           << dendl;
ldout(cct, 20) << "image_extents=" << image_extents << ", "                 << "on_finish=" << on_finish << dendl;
ldout(cct, 20) << "image_extents=" << image_extents << ", "                 << "on_finish=" << on_finish << dendl;
ldout(cct, 20) << "offset=" << offset << ", "                 << "length=" << length << ", "                << "on_finish=" << on_finish << dendl;
ldout(cct, 20) << "offset=" << offset << ", "                 << "length=" << length << ", "                 << "data_len=" << bl.length() << ", "                 << "on_finish=" << on_finish << dendl;
ldout(cct, 20) << "image_extents=" << image_extents << ", "                 << "on_finish=" << on_finish << dendl;
ldout(cct, 5) << "Parent cache try to re-connect to RO daemon. "                  << "dispatch current request to lower object layer" << dendl;
ldout(cct, 5) << "read from file return error: " << error                  << "file path= " << file_path                  << dendl;
ldout(cct, 5) << "Initial cache settings:"                << " size=" << cache_size                << " num_objects=" << 10                << " max_dirty=" << init_max_dirty                << " target_dirty=" << target_dirty                << " max_dirty_age=" << max_dirty_age << dendl;
ldout(cct, 5) << " cache bytes " << cache_size                << " -> about " << max_dirty_object << " objects" << dendl;
ldout(cct, 20) << "object_no=" << object_no << " " << object_off << "~"                 << object_len << dendl;
ldout(cct, 20) << "object_no=" << object_no << " " << object_off << "~"                 << data.length() << dendl;
ldout(cct, 20) << "object_no=" << object_no << " " << object_off << "~"                 << object_len << dendl;
ldout(cct, 20) << "object_no=" << object_no << " " << object_off << "~"                 << cmp_data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << "completing flush: tid=" << it.first << ", "                   << "r=" << pending_flush_error << dendl;
ldout(m_cct, 20) << "Prior log entries persisted for sync point =["                       << sp << "]" << dendl;
ldout(cct, 10) << "old_features=" << m_image_ctx.features                 << ", new_features=" << new_features                 << ", features_mask=" << features_mask                 << dendl;
ldout(pwl.get_context(), 20) << "write_req=" << *this << " op_set=" << op_set.get()                                   << " operation=" << operation << dendl;
ldout(pwl.get_context(), 20) << "flush_req=" << this                               << " cell=" << this->get_cell() << dendl;
ldout(pwl.get_context(), 20) << "req type=" << get_name() << " "                               << "req=[" << *this << "]" << dendl;
ldout(pwl.get_context(), 20) << "req type=" << get_name() << " "                               << "req=[" << *this << "]" << dendl;
ldout(pwl.get_context(), 20) << "req type=" << get_name() << " "                               << "req=[" << *this << "]" << dendl;
ldout(pwl.get_context(), 20) << "discard_req=" << discard_req                                   << " cell=" << discard_req->get_cell() << dendl;
ldout(pwl.get_context(), 20) << "req type=" << get_name() << " "                               << "req=[" << *this << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "entries to flush wrap around the end of the ring at "                                   << "operation=[" << *operation << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Copying entry for operation at index="                               << operation->get_log_entry()->log_entry_index << " "                               << "from " << &operation->get_log_entry()->ram_entry << " "                               << "to " << operation->get_log_entry()->cache_entry << " "                               << "operation=[" << *operation << "]" << dendl;
ldout(m_image_ctx.cct, 05) << "APPENDING: index="                               << operation->get_log_entry()->log_entry_index << " "                               << "operation=[" << *operation << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "APPENDING: index="                               << operation->get_log_entry()->log_entry_index << " "                               << "pmem_entry=[" << *operation->get_log_entry()->cache_entry                               << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "entry count=" << ops.size() << " "                             << "start address="                             << ops.front()->get_log_entry()->cache_entry << " "                             << "bytes="                             << ops.size() * sizeof(*(ops.front()->get_log_entry()->cache_entry))                             << dendl;
ldout(m_image_ctx.cct, 20) << "flushed_sync_gen in log updated from "                                     << D_RO(pool_root)->flushed_sync_gen << " to "                                     << flushed_sync_gen << dendl;
ldout(cct, 20) << "Freeing " << entry->ram_entry.write_data.oid.pool_uuid_lo                           << "." << entry->ram_entry.write_data.oid.off << dendl;
ldout(m_image_ctx.cct, 15) << "flushing:" << log_entry                                     << " " << *log_entry << dendl;
ldout(m_image_ctx.cct, 20) << "flushing " << ops.size() << ", "                                   << m_ops_to_flush.size() << " remain" << dendl;
ldout(m_image_ctx.cct, 10) << "alloc_fail=" << this->m_alloc_failed_since_retire                                 << ", allocated > high_water="                                 << (this->m_bytes_allocated > high_water_bytes)                                 << ", allocated_entries > high_water="                                 << (m_log_entries.size() > high_water_entries)                                 << dendl;
ldout(m_image_ctx.cct, 15) << "flushed_sync_gen in log updated from "                               << D_RO(pool_root)->flushed_sync_gen << " to "                               << flushed_sync_gen << dendl;
ldout(m_image_ctx.cct, 5) << "can't allocate all data buffers: "                                << pmemobj_errormsg() << ". "                                << *req << dendl;
ldout(m_image_ctx.cct, 20) << "Allocated " << buffer.buffer_oid.oid.pool_uuid_lo                               << "." << buffer.buffer_oid.oid.off                               << ", size=" << buffer.allocation_size << dendl;
ldout(cct, 10) << "old_features=" << m_image_ctx.features                 << ", new_features=" << new_features                 << ", features_mask=" << features_mask                 << dendl;
ldout(image_ctx->cct, 20) << "Initialize RWL cache state with config data. "                            << dendl;
ldout(image_ctx->cct, 20) << "Initialize RWL cache state with data from "                            << "server side"<< dendl;
ldout(m_image_ctx->cct, 20) << __func__ << " Store state: "                              << image_state_json << dendl;
ldout(m_cct, 20) << "block_extent=" << map_entry.block_extent                   << dendl;
ldout(m_image_ctx.cct, 5) << "Removing empty pool file: "                              << this->m_log_pool_name << dendl;
ldout(m_image_ctx.cct, 5) << "Not removing pool file: "                              << this->m_log_pool_name << dendl;
ldout(m_image_ctx.cct, 20) << "Finished appending at "                                   << *new_first_free_entry << dendl;
ldout(m_image_ctx.cct, 15) << "flushing:" << log_entry                                          << " " << *log_entry << dendl;
ldout(m_image_ctx.cct, 15) << "flushing:" << log_entry                                       << " " << *log_entry << dendl;
ldout(m_image_ctx.cct, 10) << "alloc_fail=" << this->m_alloc_failed_since_retire                                 << ", allocated > high_water="                                 << (m_bytes_allocated > high_water_bytes)                                 << ", allocated_entries > high_water="                                 << (m_log_entries.size() > high_water_entries)                                 << dendl;
ldout(cct, 20) << "Old log_entry_index is " << control_block_pos                           << ",New log_entry_index is "                           << (*it)->log_entry_index                           << ",data length is " << data_length << dendl;
ldout(cct, 1) << "Retiring " << retiring_entries.size()                  << " entries" << dendl;
ldout(m_image_ctx.cct, 20)              << "Finished root update: " << "initial_first_valid_entry="              << initial_first_valid_entry << ", " << "m_first_valid_entry="              << m_first_valid_entry << "," << "release space = "              << allocated_bytes << "," << "m_bytes_allocated="              << m_bytes_allocated << "," << "release cached space="              << allocated_bytes << "," << "m_bytes_cached="              << this->m_bytes_cached << dendl;
ldout(cct, 20) << "The write on " << pool_root.first_free_entry                   << " with length " << size << " is split into two: "                   << "pos=" << pool_root.first_free_entry << ", "                   << "length=" << bl1.length() << ";
"    ldout(cct, 20) << "first_free_entry: " << pool_root.first_free_entry                   << " bl length: " << bl.length() << dendl;
ldout(m_image_ctx.cct, 15) << "Another thread is updating pool root"                                 << dendl;
ldout(m_image_ctx.cct, 15) << "Update root number: " << root_updates.size()                             << dendl;
ldout(cct, 20) << "Read at " << log_entry->write_data_pos                   << ", length " << length << dendl;
ldout(cct, 10) << "old_features=" << m_image_ctx.features                 << ", new_features=" << new_features                 << ", features_mask=" << features_mask                 << dendl;
ldout(cct, 1) << "RWL image cache is enabled and "                  << "set discard_granularity_bytes = 0." << dendl;
ldout(m_image_ctx.cct, 1) << "STATS: "                            << "m_free_log_entries=" << m_free_log_entries << ", "                            << "m_log_entries=" << m_log_entries.size() << ", "                            << "m_dirty_log_entries=" << m_dirty_log_entries.size() << ", "                            << "m_bytes_allocated=" << m_bytes_allocated << ", "                            << "m_bytes_cached=" << m_bytes_cached << ", "                            << "m_bytes_dirty=" << m_bytes_dirty << ", "                            << "bytes available=" << m_bytes_allocated_cap - m_bytes_allocated << ", "                            << "m_current_sync_gen=" << m_current_sync_gen << ", "                            << "m_flushed_sync_gen=" << m_flushed_sync_gen << ", "                            << dendl;
ldout(m_image_ctx.cct, 20) << "Entry " << entry_index                                 << " is a sync point. cache_entry=[" << *cache_entry << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Entry " << entry_index                                 << " is a write. cache_entry=[" << *cache_entry << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Entry " << entry_index                                 << " is a write same. cache_entry=[" << *cache_entry << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Entry " << entry_index                                 << " is a discard. cache_entry=[" << *cache_entry << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Entry " << entry_index                                 << " writes. cache_entry=[" << *cache_entry << "]" << dendl;
ldout(cct, 5) << "There's an existing pool file " << m_log_pool_name                  << ", While there's no cache in the image metatata." << dendl;
ldout(cct,1) << "pool " << m_log_pool_name << " has " << m_total_log_entries               << " log entries, " << m_free_log_entries << " of which are free."               << " first_valid=" << m_first_valid_entry               << ", first_free=" << m_first_free_entry               << ", flushed_sync_gen=" << m_flushed_sync_gen               << ", m_current_sync_gen=" << m_current_sync_gen << dendl;
ldout(cct, 20) << "name: " << m_image_ctx.name << " id: " << m_image_ctx.id                 << "image_extents=" << image_extents << ", "                 << "bl=" << bl << ", "                 << "on_finish=" << on_finish << dendl;
ldout(cct, 20) << "read hit on discard entry: log_entry="                       << *discard_entry                       << dendl;
ldout(cct, 20) << "miss_extents=" << read_ctx->miss_extents << ", "                 << "miss_bl=" << read_ctx->miss_bl << dendl;
ldout(m_image_ctx.cct, 20) << "name: " << m_image_ctx.name << " id: " << m_image_ctx.id                                     << "cw_req=" << cw_req << dendl;
ldout(cct, 20) << "detaining guarded request due to in-flight requests: "                   << "req=" << req << dendl;
ldout(m_image_ctx.cct, 20) << "appending " << ops.size() << ", "                                 << m_ops_to_append.size() << " remain" << dendl;
ldout(m_image_ctx.cct, 20) << "not enough free lanes (need "                                 <<  num_lanes                                 << ", have " << m_free_lanes << ") "                                 << *req << dendl;
ldout(m_image_ctx.cct, 20) << "not enough free entries (need "                                 << num_log_entries                                 << ", have " << m_free_log_entries << ") "                                 << *req << dendl;
ldout(m_image_ctx.cct, 1) << "Waiting for allocation cap (cap="                                  << bytes_allocated_cap                                  << ", allocated=" << m_bytes_allocated                                  << ") in write [" << *req << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "flushed: " << log_entry                                     << " invalidating=" << invalidating                                     << dendl;
ldout(m_image_ctx.cct, 20) << "All writes flushed up to sync point="                               << *log_entry << dendl;
ldout(m_image_ctx.cct, 15) << "All writes flushed for sync point="                               << *log_entry << dendl;
ldout(cct,6) << "new sync point = [" << *m_current_sync_point                 << "], prior = [" << *old_sync_point << "]" << dendl;
ldout(cct,6) << "first sync point = [" << *m_current_sync_point                 << "]" << dendl;
ldout(m_image_ctx.cct, 20) << "Flush req=" << flush_req                               << " sync point =" << flush_req->to_append                               << ". Ready to persist." << dendl;
ldout(m_image_ctx.cct, 6) << "Done flush/invalidating (invalidate="                                      << invalidate << ")" << dendl;
ldout(m_image_ctx.cct, 1) << "m_log_entries.size()="                                        << m_log_entries.size() << ", "                                        << "front()=" << *m_log_entries.front()                                        << dendl;
ldout(m_cct, 20) << "Sync point op=[" << *this                   << "] appending" << dendl;
ldout(m_cct, 20) << "Sync point op =[" << *this                   << "] completed" << dendl;
ldout(m_cct, 20) << __func__ << " " << this << " on_persist=" << on_persist                     << dendl;
ldout(m_cct, 5) << "client is not lock owner -- client blocklisted"                      << dendl;
ldout(m_cct, 5) << "client is not lock owner -- no lock detected"                      << dendl;
ldout(m_cct, 5) << "client is not lock owner -- owned by different client"                      << dendl;
ldout(m_cct, 10) << "skipping reacquire since cookie still valid"                     << dendl;
ldout(m_image_ctx.cct, 20) << this << " remote async request progress: "        << request << " @ " << offset        << "/" << total << dendl;
ldout(m_image_ctx.cct, 20) << this << " remote async request finished: "        << request << " = " << r << dendl;
ldout(m_image_ctx.cct, 20) << this << " " << __func__ << ": "                             << "request=" << request << ", r=" << ret_val                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " " << __func__ << ": request_id="                             << request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " " << __func__ << ": async_request_id="                             << async_request_id << " attempts=" << attempts                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " " << __func__ << ": async_request_id="                                   << async_request_id << " timed out" << dendl;
ldout(m_image_ctx.cct, 10) << this << " " << __func__ << ": request_id="                             << request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " current lock owner: "                             << m_owner_client_id << dendl;
ldout(m_image_ctx.cct, 5) << this << " timed out requesting lock: retrying"                              << dendl;
ldout(m_image_ctx.cct, 15) << this << " will retry in " << retry_timeout                               << " seconds" << dendl;
ldout(m_image_ctx.cct, 20) << "scheduling async request time out: " << id                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " async request: " << async_request_id                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " quiesce request "                                       << request << " timed out" << dendl;
ldout(m_image_ctx.cct, 20) << this << " " << request                                 << ": not found in complete" << dendl;
ldout(m_image_ctx.cct, 20) << this << " " << request                               << ": timer task not found" << dendl;
ldout(m_image_ctx.cct, 10) << this << " image exclusively locked announcement"                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " unexpected owner: "                                 << payload.client_id << " != "                                 << m_owner_client_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " queuing release of exclusive lock"                                 << dendl;
ldout(m_image_ctx.cct, 20) << this << " request progress: "          << payload.async_request_id << " @ "          << payload.offset << "/" << payload.total          << dendl;
ldout(m_image_ctx.cct, 10) << this << " request finished: "                               << payload.async_request_id << "="          << payload.result << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote flatten request: "                             << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote resize request: "                             << payload.async_request_id << " "                             << payload.size << " "                             << payload.allow_shrink << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote snap_create request: "                             << payload.async_request_id << " "                             << payload.snap_namespace << " "                             << payload.snap_name << " "                             << payload.flags << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote snap_rename request: "                             << payload.async_request_id << " "                             << payload.snap_id << " to "                             << payload.snap_name << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote snap_remove request: "                             << payload.snap_name << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote snap_protect request: "                               << payload.async_request_id << " "                               << payload.snap_name << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote snap_unprotect request: "                               << payload.async_request_id << " "                               << payload.snap_name << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote rebuild object map request: "                             << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote rename request: "                             << payload.async_request_id << " "                             << payload.image_name << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote update_features request: "                             << payload.async_request_id << " "                             << payload.features << " "                             << (payload.enabled ? "enabled" : "disabled")                             << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote migrate request: "                             << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote sparsify request: "                             << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote metadata_set request: "                               << payload.async_request_id << " "                               << "key=" << payload.key << ", value="                               << *payload.value << dendl;
ldout(m_image_ctx.cct, 10) << this << " remote metadata_remove request: "                               << payload.async_request_id << " "                               << "key=" << payload.key << dendl;
ldout(m_image_ctx.cct, 10) << this << " duplicate quiesce request: "                               << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " quiesce request: "                             << payload.async_request_id << dendl;
ldout(m_image_ctx.cct, 10) << this << " unquiesce request: "                             << payload.async_request_id << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "client: " << client << ", "                 << "image meta: " << *image_client_meta << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << write_data.length()                 << dendl;
ldout(cct, 20) << object_no << " " << object_off << "~" << object_len                 << dendl;
ldout(cct, 20) << ": C_RefreshIfRequired::" << __func__ << ": "                     << "refresh required" << dendl;
ldout(cct, 20) << ": on_ready=" << on_ready << ", on_safe=" << on_safe                 << dendl;
ldout(cct, 20) << ": Op finish event: "                 << "op_tid=" << event.op_tid << dendl;
ldout(cct, 10) << ": unable to locate associated op: assuming previously "                     << "committed." << dendl;
ldout(cct, 20) << ": on_ready=" << on_ready << ", "                 << "on_safe=" << on_safe << ", r=" << r << dendl;
ldout(cct, 20) << ": op_tid=" << op_tid << ", "                 << "r=" << r << dendl;
ldout(cct, 10) << ": hit AIO replay low-water mark: scheduling flush"                   << dendl;
ldout(cct, 10) << ": hit AIO replay high-water mark: pausing replay"                   << dendl;
ldout(cct, 20) << "C_DecodeTag: " << this << " " << __func__ << ": "                 << "allocated journal tag: "                 << "tid=" << tag.tid << ", "                 << "data=" << *tag_data << dendl;
ldout(cct, 20) << "C_DecodeTags: " << this << " " << __func__ << ": "                 << "most recent journal tag: "                 << "tid=" << *tag_tid << ", "                 << "data=" << *tag_data << dendl;
ldout(cct, 20) << this << " C_IsTagOwner::" << __func__ << ": r=" << r     << dendl;
ldout(cct, 20) << this << " " << __func__ << ":  mirror_uuid=" << mirror_uuid                 << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "event=" << event_type << ", "                 << "offset=" << offset << ", "                 << "length=" << length << ", "                 << "flush=" << flush_entry << ", tid=" << tid << dendl;
ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "                 "r=" << r << dendl;
ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "                 << "offset=" << offset << ", "                 << "length=" << length << ", "                 << "r=" << r << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                   << "pending extents: " << event.pending_extents << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "op_tid=" << op_tid << ", "                 << "event=" << event_entry.get_event_type() << dendl;
ldout(cct, 10) << this << " " << __func__ << ": op_tid=" << op_tid << ", "                 << "r=" << r << dendl;
ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "                 << "on_safe=" << on_safe << dendl;
ldout(cct, 20) << this << " " << __func__ << ": tid=" << tid << ", "                 << "on_safe=" << on_safe << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                   << "journal entry already safe" << dendl;
ldout(cct, 20) << this << " " << __func__ << ": tid=" << it->first << " "                 << "r=" << r << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "tag_class=" << m_tag_class << ", "                 << "max_append_size=" << m_max_append_size << dendl;
ldout(cct, 20) << this << " handle_replay_complete: "                     << "handle shut down replay" << dendl;
ldout(cct, 20) << this << " handle_replay_complete: "                     << "shut down replay" << dendl;
ldout(cct, 20) << this << " handle_replay_process_safe: "                         << "shut down replay" << dendl;
ldout(cct, 20) << this << " " << __func__ << ": r=" << r << ", "                 << "tid=" << tid << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "completing tid=" << tid << dendl;
ldout(cct, 20) << this << " " << __func__ << ": r=" << r << ", "                 << "tid=" << tid << dendl;
ldout(cct, 20) << this << " " << __func__ << ": on_state=" << on_state                 << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "refresh_sequence=" << refresh_sequence << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "refresh_sequence=" << refresh_sequence << ", "                 << "tag_tid=" << tag_tid << ", "                 << "tag_data=" << tag_data << dendl;
ldout(cct, 15) << ": notify_id=" << notify_id << ", "                 << "handle=" << handle << dendl;
ldout(m_image_ctx.cct, 20) << "object_no=" << object_no << " r=" << exists        << dendl;
ldout(m_image_ctx.cct, 20) << "object_no=" << object_no << " r="                             << nonexistent << dendl;
ldout(cct, 20) << "detaining object map update due to in-flight update: "                   << "start=" << op.start_object_no << ", "     << "end=" << op.end_object_no << ", "                   << (op.current_state ?                         stringify(static_cast<uint32_t>(*op.current_state)) :                         "")     << "->" << static_cast<uint32_t>(op.new_state) << dendl;
ldout(cct, 20) << "start=" << start_object_no << ", "   << "end=" << end_object_no << ", "                 << (current_state ?                       stringify(static_cast<uint32_t>(*current_state)) : "")   << "->" << static_cast<uint32_t>(new_state) << dendl;
ldout(cct, 5) << "original_size=" << m_original_size << ", "                << "new_size=" << m_new_size << dendl;
ldout(cct, 5) << "original_size=" << m_original_size << ", "                << "new_size=" << m_new_size << dendl;
;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(cct, 5) << this << " " << __func__ << ": r=" << *result << ", "                << "snap_id=" << m_snap_id << dendl;
ldout(cct, 5) << this << " " << __func__                    << ": updating migration snap_map" << dendl;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(cct, 20) << "copyup object req " << req << ", object_no "                     << m_object_no << dendl;
ldout(cct, 20) << "deep copy object req " << req << ", object_no "                     << m_object_no << dendl;
ldout(cct, 20) << this << " " << __func__ << ": features=" << m_features   << dendl;
ldout(cct, 20) << this << " " << __func__ << ": enable_flags="   << m_enable_flags << dendl;
ldout(cct, 20) << this << " " << __func__ << ": new_features="   << m_new_features << ", features_mask=" << m_features_mask   << dendl;
ldout(cct, 20) << "C_RollbackObject: " << __func__ << ": object_num="                   << m_object_num << dendl;
ldout(cct, 20) << this << " " << __func__ << ": features=" << m_features   << dendl;
ldout(cct, 20) << this << " " << __func__ << ": m_mirror_mode="                 << m_mirror_mode << dendl;
ldout(cct, 20) << this << " " << __func__ << ": new_features="   << m_new_features << ", features_mask=" << m_features_mask   << dendl;
ldout(cct, 5) << this << " " << __func__                  << ": re-attempt with a reduced mask" << dendl;
ldout(cct, 20) << this << " " << __func__ << ": disable_flags="   << m_disable_flags << dendl;
ldout(cct, 15) << image_ctx.get_object_name(object_no)                   << " rebuild updating object map "                   << static_cast<uint32_t>(current_state) << "->"                   << static_cast<uint32_t>(new_state) << dendl;
ldout(cct, 10) << this << " scanning pool '" << m_pool.second << "'"                   << dendl;
ldout(cct, 1) << "pool '" << m_pool.second << "' no longer exists"                    << dendl;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(image_ctx.cct, 20) << m_oid << " C_VerifyObjectCallback completed "          << dendl;
ldout(cct, 20) << m_oid << " C_VerifyObjectCallback::should_complete: "     << " r="                   << r << dendl;
ldout(image_ctx.cct, 5) << m_oid       << " C_VerifyObjectCallback::send_list_snaps"                            << dendl;
ldout(cct, 10) << "C_VerifyObjectCallback::object_map_action"     << " object " << image_ctx.get_object_name(m_object_no)     << " state " << (int)state     << " new_state " << (int)new_state << dendl;
ldout(cct, 1) << "object map inconsistent: object "     << image_ctx.get_object_name(m_object_no)     << " marked as " << (int)state << ", but should be "     << (int)new_state << dendl;
ldout(cct, 5) << "snap_name=" << m_snap_name << ", "                << "snap_id=" << m_snap_id << dendl;
ldout(cct, 10) << this << " trim image " << original_size << " -> "   << m_new_size << " periods " << new_num_periods                 << " discard to offset " << m_delete_off                 << " delete objects " << m_delete_start                 << " to " << m_num_objects << dendl;
ldout(image_ctx.cct, 5) << this << " send_pre_trim: "                              << " delete_start_min=" << m_delete_start_min                              << " num_objects=" << m_num_objects << dendl;
ldout(image_ctx.cct, 5) << this << " send_copyup_objects: "                          << " start object=" << copyup_start << ", "                          << " end object=" << copyup_end << dendl;
ldout(image_ctx.cct, 5) << this << " send_remove_objects: "       << " delete_start=" << m_delete_start       << " num_objects=" << m_num_objects << dendl;
ldout(image_ctx.cct, 5) << this << " send_post_trim:"                              << " delete_start_min=" << m_delete_start_min                              << " num_objects=" << m_num_objects << dendl;
ldout(image_ctx.cct, 5) << this << " send_clean_boundary: "       << " delete_off=" << m_delete_off       << " length=" << delete_len << dendl;
ldout(m_image_ctx->cct, 20) << this << " " << __func__ << ": force=" << force         << dendl;
ldout(m_image_ctx->cct, 20) << this << " " << __func__ << ": force=" << force         << dendl;
ldout(cct, 20) << "direction=" << direction << ", enabled=" << enabled                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(m_cct, 20) << "watcher=["                     << "addr=" << watcher.addr << ", "                     << "entity=client." << watcher.watcher_id << "]" << dendl;
ldout(m_cct, 10) << "local entity=" << entity_name << ", "                   << "locker entity=" << m_locker.entity << dendl;
ldout(m_cct, 5) << "locked by external mechanism: "      << "cookie=" << iter->first.cookie << dendl;
ldout(m_cct, 10) << "retrieved exclusive locker: "                 << m_locker->entity << "@" << m_locker->address << dendl;
ldout(cct, 10) << "entity=client." << m_ioctx.get_instance_id() << ", "                 << "cookie=" << m_cookie << dendl;
ldout(m_cct, 10) << "entity=client." << m_ioctx.get_instance_id() << ", "                   << "cookie=" << m_cookie << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 15) << "on_dispatched=" << on_dispatched << ", "                     << "flag=" << flag << dendl;
ldout(cct, 15) << "on_dispatched=" << tag.on_dispatched << ", "                 << "flag=" << flag << dendl;
ldout(cct, 20) << "pending IOs: [" << m_in_flight_flush_tids << "], "                     << "pending flushes=" << m_flush_contexts << dendl;
ldout(cct, 20) << "flush_tid=" << flush_tid << ", ctx=" << on_finish << ", "                 << "flush_contexts=" << m_flush_contexts << dendl;
ldout(m_ictx->cct, 20) << "overlap " << parent_overlap << " "                           << "extents " << *parent_extents << dendl;
ldout(image_ctx->cct, 20) << this->get_op_type() << " "                            << this->m_object_off << "~" << this->m_object_len                            << dendl;
ldout(image_ctx->cct, 20) << "skipping no-op on nonexistent object"                              << dendl;
ldout(image_ctx->cct, 20) << this->m_object_off << "~" << this->m_object_len                            << dendl;
ldout(image_ctx->cct, 20) << "guarding write: snap_seq=" << snap_seq                                << dendl;
ldout(cct, 20) << "start_snap_id=" << start_snap_id << ", "                   << "end_snap_id=" << end_snap_id << ", "                   << "clone_end_snap_id=" << clone_end_snap_id << ", "                   << "diff=" << diff << ", "                   << "diff_interval=" << diff_interval<< ", "                   << "zero_interval=" << zero_interval<< ", "                   << "end_size=" << end_size << ", "                   << "prev_end_size=" << prev_end_size << ", "                   << "exists=" << exists << ", "                   << "whole_object=" << read_whole_object << dendl;
ldout(cct, 20) << "aio_comp=" << aio_comp<< ", "                 << "parent_image_extents " << parent_image_extents << dendl;
ldout(cct, 20) << "r=" << r << ", "                 << "parent_snapshot_delta=" << m_parent_snapshot_delta                 << dendl;
ldout(cct, 20) << "snapshot " << snap_id << ": "                     << (dne ? "DNE" : "zeroed") << " extent "                     << offset << "~" << length << dendl;
ldout(m_image_ctx->cct, 20) << "moving flush contexts to previous op: "                                  << *iter << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << write_data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << "extents=" << extents << ", "                 << "snap_ids=" << snap_ids << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " " << extents                 << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << data.length() << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << object_len << dendl;
ldout(cct, 20) << data_object_name(m_image_ctx, object_no) << " "                 << object_off << "~" << cmp_data.length() << dendl;
ldout(cct, 20) << "object_no=" << object_requests->get_object_no() << ", "                 << object_requests->delayed_requests_size() << " requests, "                 << "dispatch_time=" << object_requests->get_dispatch_time()                 << dendl;
ldout(cct, 20) << "scheduling task " << m_timer_task << " at "                 << object_requests->get_dispatch_time() << dendl;
ldout(cct, 20) << "copying resulting bytes to "                   << reinterpret_cast<void*>(linear.buf) << dendl;
ldout(cct, 20) << "copying resulting " << bl.length() << " bytes to iovec "                   << reinterpret_cast<const void*>(vector.iov) << dendl;
ldout(cct, 20) << "moved resulting " << bufferlist.bl->length() << " "                   << "bytes to bl " << reinterpret_cast<void*>(bufferlist.bl)                   << dendl;
ldout(cct, 20) << "image_extents="                   << sparse_bufferlist.image_extents << ", "                   << "buffer_extent_map=" << buffer_extent_map << dendl;
ldout(cct, 20) << "mapping buffer extent " << buffer_extent_offset                       << "~" << buffer_extent_length << " to image extent "                       << image_extent_offset << "~" << buffer_extent_length                       << dendl;
ldout(cct, 20) << "moved resulting " << *sparse_bufferlist.extent_map                   << " extents of total " << sparse_bufferlist.bl->length()                   << " bytes to bl "                   << reinterpret_cast<void*>(sparse_bufferlist.bl) << dendl;
ldout(cct, 10) << "C_ImageReadRequest: r=" << r                 << dendl;
ldout(cct, 10) << "C_ObjectReadRequest: r=" << r                 << dendl;
ldout(cct, 10) << " got " << extent.extent_map                     << " for " << extent.buffer_extents                     << " bl " << extent.bl.length() << dendl;
ldout(cct, 5) << m_image_ctx << ", "                  << "num=" << m_write_blockers << dendl;
ldout(cct, 5) << "waiting for in-flight writes to complete: "                    << "in_flight_writes=" << m_in_flight_writes << dendl;
ldout(cct, 5) << m_image_ctx << ", "                  << "num=" << m_write_blockers << dendl;
ldout(cct, 20) << m_image_ctx << ", "                   << "write_blockers=" << m_write_blockers << dendl;
ldout(cct, 20) << "object_no=" << object_no << ", "                     << "object_snapshot_delta="                     << object_snapshot_delta << ", "                     << "image_snapshot_delta=" << image_snapshot_delta                     << dendl;
ldout(ictx->cct, 20) << "C_RBD_Readahead on "                         << data_object_name(ictx, object_no) << ": "                         << extent.offset << "~" << extent.length << dendl;
ldout(ictx->cct, 20) << "(readahead logical) " << readahead_offset << "~"                         << readahead_length << dendl;
ldout(ictx->cct, 20) << "(readahead) "                           << data_object_name(ictx,                                               object_extent.object_no) << " "                           << object_extent.offset << "~"                           << object_extent.length << dendl;
ldout(cct, 20) << get_request_type() << ": ictx=" << &image_ctx << ", "                 << "completion=" << aio_comp << dendl;
ldout(cct, 20) << data_object_name(&image_ctx, oe.object_no) << " "                   << oe.offset << "~" << oe.length << " from "                   << oe.buffer_extents << dendl;
ldout(cct, 20) << data_object_name(&image_ctx, oe.object_no) << " "                   << oe.offset << "~" << oe.length << " from "                   << oe.buffer_extents << dendl;
ldout(cct, 20) << data_object_name(&image_ctx, oe.first) << " "                   << oe.second << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "tid=" << tid << ", image_extents=" << image_extents                 << dendl;
ldout(cct, 20) << "object_request=" << req << ", "                 << "append=" << m_append_request_permitted << dendl;
ldout(cct, 20) << "completion=" << comp << ", "                 << "extents=" << m_image_extents                 << dendl;
ldout(cct, 20) << (!deep_copyup && write_op.size() > 2 ?                        "copyup + ops" : !deep_copyup ? "copyup" : "ops")                   << " with current snapshot context" << dendl;
ldout(cct, 20) << "r=" << r << ", "                 << "pending=" << pending_copyups << dendl;
ldout(cct, 5) << "failed getting parent overlap for snap_id: "                      << snap_id << ": " << cpp_strerror(r) << dendl;
ldout(cct, 20) << "image_extents=" << image_extent_map << ", "                 << "object_extents=" << m_copyup_extent_map << dendl;
ldout(cct, 20) << "processing partial copy-up: " << sparse_bufferlist                   << dendl;
ldout(cct, 20) << object_no << " " << object_off << "~" << object_len                 << dendl;
ldout(cct, 20) << "completion " << comp << ", extents " << parent_extents                 << dendl;
ldout(cct, 20) << "cb=" << complete_cb << ", "                 << "pending=" << pending_count << dendl;
ldout(m_image_ctx.cct, 20) << "=" << accept_request << " (request_type="                             << request_type << ")" << dendl;
ldout(m_image_ctx.cct, 10) << ": r=" << r << " shutting_down="                             << shutting_down << dendl;
ldout(cct, 15) << "snap_id=" << m_snap_id << ", "                 << "mirror_peer_uuid=" << m_mirror_peer_uuid << dendl;
ldout(cct, 15) << "skipping removal of snapshot: "                   << "snap_id=" << m_snap_id << ": "                   << "mirror_peer_uuid=" << m_mirror_peer_uuid << ", "                   << "mirror_peer_uuids=" << info.mirror_peer_uuids << dendl;
ldout(cct, 15) << "requires_orphan=" << requires_orphan << ", "                 << "rollback_snap_id=" << m_rollback_snap_id << dendl;
ldout(cct, 15) << "name=" << m_snap_name << ", "                 << "ns=" << ns << dendl;
ldout(m_image_ctx->cct, 15) << "oid=" << m_image_ctx->header_oid << ", "                              << "key=" << get_image_meta_key(m_mirror_uuid)                              << dendl;
ldout(m_image_ctx->cct, 15) << "no snapshot-based mirroring image-meta: "                                << cpp_strerror(r) << dendl;
ldout(m_image_ctx->cct, 15) << "oid=" << m_image_ctx->header_oid << ", "                              << "key=" << get_image_meta_key(m_mirror_uuid)                              << dendl;
ldout(cct, 20) << "previous snapshot snap_id=" << it->first << " "                   << *mirror_ns << dendl;
ldout(cct, 20) << "previous mirror snapshot snap_id=" << it->first << " "                     << *mirror_ns << dendl;
ldout(cct, 10) << "client_id=" << client_id                 << ", snap_name=" << snap_name << dendl;
ldout(m_cct, 20) << "unknown mirror image mode: " << m_mirror_image->mode                     << dendl;
ldout(m_cct, 10) << "image does not exist for mirror image id "                     << m_image_id << dendl;
ldout(m_cct, 10) << "promotion_state=" << *m_promotion_state << ", "                   << "primary_mirror_uuid=" << *m_primary_mirror_uuid << dendl;
ldout(m_cct, 10) << "enabling mirroring on in-progress image replication"                     << dendl;
ldout(cct, 5) << this << " resizing on-disk object map: "                << "ictx=" << &m_image_ctx << ", "                << "oid=" << oid << ", num_objs=" << m_num_objs << dendl;
ldout(cct, 5) << this << " resizing in-memory object map: "  << m_num_objs << dendl;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_oid=" << snap_oid                << dendl;
ldout(cct, 10) << "snapshot " << m_current_snap_id << " does not exist"                     << dendl;
ldout(cct, 1) << "cannot perform fast diff on invalid object map"                  << dendl;
ldout(cct, 1) << "object map too small: "                  << m_object_map.size() << " < " << num_objs << dendl;
ldout(cct, 20) << "object state: " << i << " "                   << static_cast<uint32_t>(prev_object_diff_state)                   << "->" << static_cast<uint32_t>(*diff_it) << " ("                   << static_cast<uint32_t>(object_map_state) << ")"                   << dendl;
ldout(cct, 20) << "object state: " << i << " "                     << "->" << static_cast<uint32_t>(*diff_it) << " ("                     << static_cast<uint32_t>(*it) << ")" << dendl;
ldout(cct, 5) << this << " " << __func__ << ": state=" << m_state << ", "                << "r=" << r << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_oid=" << snap_oid                << dendl;
ldout(cct, 5) << this << " " << __func__ << ": snap_oid=" << snap_oid                << dendl;
ldout(cct, 20) << "ictx=" << &m_image_ctx << ", oid=" << oid << ", "                 << "[" << m_update_start_object_no << ","                        << m_update_end_object_no << ") = "   << (m_current_state ?         stringify(static_cast<uint32_t>(*m_current_state)) : "")   << "->" << static_cast<uint32_t>(m_new_state)   << dendl;
ldout(cct, 10) << this << " " << __func__ << ": oid=" << oid << ", "                 << "num_lockers=" << m_lockers.size() << dendl;
ldout(cct, 20) << this << " " << __func__ << ": "                 << "object_count=" << m_object_count << dendl;
ldout(cct, 20) << "refreshed object map: num_objs="                 << m_on_disk_object_map.size() << dendl;
ldout(cct, 1) << "object map larger than current object count: "                  << m_on_disk_object_map.size() << " != "                  << m_object_count << dendl;
ldout(cct, 5) << "failed to retrieve snapshot: " << cpp_strerror(r)                  << dendl;
ldout(cct, 5) << "failed to open parent for read/write: "                  << cpp_strerror(r) << dendl;
ldout(cct, 5) << "failed to remove trashed clone snapshot: "                  << cpp_strerror(r) << dendl;
ldout(cct, 5) << "failed to get parent trash entry: " << cpp_strerror(r)                  << dendl;
ldout(cct, 5) << "failed to remove parent image:" << cpp_strerror(r)                  << dendl;
ldout(cct, 5) << "failed to close parent image:" << cpp_strerror(r)                  << dendl;
ldout(m_cct, 10) << "name=" << m_image_name << ", "                   << "id=" << m_image_id << ", "                   << "size=" << m_size << ", "                   << "features=" << m_features << ", "                   << "order=" << (uint64_t)m_order << ", "                   << "stripe_unit=" << m_stripe_unit << ", "                   << "stripe_count=" << m_stripe_count << ", "                   << "journal_order=" << (uint64_t)m_journal_order << ", "                   << "journal_splay_width="                   << (uint64_t)m_journal_splay_width << ", "                   << "journal_pool=" << m_journal_pool << ", "                   << "data_pool=" << m_data_pool << dendl;
ldout(m_cct, 5) << "directory entry for image " << m_image_name                    << " already exists" << dendl;
ldout(m_cct, 5) << "namespace " << m_io_ctx.get_namespace()                    << " does not exist" << dendl;
ldout(m_cct, 5) << "id object for  " << m_image_name << " already exists"                    << dendl;
ldout(m_cct, 10) << "error retrieving server supported features set: "                     << cpp_strerror(r) << dendl;
ldout(m_cct, 10) << "limiting default features set to server supported: "       << m_features << dendl;
ldout(cct, 1) << "RBD image format 1 is deprecated. "                  << "Please copy this image to image format 2." << dendl;
ldout(cct, 10) << "image id " << m_image_ctx->id << " does not exist in "                   << "rbd directory, searching in rbd trash..." << dendl;
ldout(cct, 5) << "failed to retrieve name for image id "                    << m_image_ctx->id << dendl;
ldout(cct, 5) << "cannot obtain exclusive lock - "                    << "proceeding due to force flag set" << dendl;
ldout(cct, 20) << "snap_id=" << snap_id << ", "                 << "snap_name=" << snap_info.name << dendl;
ldout(cct, 5) << "failed to locate snapshot '" << m_snap_id << "'"                    << dendl;
ldout(m_cct, 20) << "parent_pool_id=" << parent_io_ctx.get_id() << ", "                   << "parent_image_id=" << parent_image_id << ", "     << "parent_snap=" << parent_snap_name << "/"                   << parent_snap_id << " clone to "                   << "pool_id=" << m_ioctx.get_id() << ", "                   << "name=" << m_name << ", "                   << "opts=" << m_opts << dendl;
ldout(m_cct, 1) << "error listing mirror watchers: " << cpp_strerror(r)                    << dendl;
ldout(m_cct, 20) << "filtering out non-mirror instance: " << w                             << dendl;
ldout(cct, 5) << this << " " << __func__ << ": no migration header found"                  << ", retrying" << dendl;
ldout(cct, 1) << this << " " << __func__ << ": migrating to: "                  << m_migration_spec << dendl;
ldout(cct, 1) << this << " " << __func__ << ": migrating from: "                  << m_migration_spec << dendl;
ldout(cct, 5) << this << " " << __func__ << ": current migration state: "                    << m_migration_spec.state << ", retrying" << dendl;
ldout(cct, 1) << this << " " << __func__ << ": migration type "                  << m_migration_spec.header_type << dendl;
ldout(cct, 1) << this << " " << __func__ << ": migration v1 header detected"                    << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "r=" << *result << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "r=" << *result << dendl;
ldout(cct, 10) << this << " " << __func__ << ": legacy=" << m_legacy_parent                 << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "r=" << *result << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                 << "r=" << *result << dendl;
ldout(cct, 20) << "new snapshot id=" << m_snapc.snaps[i].val                     << " name=" << m_snap_infos[i].name                     << " size=" << m_snap_infos[i].image_size                     << dendl;
ldout(m_cct, 10) << "previous unfinished deferred remove for image: "                     << m_image_id << dendl;
ldout(cct, 10) << this << " " << __func__ << ": "                   << "image_name=" << image_name << ", "                   << "image_id=" << image_id << dendl;
ldout(cct, 10) << "init_layout stripe_unit " << stripe_unit     << " stripe_count " << stripe_count     << " object_size " << layout.object_size     << " prefix " << object_prefix     << " format " << format_string     << dendl;
ldout(cct, 10) << "prune_parent_extents image overlap " << overlap     << ", object overlap " << len     << " from image extents " << objectx << dendl;
ldout(cct, 10) << "canceling async requests: count="                       << async_requests.size() << dendl;
ldout(m_cct, 10) << "delaying unregister until register completed"                       << dendl;
ldout(cct, 1) << pool_desc << " pool " << pool_id << " no longer exists"                  << dendl;
ldout(cct, 15) << "notify_id=" << notify_id << ", "                 << "handle=" << handle << dendl;
ldout(m_cct, 20) << "start_object=" << m_object_no << ", "                   << "end_object=" << m_end_object_no << dendl;
ldout(m_cct, 20) << "object_map_oid=" << object_map_oid << ", "                   << "object_count=" << object_count << dendl;
ldout(m_cct, 20) << "m_src_image_ctx->is_snap_unprotected("                       << snap_seq_it->first << "): r=" << r                       << ", src_unprotected=" << src_unprotected << dendl;
ldout(m_cct, 20) << "snap_name=" << m_snap_name << ", "                   << "snap_id=" << m_prev_snap_id << dendl;
ldout(m_cct, 20) << ""           << "snap_name=" << m_snap_name << ", "           << "snap_id=" << m_prev_snap_id << dendl;
ldout(m_cct, 20) << "snap_name=" << m_snap_name << ", "                   << "snap_id=" << m_prev_snap_id << ", "                   << "size=" << size << ", "                   << "parent_info=["                   << "pool_id=" << parent_spec.pool_id << ", "                   << "image_id=" << parent_spec.image_id << ", "                   << "snap_id=" << parent_spec.snap_id << ", "                   << "overlap=" << parent_overlap << "]" << dendl;
ldout(m_cct, 20) << "mapping source snap id " << m_prev_snap_id << " to "                   << dst_snap_id << dendl;
ldout(m_cct, 20) << "snap_name=" << m_snap_name << ", "                   << "snap_id=" << m_prev_snap_id << dendl;
ldout(m_cct, 20) << "dst_oid=" << m_dst_oid << ", "                   << "src_snap_id_start=" << m_src_snap_id_start << ", "                   << "dst_snap_id_start=" << m_dst_snap_id_start << ", "                   << "snap_map=" << m_snap_map << dendl;
ldout(m_cct, 20) << "read: src_snap_seq=" << index.second << ", "                   << "image_extents=" << image_extents << dendl;
ldout(m_cct, 20) << "dst_snap_id=" << dst_snap_id << ", object_state="                   << static_cast<uint32_t>(object_state) << dendl;
ldout(m_cct, 20) << "src_snap_seq=" << src_snap_seq << ", "                   << "dst_snap_seq=" << dst_snap_seq << ", "                   << "dst_snaps=" << dst_snap_ids << dendl;
ldout(m_cct, 20) << "write op: " << sbe.get_off() << "~"                       << sbe.get_len() << dendl;
ldout(m_cct, 20) << "zero op: " << sbe.get_off() << "~"                         << sbe.get_len() << dendl;
ldout(m_cct, 20) << "DNE snapshot: " << write_read_snap_ids.first                         << dendl;
ldout(m_cct, 20) << "DNE extent: "                           << image_interval.get_off() << "~"                           << image_interval.get_len() << dendl;
ldout(m_cct, 20) << "read op: "                         << "snap_ids=" << write_read_snap_ids << " "                         << image_interval.get_off() << "~"                         << image_interval.get_len() << dendl;
ldout(m_cct, 5) << "failed getting parent overlap for snap_id: "                      << src_snap_seq << ": " << cpp_strerror(r) << dendl;
ldout(m_cct, 20) << "parent read op: "                         << "snap_ids=" << write_read_snap_ids << " "                         << image_offset << "~" << image_length << dendl;
ldout(m_cct, 20) << "src_snap_seq=" << src_snap_seq << ", "                       << "inserting sparse-read zero " << image_offset << "~"                       << image_length << dendl;
ldout(m_cct, 20) << "src_snap_seq=" << src_snap_seq << ", "                         << "object_offset=" << object_extent.offset << ", "                         << "object_length=" << object_extent.length << dendl;
ldout(m_cct, 5) << "failed getting parent overlap for snap_id: "                        << dst_snap_seq << ": " << cpp_strerror(r) << dendl;
ldout(m_cct, 20) << "zeroed extent: "                             << "src_snap_seq=" << src_snap_seq << " "                             << image_interval.get_off() << "~"                             << image_interval.get_len() << dendl;
ldout(m_cct, 20) << "zeroed (hide parent) extent: "                             << "src_snap_seq=" << src_snap_seq << "  "                             << image_interval.get_off() << "~"                             << image_interval.get_len() << dendl;
ldout(m_cct, 20) << "src_snap_seq=" << src_snap_seq << ", "                     << "dst_snap_seq=" << dst_snap_seq << ", "                     << "zero_interval=" << zero_interval << ", "                     << "end_size=" << end_size << dendl;
ldout(m_cct, 20) << "truncate " << object_extent.offset                             << dendl;
ldout(m_cct, 20) << "zero "                           << object_extent.offset << "~"                           << object_extent.length << dendl;
ldout(m_cct, 20) << "dst_snap_seq=" << dst_snap_seq << ", "                     << "end_size=" << end_size << ", "                     << "dst_object_map_state="                     << static_cast<uint32_t>(dst_object_map_state) << dendl;
ldout(m_cct, 20) << "dst_object_may_exist=" << m_dst_object_may_exist                   << dendl;
ldout(cct, 10) << "src_snap_id_start=" << src_snap_id_start << ", "                 << "src_snap_id_end=" << src_snap_id_end << ", "                 << "dst_snap_ids=" << dst_snap_ids << ", "                 << "snap_seqs=" << snap_seqs << ", "                 << "snap_map=" << *snap_map << dendl;
lsubdout(client->cct, client, 0) << __func__ << ": leftover objects on inode 0x"      << std::hex << ino << std::dec << dendl;
lsubdout(client->cct, client, 0) << __func__ << ": leftover delegations on inode 0x"      << std::hex << ino << std::dec << dendl;
lsubdout(client->cct, client, 15) << "inode.get on " << this << " " <<  ino << '.' << snapid        << " now " << _ref << dendl;
lsubdout(client->cct, client, 15) << "inode.put on " << this << " " << ino << '.' << snapid        << " now " << _ref << dendl;
lsubdout(client->cct, client, 10) <<   __func__ << ": delegations empty on " << *this << dendl;
lsubdout(client->cct, client, 10) << __func__ << ": read delegs only on " << *this << dendl;
lsubdout(client->cct, client, 10) << __func__ << ": not broken" << *this << dendl;
lsubdout(client->cct, client, 10) <<   __func__ << ": breaking delegs on " << *this << dendl;
lsubdout(client->cct, client, 10) <<   __func__ << ": inode " << *this << dendl;
lsubdout(client->cct, client, 10) << __func__ <<   ": has_recalled_deleg" << dendl;
lsubdout(client->cct, client, 10) << __func__ <<     ": open for write" << dendl;
lsubdout(client->cct, client, 10) << __func__ << ": cap mismatch, have="      << ccap_string(caps_issued()) << " need=" << ccap_string(need) << dendl;
lsubdout(client->cct, client, 10) << __func__ << " " << *this << " " << ccap_string(dirty_caps) << " -> "           << ccap_string(dirty_caps | caps) << dendl;
cldout(cl, 1) << "C_Block_Sync::finish() for " << ino << " "  << iv << " r==" << r << dendl;
dout(2) << "createobjects " << count << " of " << size << " bytes"    << ", " << inflight << " in flight" << dendl;
dout(2) << "objectrw " << count << " " << size << " " << wrpc     << " " << overlap << " " << rskew << " " << wskew << dendl;
dout(0) << "OSD " << osd << ", offset " << be.first       << ", length " << be.second << dendl;
dout(1) << "OSD Overload workload: SKIPPING file " << filename << " with OSD " << primary_osd << " as first primary. " << dendl;
dout(1) << "OSD Overload workload: USING file " << filename << " with OSD 0 as first primary. " << dendl;
dout(0) << "write total " << (total / el / 1048576.0) << " MB/sec ("   << total << " bytes in " << el << " seconds)" << dendl;
dout(0) << "WARNING: wrong data from OSD, block says fileoffset=" << readoff << " client=" << readclient    << ", should be offset " << wantoff << " client " << client->get_nodeid()    << dendl;
dout(0) << "read total " << (total / el / 1048576.0) << " MB/sec ("   << total << " bytes in " << el << " seconds)" << dendl;
dout(5) << "create_objects " << nobj << " size=" << osize    << " .. doing [" << start << "," << end << ") inc " << inc   << dendl;
dout(5) << "object_rw " << nobj << " size=" << osize << " with "   << wrpc << "% writes"    << ", " << overlappc << "% overlap"   << ", rskew = " << rskew   << ", wskew = " << wskew   << dendl;
dout(0) << "WARNING: wrong data from OSD, block says fileoffset=" << readoff << " client=" << readclient      << ", should be offset " << wantoff << " client " << client->get_nodeid()      << dendl;
dout(0) << "WARNING: wrong data from OSD, block says fileoffset=" << readoff << " client=" << readclient      << ", should be offset " << wantoff << " client " << client->get_nodeid()      << dendl;
dout(1) << "thrash_links " << basedir << " " << dirs << " " << files << " " << depth   << " links " << n   << dendl;
ldout(cct, 1) << "dump_inode: "  << (disconnected ? "DISCONNECTED ":"")  << "inode " << in->ino  << " " << path  << " ref " << in->get_num_ref()  << " " << *in << dendl;
ldout(cct, 20) << __func__ << " mds." << mds   << " trimmed " << trimmed << " dentries" << dendl;
ldout(cct, 15) << "trim_dentry unlinking dn " << dn->name    << " in dir "   << std::hex << dn->dir->parent_inode->ino << std::dec   << dendl;
ldout(cct, 10) << "truncate_seq " << in->truncate_seq << " -> "        << truncate_seq << dendl;
ldout(cct, 10) << "truncate_size " << in->truncate_size << " -> "        << truncate_size << dendl;
ldout(cct, 10) << __func__ << " " << *in << " " << ccap_string(issued)   << " ctime " << ctime << " mtime " << mtime << dendl;
ldout(cct, 10) << " mds time_warp_seq " << time_warp_seq     << " is higher than local time_warp_seq "     << in->time_warp_seq << dendl;
ldout(cct, 0) << "WARNING: " << *in << " mds time_warp_seq "     << time_warp_seq << " is lower than local time_warp_seq "     << in->time_warp_seq     << dendl;
ldout(cct, 10) << " dir is open on empty dir " << in->ino << " with "         << in->dir->dentries.size() << " entries, marking all dentries null" << dendl;
ldout(cct, 12) << __func__ << " '" << dname << "' vino " << in->vino()   << " in dir " << dir->parent_inode->vino() << " dn " << dn   << dendl;
ldout(cct, 12) << " had dentry " << dname        << " with correct vino " << dn->inode->vino()        << dendl;
ldout(cct, 12) << " had dentry " << dname        << " with WRONG vino " << dn->inode->vino()        << dendl;
ldout(cct, 10) << "got dentry lease on " << dn->name        << " dur " << dlease->duration_ms << "ms ttl " << dttl << dendl;
ldout(cct, 10) << __func__ << " " << numdn << " readdir items, end=" << end     << ", hash_order=" << hash_order     << ", readdir_start " << readdir_start     << ", last_hash " << last_hash     << ", next_offset " << readdir_offset << dendl;
ldout(cct, 10) << "insert_trace from " << request->sent_stamp << " mds." << session->mds_num    << " is_target=" << (int)reply->head.is_target    << " is_dentry=" << (int)reply->head.is_dentry    << dendl;
ldout(cct, 10) << " hrm "     << " is_target=" << (int)reply->head.is_target    << " is_dentry=" << (int)reply->head.is_dentry    << dendl;
ldout(cct, 20) << __func__ << " inode dir hash is " << (int)in->dir_layout.dl_dir_hash        << " on " << req->path[0]        << " => " << hash << dendl;
ldout(cct, 20) << __func__ << " dentry dir hash is " << (int)in->dir_layout.dl_dir_hash        << " on " << de->name        << " => " << hash << dendl;
ldout(cct, 20) << __func__ << " " << *in << " is_hash=" << is_hash             << " hash=" << hash << dendl;
ldout(cct, 10) << "check_mds_sessions opening mds." << mds       << " export target mds." << rank << dendl;
ldout(cct, 10) << "make_request got traceless reply, looking up #"    << d->dir->parent_inode->ino << "/" << d->name    << " got_ino " << got_created_ino    << " ino " << created_ino    << dendl;
ldout(cct, 10) << "make_request got traceless reply, forcing getattr on #"         << in->ino << dendl;
ldout(cct, 20) << __func__ << " enter(in:" << *in << ", req:" << req    << " mds:" << mds << ", drop:" << ccap_string(drop) << ", unless:" << ccap_string(unless)    << ", force:" << force << ")" << dendl;
ldout(cct, 25) << __func__ << " exit(in:" << *in << ") released:"    << released << dendl;
ldout(cct, 20) << __func__ << " enter(dn:"    << dn << ")" << dendl;
ldout(cct, 25) << __func__ << " exit(dn:"    << dn << ")" << dendl;
ldout(cct, 20) << __func__ << " enter (req: "   << req << ", mds: " << mds << ")" << dendl;
ldout(cct, 25) << __func__ << " exit (req: "    << req << ", mds " << mds <<dendl;
ldout(cct, 1) << __func__ << " warning, overriding metadata field '" << k    << "' from '" << it->second << "' to '" << v << "'" << dendl;
ldout(cct, 10) << __func__ << " rebuilding request " << request->get_tid()   << " for mds." << mds << dendl;
else ldout(cct, 1) << "Warning -- unable to construct a filepath!"     << " No path, inode, or appropriately-endowed dentry given!"     << dendl;
} else ldout(cct, 1) << "Warning -- unable to construct a filepath!"     << " No path, inode, or dentry given!"     << dendl;
ldout(cct, 10) << __func__ << " tid " << tid    << " fwd " << fwd->get_num_fwd()     << " to mds." << fwd->get_dest_mds()     << ", resending to " << fwd->get_dest_mds()    << dendl;
ldout(cct, 20) << __func__ << " got a reply. Safe:" << is_safe   << " tid " << tid << dendl;
ldout(cct, 0) << "got a duplicate reply on tid " << tid << " from mds "     << mds_num << " safe:" << is_safe << dendl;
ldout(cct, 20) << "got ESTALE on tid " << request->tid     << " from mds." << request->mds << dendl;
ldout(cct, 20) << "handle_client_reply awaiting kickback on tid "         << tid << " " << &cond << dendl;
ldout(cct, 1) << __func__ << ": FULL: cancelling outstanding operations "    << "on " << pool << dendl;
ldout(cct, 4) << __func__ << ": FULL: inode 0x" << std::hex << i->first << std::dec        << " has dirty objects, purging and setting ENOSPC" << dendl;
ldout(cct, 10) << "unmounting: trim pass, size was " << lru.lru_get_size()              << "+" << inode_map.size() << dendl;
ldout(cct, 10) << "unmounting: trim pass, size still " << lru.lru_get_size()                << "+" << inode_map.size() << dendl;
ldout(cct, 1) << __func__ << " epoch " << m->get_epoch()                  << " is identical to or older than our "                  << mdsmap->get_epoch() << dendl;
ldout(cct, 1) << "mds incarnation changed from "        << old_inc << " to " << new_inc << dendl;
ldout(cct, 10) << " caps on " << p->first        << " " << ccap_string(cap.issued)        << " wants " << ccap_string(in->caps_wanted())        << dendl;
ldout(cct, 15) << "link dir " << dir->parent_inode << " '" << name << "' to inode " << in     << " dn " << dn << " (new dn)" << dendl;
ldout(cct, 15) << "link dir " << dir->parent_inode << " '" << name << "' to inode " << in     << " dn " << dn << " (old dn)" << dendl;
ldout(cct, 15) << "unlink dir " << dn->dir->parent_inode << " '" << dn->name << "' dn " << dn   << " inode " << dn->inode << dendl;
ldout(client->cct, 1) << "I/O error from flush on inode " << inode        << " 0x" << std::hex << inode->ino << std::dec        << ": " << r << "(" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 10) << "get_caps " << *in << " need " << ccap_string(need)       << " file_wanted " << ccap_string(file_wanted) << ", EBADF "       << dendl;
ldout(cct, 10) << "get_caps " << *in << " have " << ccap_string(have)   << " need " << ccap_string(need) << " want " << ccap_string(want)   << " revoking " << ccap_string(revoking)   << dendl;
ldout(cct, 10) << __func__ << " " << *in    << " mds." << session->mds_num << " seq " << cap->seq    << " used " << ccap_string(used)    << " want " << ccap_string(want)    << " flush " << ccap_string(flush)    << " retain " << ccap_string(retain)    << " held "<< ccap_string(held)    << " revoking " << ccap_string(revoking)    << " dropping " << ccap_string(dropping)    << dendl;
ldout(cct, 10) << __func__ << " on " << *in    << " wanted " << ccap_string(wanted)    << " used " << ccap_string(used)    << " issued " << ccap_string(issued)    << " revoking " << ccap_string(revoking)    << " flags=" << flags    << dendl;
ldout(cct, 10) << " cap mds." << mds      << " issued " << ccap_string(cap.issued)      << " implemented " << ccap_string(cap.implemented)      << " revoking " << ccap_string(revoking) << dendl;
ldout(cct, 10) << "size " << in->size << " approaching max_size " << in->max_size       << ", reported " << in->reported_size << dendl;
ldout(cct, 20) << " reflushing caps (check_caps) on " << *in         << " to mds." << mds << dendl;
ldout(cct, 10) << __func__ << " " << *in << " cap_snap " << &capsnap << " used " << used      << " WRBUFFER, delaying" << dendl;
ldout(cct, 10) << "flush_snaps mds." << session->mds_num      << " follows " << p.first      << " size " << capsnap.size      << " mtime " << capsnap.mtime      << " dirty_data=" << capsnap.dirty_data      << " writing=" << capsnap.writing      << " on " << *in << dendl;
ldout(cct, 10) << __func__ << " changing auth cap: "         << "add myself to new auth MDS' flushing caps list" << dendl;
ldout(cct, 10) << __func__ << " issued " << ccap_string(old_caps) << " -> " << ccap_string(cap.issued)    << " from mds." << mds    << " on " << *in    << dendl;
ldout(cct, 10) << __func__ << " mds." << mds << " max " << max     << " caps " << caps_size << dendl;
ldout(cct, 10) << __func__ << " on " << *in << " flushing "     << ccap_string(it->second) << " want " << want     << " last " << it->first << dendl;
ldout(cct, 10) << __func__ << " want " << want  << " (last is " << last_flush_tid << ", "    << num_flushing_caps << " total flushing)" << dendl;
ldout(cct, 10) << " waiting on mds." << p.first << " tid " << oldest_tid       << " (want " << want << ")" << dendl;
ldout(cct, 20) << " reflushing caps (early_kick) on " << *in     << " to mds." << session->mds_num << dendl;
ldout(cct, 20) << __func__ << " " << realm->ino << " " << realm   << " " << realm->nref << " -> " << (realm->nref - 1) << dendl;
ldout(cct, 10) << __func__ << " " << *realm      << " " << realm->parent << " -> " << parent << dendl;
ldout(cct, 10) << __func__ << " " << *realm << " seq " << info.seq() << " > " << realm->seq        << dendl;
ldout(cct, 10) << __func__ << " " << *realm << " seq " << info.seq()        << " <= " << realm->seq << " and same parent, SKIPPING" << dendl;
ldout(cct, 10) << " NOT moving " << *in << " from _newer_ realm "      << *in->snaprealm << dendl;
ldout(cct, 5) << __func__ << " ino " << m->get_ino() << " mseq " << m->get_mseq()  << " IMPORT from mds." << mds << dendl;
ldout(cct, 5) << __func__ << " ino " << m->get_ino() << " mseq " << m->get_mseq()  << " EXPORT from mds." << mds << dendl;
ldout(cct, 10) << __func__ << " on ino " << *in    << " size " << in->size << " -> " << m->get_size()    << dendl;
ldout(cct, 0) << __func__ << " mds." << session->mds_num                   << " got unexpected flush ack tid " << flush_ack_tid                   << " expected is " << it->first << dendl;
ldout(cct, 5) << __func__ << " mds." << session->mds_num   << " cleaned " << ccap_string(cleaned) << " on " << *in   << " with " << ccap_string(dirty) << dendl;
ldout(cct, 5) << "  flushing_caps " << ccap_string(in->flushing_caps)       << " -> " << ccap_string(in->flushing_caps & ~cleaned) << dendl;
ldout(cct, 5) << __func__ << " mds." << mds << " flushed snap follows " << follows       << " on " << *in << dendl;
ldout(cct, 5) << __func__ << " DUP(?) mds." << mds << " flushed snap follows " << follows     << " on " << *in << dendl;
ldout(cct, 10) << __func__ << " '" << name << "' ino " << ino   << " in dir " << dirino << dendl;
ldout(cct, 5) << __func__ << " on in " << m->get_ino()   << " mds." << mds << " seq " << m->get_seq()  << " caps now " << ccap_string(new_caps)  << " was " << ccap_string(cap->issued)  << (was_stale ? " (stale)" : "") << dendl;
ldout(cct, 10) << __func__ << ": resolved " << mds_spec << " to role '"      << role << "' aka " << info.human_name() << dendl;
ldout(cct, 10) << __func__ << ": validated gid " << mds_gid << " aka "                     << info.human_name() << dendl;
ldout(cct, 10) << __func__ << ": resolved name '" << mds_spec                     << "' to " << info.human_name() << dendl;
ldout(cct, 10) << __func__ << " finished waiting for FSMap version "   << fsmap_latest << dendl;
ldout(cct, 4) << __func__ << ": new command op to " << target_gid        << " tid=" << op.tid << cmd << dendl;
ldout(cct, 2) << "waiting for " << mds_ranks_closing.size() << " mds session(s) to close (timeout: "                  << timo << "s)" << dendl;
ldout(cct, 10) << "waiting on " << mds_requests.size() << " requests"       << dendl;
ldout(cct, 2) << "cache still has " << lru.lru_get_size()            << "+" << inode_map.size() << " items"     << ", waiting (for caps to release?)"            << dendl;
ldout(cct, 5) << __func__ << ": no session with rank=0 -- not sending metric"                  << dendl;
ldout(cct, 20) << " bad lease, cap_ttl " << s.cap_ttl << ", cap_gen " << s.cap_gen                   << " vs lease_gen " << dn->lease_gen << dendl;
ldout(cct, 20) << __func__ << " have " << *dn << " from mds." << dn->lease_mds        << " ttl " << dn->lease_ttl << " seq " << dn->lease_seq << dendl;
ldout(cct, 10) << __func__ << " concluded ENOENT locally for "    << *dir << " dn '" << dname << "'" << dendl;
ldout(cct, 20) << __func__ << ": successfully created directory "     << filepath(cur->ino).get_path() << dendl;
ldout(cct, 10) << __func__ << " mask " << mask << " issued " <<    ccap_string(issued) << dendl;
ldout(cct, 10) << __func__ << " caller " << perms.uid() << ":" << perms.gid()     << " != cap dirtier " << in->cap_dirtier_uid << ":"     << in->cap_dirtier_gid << ", forcing sync setattr"     << dendl;
ldout(cct, 10) << __func__ << " on " << in->ino << " snap/dev" << in->snapid    << " mode 0" << oct << in->mode << dec    << " mtime " << in->mtime << " ctime " << in->ctime << dendl;
ldout(cct, 10) << __func__ << " on " << in->ino << " snap/dev" << in->snapid    << " mode 0" << oct << in->mode << dec    << " mtime " << in->mtime << " ctime " << in->ctime << dendl;
ldout(cct, 10) << __func__ << " '" << de->d_name << "' -> " << inodeno_t(de->d_ino)    << " type " << (int)de->d_type << " w/ next_off " << hex << next_off << dec << dendl;
ldout(cct, 10) << __func__ << " " << dirp << " on " << dirp->inode->ino << " fg " << fg   << " offset " << hex << dirp->offset << dec << dendl;
ldout(cct, 10) << __func__ << " " << dirp << " got frag " << dirp->buffer_frag     << " size " << dirp->buffer.size() << dendl;
ldout(cct, 10) << __func__ << " " << dirp << " on " << dirp->inode->ino    << " last_name " << dirp->last_name << " offset " << hex << dirp->offset << dec    << dendl;
ldout(cct, 15) << " de " << de.d_name << " off " << hex << dn->offset << dec     << " = " << r << dendl;
ldout(cct, 10) << __func__ << " " << *dirp->inode << " offset " << hex << dirp->offset   << dec << " at_end=" << dirp->at_end()   << " hash_order=" << dirp->hash_order() << dendl;
ldout(cct, 10) << "offset " << hex << dirp->offset << dec    << " snapid " << dirp->inode->snapid << " (complete && ordered) "    << dirp->inode->is_complete_and_ordered()    << " issued " << ccap_string(dirp->inode->caps_issued())    << dendl;
ldout(cct, 10) << "frag " << fg << " buffer size " << dirp->buffer.size()     << " offset " << hex << dirp->offset << dendl;
ldout(cct, 15) << " de " << de.d_name << " off " << hex << next_off - 1 << dec       << " = " << r << dendl;
ldout(cct, 5) << "open success, fh is " << f << " combined IMMUTABLE SNAP caps "      << ccap_string(in->caps_issued()) << dendl;
ldout(cct, 1) << __func__ << " " << f << " on inode " << *in << " caught async_err = "                  << cpp_strerror(err) << dendl;
ldout(cct, 8) << "Unable to get caps after open of inode " << *in <<     " . Denying open: " <<     cpp_strerror(result) << dendl;
ldout(cct, 10) << " min_bytes=" << f->readahead.get_min_readahead_size()                 << " max_bytes=" << f->readahead.get_max_readahead_size()                 << " max_periods=" << conf->client_readahead_max_periods << dendl;
ldout(cct, 20) << "readahead " << readahead_extent.first << "~" << readahead_extent.second       << " (caller wants " << off << "~" << len << ")" << dendl;
ldout(cct, 1) << __func__ << ": " << f << " on inode " << *in << " caught async_err = "                  << cpp_strerror(err) << dendl;
ldout(cct, 5) << "fsync(" << fd << ", " << syncdataonly                  << ") = 0, async_err = " << r << dendl;
ldout(cct, 5) << "fsync(" << fd << ", " << syncdataonly << ") = "                  << r << dendl;
ldout(cct, 10) << "ino " << in->ino << " has " << in->cap_refs[CEPH_CAP_FILE_BUFFER]       << " uncommitted, waiting" << dendl;
ldout(cct, 8) << "ino " << in->ino << " failed to commit to disk! "    << cpp_strerror(-r) << dendl;
ldout(cct, 1) << "underlying call to statfs returned error: "                  << cpp_strerror(rval)                  << dendl;
ldout(cct, 10) << __func__ << " ino " << in->ino   << (lock_type == CEPH_LOCK_FCNTL ? " fcntl" : " flock")   << " type " << fl->l_type << " owner " << owner   << " " << fl->l_start << "~" << fl->l_len << dendl;
ldout(cct, 10) << __func__ << " ino " << in->ino << ", " << nr_fcntl_locks   << " fcntl locks, " << nr_flock_locks << " flock locks" <<  dendl;
ldout(cct, 10) << __func__ << " cb " << args->handle   << " invalidate_ino_cb " << args->ino_cb   << " invalidate_dentry_cb " << args->dentry_cb   << " switch_interrupt_cb " << args->switch_intr_cb   << " remount_cb " << args->remount_cb   << dendl;
ldout(cct, 3) << "op: client->lazyio_propagate(" << fd          << ", " << offset << ", " << count << ")" << dendl;
ldout(cct, 3) << "op: client->lazyio_synchronize(" << fd          << ", " << offset << ", " << count << ")" << dendl;
ldout(cct, 3) << __func__ << " " << vparent << " " << name   << " -> " << r << " (" << hex << attr->st_ino << dec << ")" << dendl;
ldout(cct, 3) << __func__ << " " << vparent << " " << name   << " -> " << r << " (" << hex << stx->stx_ino << dec << ")" << dendl;
ldout(cct, 1) << "WARNING: ll_forget on " << ino << " " << count    << ", which only has ll_ref=" << in->ll_ref << dendl;
ldout(cct, 8) << __func__ << " " << vino << " mask " << hex << mask << dec  << dendl;
ldout(cct, 3) << __func__ << "(" << in->ino << ", \"" << name << "\") = " <<    res << dendl;
ldout(cct, 8) << "_mknod(" << dir->ino << " " << name << ", 0" << oct  << mode << dec << ", " << rdev << ", uid " << perms.uid()  << ", gid " << perms.gid() << ")" << dendl;
ldout(cct, 3) << "ll_mknod " << vparent << " " << name   << " = " << r << " (" << hex << attr->st_ino << dec << ")" << dendl;
ldout(cct, 3) << "ll_mknodx " << vparent << " " << name   << " = " << r << " (" << hex << stx->stx_ino << dec << ")" << dendl;
ldout(cct, 8) << "_create(" << dir->ino << " " << name << ", 0" << oct <<    mode << dec << ")" << dendl;
ldout(cct, 8) << "create(" << path << ", 0" << oct << mode << dec  << " layout " << stripe_unit  << ' ' << stripe_count  << ' ' << object_size  <<") = " << res << dendl;
ldout(cct, 8) << "_mkdir(" << dir->ino << " " << name << ", 0" << oct  << mode << dec << ", uid " << perm.uid()  << ", gid " << perm.gid() << ")" << dendl;
ldout(cct, 3) << "ll_mkdir " << vparent << " " << name   << " = " << r << " (" << hex << attr->st_ino << dec << ")" << dendl;
ldout(cct, 3) << "ll_mkdirx " << vparent << " " << name   << " = " << r << " (" << hex << stx->stx_ino << dec << ")" << dendl;
ldout(cct, 8) << "_symlink(" << dir->ino << " " << name << ", " << target  << ", uid " << perms.uid() << ", gid " << perms.gid() << ")"  << dendl;
ldout(cct, 8) << "_symlink(\"" << path << "\", \"" << target << "\") = " <<    res << dendl;
ldout(cct, 3) << "ll_symlink " << vparent << " " << name << " -> " << value  << dendl;
ldout(cct, 3) << "ll_symlink " << vparent << " " << name   << " = " << r << " (" << hex << attr->st_ino << dec << ")" << dendl;
ldout(cct, 3) << "ll_symlinkx " << vparent << " " << name << " -> " << value  << dendl;
ldout(cct, 3) << "ll_symlinkx " << vparent << " " << name   << " = " << r << " (" << hex << stx->stx_ino << dec << ")" << dendl;
ldout(cct, 8) << "_unlink(" << dir->ino << " " << name  << " uid " << perm.uid() << " gid " << perm.gid()  << ")" << dendl;
ldout(cct, 8) << "_rmdir(" << dir->ino << " " << name << " uid "  << perms.uid() << " gid " << perms.gid() << ")" << dendl;
ldout(cct, 8) << "_rename(" << fromdir->ino << " " << fromname << " to "  << todir->ino << " " << toname  << " uid " << perm.uid() << " gid " << perm.gid() << ")"  << dendl;
ldout(cct, 3) << "ll_rename " << vparent << " " << name << " to "   << vnewparent << " " << newname << dendl;
ldout(cct, 8) << "_link(" << in->ino << " to " << dir->ino << " " << newname  << " uid " << perm.uid() << " gid " << perm.gid() << ")" << dendl;
ldout(cct, 3) << "ll_link " << vino << " to " << vnewparent << " " <<    newname << dendl;
ldout(cct, 3) << "ll_opendir " << vino << " = " << r << " (" << *dirpp << ")"  << dendl;
ldout(cct, 3) << "ll_open " << vino << " " << ceph_flags_sys2wire(flags) <<      " = " << r << " (" << fhptr << ")" << dendl;
ldout(cct, 8) << "_ll_create " << vparent << " " << name << " 0" << oct <<    mode << dec << " " << ceph_flags_sys2wire(flags) << ", uid " << perms.uid()  << ", gid " << perms.gid() << dendl;
ldout(cct, 8) << "_ll_create " << vparent << " " << name << " 0" << oct <<    mode << dec << " " << ceph_flags_sys2wire(flags) << " = " << r << " (" <<    *fhp << " " << hex << ino << dec << ")" << dendl;
ldout(cct, 3) << "ll_read " << fh << " " << off << "~" << len << " = " << r  << dendl;
ldout(cct, 1) << "ll_block_write for " << vino.ino << "." << blockid  << dendl;
ldout(cct, 1) << "ll_commit_blocks for " << vino.ino << " from "    << offset << " to " << length << dendl;
ldout(cct, 3) << "ll_write " << fh << " " << fh->inode->ino << " " << off <<    "~" << len << dendl;
ldout(cct, 3) << "ll_write " << fh << " " << off << "~" << len << " = " << r  << dendl;
ldout(cct, 3) << __func__ << " (fh)" << fh << " " << fh->inode->ino << " " <<    dendl;
ldout(cct, 10) << __func__ << " on pool " << pool_id << " ns " << pool_ns       << " rd_err = " << rd_ret << " wr_err = " << wr_ret << dendl;
ldout(cct, 10) << __func__ << " on pool " << pool_id << " ns " << pool_ns       << " rd_err = " << rd_ret << " wr_err = " << wr_ret << dendl;
ldout(cct, 10) << __func__ << " on pool " << pool_id << " ns " << pool_ns     << " need " << ccap_string(need) << ", but no read perm" << dendl;
ldout(cct, 10) << __func__ << " on pool " << pool_id << " ns " << pool_ns     << " need " << ccap_string(need) << ", but no write perm" << dendl;
lsubdout(client->cct, client, 0) << __func__ <<   ": delegation return timeout for inode 0x" <<   std::hex << in->ino << ". Forcibly unmounting client. "<<   client << std::dec << dendl;
ldout(cct, 10) << __func__ << " Priority: " << static_cast<uint32_t>(pri)                 << " Request: " << request << dendl;
ldout(cct, 10) << __func__ << " old: " << old_bytes                 << " new: " << new_bytes << dendl;
dout(5) << __func__ << " error '" << status.getState() <<      "' while parsing options '" << opt_str << "'" << dendl;
lgeneric_dout(cct, 1) << " set rocksdb option " << it->first      << " = " << it->second << dendl;
dout(10) << __func__ << " set bloom filter bits per key to "      << bloom_bits << dendl;
dout(10) << __func__ << " block size " << cct->_conf->rocksdb_block_size           << ", block_cache size " << byte_u_t(block_cache_size)    << ", row_cache size " << byte_u_t(row_cache_size)    << ";
shards "  dout(10) << __func__ << " column_name=" << cf_name << " shard_idx=" << shard_idx <<    " hash_l=" << hash_l << " hash_h=" << hash_h << " handle=" << (void*) handle << dendl;
dout(5) << __func__ << " error '" << status.getState() <<      "' while parsing options '" << opts_str << "'" << dendl;
dout(20) << __func__ << " RocksDB perf is disabled, can't probe for stats"      << dendl;
dout(10) << "flushing batch, " << keys_in_batch << " keys, for "             << bytes_in_batch << " bytes" << dendl;
dout(25) << "moving " << (void*)handle << "/" << pretty_binary_string(raw_key.ToString()) << " to " << (void*)new_handle << "/" << pretty_binary_string(new_raw_key) << " size " << value.size() << dendl;
dout(5) << "Processing column=" << name     << " handle=" << handle.get() << dendl;
ldpp_dout(op,10) << "scheduling with "       << s->cct->_conf.get_val<std::string>("rgw_scheduler_type")       << " client=" << static_cast<int>(client)       << " cost=" << cost << dendl;
dout(1) << "====== starting new request req=" << hex << req << dec   << " =====" << dendl;
dout(0) << "ERROR: client_io->complete_request() returned "            << e.what() << dendl;
dout(1) << "====== req done req=" << hex << req << dec   << " op status=" << op_ret   << " http_status=" << s->err.http_ret   << " latency=" << lat   << " ======"   << dendl;
ldout(s->cct, 4) << "Request failed with " << op_ret          << ": " << s->err.message << dendl;
ldout(cct, 10) << "master zone rejecting period id="        << period.get_id() << " epoch=" << period.get_epoch() << dendl;
ldout(cct, 4) << "already have epoch >= " << period.get_epoch()        << " for period " << period.get_id() << dendl;
ldout(cct, 10) << "discarding period " << period.get_id()          << " with realm epoch " << period.get_realm_epoch()          << " older than current epoch " << current_epoch << dendl;
ldout(cct, 4) << "attached period " << period.get_id()          << " to history, but the history contains newer periods" << dendl;
ldout(cct, 4) << "period " << period.get_id()        << " is newer than current period " << current_period.get_id()        << ", updating realm's current period and notifying zone" << dendl;
ldout(cct, 4) << "period epoch " << period.get_epoch()      << " is newer than current epoch " << current_period.get_epoch()      << ", updating period's latest epoch and notifying zone" << dendl;
dout(0)        << __func__        << " ERROR: librados::Rados::pool_create returned " << cpp_strerror(-r)        << " (this can be due to a pool or placement group misconfiguration, e.g."        << " pg_num < pgp_num or mon_max_pg_per_osd exceeded)"        << dendl;
dout(10) << __func__ << " warning: failed to set pg_autoscale_bias on "   << pool.name << dendl;
dout(10) << __func__ << " warning: failed to set pg_num_min on "   << pool.name << dendl;
dout(10) << __func__ << " warning: failed to set recovery_priority on "   << pool.name << dendl;
ldout(cct, 0) << __func__ << " failed to open file=" << ext_map                  << " : " << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << __func__ << " failed to stat file=" << ext_map                  << " : " << cpp_strerror(-ret) << dendl;
ldout(store->ctx(), 1) << "Cannot load plugin for compression type "        << compression_type << dendl;
ldpp_dout(dpp, 0) << __func__ << " failed to parse bucket instance: "                 << bucket_instance_id << " skipping" << dendl;
ldpp_dout(dpp, 0) << __func__ << ": Skipping stale bucket instance: "                           << orphan_bucket.name << ": "                           << orphan_bucket.bucket_id << dendl;
ldpp_dout(dpp, 0) << __func__ << ": reshard in progress. Skipping "                           << orphan_bucket.name << ": "                           << orphan_bucket.bucket_id << dendl;
ldpp_dout(dpp, 5) << __func__ << "skipping stat as the object " << entry.key.name                              << "fits in a head" << dendl;
ldout(store->ctx(), 20) << "RGWRadosList::" << __func__ <<    " bucket=" << bucket <<    ", has_manifest=" << !!result.manifest <<    dendl;
ldout(store->ctx(), 20) << "radoslist processing object=\"" <<      oid << "\"" << dendl;
ldout(store->ctx(), 15) <<      "radoslist stopped loop at already visited object=\"" <<      oid << "\"" << dendl;
ldout(store->ctx(), 15) << "radoslist added to visited list DLO=\"" <<      oid << "\"" << dendl;
ldout(store->ctx(), 25) << "radoslist DLO oid=\"" << oid <<      "\" added bucket=\"" << bucket_name << "\" prefix=\"" <<      prefix << "\" to process list" << dendl;
ldout(store->ctx(), 15) << "radoslist added to visited list SLO=\"" <<      oid << "\"" << dendl;
ldout(store->ctx(), 0) << "ERROR: failed to decode slo manifest for " << oid << dendl;
ldout(store->ctx(), 25) << "radoslist SLO oid=\"" << oid << "\" added bucket=\"" << bucket_name << "\" obj_key=\"" << obj_key << "\" to process list" << dendl;
ldpp_dout(dpp, 10) << "RGWRadosList::" << __func__ <<    " bucket_instance_id=" << bucket_instance_id <<    ", prefix=" << prefix <<    ", entries_filter.size=" << entries_filter.size() << dendl;
ldpp_dout(dpp, -1) << __func__ <<      ": ERROR: RGWRados::get_bucket_instance_info() returned ret=" <<      ret << dendl;
ldpp_dout(dpp, 20) << "obj entry: " << entry.key.name <<   " [" << entry.key.instance << "]" << dendl;
ldpp_dout(dpp, 20) << __func__ << ": entry.key.name=" << entry.key.name << " entry.key.instance=" << entry.key.instance << dendl;
ldpp_dout(dpp, -1) << "RGWRadosList::" << __func__ <<     ": ERROR: process_bucket();
bucket_id=" <<    ldpp_dout(dpp, -1) << "RGWRadosList::" << __func__ <<      ": ERROR: get_bucket_info returned ret=" << ret << dendl;
ldpp_dout(dpp, 20) << "RGWRadosList::" << __func__ << ": WARNING: call to list_objects of multipart namespace got ENOENT;
"      ldpp_dout(dpp, -1) << "RGWRadosList::" << __func__ << ": ERROR: list_objects op returned ret=" << ret << dendl;
ldpp_dout(dpp, 20) << "RGWRadosList::" << __func__ <<   " processing incomplete multipart entry " <<   entry << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << "(): trim of shard=" << shard    << " marker=" << marker << " returned r=" << r << dendl;
ldout(cct, 10) << "trimming log shard " << i            << " at marker=" << m            << " last_trim=" << last_trim[i] << dendl;
ldout(cct, 4) << "failed to lock " << lock_oid << ", trying again in "            << interval.sec() << "s" << dendl;
dout(0) << "NOTICE: bad content-md5 provided (not base64),"                << " aborting request p=" << *p << " " << (int)*p << dendl;
ldpp_dout(dpp, 10) << "NOTICE: failed to parse auth header (s=" << s << ")"               << dendl;
dout(0) << "NOTICE: bad content-md5 provided (not base64)"            << ", aborting request" << dendl;
ldpp_dout(dpp, 10) << "canonical request hash = "                 << canonical_req_hash << dendl;
ldpp_dout(dpp, 10) << "string to sign = "                 << rgw::crypt_sanitize::log_content{string_to_sign}                 << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: cannot parse the data size"                   << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: cannot find the '=' separator"                   << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: no new line at signature end"                   << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: signature.length() != 64"                   << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: string_to_sign=\n" << string_to_sign                 << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: ERROR: chunk signature mismatch"                   << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: declared signature="                   << chunk_meta.get_signature() << dendl;
ldout(cct, 20) << "AWSv4ComplMulti: calculated signature="                   << calc_signature << dendl;
ldout(cct, 10) << "ERROR: signature of last chunk does not match"                   << dendl;
ldout(cct, 10) << "ERROR: x-amz-content-sha256 does not match"                   << dendl;
ldout(cct, 10) << "ERROR:   grab_aws4_sha256_hash()="                   << payload_hash << dendl;
ldout(cct, 10) << "ERROR:   expected_request_payload_hash="                   << expected_request_payload_hash << dendl;
ldout(conn->cct, 20) << "Kafka run: n/ack received, invoking callback with tag=" <<           *tag << " and result=" << rd_kafka_err2str(result) << dendl;
ldout(conn->cct, 10) << "Kafka run: unsolicited n/ack received with tag=" <<         *tag << dendl;
ldout(store->ctx(), 20) << "quota: can't use cached stats, exceeded soft threshold (size): "        << cached_stats.size_rounded << " >= " << quota.max_size_soft_threshold << dendl;
ldout(store->ctx(), 20) << "quota: can't use cached stats, exceeded soft threshold (num objs): "        << cached_stats.num_objects << " >= " << quota.max_objs_soft_threshold << dendl;
ldout(store->ctx(), 0) << "could not get bucket stats for bucket="                           << _b.name << dendl;
dout(10) << "quota exceeded: stats.size_rounded=" << stats.size_rounded             << " size=" << new_size << " "             << entity << "_quota.max_size=" << qinfo.max_size << dendl;
dout(10) << "quota exceeded: stats.num_objects=" << stats.num_objects             << " " << entity << "_quota.max_objects=" << qinfo.max_objects             << dendl;
dout(10) << "quota exceeded: stats.size=" << stats.size             << " size=" << size << " "             << entity << "_quota.max_size=" << qinfo.max_size << dendl;
dout(10) << "quota exceeded: stats.num_objects=" << stats.num_objects             << " " << entity << "_quota.max_objects=" << qinfo.max_objects             << dendl;
ldout(store->ctx(), 20) << entity                            << " quota: max_objects=" << quota.max_objects                            << " max_size=" << quota.max_size << dendl;
ldout(store->ctx(), 20) << entity << " quota OK:"                            << " stats.num_objects=" << stats.num_objects                            << " stats.size=" << stats.size << dendl;
ldout(store->ctx(), 0) << __func__ << ": resharding needed: stats.num_objects=" << num_objs             << " shard max_objects=" <<  max_objs_per_shard * num_shards << dendl;
ldout(cct, 0) << "placement target (" << placement_rule << ")"      << " doesn't exist in the placement targets of zonegroup"      << " (" << zone_svc->get_zonegroup().api_name << ")" << dendl;
ldout(cct, 0) << "bucket already exists on a different placement rule: "        << " selected_rule= " << selected_placement_rule        << " existing_rule= " << bucket_info.placement_rule << dendl;
ldpp_dout(dpp, 1) << "waiting for incremental sync to catch up:\n"        << "      local status: " << status << '\n'        << "    remote markers: " << remote_markers << dendl;
ldpp_dout(dpp, 1) << "bucket sync caught up with source:\n"      << "      local status: " << status << '\n'      << "    remote markers: " << remote_markers << dendl;
ldpp_dout(dpp, 0) << "failed to fetch remote bilog markers: "            << cpp_strerror(r) << dendl;
ldpp_dout(dpp, 0) << "failed to read source bucket info: "            << cpp_strerror(r) << dendl;
ldpp_dout(s, 0) << "ERROR: s->cio->send_status() returned err="                     << e.what() << dendl;
ldpp_dout(s, 0) << "ERROR: s->cio->send_header() returned err="                     << e.what() << dendl;
ldpp_dout(s, 0) << "ERROR: s->cio->send_content_length() returned err="                     << e.what() << dendl;
ldpp_dout(s, 0) << "ERROR: RESTFUL_IO(s)->send_chunked_transfer_encoding()"                     << " returned err=" << e.what() << dendl;
ldpp_dout(s, 0) << "ERROR: RESTFUL_IO(s)->complete_header() returned err="       << e.what() << dendl;
ldpp_dout(s, 1) << "op->ERRORHANDLER: err_no=" << err_no        << " new_err_no=" << new_err_no << dendl;
ldpp_dout(s, 1) << "handler->ERRORHANDLER: err_no=" << err_no        << " new_err_no=" << new_err_no << dendl;
ldpp_dout(s, 0) << "ERROR: RESTFUL_IO(s)->send_100_continue() returned err="       << e.what() << dendl;
ldpp_dout(s, 20) << "request content_type_str="        << req_content_type_str << dendl;
ldpp_dout(s, 20) << " " << pair.first << " -> " << pair.second   << dendl;
ldpp_dout(s, 20)      << "subdomain=" << subdomain       << " domain=" << domain       << " in_hosted_domain=" << in_hosted_domain       << " in_hosted_domain_s3website=" << in_hosted_domain_s3website       << dendl;
ldpp_dout(s, 0)   << "WARNING: rgw_resolver->resolve_cname() returned r=" << r   << dendl;
ldpp_dout(s, 5) << "resolved host cname " << info.host << " -> "    << cname << dendl;
ldpp_dout(s, 20)          << "subdomain=" << subdomain           << " domain=" << domain           << " in_hosted_domain=" << in_hosted_domain           << " in_hosted_domain_s3website=" << in_hosted_domain_s3website           << dendl;
ldpp_dout(s, 20)      << "final domain/bucket"      << " subdomain=" << subdomain      << " domain=" << domain      << " in_hosted_domain=" << in_hosted_domain      << " in_hosted_domain_s3website=" << in_hosted_domain_s3website      << " s->info.domain=" << s->info.domain      << " s->info.request_uri=" << s->info.request_uri      << dendl;
ldout(store->ctx(), 1) << "ERROR: failed to read topics from bucket '" <<       bucket.name << "': ret=" << ret << dendl;
ldout(store->ctx(), 20) << "successfully read " << bucket_topics.topics.size() << " topics from bucket '" <<     bucket.name << "'" << dendl;
ldpp_dout(dpp, 0) << "ERROR: name " << name << " already in use for role id "                    << id << dendl;
ldpp_dout(dpp, 0) << "failed reading role id  " << id << ": "                  << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR:  storing role info in pool: " << pool.name << ": "                  << id << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: storing role name in pool: " << pool.name << ": "                  << name << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: cleanup of role id from pool: " << pool.name << ": "                  << id << ": " << cpp_strerror(-info_ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: storing role path in pool: " << pool.name << ": "                  << path << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: cleanup of role id from pool: " << pool.name << ": "                  << id << ": " << cpp_strerror(-info_ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: cleanup of role name from pool: " << pool.name << ": "                  << name << ": " << cpp_strerror(-name_ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: deleting role id from pool: " << pool.name << ": "                  << id << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: deleting role name from pool: " << pool.name << ": "                  << name << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: deleting role path from pool: " << pool.name << ": "                  << path << ": " << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "ERROR:  storing info in pool: " << pool.name << ": "                  << id << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode role from pool: " << pool.name << ": "                  << role_name << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed reading role info from pool: " << pool.name <<                  ": " << id << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode role info from pool: " << pool.name <<                  ": " << id << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed reading role name from pool: " << pool.name << ": "                  << name << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode role name from pool: " << pool.name << ": "                  << name << dendl;
ldpp_dout(dpp, 0) << "ERROR: listing filtered objects failed: " << pool.name << ": "                  << prefix << ": " << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 20) << "zone_params::create_default() " << zone_params.get_name() << " id " << zone_params.get_id()     << dendl;
ldout(cct, 0) << "ERROR: found existing zone name " << zone_name            << " (" << zone.first << ") in zonegroup " << get_name() << dendl;
ldout(cct, 0) << "ERROR: could not found sync module: " << *ptier_type                     << ",  valid sync modules: "                     << sync_mgr->get_registered_module_names()                    << dendl;
ldout(cct, 0) << "zone id " << zone_id << " is not a part of zonegroup "        << name << dendl;
ldout(cct, 0) << "ERROR: set_current_period with old realm epoch "        << period.get_realm_epoch() << ", current epoch=" << epoch << dendl;
ldout(cct, 0) << "ERROR: set_current_period with same realm epoch "        << period.get_realm_epoch() << ", but different period id "        << period.get_id() << " != " << current_period << dendl;
ldout(cct, 0) << "RGWPeriod::init failed to init realm " << realm_name  << " id " << realm_id << " : " << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "failed to use_latest_epoch period id " << id << " realm " << realm_name  << " id " << realm_id    << " : " << cpp_strerror(-ret) << dendl;
ldout(cct, 20) << "creating initial latest_epoch=" << epoch          << " for period=" << id << dendl;
ldout(cct, 10) << "found existing latest_epoch " << info.epoch          << " >= given epoch " << epoch << ", returning r=" << r << dendl;
ldout(cct, 20) << "updating latest_epoch from " << info.epoch          << " -> " << epoch << " on period=" << id << dendl;
ldout(cct, 0) << "WARNING: failed to delete period object " << oid          << ": " << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "WARNING: failed to delete period object " << oid        << ": " << cpp_strerror(-ret) << dendl;
ldout(cct,0) << "ERROR: zonegroup " << zg.get_name()                   << " has a non existent master zone "<< dendl;
ldout(cct, 0) << "ERROR: failed to read period config: "        << cpp_strerror(ret) << dendl;
ldout(cct, 1) << "Set the period's master zonegroup " << zg.get_id()            << " as the default" << dendl;
ldout(cct, 0) << "ERROR: failed to store period config: "        << cpp_strerror(-r) << dendl;
ldout(cct, 0) << "period failed to read sync status: "        << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 0) << "failed to update metadata sync status: "          << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 0) << "failed to update realm's current period: "          << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 4) << "Promoted to master zone and committed new period "        << id << dendl;
ldpp_dout(dpp, 4) << "Committed new epoch " << epoch      << " for period " << id << dendl;
ldout(cct, 0) << "New zone '" << zone.name << "' (" << zone.id            << ") generates the same short_zone_id " << short_id            << " as existing zone id " << s.first << dendl;
ldout(cct, 10) << "RGWWatcher::handle_notify() "                   << " notify_id " << notify_id                   << " cookie " << cookie                   << " notifier " << notifier_id                   << " bl.length()=" << bl.length() << dendl;
ldout(cct, 0) << "RGWWatcher::handle_notify() dropping notification! " << "If this isn't what you want, set " << "rgw_inject_notify_timeout_probability to zero!" << dendl;
ldout(cct, 10) << "distributing notification oid=" << notify_obj.get_ref().obj        << " bl.length()=" << bl.length() << dendl;
ldout(cct, 1) << "robust_notify: If at first you don't succeed: "    << cpp_strerror(-r) << dendl;
ldout(cct, 0) << "robust_notify: notify response parse failed: "      << e.what() << dendl;
ldout(cct, 1) << "robust_notify: retry " << tries << " failed: "        << cpp_strerror(-r) << dendl;
ldout(cct, 20) << "robust_notify: " << id << " timed out."        << dendl;
ldout(cct, 0) << "robust_notify: notify response parse failed: "   << e.what() << dendl;
ldout(cct, 20) << __func__ << ": open_bucket_index_pool() returned "                   << r << dendl;
ldout(cct, 20) << __func__ << ": open_bucket_index_pool() returned "                   << ret << dendl;
ldout(cct, 20) << __func__ << ": open_bucket_index_pool() returned "                   << ret << dendl;
ldout(cct, 20) << __func__ << ": open_bucket_index_pool() returned "                   << ret << dendl;
ldpp_dout(dpp, -1) << "WARNING: The bucket info cache is inconsistent. This is "        << "a failure that should be debugged. I am a nice machine, "        << "so I will try to recover." << dendl;
ldpp_dout(dpp, -1) << "WARNING: The OSD has the same version I have. Something may "               << "have gone squirrelly. An administrator may have forced a "               << "change;
otherwise there is a problem somewhere." << dendl;
ldpp_dout(dpp, -1) << "WARNING: The OSD has the same version I have. Something may "               << "have gone squirrelly. An administrator may have forced a "               << "change;
otherwise there is a problem somewhere." << dendl;
ldout(rados_svc->cct, 0) << "WARNING: async application_enable returned " << ret                    << dendl;
ldout(cct, 0) << "ERROR: failed to read period config: "          << cpp_strerror(ret) << dendl;
ldout(cct, 20) << "started zone id=" << zone_params->get_id() << " (name=" << zone_params->get_name() <<         ") with tier type = " << zone_public_config->tier_type << dendl;
ldout(cct, 0) << __func__ << " failed to read converted: ret "<< ret << " " << cpp_strerror(-ret)    << dendl;
ldout(cct, 0) << __func__ << " zonegroup  "<< *iter << " already exists id " << new_zonegroup.get_id () << " skipping conversion " << dendl;
ldout(cct, 0) << __func__ << " failed to update zonegroup " << *iter << ": ret "<< ret << " " << cpp_strerror(-ret)        << dendl;
ldout(cct, 0) << __func__ << " failed to update_name for zonegroup " << *iter << ": ret "<< ret << " " << cpp_strerror(-ret)        << dendl;
ldout(cct, 0) << __func__ << " failed to set_as_default " << *iter << ": ret "<< ret << " " << cpp_strerror(-ret)          << dendl;
ldout(cct, 0) << __func__ << " failed to delete region " << iter << ": ret "<< ret << " " << cpp_strerror(-ret)        << dendl;
ldout(cct, 0) << __func__ << " failed to mark cluster as converted: ret "<< ret << " " << cpp_strerror(-ret)    << dendl;
ldout(cct, 0) << "zonegroup " << zg.get_name() << " missing master_zone, setting zone " <<   master->second.name << " id:" << master->second.id << " as master" << dendl;
ldout(cct, 0) << "zonegroup " << zg.get_name() << " missing zone for master_zone=" <<   zg.master_zone << dendl;
ldpp_dout(dpp, 0) << "failure in zonegroup create_default: ret "<< ret << " " << cpp_strerror(-ret)        << dendl;
ldout(cct, 0) << "failure in zonegroup create_default: ret "<< ret << " " << cpp_strerror(-ret)        << dendl;
ldout(cct, 0) << "zonegroup " << zonegroup->get_name() << " missing master_zone, setting zone " <<   master->second.name << " id:" << master->second.id << " as master" << dendl;
ldout(cct, 0) << "zonegroup " << zonegroup->get_name() << " missing zone for "          "master_zone=" << zonegroup->master_zone << dendl;
ldout(cct, 0) << "Error could not update zonegroup " << zonegroup.get_name() << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "Error could not create " << zonegroup.get_name() << ": " <<   cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "Error could not remove " << sysobj.get_obj()        << " after upgrading to zonegroup map: " << cpp_strerror(ret) << dendl;
ldout(cct, 0) << "could not find requested placement id " << request_rule                     << " within zonegroup " << dendl;
ldout(cct, 0) << "could not find user default placement id " << user_info.default_placement                    << " within zonegroup " << dendl;
ldout(cct, 0) << "could not find zonegroup default placement id " << zonegroup.default_placement                      << " within zonegroup " << dendl;
ldout(cct, 0) << "ERROR: This zone does not contain placement rule "                  << location_rule << " present in the zonegroup!" << dendl;
ldpp_dout(dpp, 0) << "WARNING: can't store user info, swift id (" << k.id          << ") already mapped to another user (" << info.user_id << ")" << dendl;
ldout(cct, 0) << "ERROR: could not remove email index object for "        << info.user_email << ", should be fixed (err=" << ret << ")" << dendl;
ldpp_dout(dpp, 1) << "failed to decode the mdlog history: "        << e.what() << dendl;
ldout(cct, 1) << "failed to read mdlog history: "            << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "read mdlog history with oldest period id="          << state.oldest_period_id << " realm_epoch="          << state.oldest_realm_epoch << dendl;
ldout(cct, 1) << "failed to write mdlog history: "            << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "wrote mdlog history with oldest period id="          << state.oldest_period_id << " realm_epoch="          << state.oldest_realm_epoch << dendl;
ldout(cct, 4) << "found oldest log epoch=" << existing.get_epoch()            << ", rejecting trim at epoch=" << cursor.get_epoch() << dendl;
ldout(cct, 10) << "find_oldest_period returning first "            "period " << cursor.get_period().get_id() << dendl;
ldout(cct, 20) << "find_oldest_period advancing to "          "predecessor period " << predecessor << dendl;
ldpp_dout(dpp, 1) << "failed to write mdlog history: "          << cpp_strerror(ret) << dendl;
ldpp_dout(dpp, 1) << "failed to read mdlog history: "        << cpp_strerror(ret) << dendl;
ldout(cct, 1) << "failed to write mdlog history: "          << cpp_strerror(ret) << dendl;
ldout(cct, 1) << "failed to read period id=" << state.oldest_period_id        << " for mdlog history: " << cpp_strerror(ret) << dendl;
ldout(cct, 1) << "inconsistent mdlog history: read period id="        << period.get_id() << " with realm_epoch=" << period.get_realm_epoch()        << ", expected realm_epoch=" << state.oldest_realm_epoch << dendl;
ldpp_dout(dpp, 1) << "failed to read mdlog history: "        << cpp_strerror(ret) << dendl;
ldpp_dout(dpp, 10) << "read mdlog history with oldest period id="      << state.oldest_period_id << " realm_epoch="      << state.oldest_realm_epoch << dendl;
ldout(svc->ctx(), 0) << "ERROR: fail to register admin socket command (r=" << r                           << ")" << dendl;
dout(1) << "====== " << __func__     << " starting new request req=" << hex << req << dec     << " ======" << dendl;
dout(0) << "ERROR: io->complete_request() returned "              << e.what() << dendl;
ldpp_dout(op, 1) << "====== " << __func__     << " req done req=" << hex << req << dec << " http_status="     << http_ret     << " ======" << dendl;
dout(1) << "====== " << __func__     << " starting new continued request req=" << hex << req << dec     << " ======" << dendl;
ldpp_dout(op, 1) << "====== " << __func__     << " finishing continued request req=" << hex << req << dec     << " op status=" << op_ret     << " ======" << dendl;
ldpp_dout(&dp, 10) << "read_permissions (bucket policy) on "      << get_state()->bucket << ":"      << get_state()->object      << " only_bucket=" << only_bucket()      << " ret=" << ret << dendl;
ldpp_dout(&dp, 10) << "read_permissions (object policy) on"        << get_state()->bucket << ":"        << get_state()->object        << " ret=" << ret << dendl;
ldout(cct, 20) << "cache get: touching lru, lru_counter=" << lru_counter                   << " promotion_ts=" << entry->lru_promotion_ts << dendl;
ldout(cct, 10) << "cache get: name=" << name << " : type miss (requested=0x"                   << std::hex << mask << ", cached=0x" << src.flags                   << std::dec << ")" << dendl;
ldout(cct, 10) << "cache get: name=" << name << " : hit (requested=0x"                 << std::hex << mask << ", cached=0x" << src.flags                 << std::dec << ")" << dendl;
ldout(cct, 10) << "chain_cache_entry: cache_locator="     << cache_info->cache_locator << dendl;
ldout(cct, 20) << "chain_cache_entry: entry.gen (" << entry->gen       << ") != cache_info.gen (" << cache_info->gen << ")"       << dendl;
ldout(cct, 10) << "cache put: name=" << name << " info.flags=0x"                 << std::hex << info.flags << std::dec << dendl;
ldout(sc->cct, 4) << "AWS: download begin: z=" << sc->source_zone                              << " b=" << src_bucket << " k=" << key << " size=" << size                              << " mtime=" << mtime << " etag=" << etag                              << " zone_short_id=" << src_zone_short_id << " pg_ver=" << src_pg_ver                              << dendl;
ldout(sc->cct, 0) << ": remove remote obj: z=" << sc->source_zone                              << " b=" <<sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime << dendl;
ldout(sc->cct, 0) <<"AWS Not implemented: create_delete_marker: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime                            << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
ldout(bucket_sync_svc->ctx(), 0) << "ERROR: failed to initialize bucket sync policy handler: get_bucket_sync_hints() on bucket="      << bucket << " returned r=" << r << dendl;
ldout(cct, 1) << "beast: " << std::hex << &req << std::dec << ": "            << remote_endpoint.address() << " - " << user << " [" << log_apache_time{started} << "] \""            << message.method_string() << ' ' << message.target() << ' '            << http_version{message.version()} << "\" " << http_ret << ' '            << client.get_bytes_sent() + client.get_bytes_received() << ' '            << log_header{message, http::field::referer, "\""} << ' '            << log_header{message, http::field::user_agent, "\""} << ' '            << log_header{message, http::field::range} << " latency="            << latency << dendl;
ldout(cct, 5) << "failed to discard unread message: "            << ec.message() << dendl;
ldout(ctx, 0) << "set uid:gid to " << uid << ":" << gid                  << " (" << uid_string << ":" << gid_string << ")" << dendl;
ldout(ctx(), 0) << "WARNING: cannot open socket for endpoint=" << l.endpoint   << ", " << ec.message() << dendl;
ldout(s->cct, 5) << "format error <" << context     << ">: partial.results=" << buf.GetString() << dendl;
ldout(cct, 20) << "fixup_range [" << inp_ofs << "," << inp_end      << "] => [" << bl_ofs << "," << bl_end << "]" << dendl;
ldout(s->cct, 5) << "ERROR: Invalid value for header "                         << "x-amz-server-side-encryption-customer-algorithm"                         << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_encrypt invalid encryption "                         << "key which contains character that is not base64 encoded."                         << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_encrypt invalid encryption key "                         << "md5 which contains character that is not base64 encoded."                         << dendl;
ldout(s->cct, 5) << "ERROR: SSE-C encryption request is missing the header "                         << "x-amz-server-side-encryption-customer-algorithm"                         << dendl;
ldout(s->cct, 5) << "ERROR: SSE-C encryption request is missing the header "                         << "x-amz-server-side-encryption-customer-algorithm"                         << dendl;
ldout(s->cct, 5) << "ERROR: key obtained from key_id:" <<            key_id << " is not 256 bit size" << dendl;
ldout(s->cct, 5) << "ERROR: Invalid value for header x-amz-server-side-encryption"                         << dendl;
ldout(s->cct, 5) << "ERROR: SSE-KMS encryption request is missing the header "                         << "x-amz-server-side-encryption"                         << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_encrypt invalid default encryption key "                         << "which contains character that is not base64 encoded."                         << dendl;
ldout(s->cct, 5) << "ERROR: Request for SSE-C encrypted object missing "                       << "x-amz-server-side-encryption-customer-algorithm"                       << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_decrypt invalid encryption key "                       << "which contains character that is not base64 encoded."                       << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_decrypt invalid encryption key md5 "                       << "which contains character that is not base64 encoded."                       << dendl;
ldout(s->cct, 0) << "ERROR: key obtained from key_id:" <<          key_id << " is not 256 bit size" << dendl;
ldout(s->cct, 5) << "ERROR: rgw_s3_prepare_decrypt invalid default encryption key "                       << "which contains character that is not base64 encoded."                       << dendl;
ldout(s->cct, 1) << "failed to auto-generate unique topic '" << unique_topic_name <<         "', ret=" << op_ret << dendl;
ldout(s->cct, 1) << "failed to auto-generate notification for unique topic '" << unique_topic_name <<        "', ret=" << op_ret << dendl;
ldpp_dout(dpp, 5) << "Failed keystone auth from " << url << " with "                  << validate.get_http_status() << dendl;
ldpp_dout(dpp, 20) << "received response status=" << validate.get_http_status()                 << ", body=" << token_body_bl.c_str() << dendl;
ldpp_dout(dpp, 20) << "cached token.project.id=" << t->get_project_id()                   << dendl;
ldpp_dout(dpp, 0) << "got expired token: " << t->get_project_name()                  << ":" << t->get_user_name()                  << " expired: " << t->get_expires() << dendl;
ldpp_dout(dpp, 0) << "validated token: " << t->get_project_name()                    << ":" << t->get_user_name()                    << " expires: " << t->get_expires() << dendl;
ldpp_dout(dpp, 2) << "s3 keystone: cannot get token for keystone access"                  << dendl;
ldpp_dout(dpp, 2) << "s3 keystone: token validation ERROR: "                  << token_body_bl.c_str() << dendl;
ldpp_dout(dpp, 2) << "s3 keystone: token parsing failed, ret=0" << ret                  << dendl;
ldpp_dout(dpp, 2) << "s3 keystone: cannot get token for keystone access"                  << dendl;
ldpp_dout(dpp, 2) << "s3 keystone: secret fetching error: "                  << token_body_bl.c_str() << dendl;
ldpp_dout(dpp, 0) << "got expired token: " << t->get_project_name()                  << ":" << t->get_user_name()                  << " expired: " << t->get_expires() << dendl;
ldpp_dout(dpp, 5) << "s3 keystone: validated token: " << t->get_project_name()                  << ":" << t->get_user_name()                  << " expires: " << t->get_expires() << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " canceled: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " handling async update_meta: tid="     << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__         << " update failed, marking canceled: r=" << r << " tid="         << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " completing: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " handling async read_meta: tid="   << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " completing: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " processing entry: entry=" << entry << " tid=" << tid     << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " postprocessing: i=" << i << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " nothing to update any more: i=" << i << " tid="       << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " update canceled, retrying: i=" << i << " tid="       << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 5) << __PRETTY_FUNCTION__ << ":" << __LINE__    << " new part journaled, but not processed: tid="    << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " needs new head: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " updating metadata: i=" << i << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__         << " raced, but journaled and processed: i=" << i         << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__         << " raced, journaled but not processed: i=" << i         << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " need new part: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " updating head: i=" << i << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " raced, but completed by the other caller: i=" << i       << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20)    << __PRETTY_FUNCTION__ << ":" << __LINE__    << " entering" << dendl;
ldout(cct, 20)      << __PRETTY_FUNCTION__ << ":" << __LINE__      << " processing leftover journal" << dendl;
ldout(cct, 20)    << __PRETTY_FUNCTION__ << ":" << __LINE__    << " entering" << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " empty push, returning success tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " need new head tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " preparing push: remaining=" << remaining.size()     << " batch=" << batch.size() << " retries=" << retries     << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " prepared push: remaining=" << remaining.size()     << " batch=" << batch.size() << " retries=" << retries     << " batch_len=" << batch_len     << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " need new head tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " max_entries=" << max_entries << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " missing part, rereading metadata"       << " tid= "<< tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__         << " raced with trim, restarting: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " assuming part was not written yet, so end of data: "       << "tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " head part is not full, so we can assume we're done: "       << "tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " pn=" << pn << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__       << " canceled: retries=" << retries       << " tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " entering: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__     << " handling preceding trim callback: tid=" << tid << dendl;
ldout(cct, 20) << __PRETTY_FUNCTION__ << ":" << __LINE__   << " handling update-needed callback: tid=" << tid << dendl;
ldout(s->cct, 20) << "ERROR: one of policy name, user name or policy document is empty"    << dendl;
ldout(s->cct, 20) << "ERROR: one of policy name or user name is empty"    << dendl;
ldpp_dout(this, 0) << "could not get bucket info for bucket="    << bucket_name << dendl;
ldpp_dout(this, 20) << "slo_part: " << entry.path                        << " size=" << entry.size_bytes                        << " etag=" << entry.etag                        << dendl;
ldpp_dout(dpp, 0) << "ERROR: cannot decode object's " RGW_ATTR_DELETE_AT                          " attr, ignoring"                       << dendl;
ldpp_dout(dpp, 20) << "bulk_upload: get_at_most max_to_read="                        << max_to_read                        << ", dst.c_str()=" << reinterpret_cast<intptr_t>(dst.c_str()) << dendl;
ldpp_dout(this, 20) << "bulk upload: create_stream for length="                      << s->length << dendl;
ldpp_dout(this, 5) << "failed to parse FormPost's max_file_size: " << err                     << dendl;
ldpp_dout(this, 5) << "FormPost form expired: "            << expires_timestamp << " <= " << now.sec() << dendl;
ldpp_dout(this, 20) << "FormPost signature [" << temp_url_key_num << "]"                      << " (calculated): " << local_sig << dendl;
ldpp_dout(this, 5) << "FormPost's signature mismatch: "                       << local_sig << " != " << form_signature << dendl;
ldpp_dout(this, 20) << "temp url user (bucket owner): " << bucket->get_info().owner                 << dendl;
ldpp_dout(this, 20) << "read part header -- part.name="                        << part.name << dendl;
ldpp_dout(this, 20) << " " << param_pair.first                            << " -> " << param_pair.second << dendl;
ldpp_dout(s, 10) << "s->object=" <<    (!s->object->empty() ? s->object->get_key() : rgw_obj_key("<NULL>"))           << " s->bucket="    << rgw_make_bucket_entry_name(s->bucket_tenant, s->bucket_name)    << dendl;
ldout(cct, 0) << "ERROR: failed to parse bucket shard '"          << instance.data() << "': " << err << dendl;
ldout(store->ctx(), 0) << "failed to read user buckets: "        << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, -1) << "error: reading bucket info for bucket: "                          << bname << cpp_strerror(-r) << dendl;
ldout(store->ctx(), 5) << __func__                             << "failed to take reshard lock;
reshard underway likey" << dendl;
ldout(cct, 0) << "ERROR: store->get_bucket_entrypoint_info() returned: "                      << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "ERROR: error adding bucket to user directory:"    << " user=" << user_id                  << " bucket=" << bucket    << " err=" << cpp_strerror(-ret)    << dendl;
ldout(cct, 0) << "ERROR: failed unlinking bucket on error cleanup: "                           << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 0) << "ERROR: error removing bucket from directory: "        << cpp_strerror(-ret)<< dendl;
ldpp_dout(dpp, 0) << "ERROR: decode policy failed" << err.what()     << dendl;
ldpp_dout(dpp, 20) << "finished applying changes to req_state for TempURL: "                    << " content_disp override " << s->content_disp.override                    << " content_disp fallback " << s->content_disp.fallback                    << dendl;
ldpp_dout(dpp, 20) << "temp url user (bucket owner): " << bucket->get_info().owner                 << dendl;
ldpp_dout(dpp, 20) << "temp url signature [" << temp_url_key_num                          << "] (calculated): " << local_sig                          << dendl;
ldpp_dout(dpp,  5) << "temp url signature mismatch: " << local_sig                            << " != " << temp_url_sig  << dendl;
ldpp_dout(dpp, 0) << "NOTICE: failed to verify token: odd token length="           << etoken_len << dendl;
ldpp_dout(dpp, 0) << "NOTICE: old timed out token was used now=" << now           << " token.expiration=" << expiration                  << dendl;
ldpp_dout(dpp, 0) << "NOTICE: tokens length mismatch:"                  << " tok_bl.length()=" << tok_bl.length()           << " local_tok_bl.length()=" << local_tok_bl.length()                  << dendl;
ldout(sync_env->cct, 0) << "SYNC_LOG: stat of remote obj: z=" << sc->source_zone                            << " b=" << src_bucket << " k=" << key << " size=" << size << " mtime=" << mtime                            << " attrs=" << attrs << dendl;
ldout(sc->cct, 0) << prefix << ": SYNC_LOG: create_delete_marker: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime                            << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
dout(0) << "ERROR: wrong Keystone API version: "            << g_ceph_context->_conf->rgw_keystone_api_version            << ";
falling back to v2" <<  dendl;
ldpp_dout(this, 20) << "INFO: push endpoint created: " << event_entry.push_endpoint <<        " for entry: " << entry.marker << dendl;
ldpp_dout(this, 5) << "WARNING: push entry: " << entry.marker << " to endpoint: " << event_entry.push_endpoint           << " failed. error: " << ret << " (will retry)" << dendl;
ldpp_dout(this, 20) << "INFO: push entry: " << entry.marker << " to endpoint: " << event_entry.push_endpoint           << " ok" <<  dendl;
ldpp_dout(this, 5) << "WARNING: failed to create push endpoint: "           << event_entry.push_endpoint << " for entry: " << entry.marker << ". error: " << e.what() << " (will retry) " << dendl;
ldpp_dout(this, 5) << "INFO: queue: "           << queue_name << ". was removed. cleanup will stop" << dendl;
ldpp_dout(this, 5) << "WARNING: failed to cleanup stale reservation from queue and/or lock queue: " << queue_name          << ". error: " << ret << dendl;
ldpp_dout(this, 5) << "INFO: queue: "             << queue_name << ". was removed. processing will stop" << dendl;
ldpp_dout(this, 5) << "WARNING: failed to get list of entries in queue and/or lock queue: "             << queue_name << ". error: " << ret << " (will retry)" << dendl;
ldpp_dout(this, 5) << "WARNING: failed to parse list of entries in queue: "             << queue_name << ". error: " << ret << " (will retry)" << dendl;
ldpp_dout(this, 20) << "INFO: found: " << total_entries << " entries in: " << queue_name <<        ". end marker is: " << end_marker << dendl;
ldpp_dout(this, 20) << "INFO: processing of entry: " <<                 entry.marker << " (" << entry_idx << "/" << total_entries << ") from: " << queue_name << " ok" << dendl;
ldpp_dout(this, 20) << "INFO: processing of entry: " <<                 entry.marker << " (" << entry_idx << "/" << total_entries << ") from: " << queue_name << " failed" << dendl;
ldpp_dout(this, 5) << "INFO: queue: "             << queue_name << ". was removed. processing will stop" << dendl;
ldpp_dout(this, 1) << "ERROR: failed to remove entries and/or lock queue up to: " << end_marker <<  " from queue: "             << queue_name << ". error: " << ret << dendl;
ldpp_dout(this, 20) << "INFO: removed entries up to: " << end_marker <<  " from queue: "           << queue_name << dendl;
ldout(res.s->cct, 20) << "INFO: notification: '" << topic_filter.s3_id <<         "' on topic: '" << topic_cfg.dest.arn_topic <<         "' and bucket: '" << res.s->bucket->get_name() <<         "' (unique topic: '" << topic_cfg.name <<        "') apply to event of type: '" << to_string(event_type) << "'" << dendl;
ldout(res.s->cct, 1) << "ERROR: failed to reserve notification on queue: " << queue_name           << ". error: " << ret << dendl;
ldpp_dout(dpp, 5) << "WARNING: committed size: " << bl.length() << " exceeded reserved size: " << res.size <<          " . trying to make a larger reservation on queue:" << queue_name << dendl;
ldpp_dout(dpp, 1) << "ERROR: failed to abort reservation: " << topic.res_id <<             " when trying to make a larger reservation on queue: " << queue_name            << ". error: " << ret << dendl;
ldpp_dout(dpp, 1) << "ERROR: failed to reserve extra space on queue: " << queue_name            << ". error: " << ret << dendl;
ldpp_dout(dpp, 1) << "ERROR: failed to commit reservation to queue: " << queue_name          << ". error: " << ret << dendl;
ldpp_dout(dpp, 1) << "ERROR: failed to create push endpoint: "             << topic.cfg.dest.push_endpoint << ". error: " << e.what() << dendl;
ldout(res.s->cct, 1) << "ERROR: failed to abort reservation: " << topic.res_id <<         " from queue: " << queue_name << ". error: " << ret << dendl;
ldpp_dout(dpp, 20) << engine.get_name() << " rejected with reason="                 << engine_result.get_reason() << dendl;
ldpp_dout(dpp, 20) << engine.get_name() << " denied with reason="                 << engine_result.get_reason() << dendl;
ldpp_dout(dpp, 5) << "Failed the auth strategy, reason="                       << result.get_reason() << dendl;
ldpp_dout(dpp, 5) << "applier throwed unexpected err: " << e.what()                        << dendl;
ldpp_dout(dpp, 5) << "auth engine throwed unexpected err: " << e.what()                      << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to store new user info: user="                  << user << " ret=" << ret << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to store new user info: user="                  << user << " ret=" << ret << dendl;
ldpp_dout(dpp, 0) << "ERROR: do life cycle process() returned error r="     << r << dendl;
ldpp_dout(dpp, 5) << "schedule life cycle next start time: "        << rgw_to_asctime(next) << dendl;
dout(5) << "RGWLC::bucket_lc_prepare(): PREPARE "   << "index: " << index << " worker ix: " << worker->ix   << dendl;
ldpp_dout(this, 0)   << "RGWLC::bucket_lc_prepare() failed to set entry on "   << obj_names[index] << dendl;
ldout(cct, 20) << __func__ << __func__   << "(): mtime=" << mtime << " days=" << days   << " base_time=" << base_time << " timediff=" << timediff   << " cmp=" << cmp   << " is_expired=" << (timediff >= cmp)    << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode RGWObjectRetention"          << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode RGWObjectLegalHold"          << dendl;
ldout(store->ctx(), 0) << "ERROR: list_op returned ret=" << ret     << dendl;
ldpp_dout(wk->get_lc(), 5)     << "ERROR: abort_multipart_upload failed, ret=" << ret     << wq->thr_name()     << ", meta:" << obj.key     << dendl;
ldpp_dout(wk->get_lc(), 0)     << "ERROR: abort_multipart_upload failed, ret=" << ret     << wq->thr_name()     << ", meta:" << obj.key     << dendl;
ldout(cct, 5) << __func__ << " interval budget EXPIRED worker "       << worker->ix       << dendl;
ldout(oc.cct, 5) << "ERROR: read_obj_tags returned r="    << ret << " " << oc.wq->thr_name() << dendl;
ldout(oc.cct,0) << "ERROR: caught buffer::error, couldn't decode TagSet "        << oc.wq->thr_name() << dendl;
ldout(oc.cct, 20) << __func__ << "() skipping obj " << oc.obj   << " as tags do not match in rule: "   << op.id << " "   << oc.wq->thr_name() << dendl;
ldout(oc.cct, 0) << "ERROR: check_tags on obj=" << oc.obj         << " returned ret=" << ret << " "         << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key   << ": not current, skipping "   << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 7) << __func__ << "(): dm-check SAME: key=" << o.key         << " next_key_name: %%" << nkn << "%% "         << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 7) << __func__ << "(): dm-check DELE: key=" << o.key    << " next_key_name: %%" << nkn << "%% "    << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key     << ": no expiration set in rule, skipping "     << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key << ": is_expired="        << (int)is_expired << " "        << oc.wq->thr_name() << dendl;
ldout(oc.cct, 0) << "ERROR: current is-dm remove_expired_obj "    << oc.bucket << ":" << o.key    << " " << cpp_strerror(r) << " "    << oc.wq->thr_name() << dendl;
ldout(oc.cct, 2) << "DELETED: current is-dm "         << oc.bucket << ":" << o.key         << " " << oc.wq->thr_name() << dendl;
ldout(oc.cct, 0) << "ERROR: remove_expired_obj "    << oc.bucket << ":" << o.key    << " " << cpp_strerror(r) << " "    << oc.wq->thr_name() << dendl;
ldout(oc.cct, 2) << "DELETED:" << oc.bucket << ":" << o.key         << " " << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key   << ": current version, skipping "   << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key << ": is_expired="        << is_expired << " "        << oc.wq->thr_name() << dendl;
ldout(oc.cct, 0) << "ERROR: remove_expired_obj (non-current expiration) "          << oc.bucket << ":" << o.key         << " " << cpp_strerror(r)         << " " << oc.wq->thr_name() << dendl;
ldout(oc.cct, 2) << "DELETED:" << oc.bucket << ":" << o.key       << " (non-current expiration) "       << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key   << ": not a delete marker, skipping "   << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key   << ": next is same object, skipping "   << oc.wq->thr_name() << dendl;
ldout(oc.cct, 0) << "ERROR: remove_expired_obj (delete marker expiration) "         << oc.bucket << ":" << o.key         << " " << cpp_strerror(r)         << " " << oc.wq->thr_name()         << dendl;
ldout(oc.cct, 2) << "DELETED:" << oc.bucket << ":" << o.key       << " (delete marker expiration) "       << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key     << ": no transition day/date set in rule, skipping "     << oc.wq->thr_name() << dendl;
ldout(oc.cct, 20) << __func__ << "(): key=" << o.key << ": is_expired="        << is_expired << " "        << oc.wq->thr_name() << dendl;
ldpp_dout(oc.dpp, 0) << "ERROR: non existent dest placement: "      << target_placement                           << " bucket="<< oc.bucket                           << " rule_id=" << oc.op.id      << " " << oc.wq->thr_name() << dendl;
ldpp_dout(oc.dpp, 0) << "ERROR: failed to transition obj "       << oc.bucket << ":" << o.key      << " -> " << transition.storage_class       << " " << cpp_strerror(r)      << " " << oc.wq->thr_name() << dendl;
ldpp_dout(oc.dpp, 2) << "TRANSITIONED:" << oc.bucket    << ":" << o.key << " -> "    << transition.storage_class    << " " << oc.wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): key=" << o.key    << ": no rule match, skipping "    << " " << wq->thr_name() << dendl;
ldpp_dout(dpp, 0) << "ERROR: remove_expired_obj "    << env.bucket << ":" << o.key   << " " << cpp_strerror(r)   << " " << wq->thr_name() << dendl;
ldpp_dout(dpp, 20) << "processed:" << env.bucket << ":"         << o.key << " " << wq->thr_name() << dendl;
ldpp_dout(this, 0) << "LC:get_bucket for " << bucket_name         << " failed" << dendl;
ldpp_dout(this, 0) << "LC:get_bucket_info for " << bucket_name         << " failed" << dendl;
ldpp_dout(this, 1) << "LC: deleting stale entry found for bucket="         << bucket_tenant << ":" << bucket_name         << " cur_marker=" << bucket->get_marker()                       << " orig_marker=" << bucket_marker << dendl;
ldpp_dout(this, 0) << __func__ <<  "() decode life cycle config failed"    << dendl;
ldpp_dout(wk->get_lc(), 20)      << __func__ << "(): key=" << o.key << wq->thr_name()       << dendl;
ldpp_dout(wk->get_lc(), 20) << "ERROR: orule.process() returned ret=" << ret << wq->thr_name()  << dendl;
ldpp_dout(this, 10) << __func__ <<  "() prefix_map size="        << prefix_map.size()        << dendl;
ldout(cct, 5) << __func__ << " interval budget EXPIRED worker "       << worker->ix       << dendl;
ldpp_dout(this, 20) << __func__ << "(): prefix=" << prefix_iter->first   << dendl;
dout(5) << "RGWLC::bucket_lc_post(): POST " << entry   << " index: " << index << " worker ix: " << worker->ix   << dendl;
ldpp_dout(this, 0) << "RGWLC::bucket_lc_post() failed to acquire lock on "    << obj_names[index] << ", sleep 5, try again " << dendl;
ldpp_dout(this, 20) << "RGWLC::bucket_lc_post() lock " << obj_names[index]   << dendl;
ldpp_dout(this, 0) << "RGWLC::bucket_lc_post() failed to remove entry "            << obj_names[index] << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to set entry on "          << obj_names[index] << dendl;
ldpp_dout(this, 20) << "RGWLC::bucket_lc_post() unlock "   << obj_names[index] << dendl;
ldpp_dout(this, 10) << __func__ << "() ignoring unfound lc object="                             << obj_names[index] << dendl;
dout(16) << "RGWLC::expired_session"    << " started: " << started    << " interval: " << interval << "(*2==" << 2*interval << ")"    << " now: " << now    << dendl;
dout(5) << "RGWLC::process(): ENTER: "   << "index: " << index << " worker ix: " << worker->ix   << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to acquire lock on "          << obj_names[index] << ", sleep 5, try again" << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to get obj head "          << obj_names[index] << ", ret=" << ret << dendl;
dout(5) << "RGWLC::process(): STALE lc session found for: " << entry      << " index: " << index << " worker ix: " << worker->ix      << " (clearing)"      << dendl;
dout(5) << "RGWLC::process(): ACTIVE entry: " << entry      << " index: " << index << " worker ix: " << worker->ix    << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to update lc object "    << obj_names[index]    << ", ret=" << ret    << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to get obj entry "          << obj_names[index] << dendl;
ldpp_dout(this, 5) << "RGWLC::process(): START entry 1: " << entry     << " index: " << index << " worker ix: " << worker->ix     << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to set obj entry "       << obj_names[index] << entry.bucket << entry.status << dendl;
ldpp_dout(this, 0) << "RGWLC::process() failed to put head "    << obj_names[index]       << dendl;
ldpp_dout(this, 5) << "RGWLC::process(): START entry 2: " << entry     << " index: " << index << " worker ix: " << worker->ix     << dendl;
ldout(cct, 0) << "RGWLC::RGWPutLC() failed to acquire lock on "          << oid << ", sleep 5, try again" << dendl;
ldout(cct, 0) << "RGWLC::RGWPutLC() failed to acquire lock on "          << oid << ", ret=" << ret << dendl;
ldout(cct, 0) << "RGWLC::RGWPutLC() failed to set entry on "          << oid << ", ret=" << ret << dendl;
ldout(cct, 0) << "RGWLC::RGWDeleteLC() failed to set attrs on bucket="        << b.name << " returned err=" << ret << dendl;
ldout(store->ctx(), 1) << "No entry for bucket=" << bucket      << " creating " << dendl;
ldpp_dout(dpp, 0) << __func__   <<  "() decode life cycle config failed"   << dendl;
ldout(cct, 16) << __func__       <<  "() key=" << elt.first << " val=" << elt.second       << dendl;
ldpp_dout(dpp, 10) << "rule: " << ri.first         << " prefix: " << prefix         << " expiration: "         << " date: " << expiration.get_date()         << " days: " << expiration.get_days()         << " noncur_expiration: "         << " date: " << noncur_expiration.get_date()         << " days: " << noncur_expiration.get_days()         << dendl;
ldpp_dout(dpp, 10) << "tag does not match obj_key=" << obj_key            << " rule_id=" << id            << " tag=" << tag            << dendl;
ldpp_dout(dpp, 0) << __func__ << "() strftime of life cycle expiration header failed"   << dendl;
ldpp_dout(dpp, 0) << __func__                      <<  "() decode life cycle config failed"                      << dendl;
ldout(s->cct, 20) << __func__ << " handler=" << typeid(*handler).name()      << dendl;
ldout(store->ctx(), 20) << __func__ <<   ": shard->wait_all_aio() returned ret=" << ret << dendl;
ldout(store->ctx(), 0) << "RGWReshard::" << __func__ << " ERROR: error setting bucket resharding flag on bucket index: "    << cpp_strerror(-ret) << dendl;
ldout(store->ctx(), 0) << "RGWBucketReshard::" << __func__ <<      " ERROR: error clearing reshard status from index shard " <<      cpp_strerror(-ret) << dendl;
ldout(store->ctx(), 0) << "RGWReshard::" << __func__ <<      " ERROR: error setting bucket resharding flag on bucket index: " <<      cpp_strerror(-ret) << dendl;
ldout(store->ctx(), 0) << "RGWBucketReshard::" << __func__ << " ERROR: error clearing reshard status from index shard " << cpp_strerror(-ret) << dendl;
ldout(store->ctx(), 0) << "RGWReshardLock::" << __func__ <<      " failed to acquire lock on " << lock_oid << " ret=" << ret << dendl;
ldout(store->ctx(), 0) << "WARNING: RGWBucketReshardLock::" << __func__ <<      " failed to drop lock on " << lock_oid << " ret=" << ret << dendl;
ldout(store->ctx(), 5) << __func__ << "(): failed to renew lock on " <<      lock_oid << " with error " << error_s.str() << dendl;
ldout(store->ctx(), 20) << __func__ << "(): successfully renewed lock on " <<    lock_oid << dendl;
ldpp_dout(dpp, 0) << __func__ <<      ": can't reshard, negative max_entries" << dendl;
ldpp_dout(dpp, -1) << "Error: " << __func__ <<      " failed to clean old bucket info object \"" <<      bucket_info.bucket.get_key() <<      "\"created after successful resharding with error " << ret << dendl;
ldpp_dout(dpp, 1) << __func__ <<    " INFO: reshard of bucket \"" << bucket_info.bucket.name << "\" from \"" <<    bucket_info.bucket.get_key() << "\" to \"" <<    new_bucket_info.bucket.get_key() << "\" completed successfully" << dendl;
ldpp_dout(dpp, -1) << "Error: " << __func__ <<      " failed to clean bucket info object \"" <<      new_bucket_info.bucket.get_key() <<      "\"created during incomplete resharding with error " << ret2 << dendl;
ldout(store->ctx(), 0) << __func__ << ":Error in updating entry bucket " << entry.bucket_name << ": " <<      cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 5) << __func__ << "(): failed to acquire lock on " <<      logshard_oid << ", ret = " << ret <<dendl;
ldpp_dout(dpp, 10) << "cannot list all reshards in logshard oid=" << logshard_oid << dendl;
ldpp_dout(dpp, 20) << __func__ << " resharding " <<   entry.bucket_name  << dendl;
ldpp_dout(dpp, 0) <<  __func__ <<       ": Error in get_bucket_info for bucket " << entry.bucket_name <<       ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << __func__ <<       ": Bucket: " << entry.bucket_name <<       " already resharded by someone, skipping " << dendl;
ldpp_dout(dpp, 0) <<  __func__ <<     ": removing reshard queue entry for a resharded or non-existent bucket" <<     entry.bucket_name << dendl;
ldpp_dout(dpp, 0) << __func__ <<       ": Error removing non-existent bucket " <<       entry.bucket_name << " from resharding queue: " <<       cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) <<  __func__ <<     ": Error during resharding bucket " << entry.bucket_name << ":" <<     cpp_strerror(-ret)<< dendl;
ldpp_dout(dpp, 20) << __func__ <<   " removing reshard queue entry for bucket " << entry.bucket_name <<   dendl;
ldpp_dout(dpp, 0) << __func__ << ": Error removing bucket " <<     entry.bucket_name << " from resharding queue: " <<     cpp_strerror(-ret) << dendl;
ldout(s->cct, 20) << "ERROR: one of role name or assume role policy document is empty"    << dendl;
ldout(s->cct, 30) << "log_usage: bucket_name=" << bucket_name << " tenant=" << s->bucket_tenant << ", bytes_sent=" << bytes_sent << ", bytes_received=" << bytes_received << ", success=" << data.successful_ops << dendl;
ldout(conn->cct, 10) << "AMQP run: connection (" << to_string(conn_it->first) << ") retry failed. error: " <<                status_to_string(conn->status) << " (" << conn->reply_code << ")"  << dendl;
ldout(conn->cct, 10) << "AMQP run: ignoring non n/ack messages. frame type: "             << unsigned(frame.frame_type) << dendl;
ldout(cct, 10) << "AMQP connect: connection (" << to_string(id) << ") creation failed. error:" <<              status_to_string(conn->status) << "(" << conn->reply_code << ")" << dendl;
ldpp_dout(dpp, 0) << "ERROR: parse_list for read returned r="                    << r << dendl;
ldout(cct, 0) << "ERROR: add_grants for read returned r="                    << r << dendl;
ldpp_dout(dpp, 0) << "ERROR: parse_list for write returned r="                    << r << dendl;
ldout(cct, 0) << "ERROR: add_grants for write returned r="                    << r << dendl;
ldout(cct, 1) << "metadata master failed to read period "          << period_id << " from local storage: " << cpp_strerror(r) << dendl;
ldout(cct, 14) << "pulling period " << period_id        << " from master" << dendl;
ldout(cct, 14) << "period " << period_id        << " pulled and written to local storage" << dendl;
ldout(cct, 14) << "found period " << period_id        << " in local storage" << dendl;
ldout(cct,0) << "ERROR: failed to decode obj tags for "                       << bucket_info.bucket << "/" << key << dendl;
ldout(cct,0) << "ERROR: failed to decode compression attr for "                       << bucket_info.bucket << "/" << key << dendl;
ldout(sync_env->cct, 10) << ": stat of remote obj: z=" << sc->source_zone                               << " b=" << sync_pipe.info.source_bs.bucket << " k=" << key                               << " size=" << size << " mtime=" << mtime << dendl;
ldout(sync_env->cct, 10) << ": remove remote obj: z=" << sc->source_zone                               << " b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime << dendl;
ldout(sc->cct, 10) << conf->id << ": create_delete_marker: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime                            << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
lsubdout(get_context(), rgw, 15)         << __func__  << ": stat leaf not exact match file name = "  << path << dendl;
ldout(get_context(), 0) << __func__         << " BUG no such src renaming path="         << src_name         << dendl;
ldout(get_context(), 12) << __func__   << " rejecting attempt to rename directory path="   << rgw_fh->full_object_name()   << dendl;
ldout(get_context(), 12) << __func__   << " rejecting attempt to rename open file path="   << rgw_fh->full_object_name()   << dendl;
ldout(get_context(), 1)     << __func__     << " rename step 0 failed src="     << src_fh->full_object_name() << " " << src_name     << " dst=" << dst_fh->full_object_name()     << " " << dst_name     << "rc " << rc     << dendl;
ldout(get_context(), 12)   << __func__   << " rename step 0 success src="   << src_fh->full_object_name() << " " << src_name   << " dst=" << dst_fh->full_object_name()   << " " << dst_name   << " rc " << rc   << dendl;
ldout(get_context(), 12)     << __func__     << " rename step 1 success src="     << src_fh->full_object_name() << " " << src_name     << " dst=" << dst_fh->full_object_name()     << " " << dst_name     << " rc " << rc     << dendl;
ldout(get_context(), 1)     << __func__     << " rename step 1 failed src="     << src_fh->full_object_name() << " " << src_name     << " dst=" << dst_fh->full_object_name()     << " " << dst_name     << " rc " << rc     << dendl;
lsubdout(get_context(), rgw, 15) << __func__ << " get keys for: " << rgw_fh->object_name() << " keys:" << dendl;
lsubdout(get_context(), rgw, 15)   << "\tkey: " << attr.first << dendl;
lsubdout(get_context(), rgw, 17)      << __func__      << " update old versioned fh : " << obj_name      << dendl;
lsubdout(get_context(), rgw, 17) << __func__ << " update fh failed : " << obj_name << dendl;
lsubdout(fs->get_context(), rgw, 5)   << __PRETTY_FUNCTION__   << fh->name   << " before ObjUnref refs=" << fh->get_refcnt()   << dendl;
lsubdout(get_context(), rgw, 15) << "GC: top of expire loop" << " now=" << now << " expire_s=" << expire_s << dendl;
lsubdout(get_context(), rgw, 15)   << "GC: processing"   << " count=" << events.size()   << " events"   << dendl;
lsubdout(get_context(), rgw, 15)   << "try-expire ev: " << ev << dendl;
lsubdout(get_context(), rgw, 15)     << "ev rgw_fh: " << rgw_fh << dendl;
lsubdout(get_context(), rgw, 0)  << __func__  << " BUG non-directory found with READDIR event "  << "(" << rgw_fh->bucket_name() << ","  << rgw_fh->object_name() << ")"  << dendl;
lsubdout(get_context(), rgw, 15)    << "GC: delay expiration for "    << rgw_fh->object_name()    << " ev.ts=" << ev_ts    << " last_readdir=" << d_last_readdir    << dendl;
lsubdout(get_context(), rgw, 15)    << "GC: expiring "    << rgw_fh->object_name()    << dendl;
lsubdout(fs->get_context(), rgw, 17)      << __func__ << " " << *this      << dendl;
lsubdout(cct, rgw, 10)      << __func__ << " readdir called on "      << object_name()      << dendl;
lsubdout(fs->get_context(), rgw, 15)      << __func__      << " final link count=" << state.nlink      << dendl;
lsubdout(fs->get_context(), rgw, 5) << __func__ << " write attempted on deleted object " << this->object_name() << dendl;
lsubdout(fs->get_context(), rgw, 5)   << __func__   << " " << object_name()   << " non-0 initial write position " << off   << " (mounting with -o sync required)"   << dendl;
lsubdout(fs->get_context(), rgw, 5)   << __func__   << this->object_name()   << " write start failed " << off   << " (" << rc << ")"   << dendl;
lsubdout(fs->get_context(), rgw, 5) << __func__ << object_name() << " failed write at position " << off << " (fails write transaction) " << dendl;
lsubdout(fs->get_context(), rgw, 10) << __func__ << " finishing write trans on " << object_name() << dendl;
ldout(state->cct, 20) << "processor->prepare() returned ret=" << op_ret   << dendl;
ldout(state->cct, 1) << "Cannot load plugin for rgw_compression_type "                         << compression_type << dendl;
ldout(state->cct, 5)        << " chunks arrived in wrong order"        << " (mounting with -o sync required)"        << dendl;
ldpp_dout(this, 20) << "storing " << RGW_ATTR_COMPRESSION   << " with type=" << cs_info.compression_type   << ", orig_size=" << cs_info.orig_size   << ", blocks=" << cs_info.blocks.size() << dendl;
lsubdout(fs->get_context(), rgw, 17) << __func__ << " BANG"<< *rgw_fh << dendl;
lsubdout(fs->get_context(), rgw, 17)    << __func__ << " " << *rgw_fh    << dendl;
lsubdout(parent->get_fs()->get_context(), rgw, 15)    << __func__    << " offset=" << *offset    << dendl;
lsubdout(parent->get_fs()->get_context(), rgw, 15)    << __func__    << " offset=" << ((name) ? name : "(nil)")    << dendl;
ldpp_dout(dpp, -1) << "ERROR: could not remove non-empty bucket " << info.bucket.name << dendl;
ldpp_dout(dpp, -1) << "ERROR: could not remove bucket " <<      info.bucket.name << dendl;
ldpp_dout(dpp, 5) << "Searching permissions for identity=" << auth_identity                << " mask=" << perm_mask << dendl;
ldout(cct, 5) << "Searching permissions for group=" << (int)group                << " mask=" << perm_mask << dendl;
ldout(cct, 5) << "Searching permissions for referer=" << http_referer                << " mask=" << perm_mask << dendl;
ldpp_dout(dpp, 20) << "-- Getting permissions begin with perm_mask=" << perm_mask                 << dendl;
ldpp_dout(dpp, 5) << "-- Getting permissions done for identity=" << auth_identity                << ", owner=" << owner.get_id()                << ", perm=" << perm << dendl;
ldpp_dout(dpp, 10) << " identity=" << auth_identity                 << " requested perm (type)=" << perm                 << ", policy perm=" << policy_perm                 << ", user_perm_mask=" << user_perm_mask                 << ", acl perm=" << acl_perm << dendl;
ldpp_dout(dpp, 15) << "NOTICE: cannot find bucket = " \        << hint.bucket_name << ". The object must be already removed" << dendl;
ldpp_dout(dpp, 1) << "ERROR: could not init bucket = " \        << hint.bucket_name << "due to ret = " << ret << dendl;
ldpp_dout(dpp, 15) << "got removal hint for: " << iter->key_ts.sec() \        << " - " << iter->key_ext << dendl;
ldout(store->ctx(), 20) << "trying to trim removal hints to=" << to                          << ", to_marker=" << to_marker << dendl;
ldpp_dout(dpp, 10) << "cannot get removal hints from shard: " << shard                     << dendl;
dout(1) << "policy condition check " << v1 << " ["         << rgw::crypt_sanitize::s3_policy{v1, first}         << "] " << v2 << " ["         << rgw::crypt_sanitize::s3_policy{v2, second}         << "]" << dendl;
ldout(cct, 10) << "pushing period " << period.get_id()            << " to " << zone << dendl;
ldout(cct, 10) << "period's realm epoch " << period.get_realm_epoch()        << " is not newer than current realm epoch " << realm_epoch        << ", discarding update" << dendl;
ldout(cct, 10) << "period epoch " << period.get_epoch() << " is not newer "        "than current epoch " << period_epoch << ", discarding update" << dendl;
ldout(cct, 4) << "Zone master pushing period " << period.get_id()      << " epoch " << period_epoch << " to "      << conns.size() << " other zones" << dendl;
ldout(cct, 4) << "resume with " << pending_periods.size()      << " periods pending" << dendl;
ldout(cct, 10) << "trimming bilog shard " << shard_id          << " of " << bucket_info.bucket << " at marker " << marker << dendl;
ldout(cct, 10) << "trimming bilogs for bucket=" << pbucket_info->bucket       << " markers=" << min_markers << ", shards=" << min_markers.size() << dendl;
ldout(cct, 4) << "failed to trim bilog shards: "          << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "failed to init metadata listing: "        << cpp_strerror(r) << dendl;
ldout(cct, 10) << "failed to list metadata: "            << cpp_strerror(r) << dendl;
ldout(cct, 10) << "failed to restart metadata listing: "        << cpp_strerror(r) << dendl;
ldout(cct, 10) << "failed to list metadata: "          << cpp_strerror(r) << dendl;
ldout(cct, 10) << "failed to read bilog trim status: "            << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "listing cold buckets from marker="          << status.marker << dendl;
ldout(cct, 4) << "failed to list bucket instance metadata: "            << cpp_strerror(retcode) << dendl;
ldpp_dout(dpp, 4) << "failed to write updated trim status: "            << cpp_strerror(retcode) << dendl;
ldout(cct, 4) << "bucket index log processing completed in "        << ceph::mono_clock::now() - start_time << dendl;
ldout(cct, 20) << "oldest log realm_epoch=" << cursor.get_epoch()        << " period=" << cursor.get_period().get_id() << dendl;
ldout(cct, 4) << "purging log shards for realm_epoch=" << cursor.get_epoch()          << " period=" << cursor.get_period().get_id() << dendl;
ldout(cct, 1) << "failed to remove log shards: "            << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "removed log shards for realm_epoch=" << cursor.get_epoch()          << " period=" << cursor.get_period().get_id() << dendl;
ldout(cct, 10) << "already removed log shards for realm_epoch=" << cursor.get_epoch()            << " period=" << cursor.get_period().get_id() << dendl;
ldout(cct, 1) << "failed to remove log shards for realm_epoch="            << cursor.get_epoch() << " period=" << cursor.get_period().get_id()            << " with: " << cpp_strerror(retcode) << dendl;
ldout(cct, 1) << "take_min_status got peer status with "          << p->sync_markers.size() << " shards, expected "          << num_shards << dendl;
ldout(cct, 20) << "skipping log shard " << shard_id          << " at marker=" << stable          << " last_trim=" << last_trim          << " realm_epoch=" << sync_status.sync_info.realm_epoch << dendl;
ldout(cct, 10) << "trimming log shard " << shard_id        << " at marker=" << stable        << " last_trim=" << last_trim        << " realm_epoch=" << sync_status.sync_info.realm_epoch << dendl;
ldout(cct, 4) << "realm epoch min=" << epoch          << " current=" << env.current.get_epoch()<< dendl;
ldout(cct, 10) << "mdlogs already purged up to realm_epoch "            << env.last_trim_epoch << dendl;
ldpp_dout(env.dpp, 5) << "failed to read first entry from master's mdlog shard "          << shard_id << " for period " << period_id          << ": " << cpp_strerror(retcode) << dendl;
ldpp_dout(env.dpp, 10) << "empty master mdlog shard " << shard_id          << ", reading last timestamp from shard info" << dendl;
ldpp_dout(env.dpp, 5) << "failed to read info from master's mdlog shard "            << shard_id << " for period " << period_id            << ": " << cpp_strerror(retcode) << dendl;
ldpp_dout(env.dpp, 10) << "got mdlog shard info with last update="          << info.last_update << dendl;
ldpp_dout(env.dpp, 5) << "failed to read first entry from master's mdlog shard "            << shard_id << " for period " << period_id            << ": " << cpp_strerror(retcode) << dendl;
ldpp_dout(env.dpp, 10) << "skipping log shard " << shard_id          << " at timestamp=" << stable          << " last_trim=" << *last_trim << dendl;
ldpp_dout(env.dpp, 10) << "trimming log shard " << shard_id        << " at timestamp=" << stable        << " last_trim=" << *last_trim << dendl;
ldpp_dout(env.dpp, 1) << "failed to trim mdlog shard " << shard_id          << ": " << cpp_strerror(retcode) << dendl;
ldout(cct, 10) << "mdlogs already purged through realm_epoch "          << env.last_trim_epoch << dendl;
ldpp_dout(dpp, 0) << "ERROR: url " << provider_url << " already in use"                    << id << dendl;
ldpp_dout(dpp, 0) << "failed reading provider url  " << provider_url << ": "                  << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR:  storing role info in pool: " << pool.name << ": "                  << provider_url << ": " << cpp_strerror(-ret) << dendl;
ldout(cct, 0) << "ERROR: tenant in arn doesn't match that of user " << this->tenant << ", "                  << tenant << ": " << dendl;
ldout(cct, 0) << "ERROR: deleting oidc url from pool: " << pool.name << ": "                  << provider_url << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << "ERROR: tenant in arn doesn't match that of user " << this->tenant << ", "                  << tenant << ": " << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode oidc provider info from pool: " << pool.name <<                  ": " << url << dendl;
ldpp_dout(dpp, 0) << "ERROR: listing filtered objects failed: " << pool.name << ": "                  << prefix << ": " << cpp_strerror(-r) << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to decode oidc provider info from pool: " << pool.name <<                    ": " << iter << dendl;
ldout(cct, 0) << "WARNING: detected a version of libcurl which contains a "        "bug in curl_multi_wait(). enabling a workaround that may degrade "        "performance slightly." << dendl;
dout(0) << "WARNING: curl operation timed out, network average transfer speed less than "               << cct->_conf->rgw_curl_low_speed_limit << " Bytes per second during " << cct->_conf->rgw_curl_low_speed_time << " seconds." << dendl;
ldout(cct, 5) << "Compression failed with exit code " << cr            << " for first part, storing uncompressed" << dendl;
ldout(cct, 10) << "Compression for rgw is enabled, decompress part "      << "bl_ofs="<< bl_ofs << bl_len << dendl;
ldout(cct, 20) << __func__ << ":" << " stack=" << (void *)stack << " is_blocked_by_stack()=" << stack->is_blocked_by_stack()              << " is_sleeping=" << stack->is_sleeping() << " waiting_for_child()=" << stack->waiting_for_child() << dendl;
ldout(cct, 4) << "no match for compressed offset " << ofs            << ", disabling etag verification" << dendl;
ldout(cct, 20) << "Single part object: " << " etag:" << calculated_etag          << dendl;
dout(20) << "civetweb config: " << pair.first               << ": " << pair.second << dendl;
dout(10) << "Found origin " << origin << ", set size:" <<         allowed_origins.size() << dendl;
dout(10) << "Finding " << sl << ", in " << h           << ", at offset not less than " << flen << dendl;
dout(10) << "Origin:" << origin << ", rule num:"       << loop << ", emptying now:" << rule_empty << dendl;
ldout(cct, 4) << "Notification on realm, reconfiguration "        "already scheduled" << dendl;
ldout(cct, 1) << "Woke up with a new configuration, retrying "            "RGWRados initialization." << dendl;
ldout(cct, 4) << "Got another notification, restarting RGWRados "          "initialization." << dendl;
ldpp_dout(dpp, 0) << "NOTICE: bucket " << bucket_info.bucket.name        << " is suspended" << dendl;
ldpp_dout(dpp, 0) << "NOTICE: bucket " << bucket_info.bucket.name        << " is suspended" << dendl;
ldpp_dout(dpp, 0) << "NOTICE: couldn't get bucket from bucket_name (name="   << bucket_log << ")" << dendl;
ldpp_dout(dpp, 0) << "NOTICE: request for data in a different zonegroup ("          << s->bucket->get_info().zonegroup << " != "          << store->get_zone()->get_zonegroup().get_id() << ")" << dendl;
ldpp_dout(dpp, 0) << "NOTICE: couldn't get user attrs for handling ACL "          "(user_id=" << s->user->get_id() << ", ret=" << ret << ")" << dendl;
ldpp_dout(this, 20) << "required_mask= " << required_mask      << " user.op_mask=" << s->user->get_info().op_mask << dendl;
ldpp_dout(this, 5) << "NOTICE: modify request to a read-only zone by a "        "non-system user, permission denied"  << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get obj attrs, obj=" << s->object        << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "RGWDeleteBucketTags() failed to remove RGW_ATTR_TAGS on bucket="    << s->bucket->get_name()    << " returned err= " << op_ret << dendl;
ldpp_dout(this, 20) << "user manifest obj=" << ent.key.name      << "[" << ent.key.instance << "]" << dendl;
ldpp_dout(this, 20) << "reading obj=" << part << " ofs=" << cur_ofs      << " end=" << cur_end << dendl;
ldpp_dout(this, 0) << "ERROR: expected cs_info.orig_size=" << cs_info.orig_size          << ", actual read size=" << ent.meta.size << dendl;
ldpp_dout(this, 0) << "ERROR: expected obj_size=" << part->get_obj_size()          << ", actual read size=" << ent.meta.size << dendl;
dout(20) << "iterate_slo_parts()"                          << " obj=" << part.obj_name                          << " start_ofs=" << start_ofs                          << " end_ofs=" << end_ofs                          << dendl;
ldpp_dout(this, 2) << "RGWGetObj::handle_user_manifest() prefix="                   << prefix_view << dendl;
ldpp_dout(this, 0) << "could not get bucket info for bucket="         << bucket_name << dendl;
ldpp_dout(this, 0) << "could not get bucket info for bucket="      << bucket_name << dendl;
ldpp_dout(this, 0) << "failed to read bucket ACL for bucket "                           << bucket << dendl;
ldpp_dout(this, 20) << "slo_part: bucket=" << part.bucket                      << " obj=" << part.obj_name                      << " size=" << part.size                      << " etag=" << part.etag                      << dendl;
ldpp_dout(this, 20) << "Requested: ofs=" << ofs                    << " end=" << end                    << " total=" << total_len                    << dendl;
ldout(s->cct, 0) << "ERROR: caught buffer::error, couldn't decode TagSet" << dendl;
ldpp_dout(this, 0) << "ERROR: torrents are not supported for objects "          "encrypted with SSE-C" << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get_torrent_file ret= " << op_ret                       << dendl;
ldpp_dout(this, 0) << "ERROR: failed to handle user manifest ret="         << op_ret << dendl;
ldpp_dout(this, 0) << "ERROR: failed to handle slo manifest ret=" << op_ret         << dendl;
ldpp_dout(this, 10) << "WARNING: failed on rgw_get_user_buckets uid="   << s->user->get_id() << dendl;
ldpp_dout(this, 10) << "WARNING: failed on list_buckets uid="   << s->user->get_id() << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket->get_name()       << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket->get_name()        << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: forward_to_master failed on bucket=" << s->bucket->get_name()      << "returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket        << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) <<      "ERROR: unordered bucket listing requested with a delimiter" << dendl;
ldpp_dout(this, 10) << "user cannot create a bucket in a different tenant"                        << " (user_id.tenant=" << s->user->get_tenant()                        << " requested=" << s->bucket_tenant << ")"                        << dendl;
ldpp_dout(this, 0) << "location constraint (" << location_constraint << ")"                       << " can't be found." << dendl;
ldpp_dout(this, 0) << "location constraint (" << location_constraint << ")"                     << " doesn't match zonegroup" << " (" << store->get_zone()->get_zonegroup().api_name << ")"                     << dendl;
ldpp_dout(this, 0) << "placement target (" << placement_rule.name << ")"                     << " doesn't exist in the placement targets of zonegroup"                     << " (" << store->get_zone()->get_zonegroup().api_name << ")" << dendl;
ldpp_dout(this, 0) << "WARNING: failed to unlink bucket: ret=" << op_ret         << dendl;
ldpp_dout(this, 20) << "get_system_versioning_params() returned ret="        << op_ret << dendl;
ldpp_dout(this, 20) << "processor->prepare() returned ret=" << op_ret        << dendl;
ldpp_dout(this, 1) << "Cannot load plugin for compression type "            << compression_type << dendl;
ldpp_dout(this, 20) << "processor->process() returned ret="          << op_ret << dendl;
ldpp_dout(this, 20) << "storing " << RGW_ATTR_COMPRESSION        << " with type=" << cs_info.compression_type        << ", orig_size=" << cs_info.orig_size        << ", blocks=" << cs_info.blocks.size() << dendl;
ldpp_dout(this, 1) << "Cannot load plugin for compression type "                           << compression_type << dendl;
ldpp_dout(this, 4) << "The size of request xml data is larger than the max limitation, data size = "                       << s->length << dendl;
ldpp_dout(this, 4) << "An acl can have up to " << max_num        << " grants, request acl grants num: " << grants_num << dendl;
ldpp_dout(this, 5) << s->err.message                     << " Specified content md5: " << content_md5                     << ", calculated content md5: " << data_hash_res                     << dendl;
ldpp_dout(this, 0) << "RGWLC::RGWDeleteCORS() failed to set attrs on bucket=" << s->bucket->get_name()    << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket->get_name()       << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get obj attrs, obj=" << meta_obj       << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: total parts mismatch: have: " << total_parts         << " expected: " << parts->parts.size() << dendl;
ldpp_dout(this, 0) << "NOTICE: parts num mismatch: next requested: "    << iter->first << " next uploaded: "    << obj_iter->first << dendl;
ldpp_dout(this, 0) << "NOTICE: etag mismatch: part: " << iter->first    << " etag: " << iter->second << dendl;
ldpp_dout(this, 0) << "ERROR: empty manifest for object part: obj="    << src_obj << dendl;
ldpp_dout(this, 0) << "ERROR: compression type was changed during multipart upload ("                           << cs_info.compression_type << ">>" << obj_part.cs_info.compression_type << ")" << dendl;
ldpp_dout(this, 10) << "user cannot create a bucket in a different tenant"        << " (user_id.tenant=" << s->user->get_tenant()        << " requested=" << s->bucket_tenant << ")" << dendl;
ldpp_dout(this, 20) << "rgw_create_bucket returned ret=" << op_ret      << ", bucket=" << bucket << dendl;
ldpp_dout(this, 1) << "Cannot load plugin for rgw_compression_type "          << compression_type << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get obj attrs, obj=" << s->object        << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "ERROR: failed to delete obj attrs, obj=" << s->object         << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket->get_name()        << " returned err=" << op_ret << dendl;
ldpp_dout(this, 0) << "NOTICE: put_bucket_info on bucket=" << s->bucket->get_name()        << " returned err=" << op_ret << dendl;
ldpp_dout(s, 10) << "init_permissions on " << s->bucket        << " failed, ret=" << ret << dendl;
ldpp_dout(op, 10) << "read_permissions on " << s->bucket << ":"        << s->object << " only_bucket=" << only_bucket        << " ret=" << ret << dendl;
ldpp_dout(this, 0) << "can't find bucket IAM POLICY attr bucket_name = "        << s->bucket_name << dendl;
ldpp_dout(this, 10) << "The bucket policy does not exist, bucket: "          << s->bucket_name << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get obj attrs, obj=" << s->object                       << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "ERROR: failed to get obj attrs, obj=" << s->object                       << " ret=" << op_ret << dendl;
ldpp_dout(this, 0) << "can't find bucket IAM POLICY attr bucket_name = "         << s->bucket_name << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to get bucket instance info for "        << bucket << dendl;
ldout(cct, 0)      << __PRETTY_FUNCTION__      << ": Both Omap and FIFO backends exist, but are empty. Will remove."      << dendl;
ldout(cct, 0) << __PRETTY_FUNCTION__    << ": Omap requested, FIFO exists, but is empty. Deleting."    << dendl;
ldout(cct, 0) << __PRETTY_FUNCTION__    << ": FIFO requested, Omap exists, but is empty. Deleting."    << dendl;
ldout(cct, 20) << "RGWDataChangesLog::update_renewd() bucket_name="   << bs.bucket.name << " shard_id=" << bs.shard_id   << " expiration=" << expiration << dendl;
ldpp_dout(dpp, 20) << "RGWDataChangesLog::add_entry() bucket.name=" << bucket.name   << " shard_id=" << shard_id << " now=" << now   << " cur_expiration=" << status->cur_expiration << dendl;
ldpp_dout(sync_env->dpp, 4) << "failed to read sync status info with "          << cpp_strerror(retcode) << dendl;
ldpp_dout(sync_env->dpp, 4) << "failed to read sync status markers with "          << cpp_strerror(retcode) << dendl;
ldpp_dout(sync_env->dpp, 4) << "clearing marker=" << sync_marker.marker            << " from old realm_epoch=" << sync_marker.realm_epoch            << " (now " << realm_epoch << ')' << dendl;
ldpp_dout(sync_env->dpp, 10) << "RGWMetaSyncCR on current period="                << cursor.get_period().get_id() << dendl;
ldpp_dout(sync_env->dpp, 10) << "RGWMetaSyncCR on period="              << cursor.get_period().get_id() << ", next="              << next.get_period().get_id() << dendl;
ldpp_dout(sync_env->dpp, 10) << "RGWMetaSyncCR: skipping shard " << shard_id                    << " with empty period marker" << dendl;
ldpp_dout(dpp, 1) << "epoch=" << sync_status.sync_info.realm_epoch           << " in sync status comes before remote's oldest mdlog epoch="           << mdlog_info.realm_epoch << ", restarting sync" << dendl;
ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to read mdlog info with "                                      << cpp_strerror(ret) << dendl;
ldpp_dout(this, 4) << "An website routing config can have up to "                     << max_num                     << " rules, request website routing rules num: "                     << routing_rules_num << dendl;
ldpp_dout(this, 10) << "create bucket location constraint: "        << location_constraint << dendl;
ldpp_dout(this, 20) << "adding bucket to policy env: " << s->bucket->get_name()      << dendl;
ldpp_dout(this, 20) << "read part header -- part.name="                        << part.name << dendl;
ldpp_dout(this, 20) << " " << param_pair.first                            << " -> " << param_pair.second << dendl;
ldpp_dout(this, 4) << "An cors config can have up to "                     << max_num                     << " rules, request cors rules num: "                     << cors_rules_num << dendl;
ldpp_dout(s, 10) << "s->object=" << s->object           << " s->bucket=" << rgw_make_bucket_entry_name(s->bucket_tenant, s->bucket_name) << dendl;
ldpp_dout(s, 20) << __func__ << " handler=" << typeid(*handler).name()      << dendl;
ldpp_dout(s, 10) << "retarget get_effective_key " << s->object << " -> "      << new_obj << dendl;
ldpp_dout(s, 10) << "retarget redirect code=" << redirect_code        << " proto+host:" << protocol << "://" << hostname        << " -> " << s->redirect << dendl;
ldpp_dout(s, 10) << "error handler redirect code=" << redirect_code        << " proto+host:" << protocol << "://" << hostname        << " -> " << s->redirect << dendl;
ldpp_dout(dpp, 10) << "canonical headers format = "                     << sanitize{canonical_headers} << dendl;
ldpp_dout(s, 10) << "canonical headers format = "                      << sanitize{*canonical_headers} << dendl;
ldpp_dout(s, 10) << "failed to create the canonized auth header\n"                   << rgw::crypt_sanitize::auth{s,string_to_sign} << dendl;
ldpp_dout(s, 10) << "string_to_sign:\n"                 << rgw::crypt_sanitize::auth{s,string_to_sign} << dendl;
ldpp_dout(s, 0) << "Signature verification algorithm AWS v4"                     << " (AWS4-HMAC-SHA256)" << dendl;
ldpp_dout(dpp, 5) << "error reading user info, uid=" << access_key_id              << " can't authenticate" << dendl;
ldpp_dout(dpp, 10) << "ERROR: User id of type: " << s->user->type                     << " is present" << dendl;
ldpp_dout(dpp, 15) << "string_to_sign="                 << rgw::crypt_sanitize::log_content{string_to_sign}                 << dendl;
ldpp_dout(dpp, 15) << "string_to_sign="                 << rgw::crypt_sanitize::log_content{string_to_sign}                 << dendl;
ldout(s->cct, 10) << "processing segment " << i << " out of " << bl_len << " off " << ofs                      << " len " << len << " obj-size " << s->obj_size << dendl;
ldout(s->cct, 10) << "s3select:it->_len is zero. segment " << i << " out of " << bl_len                        <<  " obj-size " << s->obj_size << dendl;
ldout(sync_env->cct, 4) << "failed to read sync status info with "          << cpp_strerror(retcode) << dendl;
ldout(sync_env->cct, 4) << "failed to read sync status markers with "          << cpp_strerror(retcode) << dendl;
ldout(cct, 4) << "starting sync on " << bucket_shard_str{state->key}              << ' ' << *state->obligation << dendl;
ldout(cct, 0) << "ERROR: " << __func__ << ": acl translation was requested, but user (" << acl_translation_owner          << ") is not dest bucket owner (" << dest_bucket_info.owner << ")" << dendl;
ldout(sc->cct, 0) << "SYNC_ARCHIVE: create_delete_marker: b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " mtime=" << mtime                             << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
ldout(sync_env->cct, 0) << "failed to read recovering bucket shards with "           << cpp_strerror(retcode) << dendl;
ldout(sync_env->cct,0) << "failed to read sync status marker with "         << cpp_strerror(retcode) << dendl;
ldout(sync_env->cct,0) << "failed to read remote data log info with "           << cpp_strerror(retcode) << dendl;
ldpp_dout(sync_env->dpp, 20) << __func__ << ": source_zone=" << source_zone.value_or(rgw_zone_id("*")).id                                << " source_bucket=" << source_bucket.value_or(rgw_bucket())                                << " all_sources.size()=" << all_sources.size() << dendl;
ldpp_dout(sync_env->dpp, 20) << __func__ << ": target_zone=" << source_zone.value_or(rgw_zone_id("*")).id                                << " target_bucket=" << source_bucket.value_or(rgw_bucket())                                << " all_targets.size()=" << all_targets.size() << dendl;
ldpp_dout(this, 0) << "ERROR: failed to read sync status for "        << bucket_str{dest_bucket} << dendl;
ldpp_dout(this, 0) << "ERROR: failed to read sync status for "        << bucket_str{dest_bucket} << dendl;
ldout(cct, 20) << __func__ << "(): notifying datalog change, shard_id="     << shard_id << ": " << keys << dendl;
ldout(cct, 0) << "ERROR: ioctx.pool_requires_alignment2() returned "       << r << dendl;
ldout(cct, 0) << "ERROR: ioctx.pool_required_alignment2() returned "       << r << dendl;
ldpp_dout(dpp, 0) << "WARNING: This zone does not contain the placement target "                      << pt.second.name << " present in zonegroup" << dendl;
ldpp_dout(dpp, 1) << __func__ << " bucket index max shards is too large, reset to value: "      << get_max_bucket_shards() << dendl;
ldout(cct, 10) << "log_show_next pos " << state->pos << " bl " << state->bl.length()    << " off " << off    << " eof " << (int)state->eof    << dendl;
ldout(cct, 20) << "RGWRados::Bucket::List::" << __func__ <<      " starting attempt " << attempt << dendl;
ldout(cct, 0) << "RGWRados::Bucket::List::" << __func__ << ": ERROR marker failed to make forward progress;
attempt=" << attempt <<      ldpp_dout(dpp, 20) << "RGWRados::Bucket::List::" << __func__ << " considering entry " << entry.key << dendl;
ldout(cct, 0) << "ERROR: could not parse object name: " <<   obj.name << dendl;
ldout(cct, 0) <<  "WARNING: found delimiter in place other than the end of "  "the prefix;
obj.name=" << obj.name <<      ldout(cct, 20) << "RGWRados::Bucket::List::" << __func__ << " adding entry " << entry.key << " to result" << dendl;
ldout(cct, 20) << "setting cur_marker="                         << cur_marker.name                         << "[" << cur_marker.instance << "]"                         << dendl;
ldout(cct, 20) << "RGWRados::Bucket::List::" << __func__ <<      " INFO end of outer loop, truncated=" << truncated <<      ", count=" << count << ", attempt=" << attempt << dendl;
ldout(cct, 0) << "ERROR: could not parse object name: " <<   obj.name << dendl;
ldpp_dout(dpp, 20) << "iterating listing for bucket=" << bucket_info.bucket.name                 << ", obj_prefix=" << obj_prefix                 << ", obj_delim=" << obj_delim                 << dendl;
ldout(cct, 4) << "failed to decode compression info, "                "disabling etag verification" << dendl;
ldout(cct, 4) << "failed to initial etag verifier, "            "disabling etag verification" << dendl;
ldout(cct, 1) << "Cannot load plugin for compression type "                                        << compression_type << dendl;
ldout(cct, 0) << "ERROR: object truncated during fetching, expected "        << expected_size << " bytes but received " << cb.get_data_len() << dendl;
ldout(cct, 0) << "ERROR: source and destination objects don't match. Expected etag:"        << trimmed_etag << " Computed etag:" << verifier_etag << dendl;
ldpp_dout(dpp, 0) << "ERROR: copy op for encrypted object " << src_obj                  << " has not been implemented." << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): src_rule=" << src_rule->to_str() << " src_pool=" << src_pool                             << " dest_rule=" << dest_placement.to_str() << " dest_pool=" << dest_pool << dendl;
ldout(cct, 0) << "ERROR: failed to create ioctx pool=" <<        obj.pool << dendl;
ldout(cct, 5) << "delete_objs_inline: removing " << obj.pool <<    ":" << obj.key.name << dendl;
ldpp_dout(dpp, 20) << __func__ << "(): found obj in tombstone cache: obj=" << obj          << " mtime=" << s->mtime << " pgv=" << s->pg_ver << dendl;
ldout(store->ctx(), 5) << __func__         << ": ERROR: aio_operate() returned ret=" << r         << dendl;
ldout(cct, 0) << __func__ <<   " ERROR: failed to refresh bucket info after reshard at " <<   log_tag << ": " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 0) << __func__ << " ERROR: failed to get bucket resharding : " << cpp_strerror(-ret) << dendl;
ldpp_dout(dpp, 20) << __func__ <<   " INFO: failed to take reshard lock for bucket " <<   bucket_id << ";
expected if resharding underway" << dendl;
ldpp_dout(dpp, 10) << __func__ <<   " INFO: was able to take reshard lock for bucket " <<   bucket_id << dendl;
ldpp_dout(dpp, 0) << __func__ <<     " ERROR: failed to clear resharding flags for bucket " <<     bucket_id << dendl;
ldpp_dout(dpp, 5) << __func__ <<     " INFO: apparently successfully cleared resharding flags for "     "bucket " << bucket_id << dendl;
ldpp_dout(dpp, 0) << __func__ << " ERROR: bucket is still resharding, please retry" << dendl;
ldpp_dout(dpp, 0) << __func__ <<    " ERROR: bucket is still resharding, please retry" << dendl;
ldout(cct, 4) << "repair_olh setting olh_tag=" << olh.tag      << " key=" << olh.key << " delete_marker=" << olh.delete_marker << dendl;
ldout(cct, 0) << "repair_olh failed to write olh attributes with "        << cpp_strerror(r) << dendl;
ldpp_dout(dpp, 20) << "olh_log_entry: epoch=" << iter->first << " op=" << (int)entry.op                     << " key=" << entry.key.name << "[" << entry.key.instance << "] "                     << (entry.delete_marker ? "(delete)" : "") << dendl;
ldpp_dout(dpp, 20) << "apply_olh_log applying key=" << entry.key << " epoch=" << iter->first << " delete_marker=" << entry.delete_marker              << " over current=" << key << " epoch=" << link_epoch << " delete_marker=" << delete_marker << dendl;
ldpp_dout(dpp, 20) << "apply_olh skipping key=" << entry.key<< " epoch=" << iter->first << " delete_marker=" << entry.delete_marker              << " before current=" << key << " epoch=" << link_epoch << " delete_marker=" << delete_marker << dendl;
ldout(cct, 10) << "nobjects_begin threw " << e.what()       << ", returning " << r << dendl;
ldout(cct, 10) << "nobjects_begin threw " << e.what()       << ", returning -5" << dendl;
ldout(cct, 10) << "NObjectIterator threw exception " << e.what()       << ", returning " << r << dendl;
ldout(cct, 10) << "NObjectIterator threw exception " << e.what()       << ", returning -5" << dendl;
ldpp_dout(dpp, 10) << "RGWRados::" << __func__ << ": " << bucket_info.bucket <<    " start_after=\"" << start_after.name <<    "[" << start_after.instance <<    "]\", prefix=\"" << prefix <<    "\" num_entries=" << num_entries <<    ", list_versions=" << list_versions <<    ", expansion_factor=" << expansion_factor << dendl;
ldpp_dout(dpp, 10) << "RGWRados::" << __func__ <<    " request from each of " << shard_count <<    " shard(s) for " << num_entries_per_shard << " entries to get " <<    num_entries << " total entries" << dendl;
ldpp_dout(dpp, 20) << "RGWRados::" << __func__ << " currently processing " <<      dirent.key << " from shard " << tracker.shard_idx << dendl;
ldpp_dout(dpp, 10) << "RGWRados::" << __func__ << ": got " << dirent.key.name << "[" << dirent.key.instance << "]" << dendl;
ldpp_dout(dpp, 10) << "RGWRados::" << __func__ << ": skipping " << dirent.key.name << "[" << dirent.key.instance << "]" << dendl;
ldpp_dout(dpp, 20) << "RGWRados::" << __func__ <<    ": returning, count=" << count << ", is_truncated=" << *is_truncated <<    dendl;
ldpp_dout(dpp, 10) << "RGWRados::" << __func__ <<      ": INFO requested " << num_entries << " entries but returning " <<      count << ", which is truncated" << dendl;
ldpp_dout(dpp, 20) << "RGWRados::" << __func__ <<      ": returning, last_entry=" << *last_entry << dendl;
ldpp_dout(dpp, 20) << "RGWRados::" << __func__ <<      ": returning, last_entry NOT SET" << dendl;
ldpp_dout(dpp, 10) << "cls_bucket_list_unordered " << bucket_info.bucket <<    " start_after " << start_after.name << "[" << start_after.instance <<    "] num_entries " << num_entries << dendl;
ldout(cct, 0) << "ERROR: RGWRados::cls_bucket_list_unordered received an invalid " "start marker: '" << start_after << "'" << dendl;
ldpp_dout(dpp, 10) << "RGWRados::cls_bucket_list_unordered: got " <<   dirent.key.name << "[" << dirent.key.instance << "]" << dendl;
ldout(cct, 20) << "cls_bucket_head: open_bucket_index() returned "                   << r << dendl;
ldout(cct, 20) << "cls_bucket_head: CLSRGWIssueGetDirHeader() returned "                   << r << dendl;
ldpp_dout(dpp, 1) << "RGWRados::" << __func__ << " bucket " << bucket.name <<    " needs resharding;
current num shards " << bucket_info.layout.current_index.layout.normal.num_shards <<  dout(0) << "WARNING: set_req_state_err err_no=" << err_no << " resorting to 500" << dendl;
ldout(s->cct, 16) << __func__      << " raw marker " << s->info.args.get("marker")      << dendl;
ldout(s->cct, 16) << __func__      << " marker " << marker << dendl;
dout(5) << "ERROR: lists_keys_next(): " << cpp_strerror(op_ret)       << dendl;
ldout(cct, 0) << "ERROR: Vault token file '" << token_file << "' permissions are "                    << "too open, it must not be accessible by other users" << dendl;
ldout(cct, 20) << "Request to Vault returned " << res << " and HTTP status "      << secret_req.get_http_status() << dendl;
ldout(cct, 0) << "ERROR: Failed to parse JSON response from Vault: "  << rapidjson::GetParseError_En(d.GetParseError()) << dendl;
ldout(cct, 0) << "ERROR: Failed to parse JSON response from Vault: "  << rapidjson::GetParseError_En(d.GetParseError()) << dendl;
ldout(cct, 0) << "ERROR: Failed to parse JSON response from Vault: "  << rapidjson::GetParseError_En(d.GetParseError()) << dendl;
ldout(cct, 0) << "ERROR: Failed to parse JSON response from Vault: "  << rapidjson::GetParseError_En(d.GetParseError()) << dendl;
ldout(cct, 5) << "ERROR: get_actual_key_from_conf invalid encryption key id "                  << "which contains character that is not base64 encoded."                  << dendl;
ldout(cct, 0) << "Supplied resource is discarded: " << string(s, l)      << dendl;
ldpp_dout(dpp, 1) << "ERROR: failed to create push endpoint: "             << push_endpoint_name << " due to: " << e.what() << dendl;
ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to geting bucket info: " << "tenant="              << get_bucket_info.tenant << " name=" << get_bucket_info.bucket_name << ": ret=" << retcode << dendl;
ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to create bucket: " << "tenant="              << get_bucket_info.tenant << " name=" << get_bucket_info.bucket_name << ": ret=" << retcode << dendl;
ldpp_dout(sync_env->dpp, 1) << "ERROR: failed to create bucket " << "tenant=" << get_bucket_info.tenant          << " name=" << get_bucket_info.bucket_name << dendl;
ldout(sync_env->cct, 10) << "failed to push event: " << event->id <<            " to endpoint: " << sub_conf->push_endpoint_name << " ret=" << retcode << dendl;
ldout(sync_env->cct, 20) << "event: " << event->id <<          " pushed to endpoint: " << sub_conf->push_endpoint_name << dendl;
ldout(sc->cct, 20) << ": handle event: obj: z=" << sc->source_zone                               << " event=" << json_str("event", *event, false)                               << " owner=" << owner << dendl;
ldout(sc->cct, 20) << ": notification for " << event->source << ": topic=" <<           (*titer)->name << ", has " << (*titer)->subs.size() << " subscriptions" << dendl;
ldout(sc->cct, 1) << "ERROR: failed to find subscription config for subscription=" << *siter               << " ret=" << retcode << dendl;
ldout(sc->cct, 20) << ": stat of remote obj: z=" << sc->source_zone                               << " b=" << sync_pipe.info.source_bs.bucket << " k=" << key << " size=" << size << " mtime=" << mtime                               << " attrs=" << attrs << dendl;
ldout(sc->cct, 20) << ": remove remote obj: z=" << sc->source_zone                               << " b=" << bucket << " k=" << key << " mtime=" << mtime << dendl;
ldout(sc->cct, 10) << conf->id << ": sync_object: b=" << sync_pipe <<           " k=" << key << " versioned_epoch=" << versioned_epoch.value_or(0) << dendl;
ldout(sc->cct, 10) << conf->id << ": rm_object: b=" << sync_pipe <<           " k=" << key << " mtime=" << mtime << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
ldout(sc->cct, 10) << conf->id << ": create_delete_marker: b=" << sync_pipe <<           " k=" << key << " mtime=" << mtime << " versioned=" << versioned << " versioned_epoch=" << versioned_epoch << dendl;
lsubdout(cct, rgw_sync,  } else {    lsubdout(cct, rgw,  }}class RGWSyncTraceServiceMapThread : public RGWRadosThread {  RGWRados *store;
ldout(ctx, 10)      << __func__ << " LDAP auth no rgw_ldap_secret file found in conf"      << dendl;
ldout(g_ceph_context, 12)      << __func__ << " search filter: " << filter      << dendl;
ldout(g_ceph_context, 10)     << __func__ << " simple_bind failed uid=" << uid     << "ldap err=" << ret     << dendl;
ldout(g_ceph_context, 12)   << __func__ << " ldap_search_s no user matching uid=" << uid   << dendl;
ldout(g_ceph_context, 5) << __func__ << " ldap_search_s error uid=" << uid << " ldap err=" << ret << dendl;
ldout(sync_env->cct, 20) << "stat of remote obj: z=" << sc->source_zone                             << " b=" << src_bucket << " k=" << key                             << " size=" << size << " mtime=" << mtime << dendl;
dout(0) << "ERROR: no socket server point defined, cannot " "start fcgi frontend" << dendl;
dout(0) << "ERROR: cannot create socket: path=" << path_str      << " error=" << cpp_strerror(err) << dendl;
dout(0) << "ERROR: FCGX_OpenSocket (" << path << ") returned "       << sock_fd << dendl;
dout(0) << "WARNING: couldn't set permissions on unix domain socket"       << dendl;
dout(0) << "ERROR: FCGX_OpenSocket (" << bind.c_str() << ") returned "       << sock_fd << dendl;
ldout(cct, 0) << "ERROR: could not part info, caught buffer::error" << dendl;
ldpp_dout(dpp, 20) << __func__ << ": list_multipart_parts returned " << ret << dendl;
ldpp_dout(dpp, 20) << __func__ << ": del_op.delete_obj returned " <<      ret << dendl;
ldpp_dout(dpp, 0) << __func__ << " ERROR : calling list_bucket_multiparts;
ret=" << ret <<    ldpp_dout(dpp, 20) << __func__ <<      " INFO: aborting and cleaning up multipart upload(s);
bucket=\"" <<     ldpp_dout(dpp, 0) << __func__ <<       " ERROR : failed to abort and clean-up multipart upload \"" <<       key.get_oid() << "\"" << dendl;
ldpp_dout(dpp, 10) << __func__ <<       " NOTE : unable to find part(s) of "       "aborted multipart upload of \"" << key.get_oid() <<       "\" for cleaning up" << dendl;
ldpp_dout(dpp, 0) << __func__ <<   " WARNING : aborted " << num_deleted <<   " incomplete multipart uploads" << dendl;
ldpp_dout(dpp, 0) << "WARNING: gc cleanup of tags on gc shard index=" <<   io.index << " returned error, ret=" << ret << dendl;
ldpp_dout(dpp, 0) << "WARNING: gc could not remove oid=" << io.oid << ", ret=" << ret << dendl;
ldpp_dout(dpp, 20) << __func__ <<      " removing entries from gc log shard index=" << index << ", size=" <<      rt.size() << ", entries=" << rt << dendl;
ldpp_dout(dpp, 0) << "WARNING: failed to remove tags on gc shard index=" << index << " ret=" << ret << dendl;
ldpp_dout(dpp, 0) << "ERROR: failed to remove queue entries on index=" <<     index << " ret=" << ret << dendl;
ldpp_dout(this, 20) << "RGWGC::process entered with GC index_shard=" <<    index << ", max_secs=" << max_secs << ", expired_only=" <<    expired_only << dendl;
ldpp_dout(this, 10) << "RGWGC::process failed to acquire lock on " <<      obj_names[index] << dendl;
ldpp_dout(this, 20) <<      "RGWGC::process cls_rgw_gc_list returned with returned:" << ret <<      ", entries.size=" << entries.size() << ", truncated=" << truncated <<      ", next_marker='" << next_marker << "'" << dendl;
ldpp_dout(this, 20) <<      "RGWGC::process cls_rgw_gc_queue_list_entries returned with return value:" << ret <<      ", entries.size=" << entries.size() << ", truncated=" << truncated <<      ", next_marker='" << next_marker << "'" << dendl;
ldpp_dout(this, 20) << "RGWGC::process iterating over entry tag='" << info.tag << "', time=" << info.time << ", chain.objs.size()=" << info.chain.objs.size() << dendl;
ldpp_dout(this, 0) << "ERROR: failed to create ioctx pool=" <<  obj.pool << dendl;
ldpp_dout(this, 5) << "RGWGC::process removing " << obj.pool <<     ":" << obj.key.name << dendl;
ldpp_dout(this, 0) <<       "WARNING: failed to schedule deletion for oid=" << oid << dendl;
ldpp_dout(this, 0) <<          "WARNING: failed to remove queue entries" << dendl;
// dout() messages will be sent to stderr, but FCGX wants messages on stdout  // Redirect stderr to stdout.  TEMP_FAILURE_RETRY(close(STDERR_FILENO));
dout(1) << __func__ << " unable to determine rgw numa node " << numa_node              << " CPUs" << dendl;
dout(1) << __func__ << " unable to determine mds numa node " << numa_node              << " CPUs" << dendl;
dout(1) << "Compression init error: init return "         << ret << " instead of Z_OK" << dendl;
dout(1) << "Compression error: compress return Z_STREAM_ERROR("              << ret << ")" << dendl;
dout(1) << "Compression error: isal_deflate return error ("              << ret << ")" << dendl;
dout(1) << "Decompression init error: init return "         << ret << " instead of Z_OK" << dendl;
dout(1) << "Decompression error: decompress return "            << ret << dendl;
dout(10) << __func__ << " read last committed monmap ver "               << latest_ver << dendl;
dout(10) << __func__ << " using stashed monmap " << b.get_epoch()     << " instead" << dendl;
dout(10) << __func__ << " ignoring stashed monmap " << b.get_epoch()     << dendl;
dout(0) << argv[0] << ": renaming mon." << name << " " << av    << " to mon." << g_conf()->name.get_id() << dendl;
dout(0) << argv[0] << ": renaming mon." << name << " " << av    << " to mon." << g_conf()->name.get_id() << dendl;
dout(0) << " monmap addrs are " << ls << ", checking if any are local"  << dendl;
dout(0) << "no local addresses appear in bootstrap monmap"        << dendl;
dout(0) << argv[0] << ": mon." << name << " " << local      << " is local, renaming to mon." << g_conf()->name.get_id()      << dendl;
dout(0) << argv[0] << ": mon." << name << " " << local      << " is local, but not 'noname-' + something;
"    dout(0) << argv[0] << ": created monfs at " << g_conf()->mon_data      << " for " << g_conf()->name << dendl;
dout(0) << "last committed monmap epoch is " << v << ", injected map will be " << (v+1)            << dendl;
dout(0) << "changing monmap epoch from " << tmp.get_epoch()           << " to " << v << dendl;
dout(0) << "using public_addr " << g_conf()->public_addr << " -> "       << ipaddrs << dendl;
dout(0) << "starting " << g_conf()->name << " rank " << rank   << " at public addrs " << public_addrs   << " at bind addrs " << bind_addrs   << " mon_data " << g_conf()->mon_data   << " fsid " << monmap.get_fsid()   << dendl;
ldout(cct,12) << "worker wq " << wq->name << " start processing " << item   << " (" << processing << " active)" << dendl;
ldout(cct,15) << "worker wq " << wq->name << " done processing " << item   << " (" << processing << " active)" << dendl;
ldout(cct, 5) << __func__                  << " target: " << target_mem                  << " mapped: " << mapped                    << " unmapped: " << unmapped                  << " heap: " << heap_size                  << " old mem: " << tuned_mem                  << " new mem: " << new_size << dendl;
ldout(cct, 10) << __func__ << " " << it->first                       << " pri: " << (int) pri                       << " round: " << round                       << " wanted: " << cache_wants                       << " ratio: " << it->second->get_cache_ratio()                       << " cur_ratios: " << cur_ratios                       << " fair_share: " << fair_share                       << " mem_avail: " << *mem_avail                       << dendl;
ldout(cct, 10) << "get_or_fail " << c << " success (" << count.load() << " -> " << (count.load() + c) << ")" << dendl;
ldout(cct, 10) << "put " << c << " (" << count.load() << " -> "   << (count.load()-c) << ")" << dendl;
ldout(m_cct, 0) << "dropping data output, max backlog reached (skipped=="        << skipped << ")"        << dendl;
ldout(cct,10) << __func__ << " " << i.first << " = " << i.second      << " (unrecognized option)" << dendl;
ldout(cct, 4) << __func__ << " failed to set " << i.first << " = "      << i.second << ": " << err << dendl;
ldout(cct,20) << __func__ << " " << i.first << " = " << i.second      << " (no change)" << dendl;
ldout(cct,10) << __func__ << " " << name    << " cleared (was " << Option::to_str(config->second) << ")"    << dendl;
ldout(cct, 1) << __func__ << " " << type << " " << name  << " " << plugin << dendl;
ldout(cct, 1) << __func__ << " " << type << " " << name  << " = " << ret << dendl;
ldout(cct, 1) << __func__ << ": " << type << " " << name  << " loaded and registered" << dendl;
ldout(m_cct, 1) << who << " '" << h->name << "'"      << " had timed out after " << h->grace << dendl;
ldout(m_cct, 1) << who << " '" << h->name << "'"      << " had suicide timed out after " << h->suicide_grace << dendl;
ldout(m_cct, 20) << "reset_timeout '" << h->name << "' grace " << grace     << " suicide " << suicide_grace << dendl;
ldout(m_cct, 0) << "is_healthy = false, injected failure for next "                    << sec << " seconds" << dendl;
ldout(m_cct, 20) << "is_healthy = " << (healthy ? "healthy" : "NOT HEALTHY")    << ", total workers: " << total << ", number of unhealthy: " << unhealthy << dendl;
ldout(m_cct, 0) << "unable to touch " << path << ": "                     << cpp_strerror(errno) << dendl;
dout(10) << "ops_in_flight.size: " << ops_in_flight.size()           << ";
oldest is " << *oldest_secs  dout(6) << " seq: " << seq   << ", time: " << stamp   << ", event: " << event   << ", op: " << get_desc()   << dendl;
ldout(cct_, 20) << "Registry key : " << strKey                    << " does not exist." << dendl;
int SubProcess::get_stdout() const {  ceph_assert(is_spawned());
void SubProcess::close_stdout() {  ceph_assert(is_spawned());
dout(5) << "Updating service service status (" << current_state             << ") and exit code(" << exit_code << ")." << dendl;
ldout(m_cct, 5) << "AdminSocket: (ignoring) read(2) error: '"          << cpp_strerror(e) << dendl;
ldout(m_cct, 5) << "register_command " << prefix      << " cmddesc " << cmddesc << " hook " << hook      << " EEXIST" << dendl;
ldout(m_cct, 5) << "register_command " << prefix << " hook " << hook      << dendl;
ldout(m_cct, 5) << "Unix sockets require Windows 10.0.17063 or later. "                    << "The admin socket will not be available." << dendl;
lockdep_dout(0) << "ERROR OUT OF IDS .. have 0"        << " max " << MAX_LOCKS << dendl;
lockdep_dout(20) << "have " << refs << " of '" << name << "' " <<   "from " << id << dendl;
lockdep_dout(0) << "existing intermediate dependency " << lock_names[a]          << " (" << a << ") -> " << lock_names[i] << " (" << i << ") at:\n";
lockdep_dout(0) << "new dependency " << lock_names[p->first]  << " (" << p->first << ") -> " << name << " (" << id << ")"  << " creates a cycle at\n";
lgeneric_dout(this, 1) << "do_command '" << command << "' '" << cmdmap << "'"    << dendl;
lgeneric_dout(this, 1) << "do_command '" << command << "' '" << cmdmap           << "' result is " << out->length() << " bytes" << dendl;
lsubdout(local_cct, refs, 1) << "RefCountedObject::put " << this << " "     << (v + 1) << " -> " << v     << dendl;
lsubdout(cct, refs, 1) << "RefCountedObject::get " << this << " "      << (v - 1) << " -> " << v << dendl;
int SubProcess::get_stdout() const {  ceph_assert(is_spawned());
void SubProcess::close_stdout() {  ceph_assert(is_spawned());
ldout(cct, 10) << "finisher_thread done with " << in_progress_queue                     << dendl;
ldout(cct, 20) << __func__ << " log_to_monitors " << log_to_monitors   << " log_to_syslog " << log_to_syslog   << " log_channels " << log_channels   << " log_prios " << log_prios   << dendl;
ldout(cct, 10) << __func__   << " to_monitors: " << (to_monitors ? "true" : "false")   << " to_syslog: " << (to_syslog ? "true" : "false")   << " syslog_facility: " << syslog_facility   << " prio: " << prio   << " to_graylog: " << (to_graylog ? "true" : "false")   << " graylog_host: " << graylog_host   << " graylog_port: " << graylog_port   << ")" << dendl;
ldout(cct,10) << " log_queue is " << log_queue.size() << " last_log " << last_log << " sent " << last_log_sent  << " num " << log_queue.size()  << " unsent " << num_unsent  << " sending " << num_send << dendl;
dout(2) << __func__ << " " << path            << ": ceph_open failed. Error: " << fd << dendl;
dout(2) << __func__ << " " << path            << ": ceph_mkdir failed. Error: " << ret << dendl;
dout(20) << __func__ << " " << path           << ". CreationDisposition: " << CreationDisposition << dendl;
dout(2) << __func__ << " " << path            << " failed. fd: " << fdc->fd            << ". Error: " << ret << dendl;
dout(2) << __func__ << " " << get_path(FileName)            << ": Invalid offset: " << Offset << dendl;
dout(2) << "File read too large: " << get_path(FileName)            << ". Offset: " << Offset            << ". Buffer length: " << BufferLength << dendl;
dout(15) << __func__ << " " << get_path(FileName)             << ". Missing context, using temporary handle." << dendl;
dout(2) << __func__ << " " << path              << ": ceph_open failed. Error: " << fd_new << dendl;
dout(2) << __func__ << " " << path              << ": ceph_read failed. Error: " << ret              << ". Offset: " << Offset              << "Buffer length: " << BufferLength << dendl;
dout(2) << __func__ << " " << get_path(FileName)              << ": ceph_read failed. Error: " << ret              << ". Offset: " << Offset              << "Buffer length: " << BufferLength << dendl;
dout(2) << __func__ << " " << path                << ": ceph_statx failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << get_path(FileName)            << ": Invalid offset: " << Offset << dendl;
dout(2) << "File write too large: " << get_path(FileName)            << ". Offset: " << Offset            << ". Buffer length: " << NumberOfBytesToWrite            << ". WriteToEndOfFile: " << (bool) DokanFileInfo->WriteToEndOfFile            << dendl;
dout(15) << __func__ << " " << path             << ". Missing context, using temporary handle." << dendl;
dout(2) << __func__ << " " << path              << ": ceph_open failed. Error: " << fd_new << dendl;
dout(2) << __func__ << " " << path              << ": ceph_write failed. Error: " << ret              << ". Offset: " << Offset              << "Buffer length: " << NumberOfBytesToWrite << dendl;
dout(2) << __func__ << " " << get_path(FileName)              << ": ceph_write failed. Error: " << ret              << ". Offset: " << Offset              << "Buffer length: " << NumberOfBytesToWrite << dendl;
dout(2) << __func__ << " " << get_path(FileName)            << ": ceph_sync failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path              << ": ceph_statx failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path              << ": ceph_fstatx failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path            << ": ceph_mkdir failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path              << ": ceph_readdirplus_r failed. Error: " << ret << dendl;
dout(20) << __func__ << " " << path           << " found " << count << " entries." << dendl;
dout(2) << __func__ << " " << path            << ": ceph_opendir failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path                << ": directory is not empty. " << dendl;
dout(2) << __func__ << " " << path << " -> " << new_path            << ": ceph_rename failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << get_path(FileName)            << ": ceph_ftruncate failed. Error: " << ret            << " Offset: " << ByteOffset << dendl;
dout(2) << __func__ << " " << get_path(FileName)            << ": ceph_fstatx failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << get_path(FileName)              << ": ceph_ftruncate failed. Error: " << ret << dendl;
dout(2) << __func__ << " " << path            << ": ceph_setattrx failed. Error: " << ret << dendl;
dout(0) << "Mounted cephfs directory: " << ceph_getcwd(cmount)          <<". Mountpoint: " << to_string(g_cfg->mountpoint) << dendl;
dout(10) << "module " << self->this_module->get_name()          << " health checks:\n";
ldout(cct, 20) << "is_capable service=" << service << " "                   << "module=" << module << " "                   << "command=" << command                   << (op_may_read ? " read":"")                   << (op_may_write ? " write":"")                   << (op_may_exec ? " exec":"")                   << " addr " << addr                   << " on cap " << *this                   << dendl;
ldout(cct, 20) << " allow so far " << allow << ", doing grant " << grant                     << dendl;
dout(10) << " [" << prefix << "/]" << key << " not found "     << dendl;
dout(0) << "`config-key set " << global_key << " " << val << "` failed: "      << cpp_strerror(set_cmd.r) << dendl;
dout(10) << __func__ << " pre-validate failed on '" << name << "' = '"        << value << "' for " << name << dendl;
dout(10) << __func__ << " NO_MON_UPDATE option '"        << name << "' = '" << value << "' for " << name        << dendl;
dout(4) << "Missing counter: '" << path << "' ("  << svc_name << "." << svc_id << ")" << dendl;
dout(4) << "No daemon state for " << svc_name << "." << svc_id << ")"              << dendl;
dout(4) << __func__ << ": No daemon state found for "              << svc_type << "." << svc_id << ")" << dendl;
dout(20) << "mon cluster wasn't pacific when we started: falling back to 'config get'"      << dendl;
dout(10) << "ceph_foreign_option_get (mon command) " << who << " " << name << " = "      << cmd.outbl.to_str() << dendl;
dout(10) << __func__ << " crush_location " << crush_location   << " class " << device_class << dendl;
dout(10) << "ceph_foreign_option_get (configmap) " << who << " " << name << " = "    << value << dendl;
dout(0) << "remove_osd_perf_query for query_id=" << query_id << " failed: "            << cpp_strerror(r) << dendl;
dout(0) << "get_osd_perf_counters for query_id=" << query_id << " failed: "            << cpp_strerror(r) << dendl;
dout(0) << "remove_mds_perf_query for query_id=" << query_id << " failed: "            << cpp_strerror(r) << dendl;
dout(0) << "get_mds_perf_counters for query_id=" << query_id << " failed: "            << cpp_strerror(r) << dendl;
dout(20) << "Calling " << py_module->get_name()           << "." << method << "..." << dendl;
dout(20) << "Calling " << py_module->get_name() << "._config_notify..."    << dendl;
dout(1) << "mon returned valid JSON " << key  << " but not an object: '" << outbl.to_str() << "'" << dendl;
dout(1) << "mon failed to return metadata for " << key     << ": " << cpp_strerror(r) << dendl;
dout(4) << "Waiting for new OSDMap (e=" << e          << ") that may blocklist prior active." << dendl;
dout(4) << "Mgr::handle_osd_map: osd." << osd_id    << " joined cluster at " << "e" << osd_map.get_epoch()    << dendl;
dout(4) << "MDS[" << info.name << "] addr change " << metadata_addrs                  << " != " << stringify(map_addrs) << dendl;
dout(10) << __func__ << " " << final_key << " found: " << value      << dendl;
dout(4) << __func__ << " [" << prefix << "/]" << what << " not found "       << dendl;
dout(20) << "loading " << report.declare_types.size() << " new types, "    << report.undeclare_types.size() << " old types, had "    << types.size() << " types, got "           << report.packed.length() << " bytes of data" << dendl;
dout(4) << "skipping module '" << i.second->get_name() << "' because "                 "it does not implement a standby mode" << dendl;
dout(10) << query << " " << (limit ? stringify(*limit) : "unlimited")           << " query_id=" << query_id << dendl;
dout(10) << "report for " << query << " query: "             << report.group_packed_performance_counters.size() << " records"             << dendl;
dout(10) << __func__ << " map " << self->osdmap << " inc " << incobj->inc    << " next " << next << dendl;
dout(10) << __func__ << " osdmap " << self->osdmap << " inc " << incobj->inc    << " max_deviation " << max_deviation    << " max_iterations " << max_iterations    << " pools " << pools    << dendl;
dout(4) << "going active, including " << m->get_command_descs().size()              << " commands in beacon" << dendl;
dout(4) << "active in map: " << active_in_map          << " active is " << map.active_gid << dendl;
ldout(cct, 4) << "Terminating session with "    << session->con->get_peer_addr() << dendl;
ldout(cct, 4) << "Starting new session with " << map.get_active_addrs()  << dendl;
ldout(cct, 10) << "active mgr " << map.active_name << " != target "         << op.name << dendl;
ldout(cct, 20) << "sending " << session->declared.size() << " counters ("                      "of possible " << by_path.size() << "), "     << report->declare_types.size() << " new, "                   << report->undeclare_types.size() << " removed"                   << dendl;
ldout(cct, 5) << "no mgr session (no running mgr daemon?), or "    << name << " not active mgr, waiting" << dendl;
ldout(cct, 4) << "handle_command_reply tid " << tid            << " not found" << dendl;
dout(15) << " got " << pgid        << " reported at " << pg_stats.reported_epoch << ":"               << pg_stats.reported_seq               << " state " << pg_state_string(pg_stats.state)               << " but pool not in " << existing_pools               << dendl;
dout(15) << " got " << pgid        << " reported at " << pg_stats.reported_epoch << ":"               << pg_stats.reported_seq               << " state " << pg_state_string(pg_stats.state)               << " but > pg_num " << r->second               << dendl;
dout(15) << " had " << pgid << " from "        << q->second.reported_epoch << ":"        << q->second.reported_seq << dendl;
dout(20) << __func__ << " time out heartbeat for osd " << i.first            << " last_update " << j.second.last_update << dendl;
dout(10) << __func__ << " new session " << s << " con " << con    << " entity " << con->peer_name    << " addr " << con->get_peer_addrs()    << dendl;
dout(10) << " session " << s << " " << s->entity_name      << " allow_all" << dendl;
dout(10) << " session " << s << " " << s->entity_name               << " failed to decode caps" << dendl;
dout(10) << " session " << s << " " << s->entity_name        << " failed to parse caps '" << str << "'" << dendl;
dout(10) << " session " << s << " " << s->entity_name             << " has caps " << s->caps << " '" << str << "'" << dendl;
dout(10) << "registering osd." << s->osd_id << " session "      << s << " con " << con << dendl;
dout(10) << "unregistering osd." << session->osd_id      << "  session " << session << " con " << con << dendl;
dout(4) << "still waiting for " << unreported_osds.size() << " osds"                   " to report in before PGMap is ready" << dendl;
dout(2) << "ignoring open from " << key << " " << con->get_peer_addr()              << ";
not ready for session (expect reconnect)" << dendl;
dout(20) << " got config " << daemon->config        << " ignored " << daemon->ignored_mon_config << dendl;
dout(20) << " got config_defaults_bl " << daemon->config_defaults_bl.length()      << " bytes" << dendl;
dout(10) << "rejecting report from non-daemon client " << m->daemon_name      << dendl;
dout(5) << "rejecting report from " << key << ", since we do not have its metadata now."              << dendl;
dout(10) << "unregistering osd." << session->osd_id               << "  session " << session << " con " << m->get_connection() << dendl;
dout(20) << " got config " << daemon->config                 << " ignored " << daemon->ignored_mon_config << dendl;
dout(10) << "daemon_health_metrics " << daemon->daemon_health_metrics                 << dendl;
dout(10) << " " << s->entity_name << " "    << (capable ? "" : "not ") << "capable" << dendl;
dout(20) << osds << " -> " << report->ok.size() << " ok, "    << report->not_ok.size() << " not ok, "    << report->unknown.size() << " unknown"    << dendl;
dout(10) << "daemon " << key << " in service map but not in daemon state "                   << "index -- force pruning" << dendl;
dout(10) << "pruning stale " << p->first << "." << q->first   << " last_beacon " << daemon->last_service_beacon << dendl;
dout(1) << "Giving up on OSDs that haven't reported yet, sending "              << "potentially incomplete PG state to mon" << dendl;
dout(1) << "Not sending PG status to monitor yet, waiting for OSDs"              << dendl;
dout(10) << "sending service_map e" << pending_service_map.epoch     << dendl;
dout(10) << m->health_checks.checks.size() << " health checks"     << dendl;
dout(20) << " + " << state->key << " "     << metric << dendl;
dout(10) << "creating_or_unknown " << creating_or_unknown        << " max_creating " << max               << " left " << left               << dendl;
dout(20) << "misplaced_ratio " << misplaced_ratio        << " degraded_ratio " << degraded_ratio        << " inactive_pgs_ratio " << inactive_pgs_ratio        << " unknown_pgs_ratio " << unknown_pgs_ratio        << ";
target_max_misplaced_ratio " << max_misplaced   dout(20) << "pool " << i.first     << " pg_num " << p.get_pg_num()     << " target " << p.get_pg_num_target()     << dendl;
dout(10) << "pool " << i.first       << " pg_num_target " << p.get_pg_num_target()       << " pg_num " << p.get_pg_num()       << " - still creating initial pgs"       << dendl;
dout(10) << "pool " << i.first         << " pg_num_target " << p.get_pg_num_target()         << " pg_num " << p.get_pg_num()         << " - decrease and pg_num_pending != pg_num, waiting"         << dendl;
dout(10) << "pool " << i.first         << " pg_num_target " << p.get_pg_num_target()         << " pg_num " << p.get_pg_num()         << " - decrease blocked by pgp_num "         << p.get_pgp_num()         << dendl;
dout(10) << "pool " << i.first                         << " pg_num_target " << p.get_pg_num_target()                         << " pg_num " << p.get_pg_num()                         << (is_merge_source ? " - merge source " : " - merge target ")                         << merge_participant                         << " has upmap" << dendl;
dout(10) << "pool " << i.first           << " pg_num_target " << p.get_pg_num_target()           << " pg_num " << p.get_pg_num()           << " - no state for " << merge_participant           << (is_merge_source ? " (merge source)" : " (merge target)")           << dendl;
dout(10) << "pool " << i.first           << " pg_num_target " << p.get_pg_num_target()           << " pg_num " << p.get_pg_num()           << (is_merge_source ? " - merge source " : " - merge target ")                         << merge_participant           << " not clean (" << pg_state_string(q->second.state)           << ")" << dendl;
dout(10) << "pool " << i.first           << " pg_num_target " << p.get_pg_num_target()           << " pg_num " << p.get_pg_num()           << (is_merge_source ? " - merge source " : " - merge target ")                         << merge_participant    << " acting does not match (source " << source_acting    << " != target " << q->second.acting    << ")" << dendl;
dout(10) << "pool " << i.first         << " pg_num_target " << p.get_pg_num_target()         << " pg_num " << p.get_pg_num()         << " -> " << target         << " (merging " << merge_source         << " and " << merge_target         << ")" << dendl;
dout(20) << "pool " << i.first << " has " << j.second      << " pgs in " << pg_state_string(j.first)      << dendl;
dout(10) << "pool " << i.first         << " pg_num_target " << p.get_pg_num_target()         << " pg_num " << p.get_pg_num()         << " - not all pgs active"         << dendl;
dout(10) << "pool " << i.first         << " pg_num_target " << p.get_pg_num_target()         << " pg_num " << p.get_pg_num()         << " -> " << target << dendl;
dout(20) << "pool " << i.first     << " pgp_num_target " << p.get_pgp_num_target()     << " pgp_num " << p.get_pgp_num()     << " -> " << target << dendl;
dout(10) << "pool " << i.first       << " pgp_num_target " << p.get_pgp_num_target()       << " pgp_num " << p.get_pgp_num()       << " - increase blocked by pg_num " << p.get_pg_num()       << dendl;
dout(10) << "pool " << i.first       << " pgp_num_target " << p.get_pgp_num_target()       << " pgp_num " << p.get_pgp_num()       << " - inactive|degraded|unknown pgs, deferring pgp_num"       << " update" << dendl;
dout(10) << "pool " << i.first       << " pgp_num_target " << p.get_pgp_num_target()       << " pgp_num " << p.get_pgp_num()       << " - misplaced_ratio " << misplaced_ratio       << " > max " << max_misplaced       << ", deferring pgp_num update" << dendl;
dout(20) << " room " << room << " estmax " << estmax         << " delta " << (target-p.get_pgp_num())         << " next " << next << dendl;
dout(10) << "  using next " << next      << " to avoid outpacing merges (max_outpace_merges "      << max_outpace_merges << ")" << dendl;
dout(10) << "pool " << i.first       << " pgp_num_target " << p.get_pgp_num_target()       << " pgp_num " << p.get_pgp_num()       << " -> " << next << dendl;
dout(4) << "Updating stats threshold/period on "            << daemon_connections.size() << " clients" << dendl;
dout(0) << "`config set mgr " << global_key << " " << val << "` failed: "        << cpp_strerror(set_cmd.r) << dendl;
dout(0) << "`config rm mgr " << global_key << "` failed: "        << cpp_strerror(set_cmd.r) << dendl;
dout(10) << "Computed sys.path '"        << string(begin(sys_path), end(sys_path)) << "'" << dendl;
dout(4) << "Standby mode available in module '" << module_name              << "'" << dendl;
dout(4) << "Standby mode not provided by module '" << module_name              << "'" << dendl;
dout(4) << "Module " << get_name()                    << " reported that it cannot run: "                    << error_string << dendl;
dout(4) << __func__ << ": found class: '"     << module_name << "." << class_name << "'" << dendl;
dout(10) << __func__ << " " << this      << " waiting for " << num_running.load() << " aios to complete"      << dendl;
dout(1) << __func__ << " backing device/file reports st_blksize "     << st.st_blksize << ", using bdev_block_size "     << block_size << " anyway" << dendl;
dout(1) << __func__   << " size " << size   << " (0x" << std::hex << size << std::dec << ", "   << byte_u_t(size) << ")"   << " block_size " << block_size   << " (" << byte_u_t(block_size) << ")"   << " " << (rotational ? "rotational" : "non-rotational")      << " discard " << (support_discard ? "supported" : "not supported")   << dendl;
dout(1) << __func__ << " VDO volume " << vdo_name     << " maps to " << devname << dendl;
dout(10) << __func__ << " no-op (no ios since last flush), flag is "      << (int)io_since_flush.load() << dendl;
dout(10) << __func__ << " finished aio " << aio[i] << " r " << r                 << " ioc " << ioc                 << " with " << (ioc->num_running.load() - 1)                 << " aios left" << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(20) << __func__ << " " << aio << " 0x"    << std::hex << offset << "~" << length << std::dec << dendl;
dout(20) << __func__ << " ioc " << ioc    << " pending " << ioc->num_pending.load()    << " running " << ioc->num_running.load()    << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len   << std::dec << (buffered ? " (buffered)" : " (direct)") << dendl;
dout(20) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " (buffered)" : " (direct)")    << dendl;
dout(20) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " (buffered)" : " (direct)")    << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len  << std::dec << " aio " << &aio << dendl;
dout(5) << __func__ << " 0x" << std::hex << off + prev_len    << "~" << len    << std::dec << " aio " << &aio << " (piece)" << dendl;
dout(10) << __func__        << " 0x" << std::hex << offset << "~" << len << std::dec        << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << (buffered ? " (buffered)" : " (direct)")   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len     << std::dec << " aio " << &aio << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec          << "buffered " << buffered   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << dendl;
dout(10) << __func__ << " setting zone size to " << zone_size    << " and conventional region size to " << conventional_region_size           << dendl;
dout(1) << __func__ << " backing device/file reports st_blksize "     << st.st_blksize << ", using bdev_block_size "     << block_size << " anyway" << dendl;
dout(1) << __func__   << " size " << size   << " (0x" << std::hex << size << std::dec << ", "   << byte_u_t(size) << ")"   << " block_size " << block_size   << " (" << byte_u_t(block_size) << ")"   << " " << (rotational ? "rotational" : "non-rotational")      << " discard " << (support_discard ? "supported" : "not supported")   << dendl;
dout(1) << __func__ << " VDO volume " << vdo_name     << " maps to " << devname << dendl;
dout(10) << __func__ << " no-op (no ios since last flush), flag is "      << (int)io_since_flush.load() << dendl;
dout(10) << __func__ << " finished aio " << aio[i] << " r " << r                 << " ioc " << ioc                 << " with " << (ioc->num_running.load() - 1)                 << " aios left" << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(20) << __func__ << " " << aio << " 0x"    << std::hex << offset << "~" << length << std::dec << dendl;
dout(20) << __func__ << " ioc " << ioc    << " pending " << ioc->num_pending.load()    << " running " << ioc->num_running.load()    << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len   << std::dec << (buffered ? " (buffered)" : " (direct)") << dendl;
dout(20) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " (buffered)" : " (direct)")    << dendl;
dout(20) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " (buffered)" : " (direct)")    << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len  << std::dec << " aio " << &aio << dendl;
dout(5) << __func__ << " 0x" << std::hex << off + prev_len    << "~" << len    << std::dec << " aio " << &aio << " (piece)" << dendl;
dout(10) << __func__        << " 0x" << std::hex << offset << "~" << len << std::dec        << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << (buffered ? " (buffered)" : " (direct)")   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len     << std::dec << " aio " << &aio << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec          << "buffered " << buffered   << dendl;
dout(5) << __func__ << " 0x" << std::hex << off << "~" << len << std::dec   << dendl;
dout(1) << __func__ << " backing device/file reports st_blksize "      << st.st_blksize << ", using bdev_block_size "      << block_size << " anyway" << dendl;
dout(1) << __func__    << " size " << size    << " (" << byte_u_t(size) << ")"    << " block_size " << block_size    << " (" << byte_u_t(block_size) << ")"    << dendl;
dout(0) << __func__ << " found device at: "   << "trtype=" << spdk_nvme_transport_id_trtype_str(trid->trtype) << ", "          << "traddr=" << trid->traddr << dendl;
dout(20) << __func__ << " write/zero op successfully, left "             << queue->queue_op_seq - queue->completed_op_seq << dendl;
dout(1) << __func__ << " size " << size << " (" << byte_u_t(size) << ")"          << " block_size " << block_size << " (" << byte_u_t(block_size)          << ")" << dendl;
dout(20) << __func__ << " ioc " << ioc << " pending "           << ioc->num_pending.load() << " running "           << ioc->num_running.load() << dendl;
dout(20) << __func__ << " " << off << "~" << len << " ioc " << ioc           << " buffered " << buffered << dendl;
dout(20) << __func__ << " " << off << "~" << len << " buffered "           << buffered << dendl;
dout(5) << __func__ << " " << off << "~" << len          << " aligned " << aligned_off << "~" << aligned_len << dendl;
ldout(m_cct, 5) << "flush_interval=" << flush_interval << ", "                  << "flush_bytes=" << flush_bytes << ", "                  << "flush_age=" << flush_age << dendl;
ldout(m_cct, 10) << "object " << object_ptr->get_oid() << " now full"                     << dendl;
ldout(m_cct, 10) << "closing object " << object_recorder->get_oid()                       << dendl;
ldout(m_cct, 10) << "object " << object_recorder->get_oid() << " "                         << "close in-progress" << dendl;
ldout(m_cct, 10) << "object " << object_recorder->get_oid() << " closed"                         << dendl;
ldout(m_cct, 10) << "old oid=" << object_recorder->get_oid() << ", "                   << "new oid=" << new_object_recorder->get_oid() << dendl;
ldout(m_cct, 10) << "object " << new_object_recorder->get_oid() << " "                     << "now full" << dendl;
ldout(m_cct, 10) << "current_set=" << m_current_set << ", "                     << "active_set=" << active_set << dendl;
ldout(m_cct, 10) << "object " << active_object_recorder->get_oid()                   << " closed" << dendl;
ldout(m_cct, 10) << "object " << active_object_recorder->get_oid()                   << " overflowed" << dendl;
ldout(m_cct, 20) << "using pool id=" << pool_id << " for journal data"       << dendl;
ldout(m_cct, 1) << "pool id=" << pool_id << " no longer exists"   << dendl;
ldout(m_cct, 20) << __func__ << ": current=" << m_minimum_set                   << ", new=" << object_set << dendl;
ldout(m_cct, 20) << __func__ << ": current=" << m_active_set                   << ", new=" << object_set << dendl;
ldout(m_cct, 0) << "client flagged disconnected: " << m_client_id   << dendl;
ldout(m_cct, 20) << __func__ << ": "                   << "client_id=" << m_client_id << ", "                   << "commit_position=" << m_commit_position << dendl;
ldout(m_cct, 20) << "allocated commit tid: commit_tid=" << commit_tid << " ["                   << "object_num=" << object_num << ", "                   << "tag_tid=" << tag_tid << ", "                   << "entry_tid=" << entry_tid << "]"                   << dendl;
ldout(m_cct, 20) << __func__ << ": "                   << "commit_tid=" << commit_tid << ", "                   << "old_object_num=" << it->second.object_num << ", "                   << "new_object_num=" << object_num << dendl;
ldout(m_cct, 20) << "updated commit position: " << commit_position << ", "                     << "on_safe=" << m_commit_position_ctx << dendl;
ldout(m_cct, 20) << "canceling stale commit: on_safe=" << stale_ctx                     << dendl;
ldout(m_cct, 1) << __func__ << ": " << client_id                        << ": scheduling disconnect" << dendl;
ldout(m_cct, 10) << __func__ << ": " << client_id                             << ": flagging disconnected" << dendl;
ldout(m_cct, 10) << __func__ << ": " << m_oid << ", r=" << r << ", len="                   << bl.length() << dendl;
ldout(m_cct, 20) << ": partial record detected, will re-fetch"                           << dendl;
ldout(m_cct, 20) << ": partial pad detected, will re-fetch"                             << dendl;
ldout(m_cct, 20) << ": clearing invalid range: " << intersect_range                     << dendl;
ldout(m_cct, 10) << __func__ << ": " << m_oid << " poll complete, r=" << r                   << dendl;
ldout(m_cct, 10) << __func__ << ": prefetching "                   << prefetch_object_numbers.size() << " " << "objects"                   << dendl;
ldout(m_cct, 10) << __func__ << ": object_num=" << object_number << ", "                   << "r=" << r << dendl;
ldout(m_cct, 15) << "seeking known commit position " << position << " in "                       << object_player->get_oid() << dendl;
ldout(m_cct, 10) << "located next uncommitted entry: " << entry                           << dendl;
ldout(m_cct, 10) << "refetching potentially partially decoded object"                       << dendl;
ldout(m_cct, 10) << __func__ << ": "                         << "object_num=" << object_num << ", "                         << "initial tag=" << entry.get_tag_tid()                         << dendl;
ldout(m_cct, 10) << __func__ << ": detected stale entry: "                         << "object_num=" << object_num << ", "                         << "entry=" << entry << dendl;
ldout(m_cct, 10) << __func__ << ": new tag detected: "                         << "object_num=" << object_num << ", "                         << "active_tag=" << *m_active_tag_tid << ", "                         << "new_tag=" << entry.get_tag_tid() << dendl;
ldout(m_cct, 20) << __func__ << ": "                         << "object_num=" << object_num << ", "                         << "entry: " << entry << dendl;
ldout(m_cct, 10) << __func__ << ": waiting for first entry: "                         << "object_num=" << object_num << dendl;
ldout(m_cct, 10) << __func__ << ": assuming no more in-sequence entries: "                         << "object_num=" << object_num << ", "                         << "active_tag " << *m_active_tag_tid << dendl;
ldout(m_cct, 10) << __func__ << ": refetch required: "                         << "object_num=" << object_num << dendl;
ldout(m_cct, 10) << __func__ << ": no more in-sequence entries: "                         << "object_num=" << object_num << ", "                         << "active_tag=" << *m_active_tag_tid << dendl;
ldout(m_cct, 10) << __func__ << ": no more entries -- watch required"                         << dendl;
ldout(m_cct, 10) << __func__ << ": pruning remaining entries for tag "                   << tag_tid << dendl;
ldout(m_cct, 15) << __func__ << ": checking " << object_player->get_oid()                     << dendl;
ldout(m_cct, 15) << __func__ << ": resetting refetch state to immediate"                     << dendl;
ldout(m_cct, 20) << __func__ << ": new offset "                   << static_cast<uint32_t>(m_splay_offset) << dendl;
ldout(m_cct, 20) << __func__ << ": " << player->get_oid() << " requires "                     << "a refetch" << dendl;
ldout(m_cct, 20) << __func__ << ": new active set detected, all players "                     << "require refetch" << dendl;
ldout(m_cct, 15) << __func__ << ": " << player->get_oid() << " empty"                   << dendl;
ldout(m_cct, 10) << __func__ << ": "                   << utils::get_object_name(m_object_oid_prefix, object_num)                   << ": r=" << r << dendl;
ldout(m_cct, 20) << __func__ << ": asserting active tag="                     << *m_active_tag_tid << dendl;
ldout(m_cct, 20) << __func__ << ": immediately refetching "                         << object_player->get_oid()                         << dendl;
ldout(m_cct, 20) << __func__ << ": scheduling watch on "                   << object_player->get_oid() << dendl;
ldout(m_cct, 10) << __func__ << ": tag " << *m_active_tag_tid << " "                     << "no longer active" << dendl;
ldout(m_cct, 10) << __func__ << ": new_cache_bytes=" << new_cache_bytes                   << ", max_fetch_bytes=" << m_max_fetch_bytes << dendl;
ldout(m_cct, 20) << __func__ << ": removing object set " << object_set                   << dendl;
ldout(m_cct, 20) << "object set " << minimum_commit_set << " still "                     << "in-use by client " << minimum_client_id << dendl;
ldout(m_cct, 20) << __func__ << ": r=" << r << ", set=" << object_set << ", "                   << "trim=" << m_remove_set << dendl;
ldout(m_cct, 0) << "failed to retrieve min OSD release: "                    << cpp_strerror(r) << dendl;
ldout(m_cct, 5) << "flush_interval=" << flush_interval << ", "                  << "flush_bytes=" << flush_bytes << ", "                  << "flush_age=" << flush_age << dendl;
ldout(m_cct, 20) << *append_buffer.first << ", "                     << "size=" << append_buffer.second.length() << dendl;
ldout(m_cct, 10) << "append overflowed: "                     << "idle=" << m_in_flight_tids.empty() << ", "                     << "previous_overflow=" << m_overflowed << dendl;
ldout(m_cct, 20) << "flushing journal tid=" << append_tid << ", "                     << "append_bytes=" << append_bytes << ", "                     << "in_flight_bytes=" << m_in_flight_bytes << ", "                     << "pending_bytes=" << m_pending_bytes << dendl;
dout(0) << "created object store " << data_path     << " for osd." << whoami     << " fsid " << g_conf().get_val<uuid_d>("fsid")     << dendl;
dout(0) << "starting osd." << whoami          << " osd_data " << data_path          << " " << ((journal_path.empty()) ?      "(no journal)" : journal_path)          << dendl;
dout(0) << "WARNING: osd_erasure_code_plugins contains plugin "    << plugin_name << " that is now deprecated. Please modify the value "    << "for osd_erasure_code_plugins to use "  << replacement << " instead." << dendl;
ldout(cdata->m_striper->cct(), 10)    << "RadosStriperImpl : striper_remove_aio_req_complete called for "    << cdata->m_soid << dendl;
ldout(cct(), 10)    << "RadosStriperImpl : Aio_remove starting for "    << soid << dendl;
dout(20) << __func__ << ": " << *ctx << ": Pad byte count: "               << pad_byte_count << dendl;
dout(10) << __func__ << ": " << quiesce_hook << " " << devpath << " "           << command << dendl;
ldout(m_cct, 20) << "fails to connect to cache server. error : "                       << err.message() << dendl;
ldout(m_cct, 20) << "Connecting RO daenmon fails : "<< ec.message()                        << ". Immutable-object-cache daemon is down ? "                        << "Data will be read from ceph cluster " << dendl;
ldout(m_cct, 20) << "Connecting RO daemon fails : "                        << ec.message() << dendl;
ldout(m_cct, 20) << "Because ASIO domain socket fails, just shutdown RO.\                       Later all reading will be re-dispatched RADOS layer"                       << ec.message() << dendl;
ldout(cct, 20) << "max cache size= " << m_max_cache_size                 << " ,watermark= " << m_watermark                 << " ,max inflight ops= " << m_max_inflight_ops << dendl;
ldout(cct, 20) << "update status for: " << file_name                 << " new status = " << new_status << dendl;
ldout(m_cct, 20) << "to promote object: " << object_name                   << " from pool id: " << pool_id                   << " namespace: " << pool_nspace                   << " snapshot: " << snap_id << dendl;
ldout(m_cct, 20) << "object name = " << object_name                   << " in pool ID : " << pool_id << dendl;
ldout(m_cct, 5) << "fail to create cache dir: " << new_dir                      << "error: " << ec.message() << dendl;
dout(5) << ": dir_path=" << dir_path << " registered with replayer="          << replayer << dendl;
dout(5) << ": dir_path=" << dir_path << " is locked by cephfs-mirror, "              << "will retry again" << dendl;
dout(20) << ": dir_path=" << dir_path << ", snap_dir=" << snap_dir           << ", is_remote=" << is_remote << dendl;
dout(20) << ": deleting dir_path=" << dir_path << ", snapshot=" << snap             << dendl;
dout(20) << ": renaming dir_path=" << dir_path << ", snapshot from="             << from << ", to=" << to << dendl;
dout(10) << ": local_path=" << local_path << ", remote_path=" << remote_path           << dendl;
dout(10) << ": dir_path=" << dir_path << ", local_path=" << local_path           << ", remote_path=" << remote_path << dendl;
dout(10) << ": dir_path=" << dir_path << ", local_path=" << local_path           << ", remote_path=" << remote_path << dendl;
dout(5) << ": skipping entry=" << local_path << ": unsupported mode=" << stx.stx_mode            << dendl;
dout(20) << ": dir_path=" << dir_path << ", snap_id=" << snap_id           << ", snap_name=" << snap_name << dendl;
dout(20) << ": filesystem=" << filesystem << ", peers=" << peers           << ", r=" << r << dendl;
dout(20) << ": scheduling fs mirror update (" << m_timer_task << ") after "           << after << " seconds" << dendl;
dout(20) << ": notifier_id=" << notifier_id << ", dir_path=" << dir_path           << ", mode=" << mode << dendl;
dout(5) << ": mirroring enabled=" << mirroring_enabled << ", mirroring_disabled="          << mirroring_disabled << dendl;
dout(20) << ": notify_id=" << notify_id << ", handle=" << handle           << ", notifier_id=" << notifier_id << dendl;
dout(20) << ": connecting to cluster=" << cluster_name << ", client=" << client_name           << ", mon_host=" << mon_host << dendl;
dout(10) << ": connected to cluster=" << cluster_name << " using client="           << client_name << dendl;
dout(20) << "copied resulting " << req->bl.length() << " bytes to "             << ggate_drv_req_buf(req->req) << dendl;
dout(20) << this << " " << __func__ << ": image_name=" << m_image_name             << dendl;
dout(2) << "first diff data chunk: tag=" << f_tag << ", "              << "off=" << f_off << ", "              << "len=" << f_len << dendl;
dout(2) << "second diff data chunk: tag=" << s_tag << ", "              << "off=" << s_off << ", "              << "len=" << s_len << dendl;
dout(20) << __func__ << ": " << *ctx << ": Pad byte count: "             << pad_byte_count << dendl;
dout(0) << "libwnbd.dll!" << FunctionName << " "          << WnbdLogLevelToStr(LogLevel) << " " << Message << dendl;
dout(10) << "Ignoring disk: " << conn_props.InstanceName             << ". Owner: " << conn_props.Owner << dendl;
dout(5) << "Received control signal: " << dwCtrlType          << ". Exiting." << dendl;
dout(5) << __func__ << ": device already mapped: "              << cfg.devpath << dendl;
dout(5) << __func__ << ": cleaning up non-persistent mapping: "              << cfg.devpath << dendl;
dout(5) << "Remapping: " << cfg.devpath                << ". Timeout: " << time_left_ms << " ms." << dendl;
dout(5) << "Removing mapping: " << cfg.devpath                << ". Timeout: " << cfg.soft_disconnect_timeout                << "s. Hard disconnect: " << cfg.hard_disconnect                << dendl;
dout(5) << "Received device connect request. Command line: "                  << (char*)request->arguments << dendl;
dout(5) << "Received unsupported command: "                  << request->command << dendl;
dout(20) << __func__ << ": Sending reply. Status: "               << reply.status << dendl;
dout(5) << __func__ << ": cleaning up non-persistent mapping: "            << cfg->devpath << dendl;
dout(2) << "layer " << type       << "  " << l.name       << "  bucket type " << l.buckettype       << "  " << l.size        << dendl;
dout(10) << "\tomap header: " << string(oh.hdr.c_str(), oh.hdr.length())        << dendl;
dout(4) << "Successfully wrote new journal pointer and header for rank "      << role << dendl;
dout(20) << "Fast check missed: pool " << layout.pool_id << " not in "                "target set" << dendl;
dout(1) << "Error processing event 0x" << std::hex << i->first << std::dec                  << ": " << cpp_strerror(scav_r) << ", continuing..." << dendl;
dout(1) << "Error updating InoTable for " << consumed_inos.size()                << " consume inos: " << cpp_strerror(consume_r) << dendl;
dout(4) << "failed to read OMAP header from directory fragment "        << frag_oid.name << " " << cpp_strerror(r) << dendl;
dout(4) << "frag " << frag_oid.name << " fnode old v" <<          old_fnode.version << " vs new v" << lump.fnode->version << dendl;
dout(1) << "frag " << frag_oid.name                << " is corrupt, overwriting" << dendl;
dout(4) << "failed to read OMAP header from directory fragment "        << frag_oid.name << " " << cpp_strerror(r) << dendl;
dout(4) << "inspecting fullbit " << frag_oid.name << "/" << fb.dn        << dendl;
dout(10) << "Existing remote inode in slot to be (maybe) written "               << "by a full inode from the journal dn '" << fb.dn.c_str()               << "' with lump fnode version " << lump.fnode->version               << "vs existing fnode version " << old_fnode_version << dendl;
dout(4) << "decoded embedded inode version "            << inode.inode->version << " vs fullbit version "            << fb.inode->version << dendl;
dout(4) << "corrupt dentry in backing store, overwriting from "            "journal" << dendl;
dout(4) << "writing I dentry " << key << " into frag "          << frag_oid.name << dendl;
dout(4) << "inspecting remotebit " << frag_oid.name << "/" << rb.dn        << dendl;
dout(10) << "Existing hardlink inode in slot to be (maybe) written "               << "by a remote inode from the journal dn '" << rb.dn.c_str()               << "' with lump fnode version " << lump.fnode->version               << "vs existing fnode version " << old_fnode_version << dendl;
dout(10) << "Existing full inode in slot to be (maybe) written "               << "by a remote inode from the journal dn '" << rb.dn.c_str()               << "' with lump fnode version " << lump.fnode->version               << "vs existing fnode version " << old_fnode_version << dendl;
dout(4) << "corrupt dentry in backing store, overwriting from "            "journal" << dendl;
dout(4) << "writing L dentry " << key << " into frag "          << frag_oid.name << dendl;
dout(4) << "inspecting nullbit " << frag_oid.name << "/" << nb.dn << dendl;
dout(10) << "Existing hardlink inode in slot to be (maybe) removed "     << "by null journal dn '" << nb.dn.c_str()     << "' with lump fnode version " << lump.fnode->version     << "vs existing fnode version " << old_fnode_version << dendl;
dout(10) << "Existing full inode in slot to be (maybe) removed "     << "by null journal dn '" << nb.dn.c_str()     << "' with lump fnode version " << lump.fnode->version     << "vs existing fnode version " << old_fnode_version << dendl;
dout(4) << "root exists, will modify (" << old_root_ino_bl.length()        << ")" << dendl;
dout(4) << "writing root ino " << root_oid.name               << " version " << fb.inode->version << dendl;
dout(4) << "Used ino 0x" << std::hex << ino << std::dec          << " requires inotable update" << dendl;
dout(4) << "data pool '" << data_pool_name        << "' has ID " << data_pool_id << dendl;
dout(10) << "handling object " << obj_name_ino      << "." << obj_name_offset << dendl;
dout(20) << "skipping " << oid << " because it has the filter_tag"                       << dendl;
dout(10) << "handling object "      << std::hex << obj_name_ino << "." << obj_name_offset << std::dec      << dendl;
dout(4) << "Accumulated metadata missing from '"              << oid << ", did you run scan_extents?" << dendl;
dout(4) << "Unexpected error loading accumulated metadata from '"              << oid << "': " << cpp_strerror(r) << dendl;
dout(4) << "bogus xattr layout on 0x" << std::hex << obj_name_ino                << std::dec << ", ignoring in favour of best guess" << dendl;
dout(20) << "loaded layout from xattr:"          << " os: " << guessed_layout.object_size          << " sc: " << guessed_layout.stripe_count          << " su: " << guessed_layout.stripe_unit          << dendl;
dout(10) << "calculating striped size from complete objs: "                 << complete_objs << ", partial objs: " << partial_objs                 << dendl;
dout(4) << "Backtrace ino 0x" << std::hex << backtrace.ino        << " doesn't match object name ino 0x" << obj_name_ino        << std::dec << dendl;
dout(4) << "Error injecting 0x" << std::hex << backtrace.ino            << std::dec << " into lost+found: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                       "appear to be corrupt" << dendl;
dout(4) << "Error injecting 0x" << std::hex << backtrace.ino            << std::dec << " with backtrace: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                       "appear to be corrupt" << dendl;
dout(4) << "Error injecting 0x" << std::hex << obj_name_ino          << std::dec << " into lost+found: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                     "appear to be corrupt" << dendl;
dout(4) << "Error deleting accumulated metadata from '"      << oid << "': " << cpp_strerror(r) << dendl;
dout(4) << "Backtrace ino 0x" << std::hex << backtrace.ino        << " doesn't match object name ino 0x" << obj_name_ino        << std::dec << dendl;
dout(4) << "Error injecting 0x" << std::hex << backtrace.ino            << std::dec << " into lost+found: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                       "appear to be corrupt" << dendl;
dout(4) << "Error injecting 0x" << std::hex << backtrace.ino            << std::dec << " with backtrace: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                       "appear to be corrupt" << dendl;
dout(4) << "Error injecting 0x" << std::hex << obj_name_ino          << std::dec << " into lost+found: " << cpp_strerror(r) << dendl;
dout(4) << "Use --force-corrupt to overwrite structures that "                     "appear to be corrupt" << dendl;
dout(20) << "oid=" << frag_oid.name           << " dname=" << dname           << " frag=" << frag           << ", r=" << r << dendl;
dout(20) << "dentry type '" << dentry_type << "': cannot"                  "read an inode out of that" << dendl;
dout(20) << "encoding error in dentry 0x" << std::hex << parent_ino             << std::dec << "/" << dname << dendl;
dout(4) << "Unexpected error on '" << root_frag_oid << "': "      << cpp_strerror(r) << dendl;
dout(4) << "Corrupt backtrace on '" << root_frag_oid << "': "       << e.what() << dendl;
dout(4) << "No backtrace on '" << root_frag_oid            << "': cannot determine fragtree" << dendl;
dout(20) << "got backtrace parent " << parent_ino << "/"           << parent_dname << dendl;
dout(4) << "Unexpected inode in dentry! 0x" << std::hex              << existing_dentry.inode->ino              << " vs expected 0x" << dirino << std::dec << dendl;
dout(20) << "fast path, fragtree is "             << existing_dentry.dirfragtree << dendl;
dout(10) << "  backptr: 0x" << std::hex << backptr.dirino << std::dec      << "/" << backptr.dname << dendl;
dout(20) << "don't know fragment for 0x" << std::hex <<        parent_ino << std::dec << "/" << dname << ", will insert to root"        << dendl;
dout(20) << "Dentry 0x" << std::hex          << parent_ino << std::dec << "/"          << dname << " already exists and points to me" << dendl;
dout(10) << "Linking inode 0x" << std::hex << ino          << " at 0x" << parent_ino << "/" << dname << std::dec          << " with size=" << dentry.inode->size << " bytes" << dendl;
dout(10) << "Dirfrag creation race: 0x" << std::hex        << ino << " " << fragment << std::dec << dendl;
dout(10) << "Created dirfrag: 0x" << std::hex        << ino << std::dec << dendl;
dout(20) << "Dirfrag already exists: 0x" << std::hex      << ino << " " << fragment << std::dec << dendl;
dout(20) << "Injected dentry 0x" << std::hex      << dir_ino << "/" << dname << " pointing to 0x"      << inode.inode->ino << std::dec << dendl;
dout(10) << "Got 0x" << std::hex << bl.length() << std::dec               << " bytes" << dendl;
dout(10) << std::hex << "Header 0x"    << header->trimmed_pos << " 0x"    << header->expire_pos << " 0x"    << header->write_pos << std::dec << dendl;
dout(4) << "Read 0x" << std::hex << this_object.length() << std::dec              << " bytes from " << oid << " gap=" << gap << dendl;
dout(4) << "Searching for sentinel from 0x" << std::hex << read_offset              << ", 0x" << read_buf.length() << std::dec << " bytes available" << dendl;
dout(10) << "mirror_uuid=" << mirror_uuid << ", "           << "added_count=" << added_image_ids.size() << ", "           << "removed_count=" << removed_image_ids.size() << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "instance_id=" << instance_id << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "instance_id=" << instance_id << dendl;
dout(5) << "mirror_uuid=" << mirror_uuid << ", "          << "global_image_id=" << global_image_id << ", "          << "instance_id=" << instance_id << dendl;
dout(15) << "pool_id=" << pool_id << ", "           << "local_pool_meta=" << local_pool_meta << dendl;
dout(15) << "pool_id=" << pool_id << ", "           << "remote_pool_meta=" << remote_pool_meta << dendl;
dout(20) << "global_image_id=" << global_image_id << " maps to instance_id="           << min_it->first << dendl;
dout(5) << "shuffling global_image_ids=[" << shuffle_global_image_ids          << "]" << dendl;
dout(5) << "force shuffling: instance_id=" << instance_id << ", "            << "global_image_ids=[" << instance_global_image_ids << "]"<< dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "state=" << image_state.state << ", "          << "action_type=" << transition.action_type << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "state=" << image_state.state << ", "          << "action_type=" << transition.action_type << ", "          << "r=" << r << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "policy_action=" << policy_action << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "instance_id=" << instance_id << dendl;
dout(5) << "global_image_id=" << global_image_id << ", "          << "instance_id=" << instance_id << dendl;
dout(20) << "global_image_id=" << global_image_id << ", "           << "result=" << result << dendl;
dout(10) << "global_image_id=" << global_image_id << ", "           << "migration_throttle=" << migration_throttle << ", "           << "last_shuffled_time=" << last_shuffled_time << ", "           << "result=" << result << dendl;
dout(10) << "global_image_id=" << global_image_id << ", "           << "resync=" << resync << dendl;
dout(20) << "image " << image_id << " "             << "was already scheduled for deletion" << dendl;
dout(10) << "image_id=" << image_id << ", "           << "deferment_end_time=" << utime_t{deferment_end_time} << dendl;
dout(10) << "scheduling " << name << " after " << after << " sec (task "           << m_timer_task << ")" << dendl;
dout(10) << "new lock owner detected -- resetting heartbeat counter"               << dendl;
dout(0) << "breaking leader lock after " << m_acquire_attempts << " "            << "failed attempts to acquire" << dendl;
dout(10) << m_heartbeat_response.acks.size() << " acks received, "           << m_heartbeat_response.timeouts.size() << " timed out" << dendl;
dout(10) << "notify_id=" << notify_id << ", handle=" << handle << ", "           << "notifier_id=" << notifier_id << dendl;
dout(5) << "updates=[" << map_updates << "], "          << "removes=[" << map_removals << "]" << dendl;
dout(15) << "global_image_id=" << global_image_id << ", "             << "action=" << action_type << ", "             << "instance=" << info.instance_id << dendl;
dout(20) << "scheduling image check update (" << m_timer_task << ")"           << " after " << after << " second(s)" << dendl;
dout(20) << "scheduling rebalance (" << m_rebalance_task << ")"           << " after " << resched_after << " second(s)" << dendl;
dout(5) << "acquire=[" << acquire << "], "          << "release=[" << release << "]" << dendl;
dout(5) << "peer_uuid=" << peer_uuid << ", "          << "remove=[" << remove << "]" << dendl;
dout(5) << "peer_uuid=" << peer_uuid << ", "          << "global_image_ids=[" << global_image_ids << "]" << dendl;
dout(5) << "peer_uuid=" << peer_uuid << ", "          << "global_image_ids=[" << global_image_ids << "]" << dendl;
dout(5) << "peer_uuid=" << peer_uuid << ", " << "added_count="          << added_global_image_ids.size() << ", " << "removed_count="          << removed_global_image_ids.size() << dendl;
dout(30) << m_base_cache_bytes << "+" << m_extra_cache_bytes << "="             << cache_bytes << dendl;
dout(20) << cache_name << " min_size=" << min_size << " max_size="             << max_size << " handler=" << handler << dendl;
dout(0) << "restarting pool replayer for " << peer << " due to "                  << "updated site name" << dendl;
dout(5) << "stopped manually, ignoring start without manual flag"       << dendl;
dout(10) << "on_finish=" << on_finish << ", manual=" << manual           << ", restart=" << restart << dendl;
dout(15) << "force=" << force << ", "           << "state=" << opt_state << dendl;
dout(15) << "force=" << force << ", "           << "state=" << opt_state << dendl;
dout(10) << "replay interrupted: "             << "r=" << error_code << ", "             << "error=" << error_description << dendl;
dout(15) << "old_image_spec=" << m_image_spec << ", "           << "new_image_spec=" << image_spec << dendl;
dout(10) << "local_mirror_uuid=" << local_mirror_uuid << ", "           << "pool_id=" << m_io_ctx.get_id() << dendl;
dout(15) << "global_image_id=" << global_image_id << ", "           << "mirror_image_site_status=" << mirror_image_site_status << dendl;
dout(20) << "r=" << r << ", "           << "image_id=" << *m_image_id << dendl;
dout(10) << "global image " << m_global_image_id << " not registered"               << dendl;
dout(15) << "local mirror snapshot: id=" << snap_info_it->first << ", "             << "mirror_ns=" << *mirror_ns << dendl;
dout(10) << "found local mirror snapshot: "             << "local_snap_id_start=" << m_local_snap_id_start << ", "             << "local_snap_id_end=" << m_local_snap_id_end << ", "             << "local_snap_ns=" << m_local_mirror_snap_ns << dendl;
dout(15) << "remote mirror snapshot: id=" << snap_info_it->first << ", "             << "mirror_ns=" << *mirror_ns << dendl;
dout(15) << "skipping remote snapshot due to missing mirror peer"               << dendl;
dout(15) << "skipping synced remote snapshot " << remote_snap_id                   << dendl;
dout(15) << "skipping synced remote snapshot " << remote_snap_id                   << " while search for in-progress sync" << dendl;
dout(10) << "located matching demotion snapshot: "                   << "remote_snap_id=" << remote_snap_id << ", "                   << "local_snap_id=" << m_local_snap_id_start << dendl;
dout(15) << "skipping remote snapshot " << remote_snap_id << " "                   << "while searching for demotion" << dendl;
dout(10) << "found remote mirror snapshot: "               << "remote_snap_id_start=" << m_remote_snap_id_start << ", "               << "remote_snap_id_end=" << m_remote_snap_id_end << ", "               << "remote_snap_ns=" << m_remote_mirror_snap_ns << dendl;
dout(10) << "local image contains in-progress mirror snapshot"                   << dendl;
dout(10) << "restarting snapshot scan due to remote update notification"             << dendl;
dout(10) << "all remote snapshots synced: idling waiting for new snapshot"           << dendl;
dout(10) << "remote_snap_id_start=" << m_remote_snap_id_start << ", "           << "remote_snap_id_end=" << m_remote_snap_id_end << ", "           << "local_snap_id_start=" << m_local_snap_id_start << dendl;
dout(10) << "remote_snap_id_start=" << m_remote_snap_id_start << ", "           << "remote_snap_id_end=" << m_remote_snap_id_end << ", "           << "local_snap_id_start=" << m_local_snap_id_start << ", "           << "snap_seqs=" << m_local_mirror_snap_ns.snap_seqs << dendl;
dout(15) << "mapping remote snapshot " << remote_snap_id << " to "                 << "local snapshot " << local_snap_id << dendl;
dout(10) << "demoted=" << m_remote_mirror_snap_ns.is_demoted() << ", "           << "primary_mirror_uuid="           << m_state_builder->remote_mirror_uuid << ", "           << "primary_snap_id=" << m_remote_snap_id_end << ", "           << "snap_seqs=" << m_local_mirror_snap_ns.snap_seqs << dendl;
dout(10) << "skipping unnecessary image copy: "             << "remote_snap_id_start=" << m_remote_snap_id_start << ", "             << "remote_mirror_snap_ns=" << m_remote_mirror_snap_ns << dendl;
dout(10) << "remote_snap_id_start=" << m_remote_snap_id_start << ", "           << "remote_snap_id_end=" << m_remote_snap_id_end << ", "           << "local_snap_id_start=" << m_local_snap_id_start << ", "           << "last_copied_object_number="           << m_local_mirror_snap_ns.last_copied_object_number << ", "           << "snap_seqs=" << m_local_mirror_snap_ns.snap_seqs << dendl;
dout(10) << "object_number=" << object_number << ", "           << "object_count=" << object_count << dendl;
dout(5) << "image id " << m_state_builder->local_image_id << " "            << "already in-use" << dendl;
dout(15) << "local_image_name=" << m_local_image_ctx->name << ", "           << "remote_image_name=" << m_image_state.name << dendl;
dout(15) << "image_features=" << m_features << ", "           << "state_features=" << image_state_features << ", "           << "feature_updates=" << feature_updates << ", "           << "enabled=" << enabled << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image"               << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image "               << "state" << dendl;
dout(15) << "snapshot " << snap_id << " is unprotected in remote image"               << dendl;
dout(15) << "snap_name=" << m_snap_name << ", "           << "snap_id=" << m_prev_snap_id << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image"               << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image "               << "state" << dendl;
dout(15) << "snap_name=" << m_snap_name << ", "           << "snap_id=" << m_prev_snap_id << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image"               << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image "               << "state" << dendl;
dout(15) << "snapshot " << snap_id << " is protected in remote image"               << dendl;
dout(15) << "snap_name=" << m_snap_name << ", "           << "snap_id=" << m_prev_snap_id << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image"               << dendl;
dout(15) << "snapshot " << snap_id << " does not exist in remote image "               << "state" << dendl;
dout(15) << "snapshot " << snap_id << " has been renamed from '"               << snap_info.name << "' to '" << snap_state.name << "'"               << dendl;
dout(15) << "snap_name=" << m_snap_name << ", "           << "snap_id=" << m_prev_snap_id << dendl;
dout(20) << "remote snapshot " << snap_id << " not tied to local"               << dendl;
dout(15) << "local snapshot " << local_snap_id << " maps to "                 << "remote snapshot " << snap_id << dendl;
dout(15) << "local snapshot " << local_snap_id << " maps to "                 << "remote snapshot " << remote_snap_id_seq << dendl;
dout(15) << "local_to_remote_snap_ids=" << m_local_to_remote_snap_ids           << dendl;
dout(20) << "local snapshot " << snap_it->first << " not tied to remote"               << dendl;
dout(15) << "local snapshot " << local_snap_id << " maps to "               << "remote snapshot " << mirror_ns->primary_snap_id << dendl;
dout(15) << "local snapshot " << local_snap_id << " maps to "                 << "remote snapshot " << remote_snap_id_seq << dendl;
dout(10) << "r=" << r << ", "           << "remote_image_id=" << m_remote_image_id << dendl;
dout(10) << "remote_mirror_uuid=" << m_remote_pool_meta.mirror_uuid << ", "           << "remote_mirror_peer_uuid="           << m_remote_pool_meta.mirror_peer_uuid << ", "           << "remote_image_id=" << m_remote_image_id << ", "           << "remote_promotion_state=" << m_promotion_state << dendl;
dout(15) << "parent_global_image_id=" << m_parent_global_image_id               << dendl;
dout(10) << "parent image " << m_remote_parent_spec.image_id             << " not mirrored" << dendl;
dout(10) << "parent image " << m_parent_global_image_id << " not "             << "registered locally" << dendl;
dout(10) << "r=" << r << ", "           << "local_image_id=" << m_local_image_id << dendl;
dout(10) << "image does not exist for local image id " << m_local_image_id             << dendl;
dout(10) << "local_image_id=" << m_local_image_id << ", "           << "local_promotion_state=" << m_promotion_state << ", "           << "local_primary_mirror_uuid=" << m_primary_mirror_uuid << dendl;
dout(10) << "failed to determine resync state: " << cpp_strerror(r)             << dendl;
dout(20) << "entry tid=" << m_replay_entry.get_commit_tid()           << "tag_tid=" << m_replay_tag_tid << dendl;
dout(15) << "decoded remote tag " << m_replay_tag_tid << ": "           << m_replay_tag_data << dendl;
dout(15) << "mirror_uuid=" << mirror_uuid << ", "           << "predecessor=" << predecessor << ", "           << "replay_tag_tid=" << m_replay_tag_tid << dendl;
dout(15) << "r=" << r << ", "           << "tag_tid=" << m_local_journal->get_tag_tid() << dendl;
dout(20) << "preprocessing entry tid=" << m_replay_entry.get_commit_tid()           << dendl;
dout(20) << "processing entry tid=" << m_replay_entry.get_commit_tid()           << dendl;
dout(20) << "commit_tid=" << replay_entry.get_commit_tid() << ", r=" << r           << dendl;
dout(5) << "image_id=" << local_image_ctx->id << ", "          << "remote_client_meta.image_id="          << remote_client_meta->image_id << ", "          << "remote_client.state=" << remote_client.state << dendl;
dout(5) << "image id " << m_state_builder->local_image_id << " "            << "already in-use" << dendl;
dout(20) << "remote_snap_id=" << event.snap_id << ", "           << "src_snap_name=" << event.src_snap_name << ", "           << "dest_snap_name=" << event.dst_snap_name << dendl;
dout(20) << "remapping remote snap id " << snap_seq_it->first << " "             << "to local snap id " << snap_seq_it->second << dendl;
dout(20) << "cannot map remote snapshot '" << event.src_snap_name << "' "             << "to local snapshot" << dendl;
dout(20) << "mapping remote snap id " << event.snap_id << " "           << "to local snap id " << snap_id_it->second << dendl;
dout(10) << "local tag=" << m_local_tag_tid << ", "           << "local tag data=" << m_local_tag_data << dendl;
dout(5) << "remote image is not primary -- skipping image replay"            << dendl;
dout(10) << "skipping processed predecessor remote tag "               << remote_tag.tid << dendl;
dout(10) << "decoded remote tag " << remote_tag.tid << ": "             << remote_tag_data << dendl;
dout(20) << "m_master_position=" << m_master_position    << ", m_mirror_position=" << m_mirror_position << dendl;
dout(20) << "clearing tags not needed any more (below mirror position)"    << dendl;
dout(20) << "erasing tag " <<  tag_data << "for tag_tid " << tag_tid      << dendl;
dout(20) << "master_tag_tid=" << master_tag_tid << ", mirror_tag_tid="    << mirror_tag_tid << dendl;
dout(20) << "m_master_position=" << m_master_position    << ", m_mirror_position=" << m_mirror_position    << ", m_entries_behind_master=" << m_entries_behind_master << dendl;
dout(10) << "remote peer does not support snapshot-based mirroring"             << dendl;
dout(20) << "ready to start op for " << id << " ["               << m_inflight_ops.size() << "/" << m_max_concurrent_ops << "]"               << dendl;
dout(20) << "ready to start op for " << id << " ["               << m_inflight_ops.size() << "/" << m_max_concurrent_ops << "]"               << dendl;
dout(20) << "ready to start op for " << id << " ["               << m_inflight_ops.size() << "/" << m_max_concurrent_ops << "]"               << dendl;
dout(10) << "C_GetInstances: " << this << " " <<  __func__ << ": r=" << r             << dendl;
dout(10) << "C_RemoveInstanceRequest: " << this << " " << __func__ << ": r="             << r << dendl;
dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__             << ": instance_watcher=" << instance_watcher << ", instance_id="             << instance_id << ", request_id=" << request_id << dendl;
dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__               << ": canceling" << dendl;
dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__                 << ": suspending" << dendl;
dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__             << ": sending to " << instance_id << dendl;
dout(10) << "C_NotifyInstanceRequest: " << this << " " << __func__ << ": r="             << r << dendl;
dout(5) << "C_NotifyInstanceRequest: " << this << " " << __func__                  << ": no payload in ack, ignoring" << dendl;
dout(10) << "C_SyncRequest: " << this << " " << __func__ << ": sync_id="             << sync_id << dendl;
dout(10) << "C_SyncRequest: " << this << " " << __func__ << ": r="             << r << dendl;
dout(10) << "instance_id=" << instance_id << ", global_image_id="           << global_image_id << dendl;
dout(10) << "instance_id=" << instance_id << ", global_image_id="           << global_image_id << dendl;
dout(10) << "instance_id=" << instance_id << ", "           << "global_image_id=" << global_image_id << ", "           << "peer_mirror_uuid=" << peer_mirror_uuid << dendl;
dout(10) << "instance_id=" << instance_id << ", request_id=" << request_id           << dendl;
dout(10) << "instance_id=" << instance_id << ", request_id=" << request_id           << dendl;
dout(10) << "notify_id=" << notify_id << ", handle=" << handle << ", "           << "notifier_id=" << notifier_id << dendl;
dout(10) << "global_image_id=" << global_image_id << ", "           << "peer_mirror_uuid=" << peer_mirror_uuid << dendl;
dout(10) << "handle_sync_request: finish: instance_id=" << instance_id                 << ", sync_id=" << sync_id << ", r=" << r << dendl;
dout(10) << "image_acquire: instance_id=" << instance_id << ", "           << "request_id=" << payload.request_id << dendl;
dout(10) << "image_release: instance_id=" << instance_id << ", "           << "request_id=" << payload.request_id << dendl;
dout(10) << "remove_peer_image: instance_id=" << instance_id << ", "           << "request_id=" << payload.request_id << dendl;
dout(10) << "sync_request: instance_id=" << instance_id << ", "           << "request_id=" << payload.request_id << dendl;
dout(10) << "sync_start: instance_id=" << instance_id << ", "           << "request_id=" << payload.request_id << dendl;
dout(10) << global_image_id << ": creating replayer " << image_replayer             << dendl;
dout(10) << "global_image_id=" << global_image_id << ", "           << "peer_mirror_uuid=" << peer_mirror_uuid << dendl;
dout(5) << "removing image replayer for global_image_id="            << global_image_id << dendl;
dout(10) << image_replayer << " global_image_id="           << image_replayer->get_global_image_id() << ", on_finish="           << on_finish << dendl;
dout(10) << "scheduling image replayer " << image_replayer << " stop after "             << after << " sec (task " << ctx << ")" << dendl;
dout(10) << "scheduling image state check after " << after << " sec (task "           << m_image_state_check_task << ")" << dendl;
dout(10) << "retrieving config-key: pool_id=" << pool_id << ", "           << "pool_name=" << pool_name << ", "           << "peer_uuid=" << peer->uuid << dendl;
dout(10) << "image_id=" << id << ", "           << "global_image_id=" << global_image_id << ", "           << "enabled=" << enabled << dendl;
dout(0) << "reverting global config option override: "                << pair.first << ": " << value << " -> " << pair.second                << dendl;
dout(20) << "pool_id=" << pool_id << ", namespace=" << namespace_name           << dendl;
dout(20) << "pool_id=" << pool_id << ", namespace=" << namespace_name           << dendl;
dout(20) << "pool_id=" << pool_id << ", "           << "callout_id=" << callout_id << ", "           << "callout_level=" << callout_level << ", "           << "text=" << text << dendl;
dout(20) << "pool_id=" << pool_id << ", "           << "callout_id=" << callout_id << dendl;
dout(20) << "pool_id=" << pool_id << ", "           << "key=" << key << ", "           << "value=" << value << dendl;
dout(20) << "pool_id=" << pool_id << ", "           << "namespace=" << namespace_name << ", "           << "key=" << key << ", "           << "value=" << value << dendl;
dout(20) << "pool_id=" << pool_id << ", "           << "key=" << key << dendl;
dout(10) << "snap_id=" << snap_id << ", "           << "snap_namespace=" << m_snap_namespace << ", "           << "snap_name=" << m_snap_name << dendl;
dout(10) << "snap_id=" << snap_id << ", "           << "snap_namespace=" << m_snap_namespace << ", "           << "snap_name=" << m_snap_name << dendl;
dout(10) << "image " << m_image_id << " is not in an expected trash state: "             << m_trash_image_spec.state << dendl;
dout(10) << "image_id=" << image_id << ", "           << "deferment_end_time=" << deferment_end_time << dendl;
dout(10) << "unable to locate OSD cap data for " << entity_name             << " in auth db" << dendl;
dout(10) << "unable to parse OSD cap data for " << entity_name             << " in auth db" << dendl;
dout(10) << "osdmap epoch " << epoch << " mapping took "        << (end - start) << " seconds" << dendl;
dout(10) << __func__               << " Error while registering osdmon caches with pcm."               << " Cache auto tuning not enabled."               << dendl;
dout(1) << __func__ << " Updated mon cache setting."             << " target: " << target             << " min: " << min             << " max: " << max             << dendl;
dout(15) << "update_from_paxos paxos e " << version    << ", my e " << osdmap.epoch << dendl;
dout(1) << __func__ << " mapping job "       << mapping_job.get() << " did not complete, "       << mapping_job->shards << " left, canceling" << dendl;
dout(10) << __func__ << " looking for valid full map in interval"      << " [" << fc << ", " << lc << "]" << dendl;
dout(10) << __func__ << " updated the on-disk full map version to "             << latest_full << dendl;
dout(7) << __func__ << " loading creating_pgs last_scan_epoch "     << creating_pgs.last_scan_epoch     << " with " << creating_pgs.pgs.size() << " pgs" << dendl;
dout(10) << __func__                 << " Error while registering osdmon caches with pcm."                 << " Proceeding without cache auto tuning."                 << dendl;
dout(7) << "update_from_paxos  applying incremental " << osdmap.epoch+1     << dendl;
dout(1) << __func__ << " pcm target: " << target           << " pcm max: " << max           << " pcm min: " << min           << " inc_osd_cache size: " << inc_osd_cache.get_size()           << dendl;
dout(1) << __func__ << " kv ratio " << cache_kv_ratio           << " inc ratio " << cache_inc_ratio           << " full ratio " << cache_full_ratio           << dendl;
dout(10) << __func__ << " canceling previous mapping_job " << mapping_job.get()      << dendl;
dout(10) << __func__ << " started mapping job " << mapping_job.get()      << " at " << fin->start << dendl;
dout(10) << __func__ << " canceling previous mapping_job " << mapping_job.get()      << dendl;
dout(1) << __func__ << " setting backfillfull_ratio = "       << pending_inc.new_backfillfull_ratio << dendl;
dout(1) << __func__ << " setting full_ratio = "       << pending_inc.new_full_ratio << dendl;
dout(1) << __func__ << " setting nearfull_ratio = "       << pending_inc.new_nearfull_ratio << dendl;
dout(1) << __func__ << " rewriting pool "       << osdmap.get_pool_name(pool_id) << " crush ruleset "       << pool.crush_rule << " -> rule id " << new_rule_id << dendl;
dout(10) << __func__ << " " << removed               << " pg removed because containing pool deleted: "               << deleted_pool << dendl;
dout(10) << __func__ << " " << removed      << " pgs removed because they're created" << dendl;
dout(10) << __func__ << " removing pg " << i->first   << " which should not exist" << dendl;
dout(10) << __func__ << " pool " << poolid      << " created " << p->second.created      << " modified " << p->second.modified      << " [" << p->second.start << "-" << p->second.end << ")"      << dendl;
dout(10) << __func__ << " pool " << poolid        << " now [" << p->second.start << "-" << p->second.end << ")"        << dendl;
dout(10) << __func__ << " queue remaining: " << pending_creatings.queue.size()    << " pools" << dendl;
dout(10) << __func__ << "  pg " << pgid << " just added, "   << " up " << i.second.up   << " p " << i.second.up_primary   << " acting " << i.second.acting   << " p " << i.second.acting_primary   << " history " << i.second.history   << " past_intervals " << i.second.past_intervals   << dendl;
dout(10) << __func__ << "  pg " << pgid << " new interval,"     << " up " << i.second.up << " -> " << up     << " p " << i.second.up_primary << " -> " << up_primary     << " acting " << i.second.acting << " -> " << acting     << " p " << i.second.acting_primary << " -> "     << acting_primary     << " history " << i.second.history     << " past_intervals " << i.second.past_intervals     << dendl;
dout(10) << __func__    << " " << (pending_creatings.pgs.size() - total)    << "/" << pending_creatings.pgs.size()    << " pgs added from queued pools" << dendl;
dout(10) << __func__ << " osd." << p->first << " weight increase, all"        << dendl;
dout(10) << __func__ << " estimate " << estimate << " pgs on "        << osds.size() << " osds >= "        << g_conf()->mon_osd_prime_pg_temp_max_estimate << " of total "        << mapping.get_num_pgs() << " pgs, all"        << dendl;
dout(10) << __func__ << " estimate " << estimate << " pgs on "        << osds.size() << " osds" << dendl;
dout(10) << __func__ << " did not finish in "        << g_conf()->mon_osd_prime_pg_temp_max_time        << ", stopping" << dendl;
dout(10) << __func__ << " consumed more than "       << g_conf()->mon_osd_prime_pg_temp_max_time       << " seconds, stopping"       << dendl;
dout(20) << __func__ << " next_up == next_acting now, clear pg_temp"      << dendl;
dout(20) << __func__ << " " << pgid << " " << up << "/" << acting    << " -> " << next_up << "/" << next_acting    << ", priming " << acting    << dendl;
dout(10) << "encode_pending e " << pending_inc.epoch    << dendl;
dout(1) << __func__ << " osdmap full prune encoded e"            << pending_inc.epoch << dendl;
dout(20) << __func__ << " encoding pending pgs without octopus features"        << dendl;
dout(10) << __func__ << " done creating pool " << i.first   << ", clearing CREATING flag" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]     << "'s nearfull flag" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]     << "'s backfillfull flag" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]     << "'s full flag" << dendl;
dout(10) << __func__ << " marking pool(s) " << full_pool_ids        << " as full" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]   << "'s full flag" << dendl;
dout(10) << __func__ << " marking pool '" << tmp.pool_name[p]   << "'s as backfillfull" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]   << "'s backfillfull flag" << dendl;
dout(10) << __func__ << " marking pool '" << tmp.pool_name[p]   << "'s as nearfull" << dendl;
dout(10) << __func__ << " clearing pool '" << tmp.pool_name[p]   << "'s nearfull flag" << dendl;
dout(1) << __func__ << " setting require_min_compat_client to currently "       << "required " << mv << dendl;
dout(10) << __func__ << " adding CREATING flag to pool " << i.first     << dendl;
dout(10) << __func__ << " switching pool " << poolid     << " cachemode from forward -> proxy" << dendl;
dout(10) << __func__ << " switching pool " << poolid     << " cachemode from readforward -> readproxy" << dendl;
dout(10) << __func__ << " clearing pool " << poolid << " removed_snaps"   << dendl;
dout(10) << __func__ << " recording pre-octopus purged_snaps in epoch "   << (pending_inc.epoch - 1) << ", " << v.length() << " bytes"   << dendl;
dout(10) << __func__ << " there were no pre-octopus purged snaps"   << dendl;
dout(10) << __func__ << " encoding full map with "      << tmp.require_osd_release      << " features " << features << dendl;
dout(20) << " full_crc " << tmp.get_crc()    << " inc_crc " << pending_inc.inc_crc << dendl;
dout(10) << "committed, telling random " << s->name    << " all about it" << dendl;
dout(0) << __func__            << " blocking osdmap trim"            << " ('mon_debug_block_osdmap_trim' set to 'true')"            << " trim_to = 0" << dendl;
dout(10) << __func__               << " explicit mon_osd_force_trim_to = " << floor << dendl;
dout(20) << __func__             << " dropping osdmap manifest from memory." << dendl;
dout(20) << __func__           << " osdmap manifest detected in store;
reload." << dendl;
dout(10) << __func__ << " store osdmap manifest pinned ("           << osdmap_manifest.get_first_pinned()           << " .. "           << osdmap_manifest.get_last_pinned()           << ")"           << dendl;
dout(10) << __func__             << " currently holding only " << (last - first)             << " epochs (min osdmap epochs: " << min_osdmap_epochs             << ");
do not prune."    dout(10) << __func__             << " could only prune " << (last_to_pin - first)             << " epochs (" << first << ".." << last_to_pin << "), which"                " is less than the required minimum (" << prune_min << ")"             << dendl;
dout(10) << __func__             << " we have pruned as far as we can;
do not prune."    dout(10) << __func__             << " not enough epochs to form an interval (last pinned: "             << last_pinned << ", last to pin: "             << last_to_pin << ", interval: " << prune_interval << ")"             << dendl;
dout(15) << __func__           << " should prune (" << last_pinned << ".." << last_to_pin << ")"           << " lc (" << first << ".." << last << ")"           << dendl;
dout(10) << __func__           << " first " << first           << " last_pinned " << osdmap_manifest.get_last_pinned()           << dendl;
dout(10) << __func__             << " first_pinned " << osdmap_manifest.get_first_pinned()             << " last_pinned " << osdmap_manifest.get_last_pinned()             << dendl;
dout(1) << __func__ << " osdmap full prune "          << ( enabled ? "enabled" : "disabled")          << dendl;
dout(5) << __func__          << " lc (" << first << " .. " << last << ")"          << " last_pinned " << last_pinned          << " interval " << prune_interval          << " last_to_pin " << last_to_pin          << dendl;
dout(5) << __func__     << " setting txsize to removal interval size ("     << removal_interval << " versions"     << dendl;
dout(20) << __func__      << " last_pinned " << last_pinned      << " next_pinned " << next_pinned      << " num_pruned " << num_pruned      << " removal interval (" << (last_pinned+1)      << ".." << (next_pinned-1) << ")"      << " txsize " << txsize << dendl;
dout(0) << "got MOSDFailure from entity with insufficient caps "     << session->caps << dendl;
dout(0) << "check_source: on fsid " << fsid     << " != " << mon.monmap->fsid << dendl;
dout(5) << "preprocess_failure from dead osd." << from       << ", ignoring" << dendl;
dout(5) << "preprocess_failure dne(/dup?): osd." << m->get_target_osd()     << " " << m->get_target_addrs()     << ", from " << m->get_orig_source() << dendl;
dout(5) << "preprocess_failure wrong osd: report osd." << m->get_target_osd()     << " " << m->get_target_addrs()     << " != map's " << osdmap.get_addrs(badboy)     << ", from " << m->get_orig_source() << dendl;
dout(5) << "preprocess_failure dup/old: osd." << m->get_target_osd()     << " " << m->get_target_addrs()     << ", from " << m->get_orig_source() << dendl;
dout(5) << "preprocess_failure ignoring report of osd."     << m->get_target_osd() << " " << m->get_target_addrs()     << " from " << m->get_orig_source() << dendl;
dout(10) << "preprocess_failure new: osd." << m->get_target_osd()    << " " << m->get_target_addrs()    << ", from " << m->get_orig_source() << dendl;
dout(5) << "preprocess_mark_me_down from dead osd."     << from << ", ignoring" << dendl;
dout(10) << "MOSDMarkMeDown for: " << m->get_orig_source()    << " " << m->target_addrs << dendl;
dout(5) << __func__ << " from nonexistent or up osd." << from     << ", ignoring" << dendl;
dout(5) << __func__ << " osd." << i << " is marked as nodown, "            << "will not mark it down" << dendl;
dout(2) << __func__ << " current up_ratio " << up_ratio << " < min "     << g_conf()->mon_osd_min_up_ratio     << ", will not mark osd." << i << " down" << dendl;
dout(5) << __func__ << " osd." << i << " is marked as noup, "            << "will not mark it up" << dendl;
dout(5) << __func__ << " osd." << i << " is marked as noout, "            << "will not mark it out" << dendl;
dout(5) << __func__ << " current in_ratio " << in_ratio << " < min "       << g_conf()->mon_osd_min_in_ratio       << ", will not mark osd." << i << " out" << dendl;
dout(5) << __func__ << " current in_ratio " << in_ratio << " < min "       << g_conf()->mon_osd_min_in_ratio       << ", will not mark osds out" << dendl;
dout(5) << __func__ << " osd." << i << " is marked as noin, "            << "will not mark it in" << dendl;
dout(10) << " dropping stale failure_info for osd." << target_osd        << " from " << fi.reporters.size() << " reporters"        << dendl;
dout(20) << " halflife " << halflife << " decay_k " << decay_k    << " failed_for " << failed_for << " decay " << decay << dendl;
dout(10) << " osd." << target_osd << " has "    << fi.reporters.size() << " reporters, "    << grace << " grace (" << orig_grace << " + " << my_grace    << " + " << peer_grace << "), max_failed_since " << fi.get_failed_since()    << dendl;
dout(1) << " we have enough reporters to mark osd." << target_osd     << " down" << dendl;
dout(1) << "prepare_failure osd." << m->get_target_osd()   << " " << m->get_target_addrs()   << " from " << m->get_orig_source()          << " is reporting failure:" << m->if_osd_failed() << dendl;
dout(10) << " removing last failure_info for osd." << target_osd   << dendl;
dout(10) << " failure_info for osd." << target_osd << " now "   << fi.reporters.size() << " reporters" << dendl;
dout(1) << " last_failed_interval " << last_failed_interval            << " > grace_interval_threshold_secs " << grace_interval_threshold_secs            << dendl;
dout(0) << "got preprocess_boot message from entity with insufficient caps"     << session->caps << dendl;
dout(0) << "preprocess_boot on fsid " << m->sb.cluster_fsid     << " != " << mon.monmap->fsid << dendl;
dout(7) << "preprocess_boot dup from " << m->get_orig_source()     << " " << m->get_orig_source_addrs()     << " =~ " << osdmap.get_addrs(from) << dendl;
dout(7) << __func__ << " from " << m->get_orig_source_inst()            << " clashes with existing osd: different fsid"            << " (ours: " << osdmap.get_uuid(from)            << " ;
theirs: " << m->sb.osd_fsid << ")" << dendl;
dout(7) << __func__ << " from " << m->get_source()   << " sb " << m->sb   << " client_addrs" << m->get_connection()->get_peer_addrs()   << " cluster_addrs " << m->cluster_addrs   << " hb_back_addrs " << m->hb_back_addrs   << " hb_front_addrs " << m->hb_front_addrs   << dendl;
dout(1) << "boot from osd." << from << " >= max_osd "     << osdmap.get_max_osd() << dendl;
dout(7) << __func__ << " was up, first marking down osd." << from << " "     << osdmap.get_addrs(from) << dendl;
dout(7) << __func__ << " already prepared, waiting on "     << m->get_orig_source_addr() << dendl;
dout(10) << " setting osd." << from << " uuid to " << m->sb.osd_fsid      << dendl;
dout(10) << __func__ << " osd." << from << " last_clean_interval "        << "[" << info.last_clean_begin << "," << info.last_clean_end        << ") -> [" << begin << "-" << end << ")"        << dendl;
dout(7) << __func__ << " NOIN set, will not mark in "  << m->get_orig_source_addr() << dendl;
dout(7) << "_booted " << m->get_orig_source_inst()    << " w " << m->sb.weight << " from " << m->sb.current_epoch << dendl;
dout(0) << "MOSDFull from entity with insufficient privileges:"     << session->caps << dendl;
dout(7) << __func__ << " ignoring full message from nonexistent "     << m->get_orig_source_inst() << dendl;
dout(7) << __func__ << " ignoring full message from down "     << m->get_orig_source_inst() << dendl;
dout(7) << __func__ << " state already " << state << " for osd." << from     << " " << m->get_orig_source_inst() << dendl;
dout(10) << __func__ << " want state " << state << " for osd." << from    << " " << m->get_orig_source_inst() << dendl;
dout(7) << __func__ << " osd." << from << " " << cur_state_set     << " -> " << want_state_set << dendl;
dout(7) << __func__ << " osd." << from << " " << cur_state_set     << " = wanted " << want_state_set << ", just waiting" << dendl;
dout(0) << "attempt to send MOSDAlive from entity with insufficient privileges:"     << session->caps << dendl;
dout(7) << "preprocess_alive ignoring alive message from down "     << m->get_orig_source() << " " << m->get_orig_source_addrs()     << dendl;
dout(10) << "preprocess_alive want up_thru " << m->want    << " from " << m->get_orig_source_inst() << dendl;
dout(7) << "prepare_alive want up_thru " << m->want << " have " << m->version   << " from " << m->get_orig_source_inst() << dendl;
dout(7) << "_reply_map " << e   << " from " << op->get_req()->get_orig_source_inst()   << dendl;
dout(10) << __func__      << " race with concurrent pg_num[_pending] update, will retry"      << dendl;
dout(0) << "attempt to send MOSDPGTemp from entity with insufficient caps "     << session->caps << dendl;
dout(7) << "ignoring pgtemp message from down "     << m->get_orig_source() << " " << m->get_orig_source_addrs()     << dendl;
dout(20) << " " << p->first      << (osdmap.pg_temp->count(p->first) ? osdmap.pg_temp->get(p->first) : empty)             << " -> " << p->second << dendl;
dout(10) << __func__ << " ignore " << p->first << " -> " << p->second               << ": pool has been removed" << dendl;
dout(10) << __func__ << " ignore " << p->first << " -> " << p->second        << ": primary has changed" << dendl;
dout(10) << __func__ << " ignore " << p->first << " -> " << p->second               << ": pool pending removal" << dendl;
dout(10) << __func__ << " ignore " << p->first << " -> " << p->second               << ": pool has been removed" << dendl;
dout(0) << "got preprocess_remove_snaps from entity with insufficient caps "     << session->caps << dendl;
dout(10) << " ignoring removed_snaps " << q->second        << " on non-existent pool " << q->first << dendl;
dout(10) << " ignoring removed_snaps " << snaps        << " on non-existent pool " << pool << dendl;
dout(10) << " pool " << pool << " removed_snaps added " << s     << " (now " << newpi->removed_snaps << ")" << dendl;
dout(10) << " pool " << pool << " snap_seq "     << newpi->get_snap_seq() << " -> " << s << dendl;
dout(10) << " added pool " << pool << " snap " << s   << " to removed_snaps queue" << dendl;
dout(10) << __func__ << " " << *beacon    << " from " << src << dendl;
dout(5) << "send_latest to " << op->get_req()->get_orig_source_inst()   << " start " << start << dendl;
dout(10) << "build_incremental [" << from << ".." << to << "] with features "    << std::hex << features << std::dec << dendl;
dout(20) << "build_incremental    inc " << e << " "        << bl.length() << " bytes" << dendl;
dout(20) << "build_incremental   full " << e << " "        << bl.length() << " bytes" << dendl;
dout(10) << __func__ << " asking proxying mon to send_incremental from "      << first << dendl;
dout(5) << "send_incremental [" << first << ".." << osdmap.get_epoch() << "]"   << " to " << session->name << dendl;
dout(10) << __func__ << " " << session->name << " should already have epoch "      << session->osd_epoch << dendl;
dout(20) << "send_incremental starting with base full "      << first << " " << bl.length() << " bytes" << dendl;
dout(20) << __func__ << " " << inc.epoch << " with features " << f    << dendl;
dout(20) << __func__ << " " << m.get_epoch() << " with features " << f    << dendl;
dout(10) << __func__ << "     "           << " epoch " << inc.epoch           << " inc_crc " << inc.inc_crc           << " full_crc " << inc.full_crc           << " encode_features " << inc.encode_features << dendl;
dout(10) << __func__ << " loaded osdmap epoch " << closest_pinned           << " e" << osdm.epoch           << " crc " << osdm.get_crc()           << " -- applying incremental maps." << dendl;
dout(10) << __func__             << " last incremental map didn't have features;
"  dout(10) << __func__ << " " << sub << " next " << sub->next    << (sub->onetime ? " (onetime)":" (ongoing)") << dendl;
dout(20) << __func__ << ": pool_id=" << pool_id << ", app_name=" << app_name           << dendl;
dout(10) << __func__ << " no change in pool " << poolid        << " " << pool << dendl;
dout(10) << __func__ << " pool is being removed: " << poolid        << " " << pool << dendl;
dout(10) << __func__ << " queueing pool create for " << poolid      << " " << pool << dendl;
dout(10) << __func__ << " " << creating_pgs.pgs.size() << " pgs creating, "    << creating_pgs.queue.size() << " pools in queue" << dendl;
dout(20) << __func__ << " ignoring " << pgid << " which should not exist"        << dendl;
dout(20) << __func__ << " " << pgid << " "       << " acting_primary:" << last_acting_primary       << " -> " << acting_primary << dendl;
dout(10) << __func__ << " will instruct osd." << acting_primary      << " to create " << pgid << "@" << mapped << dendl;
dout(30) << __func__ << " osd." << osd << " next=" << next    << " " << creating_pgs_by_osd_epoch << dendl;
dout(20) << __func__      << " not using stale creating_pgs@" << creating_pgs_epoch << dendl;
dout(20) << __func__ << " osd." << osd << " from " << next             << " : epoch " << epoch << " " << pgs.size() << " pgs" << dendl;
dout(20) << __func__ << "   " << pg << " " << create->second.history     << " " << create->second.past_intervals << dendl;
dout(20) << __func__ << " will create " << pg        << " at " << create->second.create_epoch << dendl;
dout(20) << __func__ << " osd." << osd << " from " << next             << " has nothing to send" << dendl;
dout(10) << "tick balancer "               << " inc cache_bytes: " << inc_cache->get_cache_bytes()               << " inc comtd_bytes: " << inc_cache->get_committed_size()               << " inc used_bytes: " << inc_cache->_get_used_bytes()               << " inc num_osdmaps: " << inc_cache->_get_num_osdmaps()               << dendl;
dout(10) << "tick balancer "               << " full cache_bytes: " << full_cache->get_cache_bytes()               << " full comtd_bytes: " << full_cache->get_committed_size()               << " full used_bytes: " << full_cache->_get_used_bytes()               << " full num_osdmaps: " << full_cache->_get_num_osdmaps()               << dendl;
dout(20) << "osd." << o << " laggy halflife " << halflife << " decay_k " << decay_k     << " down for " << down << " decay " << decay << dendl;
dout(10) << "tick entire containing " << down_out_subtree_limit         << " subtree for osd." << o         << " is down;
resetting timer" << dendl;
dout(10) << "tick marking osd." << o << " OUT after " << down     << " sec (target " << grace << " = " << orig_grace << " + " << my_grace << ")" << dendl;
dout(1) << __func__ << " cache_size:" << cache_size           << " inc_alloc: " << inc_alloc           << " full_alloc: " << full_alloc           << " kv_alloc: " << kv_alloc           << dendl;
dout(20) << __func__      << " pool " << pool << " snap " << snap      << " - key '" << k << "' not found" << dendl;
dout(20) << __func__      << " pool " << pool << " snap " << snap      << " - key '" << k << "' got '" << it->key()      << "', wrong prefix" << dendl;
dout(20) << __func__      << " pool " << pool << " snap " << snap      << " - key '" << k << "' got '" << gotk      << "', wrong pool " << keypool      << dendl;
dout(20) << __func__      << " pool " << pool << " snap " << snap      << " - found [" << *begin << "," << *end << "), no overlap"      << dendl;
dout(10) << __func__      << " [" << start << "," << end << ") - joins ["      << before_begin << "," << before_end << ") and ["      << after_begin << "," << after_end << ")" << dendl;
dout(10) << __func__      << " [" << start << "," << end << ") - join with earlier ["      << before_begin << "," << before_end << ")" << dendl;
dout(10) << __func__      << " [" << start << "," << end << ") - join with later ["      << after_begin << "," << after_end << ")" << dendl;
dout(10) << __func__      << " [" << start << "," << end << ") - new"      << dendl;
dout(20) << __func__ << "  we've already purged " << pbegin   << "~" << (pend - pbegin) << dendl;
dout(10) << __func__ << " pool " << p.first << " reports pruned " << to_prune        << ", actual pruned " << actual << dendl;
dout(0) << "WARNING: erasure coding profile " << profile << " uses plugin "     << plugin << " that has been deprecated. Please use "      << replacement << " instead." << dendl;
dout(10) << __func__ << " pending osd." << p->first        << " features are insufficient;
retry" << dendl;
dout(20) << "prepare_pool_crush_rule: rule "     << rule_name << " try again" << dendl;
dout(20) << __func__ << ": rule " << rule_name        << " try again" << dendl;
dout(10) << "tester.test_with_fork returns " << r        << ": " << err.str() << dendl;
dout(10) << __func__ << " crush smoke test duration: "             << duration << dendl;
dout(10) << __func__ << " allocated id " << allocated_id           << " existing id " << existing_id << dendl;
dout(20) << __func__ << " set " << name << " device_class " << device_class        << dendl;
dout(10) << __func__ << " id " << id << " uuid " << uuid           << " check_osd_exists " << check_osd_exists << dendl;
dout(10) << __func__ << " has lockbox " << has_lockbox_secret             << " dmcrypt " << has_dmcrypt_key << dendl;
dout(10) << __func__ << " destroying osd." << id           << " uuid " << uuid << dendl;
dout(10) << __func__ << " osd." << id << " does not exist and "             << "we are idempotent." << dendl;
dout(10) << __func__     << " proposed matches current and version equals previous"     << dendl;
dout(10) << " tester.test_with_fork returns " << r   << ": " << ess.str() << dendl;
dout(10) << __func__ << " crush somke test duration: "               << duration << ", result: " << ess.str() << dendl;
dout(5) << action << " crush item id " << osd << " name '" << name                << "' device_class '" << device_class << "'"                << dendl;
dout(0) << "will create and move bucket '" << name              << "' to location " << loc << dendl;
dout(5) << "adding/updating crush item id " << osdid << " name '"      << osd_name << "' weight " << weight << " at location "      << loc << dendl;
dout(0) << "create-or-move crush item name '" << osd_name       << "' initial_weight " << weight << " at location " << loc       << dendl;
dout(20) << "erasure code profile set " << name << "="        << profile_map << dendl;
dout(20) << "erasure code profile set " << profile << "="   << profile_map << dendl;
dout(10) << __func__ << " waiting for pending update on "                 << pgid << dendl;
dout(10) << __func__ << " waiting for pending update on "                 << pgid << dendl;
dout(10) << __func__ << " waiting for auth mon to be writeable for "               << "osd destroy" << dendl;
dout(10) << __func__ << " waiting for auth mon to be writeable for "               << "osd new" << dendl;
dout(1) << "implicitly use rule named after the pool: "  << poolstr << dendl;
dout(0) << "got unmanaged-snap pool op from entity with insufficient "                << "privileges. message: " << *m  << std::endl                << "caps: " << session->caps << dendl;
dout(0) << "got pool op from entity with insufficient privileges. "              << "message: " << *m  << std::endl              << "caps: " << session->caps << dendl;
dout(0) << __func__ << " drop message on fsid " << m->fsid            << " != " << mon.monmap->fsid << " for " << *m << dendl;
dout(10) << __func__ << " pool " << pool << " snap " << snap      << " - pool dne" << dendl;
dout(10) << __func__ << " pool " << pool << " snap " << snap      << " - in osdmap removed_snaps_queue" << dendl;
dout(10) << __func__ << " pool " << pool << " snap " << snap      << " - purged, [" << begin << "," << end << ")" << dendl;
dout(10) << __func__ << " pool " << pool << " snap " << snap      << " - pool pending deletion" << dendl;
dout(10) << __func__ << " pool " << pool << " snap " << snap      << " - in pending new_removed_snaps" << dendl;
dout(10) << "create snap in pool " << m->pool << " " << m->name        << " seq " << pp.get_snap_epoch() << dendl;
dout(10) << __func__ << " " << pool << " already pending removal"      << dendl;
dout(1) << __func__ << " faking pool deletion: renaming " << pool << " "     << old_name << " -> " << new_name << dendl;
dout(10) << __func__ << " " << pool << " removing obsolete pg_temp "        << p->first << dendl;
dout(10) << __func__ << " " << pool               << " removing obsolete primary_temp" << p->first << dendl;
dout(10) << __func__ << " " << pool               << " removing obsolete pg_upmap "               << p.first << dendl;
dout(10) << __func__ << " " << pool                 << " removing pending pg_upmap "                 << it->first << dendl;
dout(10) << __func__ << " " << pool               << " removing obsolete pg_upmap_items " << p.first               << dendl;
dout(10) << __func__ << " " << pool                 << " removing pending pg_upmap_items "                 << it->first << dendl;
dout(10) << __func__ << " pool " << pool_id      << " recovery_priority adjusted "      << prio << " to " << n << dendl;
dout(20) << "Checking " << bucket_name << " id " << bucket_id      << " to see if OSDs are also down" << dendl;
dout(10) << "We determined CRUSH buckets " << *really_down_buckets    << " and mons " << *really_down_mons << " are really down" << dendl;
dout(10) << __func__ << " v" << version        << " service_map e" << service_map.epoch        << " " << progress_events.size() << " progress events"        << dendl;
dout(10) << "ignoring report from non-active mgr " << m->gid      << dendl;
dout(10) << __func__ << " " << pending_digest << ", "    << pending_health_checks.checks.size() << " health checks, "    << progress_events.size() << " progress events" << dendl;
dout(0) << "MGetPoolStats received from entity with insufficient caps "            << session->caps << dendl;
dout(0) << __func__ << " on fsid "     << m->fsid << " != " << mon.monmap->fsid << dendl;
dout(0) << "MStatfs received from entity with insufficient privileges "            << session->caps << dendl;
dout(0) << __func__ << " on fsid " << statfs->fsid            << " != " << mon.monmap->fsid << dendl;
dout(10) << __func__ << " " << *statfs           << " from " << statfs->get_orig_source() << dendl;
dout(10) << __func__    << " next " << sub->next    << " have " << epoch << dendl;
ldout(cct, 20) << "is_capable service=" << service << " command=" << command     << (op_may_read ? " read":"")     << (op_may_write ? " write":"")     << (op_may_exec ? " exec":"")     << " addr " << addr     << " on cap " << *this     << dendl;
ldout(cct, 20) << " allow so far " << allow << ", doing grant " << *p       << dendl;
dout(10) << __func__ << " initial modules " << pending_map.modules    << ", always on modules " << pending_map.get_always_on_modules()           << ", " << pending_command_descs.size() << " commands"    << dendl;
dout(4) << "active server: " << map.active_addrs     << "(" << map.active_gid << ")" << dendl;
dout(4) << "mkfs or daemon transitioned to available, loading commands"       << dendl;
dout(10) << __func__ << " no health warning (never active and new cluster)"        << dendl;
dout(4) << __func__ << " encoding " << pending_command_descs.size()            << " command_descs" << dendl;
dout(1) << __func__ << " op fsid " << fsid     << " != " << mon.monmap->fsid << dendl;
dout(1) << __func__ << ":  waiting for osdmon writeable to"                 " blocklist old instance." << dendl;
dout(4) << "updated services from mgr." << m->get_name()              << ": " << m->get_services() << dendl;
dout(4) << "learned address " << m->get_server_addrs()       << " (was " << pending_map.active_addrs << ")" << dendl;
dout(4) << "First available beacon from " << pending_map.active_name                << "(" << m->get_gid() << ") does not include command descs"                << dendl;
dout(4) << "First available beacon from " << pending_map.active_name                << "(" << m->get_gid() << ") includes "                << pending_command_descs.size() << " command descs" << dendl;
dout(4) << "available_modules " << m->get_available_modules()       << " (was " << pending_map.available_modules << ")" << dendl;
dout(4) << "active's RADOS clients " << clients       << " (was " << pending_map.clients << ")" << dendl;
dout(4) << "selecting new active " << m->get_gid()     << " " << m->get_name()     << " (was " << pending_map.active_gid << " "     << pending_map.active_name << ")" << dendl;
dout(10) << "existing standby " << m->get_gid() << " available_modules "   << m->get_available_modules() << " (was "   << pending_map.standbys[m->get_gid()].available_modules << ")"   << dendl;
dout(20) << "Sending map to subscriber " << sub->session->con        << " " << sub->session->con->get_peer_addr() << dendl;
dout(10) << __func__ << " sending digest to subscriber " << sub->session->con      << " " << sub->session->con->get_peer_addr() << dendl;
dout(4) << "always on modules changed, pending "          << pending_map.always_on_modules << " != wanted "          << always_on_modules << dendl;
dout(4) << __func__ << ": resetting beacon timeouts due to mon delay "            "(slow election?) of " << now - last_tick << " seconds" << dendl;
dout(10) << " exceeded mon_mgr_mkfs_grace "             << g_conf().get_val<int64_t>("mon_mgr_mkfs_grace")             << " seconds" << dendl;
dout(5) << "blocklisting previous mgr." << pending_map.active_name << "."          << pending_map.active_gid << " ("          << pending_map.active_addrs << ")" << dendl;
ldout(cct, 1) << "init, last seen epoch " << epoch     << ", mid-election, bumping" << dendl;
ldout(cct, 5) << " got propose from old epoch, "       << from << " must have just started" << dendl;
ldout(cct, 5) << " got propose from old epoch, "       << from << " must have just started" << dendl;
ldout(cct, 30) << "propose from rank=" << from << ", tracker: "   << (stable_peer_tracker ? *stable_peer_tracker : *peer_tracker) << dendl;
ldout(cct, 10) << "propose from rank=" << from << ",score=" << from_score   << ";
my score=" << my_score     ldout(cct, 5) << "no, we already acked " << leader_acked     << " and it won't defer to " << from     << " despite better round scores" << dendl;
ldout(cct, 5) << "victory from " << from << " makes sense? lscore:"    << leader_score    << ";
my score:" << my_score << dendl;
dout(10) << __func__ << " version " << version    << ", my v " << mon.monmap->epoch << dendl;
dout(10) << __func__ << " min_mon_release (" << (int)min_mon_release      << ") and features (" << features << ") match" << dendl;
dout(1) << __func__ << " applying new features "     << new_features << ", had " << pending_map.persistent_features     << ", will have "     << (new_features | pending_map.persistent_features)     << dendl;
dout(1) << __func__ << " increasing min_mon_release to "     << to_integer<int>(min_mon_release) << " (" << min_mon_release     << ")" << dendl;
dout(10) << __func__ << " feature '" << feature               << "' already set on monmap;
no-op." << dendl;
dout(10) << " setting mon." << i.first   << " addrs " << i.second.public_addrs   << " -> " << av << dendl;
dout(1) << __func__       << ":  waiting for osdmon writeable for stretch mode" << dendl;
dout(0) << "adding/updating " << join->name   << " at " << join->addrs << " to monitor cluster" << dendl;
dout(1) << __func__ << " error obtaining monmap: "            << cpp_strerror(err) << dendl;
dout(10) << __func__    << " monmap next " << sub->next    << " have " << epoch << dendl;
dout(10) << __func__ << " first monmap with last_changed is "   << v << " with " << m.last_changed << dendl;
dout(10) << __func__ << " " << m << " " << *m    << " from " << m->get_orig_source_inst()    << " con " << m->get_connection() << dendl;
dout(10) << " discarding forwarded message from previous election epoch "      << m->rx_election_epoch << " < " << mon.get_epoch() << dendl;
dout(10) << " discarding message from disconnected client "      << m->get_source_inst() << " " << *m << dendl;
dout(10) << " setting proposal_timer " << do_propose             << " with delay of " << delay << dendl;
dout(10) << __func__ << " trim_to " << trim_to << " < first_committed"      << get_first_committed() << dendl;
dout(10) << __func__ << " trim_to " << trim_to << " would only trim " << to_remove      << " < paxos_service_trim_min " << g_conf()->paxos_service_trim_min << dendl;
dout(10) << __func__ << " trim_to " << trim_to << " would only trim " << to_remove      << " > paxos_service_trim_max, limiting to " << g_conf()->paxos_service_trim_max      << dendl;
dout(25) << __func__ << " for channel '"    << channel << "'" << dendl;
dout(20) << __func__ << " for channel '"      << channel << "' expanded to '"      << fname << "'" << dendl;
dout(20) << __func__ << " from '" << input    << "' to '" << s << "'" << dendl;
dout(25) << __func__ << " for channel '"    << channel << "'" << dendl;
dout(20) << __func__ << " for channel '"      << channel << "' to graylog host '"      << log_to_graylog_host[channel] << ":"      << log_to_graylog_port[channel]      << "'" << dendl;
dout(10) << __func__ << " version " << version           << " summary v " << summary.version << dendl;
dout(7) << "graylog: " << channel << " " << graylog  << " host:" << channels.log_to_graylog_host << dendl;
dout(20) << __func__ << " logging for channel '" << channel   << "' to file '" << log_file << "'" << dendl;
dout(1) << __func__ << " warning: log file level not defined for"      << " channel '" << channel << "' yet a log file is --"      << " will assume lowest level possible" << dendl;
dout(15) << __func__ << " logging for "           << channel_blog.size() << " channels" << dendl;
dout(15) << __func__ << " channel '" << p->first               << "': nothing to log" << dendl;
dout(15) << __func__ << " channel '" << p->first             << "' logging " << p->second.length() << " bytes" << dendl;
dout(1) << "unable to write to '" << log_file << "' for channel '"              << p->first << "': " << cpp_strerror(err) << dendl;
dout(1) << "error writing to '" << log_file << "' for channel '"                << p->first << ": " << cpp_strerror(err) << dendl;
dout(0) << "preprocess_log got MLog from entity with insufficient privileges "     << session->caps << dendl;
dout(0) << "handle_log on fsid " << m->fsid << " != " << mon.monmap->fsid      << dendl;
dout(10) << __func__ << " client " << s->session->name     << " requested version (" << s->next << ") is greater than ours ("      << summary_version << "), which means we already sent him"      << " everything we have." << dendl;
dout(10) << __func__ << " sending message to " << s->session->name   << " with " << mlog->entries.size() << " entries"   << " (version " << mlog->version << ")" << dendl;
dout(10) << __func__ << " level " << level << " ver " << sv    << " cur summary ver " << summary.version << dendl;
dout(10) << __func__ << " skipped from " << sv      << " to first_committed " << get_first_committed() << dendl;
dout(20) << __func__ << " requested " << level    << " entry " << le.prio << dendl;
dout(10) << __func__ << " incremental message ready ("     << mlog->entries.size() << " entries)" << dendl;
dout(7) << "prepare_update " << *m   << " from " << m->get_orig_source_inst() << dendl;
dout(10) << __func__ << " mute " << p->first << " count "     << p->second.count << " -> " << q->second.count     << dendl;
dout(10) << __func__ << " avail " << stats.fs_stats.avail_percent << "%"    << " total " << byte_u_t(stats.fs_stats.byte_total)    << ", used " << byte_u_t(stats.fs_stats.byte_used)    << ", avail " << byte_u_t(stats.fs_stats.byte_avail) << dendl;
dout(20) << __func__ << " highest version daemon count "        << all_versions.rbegin()->second.size() << dendl;
lgeneric_dout(cct, 1) << " removing " << get_name(i) << " " << get_addrs(i)     << dendl;
lgeneric_dout(cct, 1) << " adding self " << p << " " << my_addrs         << dendl;
dout(7) << "prepare_update " << *m   << " from " << m->get_orig_source_inst() << dendl;
dout(10) << __func__ << " unable to get dm-crypt key from store (r = "               << err << ")" << dendl;
dout(10) << __func__    << " next " << sub->next    << " have " << version << dendl;
dout(10) << __func__ << " incremental keys for " << m->prefix      << ", v " << sub->next << ".." << version      << ", " << m->data.size() << " keys"      << dendl;
dout(10) << __func__ << " sending full dump of " << m->prefix      << ", " << m->data.size() << " keys"      << dendl;
ldout(cct,10) << __func__ << " pre-mimic monitor, no config to fetch"        << dendl;
ldout(cct, 10) << __func__ << " no such monitor 'mon." << new_mon_id << "'"                   << dendl;
ldout(cct, 10) << __func__ << " ping mon." << new_mon_id                 << " " << con->get_peer_addr() << dendl;
ldout(cct, 10) << " got monmap " << monmap.epoch   << " from mon." << old_name   << " (according to old e" << monmap.get_epoch() << ")"    << dendl;
ldout(cct, 10) << "mon." << old_name << " at " << con_addrs       << " went away" << dendl;
ldout(cct,1) << " mon." << new_name << " has (v2) addrs "     << monmap.get_addrs(new_name) << " but i'm connected to "     << con_addrs << ", reconnecting" << dendl;
ldout(cct, 20) << __func__ << " canceling and discarding version request "     << version_requests.begin()->first << dendl;
ldout(cct, 20) << __func__ << " discarding " << waiting_for_session.size()   << " pending message(s)" << dendl;
ldout(cct, 5) << __func__ << " success, global_id "    << active_con->get_global_id() << dendl;
ldout(cct, 10) << "_send_mon_message to mon."     << monmap.get_name(cur_con->get_peer_addr())     << " at " << cur_con->get_peer_addr() << dendl;
ldout(cct, 10) << "picked mon." << monmap.get_name(rank)                 << " con " << conn                 << " addr " << peer                 << dendl;
ldout(cct, 10) << __func__ << " hunted mon " << con->get_peer_addrs()       << dendl;
ldout(cct, 10) << __func__ << " stray mon " << con->get_peer_addrs()       << dendl;
ldout(cct, 10) << __func__ << " current mon " << con->get_peer_addrs()       << dendl;
ldout(cct, 10) << "ms_handle_reset stray mon " << con->get_peer_addrs()       << dendl;
ldout(cct, 1) << "found mon."    << monmap.get_name(con->get_peer_addr())    << dendl;
ldout(cct, 10) << "renew subs? -- " << (maybe_renew ? "yes" : "no")       << dendl;
ldout(cct, 1) << "no keepalive since " << lk << " (" << interval   << " seconds), reconnecting" << dendl;
ldout(cct, 20) << __func__ << " reopen_interval_multipler now "   << reopen_interval_multiplier << dendl;
ldout(cct, 10) << __func__ << " called too often (last: "                   << last_rotating_renew_sent << "), skipping refresh" << dendl;
ldout(cct, 10) << " target " << r->target_rank    << " >= max mon " << monmap.size() << dendl;
ldout(cct, 10) << " target " << r->target_name    << " not present in monmap" << dendl;
ldout(cct, 10) << __func__ << " " << r->tid << " " << r->cmd       << " wants rank " << r->target_rank       << ", reopening session"       << dendl;
ldout(cct, 10) << " target " << r->target_rank         << " >= max mon " << monmap.size() << dendl;
ldout(cct, 10) << __func__ << " " << r->tid << " " << r->cmd       << " wants mon " << r->target_name       << ", reopening session"       << dendl;
ldout(cct, 10) << " target " << r->target_name         << " not present in monmap" << dendl;
ldout(cct, 10) << __func__ << " has tid 0, assuming it is " << r->tid     << dendl;
ldout(cct, 10) << __func__ << " " << reply->get_tid() << " not found"       << dendl;
ldout(cct, 10) << __func__ << " " << r->tid << " = " << ret << " " << rs   << dendl;
ldout(cct, 0) << __func__ << " version request with handle " << m->handle    << " not found" << dendl;
ldout(cct, 10) << __func__ << " finishing " << iter->first << " version "     << m->version << dendl;
ldout(cct,10) << __func__ << " con " << con << " auth_method " << *auth_method  << dendl;
ldout(cct, 0) << __func__ << " failed verifying authorizer reply"      << dendl;
ldout(cct,10) << __func__ << " hmm, they didn't like " << old_auth_method    << " result " << cpp_strerror(result)    << " and auth is " << (auth ? auth->get_protocol() : 0)    << dendl;
ldout(cct, 0) << __func__ << " for " << ceph_entity_type_name(service_id)    << ", but no auth is available now" << dendl;
ldout(cct,10) << __func__ << " method " << *method  << " preferred_modes " << *preferred_modes << dendl;
ldout(cct, 10) << __func__ << " responding with " << reply->length()     << " bytes" << dendl;
ldout(cct,10) << __func__ << " global_id " << new_global_id  << " payload " << bl.length()  << dendl;
ldout(cct,10) << __func__ << " old_auth_method " << old_auth_method  << " result " << cpp_strerror(result)  << " allowed_methods " << allowed_methods << dendl;
ldout(cct, 10) << "none of our auth protocols are supported by the server"       << dendl;
ldout(cct, 1) << __func__    << " not requesting MGR keys from pre-kraken monitor"    << dendl;
dout(10) << __func__ << " version " << version << " keys ver " << keys_ver           << " latest " << latest_full << dendl;
dout(20) << __func__ << " walking through version " << (keys_ver+1)             << " len " << bl.length() << dendl;
dout(10) << __func__ << " last_allocated_id initialized to "        << max_global_id << dendl;
dout(10) << __func__ << " max_global_id=" << max_global_id    << " format_version " << format_version    << dendl;
dout(20) << __func__ << " key server has "           << (mon.key_server.has_secrets() ? "" : "no ")           << "secrets!" << dendl;
dout(10) << __func__ << " inactive (num_mon " << mon_num      << " rank " << mon_rank << ")" << dendl;
dout(10) << __func__ << " " << id << " (max " << max_global_id << ")"    << dendl;
dout(1) << m->get_source_inst()                  << " supports cephx but not signatures and"                  << " 'cephx [cluster] require signatures = true';
"   dout(1) << m->get_source_inst()                  << " supports cephx but not signatures and"                  << " 'cephx [service] require signatures = true';
"   dout(1) << m->get_source_inst()                  << " supports cephx but not v2 and"                  << " 'cephx [cluster] require version >= 2';
"   dout(1) << m->get_source_inst()                  << " supports cephx but not v2 and"                  << " 'cephx [service] require version >= 2';
"  dout(20) << __func__ << " entity " << name << " auth " << auth           << " caps " << caps << " has_secret " << has_secret << dendl;
dout(10) << __func__ << " invalid cephx entity '"             << cephx_str << "'" << dendl;
dout(10) << __func__ << " invalid lockbox entity '"             << lockbox_str << "'" << dendl;
dout(10) << __func__ << " cephx " << cephx_entity                       << " lockbox " << lockbox_entity << dendl;
dout(10) << __func__ << " invalid cephx entity '"             << cephx_name << "'" << dendl;
dout(10) << __func__ << " invalid cephx lockbox entity '"               << lockbox_name << "'" << dendl;
dout(10) << __func__ << " cephx " << cephx_entity.name           << " lockbox ";
dout(10) << "AuthMonitor::prepare_command generating random key for "        << auth_inc.name << dendl;
dout(10) << __func__ << " unable to parse mon cap for "        << p->first << dendl;
dout(5) << __func__ << " updating " << p->first << " mon cap from "       << mon_caps << " to " << new_caps << dendl;
dout(5) << " fixing " << n << " mon cap to 'allow profile mgr'"  << dendl;
dout(20) << __func__ << " format " << format_version      << " is current" << dendl;
dout(10) << __func__ << " proposing update from format " << format_version      << " -> " << current << dendl;
dout(10) << __func__ << " required features " << required_features           << " " << required_mon_features           << ", peer features " << m->get_connection()->get_features()           << " " << m->mon_features           << dendl;
dout(5) << " ignoring propose from mon" << from     << " without required features" << dendl;
dout(5) << " ignoring propose from mon" << from     << " release " << (int)m->mon_release     << " < min_mon_release " << (int)mon->monmap->min_mon_release     << dendl;
dout(5) << " ignoring propose from mon." << from            << " without required mon_features " << missing            << dendl;
dout(5) << " ignoring ack from mon" << from     << " without required features" << dendl;
dout(5) << " ignoring ack from mon." << from            << " without required mon_features " << missing            << dendl;
dout(5) << "handle_victory from " << m->get_source()          << " quorum_features " << m->quorum_features          << " " << m->mon_features          << dendl;
dout(10) << "sending nak to peer " << m->get_source()    << " supports " << supported_features << " " << m->mon_features    << ", required " << required_features << " " << required_mon_features    << ", release " << (int)m->mon_release    << " vs required " << (int)mon->monmap->min_mon_release    << dendl;
dout(1) << "handle_nak from " << m->get_source()   << " quorum_features " << m->quorum_features          << " " << m->mon_features   << " min_mon_release " << (int)m->mon_release          << dendl;
dout(5) << " ignoring bogus election message with bad mon rank "   << op->get_req()->get_source() << dendl;
dout(0) << " ignoring election msg fsid "   << em->fsid << " != " << mon->monmap->fsid << dendl;
dout(1) << "discarding election message: " << em->get_source_addr()  << " not in my monmap " << *mon->monmap << dendl;
dout(0) << em->get_source_inst() << " has newer monmap epoch " << peermap.epoch  << " > my epoch " << mon->monmap->epoch   << ", taking it"  << dendl;
dout(0) << em->get_source_inst() << " has older monmap epoch " << peermap.epoch  << " < my epoch " << mon->monmap->epoch   << dendl;
dout(5) << __func__ << " somehow got an Election message with different strategy "  << em->strategy << " from local " << logic.strategy  << ";
dropping for now to let race resolve" << dendl;
dout(10) << __func__ << " version " << version    << ", my e " << get_fsmap().epoch << dendl;
dout(10) << __func__ << " explicit mon_mds_force_trim_to = "             << floor << dendl;
dout(10) << "preprocess_query " << *m << " from " << m->get_orig_source()    << " " << m->get_orig_source_addrs() << dendl;
dout(0) << "preprocess_beacon got MMDSBeacon from entity with insufficient privileges "     << session->caps << dendl;
dout(5)  << "preprocess_beacon " << *m    << " from " << m->get_orig_source()    << " " << m->get_orig_source_addrs()    << " " << m->get_compat()    << dendl;
dout(1) << " mds " << m->get_orig_source()     << " " << m->get_orig_source_addrs()     << " can't write to fsmap " << fsmap.compat << dendl;
dout(7) << "mds_beacon " << *m << " is not in fsmap (state "              << ceph_mds_state_name(state) << ")" << dendl;
dout(10) << "mds_beacon " << *m               << " ignoring requested state, because mds hasn't seen latest map" << dendl;
dout(10) << __func__ << " standby mds_join_fs changed to " << fscid               << " (" << m->get_fs() << ")" << dendl;
dout(10) << "mds_beacon mds can't activate itself (" << ceph_mds_state_name(info.state)        << " -> " << ceph_mds_state_name(state) << ")" << dendl;
dout(4) << "mds_beacon MDS can't go back into standby after taking rank: "                 "held rank " << info.rank << " while requesting state "              << ceph_mds_state_name(state) << dendl;
dout(0) << "preprocess_offload_targets got MMDSLoadTargets from entity with insufficient caps "     << session->caps << dendl;
dout(12) << "prepare_beacon " << *m << " from " << m->get_orig_source()    << " " << m->get_orig_source_addrs() << dendl;
dout(10) << "MDS health message (" << m->get_orig_source()        << "): " << new_metric.sev << " " << new_metric.message << dendl;
dout(10) << " fsmap " << pending.compat               << " can't write to new mds' " << m->get_compat()        << ", updating fsmap and killing old mds's"        << dendl;
dout(5) << "mds_beacon " << *m << " is not in fsmap (state "              << ceph_mds_state_name(state) << ")" << dendl;
dout(0) << "got beacon for MDS in STATE_STOPPING, ignoring requested state change"        << dendl;
dout(5)  << "prepare_beacon mds." << info.rank      << " " << ceph_mds_state_name(info.state)      << " -> " << ceph_mds_state_name(state)      << dendl;
dout(1) << __func__ << ": DAMAGED from rank " << info.rank                << " waiting for osdmon writeable to blocklist it" << dendl;
dout(0) << __func__ << ": marking rank "              << info.rank << " damaged" << dendl;
dout(1) << __func__ << ": DNE from rank " << info.rank                << " waiting for osdmon writeable to blocklist it" << dendl;
dout(10) << __func__ << ": validated rank/GID " << role               << " as a rank" << dendl;
dout(10) << __func__ << ": resolved MDS name '" << arg             << "' to GID " << mds_info->global_id << dendl;
dout(10) << __func__ << ": treating MDS reference '" << arg      << "' as an integer " << maybe_gid << dendl;
dout(1) << __func__ << ": rank/GID " << arg   << " not a existent rank or GID" << dendl;
dout(1) << "Invalid client subscription '" << sub->type                  << "'" << dendl;
dout(1) << "Client subscribed to non-existent namespace '" <<                  fscid << "'" << dendl;
dout(1) << "Client subscribed for legacy filesystem but "                     "none is configured" << dendl;
dout(10) << __func__ << " selected MDS map epoch " <<      mds_map->epoch << " for namespace " << fscid << " for subscriber "      << sub->session->name << " who wants epoch " << sub->next << dendl;
dout(1) << "assigned standby " << info->addrs            << " as mds." << mds << dendl;
dout(1)  << " failing and removing standby " << gid << " " << info.addrs      << " mds." << rank      << "." << info.inc << " " << ceph_mds_state_name(state)      << dendl;
dout(1)  << " replacing " << gid << " " << info.addrs      << " mds." << rank << "." << info.inc      << " " << ceph_mds_state_name(state)      << " with " << rep_info->global_id << "/" << rep_info->name << " " << rep_info->addrs      << dendl;
dout(1) << __func__ << ": resetting beacon timeouts due to mon delay "              "(slow election?) of " << since_last.count() << " seconds" << dendl;
dout(1) << "no beacon from mds." << info.rank << "." << info.inc              << " (gid: " << gid << " addr: " << info.addrs              << " state: " << ceph_mds_state_name(info.state) << ")"              << " since " << since_last.count() << dendl;
dout(1)  << " marking " << gid << " " << info.addrs          << " mds." << info.rank << "." << info.inc          << " " << ceph_mds_state_name(info.state)          << " laggy" << dendl;
dout(1) << " taking over failed mds." << rank << " with " << info->global_id              << "/" << info->name << " " << info->addrs << dendl;
dout(1) << "  setting mds." << info->global_id                  << " to follow mds rank " << rank << dendl;
ldout(cct, 10) << __func__ << " pool " << p.first << " gone, removing pgs"       << dendl;
ldout(cct,10) << __func__ << " pool " << poolid << " pg_num " << pg_num      << " > my pg_num " << my_pg_num << dendl;
ldout(cct,10) << __func__ << " pool " << poolid << " pg_num " << pg_num      << " < my pg_num " << my_pg_num << dendl;
ldout(cct,20) << __func__ << " removing pending update to old "      << i->first << dendl;
dout(10) << __func__ << " marking pg " << pgid      << " stale (acting_primary " << newstat->acting_primary      << ")" << dendl;
dout(10) << __func__ << " last_pn: " << last_pn << " accepted_pn: "    << accepted_pn << " last_committed: " << last_committed    << " first_committed: " << first_committed << dendl;
dout(10) << "WARNING: no pending_pn on disk, using previous accepted_pn " << accepted_pn        << " and crossing our fingers" << dendl;
dout(10) << "learned uncommitted " << (last_committed+1)      << " pn " << uncommitted_pn      << " (" << uncommitted_value.length() << " bytes) from myself"       << dendl;
dout(2) << __func__            << " leader's lowest version is too high for our last committed"            << " (theirs: " << collect->first_committed            << ";
ours: " << last_committed << ") -- bootstrap!" << dendl;
dout(10) << "accepting pn " << accepted_pn << " from "       << accepted_pn_from << dendl;
dout(10) << "NOT accepting pn " << collect->pn << " from " << collect->pn_from      << ", we already accepted " << accepted_pn      << " from " << accepted_pn_from << dendl;
dout(10) << " sharing our accepted but uncommitted value for "       << last_committed+1 << " (" << bl.length() << " bytes)" << dendl;
dout(10) << "WARNING: no pending_pn on disk, using previous accepted_pn " << previous_pn        << " and crossing our fingers" << dendl;
dout(10) << "share_state peer has fc " << peer_first_committed     << " lc " << peer_last_committed << dendl;
dout(10) << " sharing " << v << " ("        << m->values[v].length() << " bytes)" << dendl;
dout(10) << "store_state ignoring all values, they start at " << start->first      << " > last_committed+1" << dendl;
dout(10) << "store_state [" << start->first << ".."       << last_committed << "]" << dendl;
dout(10) << " forgetting obsolete uncommitted value " << uncommitted_v        << " pn " << uncommitted_pn << dendl;
dout(5) << __func__            << " mon." << from     << " lowest version is too high for our last committed"            << " (theirs: " << last->first_committed            << ";
ours: " << last_committed << ") -- bootstrap!" << dendl;
dout(5) << __func__       << " peon " << p->first       << " last_committed (" << p->second       << ") is too low for our first_committed (" << first_committed       << ") -- bootstrap!" << dendl;
dout(10) << " they accepted our pn, we now have "       << num_last << " peons" << dendl;
dout(10) << "we learned an uncommitted value for " << uncommitted_v   << " pn " << uncommitted_pn   << " " << uncommitted_value.length() << " bytes"   << dendl;
dout(10) << "ignoring uncommitted value for " << (last->last_committed+1)   << " pn " << last->uncommitted_pn   << " " << last->values[last->last_committed+1].length() << " bytes"   << dendl;
dout(10) << "begin for " << last_committed+1 << " "     << v.length() << " bytes"    << dendl;
dout(7) << "extend_lease now+" << g_conf()->mon_lease   << " (" << lease_expire << ")" << dendl;
dout(10) << "handle_lease i'm not a peon, or they're not the leader,"      << " or the last_committed doesn't match, dropping" << dendl;
dout(10) << "handle_lease on " << lease->last_committed    << " now " << lease_expire << dendl;
dout(10) << "handle_lease_ack from " << ack->get_source()      << " -- stray (probably since revoked)" << dendl;
dout(10) << "handle_lease_ack from " << ack->get_source()        << " -- got everyone" << dendl;
dout(10) << "handle_lease_ack from " << ack->get_source()        << " -- still need "        << mon.get_quorum().size() - acked_lease.size()        << " more" << dendl;
dout(10) << "handle_lease_ack from " << ack->get_source()      << " dup (lagging!), ignoring" << dendl;
dout(0) << "Got unexpected message type " << op->get_req()->get_type()     << " in Paxos::dispatch, aborting!" << dendl;
dout(5) << __func__ << " = " << (int)ret   << " - now=" << ceph_clock_now()   << " lease_expire=" << lease_expire   << " has v" << v << " lc " << last_committed   << dendl;
dout(10) << __func__ << " " << (last_committed + 1)    << " " << bl.length() << " bytes" << dendl;
dout(10) << __func__ << " crush_location " << crush_location        << " class " << device_class << dendl;
dout(7) << "prepare_update " << *m   << " from " << m->get_orig_source_inst() << dendl;
dout(20) << __func__ << " failed to parse " << key << " = '"     << val << "'" << dendl;
dout(20) << __func__ << " have " << key    << " = " << k->second.raw_value    << " (not " << value << ")" << dendl;
dout(20) << __func__ << " already have " << key         << " = " << k->second.raw_value << dendl;
dout(20) << __func__ << "  add " << key << " = " << value   << " (" << val << ")" << dendl;
dout(20) << __func__ << " skip " << key << " = " << value   << " (" << val << ")" << dendl;
dout(10) << __func__ << " pre-validate failed on '" << name << "' = '"        << value << "' for " << name << dendl;
dout(10) << __func__ << " NO_MON_UPDATE option '"        << name << "' = '" << value << "' for " << name        << dendl;
dout(10) << __func__ << " crush_location for remote_host " << s->remote_host      << " is " << crush_location << dendl;
dout(20) << __func__ << " " << s->entity_name << " crush " << crush_location    << " device_class " << device_class << dendl;
dout(10) << __func__ << " to " << s->name << " "    << (changed ? "(changed)" : "(unchanged)")    << dendl;
dout(10) << __func__    << " next " << sub->next    << " have " << version << dendl;
dout(10) << "block_device_get_metrics failed for /dev/" << devname   << dendl;
dout(1) << "finished manual compaction in "     << duration << " seconds" << dendl;
generic_dout(0) << "WARNING: mon fs missing feature list.\n"            << "Assuming it is old-style and introducing one." << dendl;
dout(0) << "we should have died but "              << "'mon_force_quorum_join' is set -- allowing boot" << dendl;
dout(1) << __func__ << " clean up potentially inconsistent store state"       << dendl;
dout(0) << "respawn execv " << orig_argv[0]   << " failed with " << cpp_strerror(errno) << dendl;
dout(0) << " monmap addrs for rank " << newrank << " changed, i am "     << messenger->get_myaddrs()     << ", monmap is " << monmap->get_addrs(newrank) << ", respawning"     << dendl;
dout(10) << "_add_bootstrap_peer_hint '" << cmd << "' addr '"      << addrstr << "'" << dendl;
dout(10) << "_add_bootstrap_peer_hintv '" << cmd << "' addrv '"      << addrstr << "'" << dendl;
dout(10) << __func__ << " marking sync in progress, storing sync_last_committed_floor "      << sync_last_committed_floor << dendl;
dout(5) << " ignoring peer mon." << m->get_source().num()     << " has features " << std::hex     << m->get_connection()->get_features()     << " but we require " << required_features << std::dec << dendl;
dout(10) << __func__ << " sync requester fell behind paxos, their lc " << sp.last_committed      << " < our fc " << paxos->get_first_committed() << dendl;
dout(20) << __func__ << " including paxos state " << sp.last_committed      << dendl;
dout(10) << __func__ << " chunk, through version " << sp.last_committed      << " key " << sp.last_key << dendl;
dout(10) << __func__ << " last chunk, through version " << sp.last_committed      << " key " << sp.last_key << dendl;
dout(10) << __func__ << " expiring cookie " << p->second.cookie        << " for " << p->second.addrs << dendl;
dout(10) << "reset_probe_timeout " << probe_timeout_event      << " after " << t << " seconds" << dendl;
dout(10) << "handle_probe_probe " << m->get_source_inst() << *m    << " features " << m->get_connection()->get_features() << dendl;
dout(1) << " peer " << m->get_source_addr()     << " release " << m->mon_release     << " < min_mon_release " << monmap->min_mon_release     << ", or missing features " << missing << dendl;
dout(1) << " peer " << m->get_source_addr() << " has first_committed "       << "ahead of us, re-bootstrapping" << dendl;
dout(1) << " adding peer " << m->get_source_addrs()     << " to list of hints" << dendl;
dout(10) << "handle_probe_reply " << m->get_source_inst()    << " " << *m << dendl;
dout(10) << " got newer/committed monmap epoch " << newmap->get_epoch()        << ", mine was " << monmap->get_epoch() << dendl;
dout(10) << " renaming peer " << m->get_source_addr() << " "      << peer_name << " -> " << m->name << " in my monmap"      << dendl;
dout(1) << " learned initial mon " << m->name     << " addrs " << m->get_source_addrs() << dendl;
dout(10) << " peer paxos versions [" << m->paxos_first_version      << "," << m->paxos_last_version << "] < my sync_last_committed_floor "      << sync_last_committed_floor << ", ignoring"      << dendl;
dout(10) << " peer paxos first versions [" << m->paxos_first_version        << "," << m->paxos_last_version << "]"        << " vs my version " << paxos->get_version()        << " (too far ahead)"        << dendl;
dout(10) << " peer paxos last version " << m->paxos_last_version        << " vs my version " << paxos->get_version()        << " (too far ahead)"        << dendl;
dout(10) << " peer paxos version " << m->paxos_last_version             << " vs my version " << paxos->get_version()             << " (ok)"             << dendl;
dout(10) << __func__ << " epoch " << epoch << " quorum " << active    << " features " << features           << " mon_features " << mon_features    << " min_mon_release " << min_mon_release           << dendl;
dout(10) << "lose_election, epoch " << epoch << " leader is mon" << leader    << " quorum is " << quorum << " features are " << quorum_con_features           << " mon_features are " << quorum_mon_features    << " min_mon_release " << min_mon_release           << dendl;
dout(20) << __func__    << " now: " << now << ","    << " next: " << next << ","    << " interval: " << cct->_conf->mon_health_to_clog_interval    << dendl;
dout(10) << __func__ << " updated " << updated.checks.size()    << " previous " << previous.checks.size()    << dendl;
dout(0) << "handle_command on fsid " << m->fsid << " != " << monmap->fsid     << dendl;
dout(10) << "Command not locally supported, forwarding request "        << m << dendl;
dout(10) << "Command not compatible with leader, forwarding request "        << m << dendl;
dout(25) << __func__ << " prefix='" << prefix           << "' module='" << module           << "' service='" << service << "'" << dendl;
dout(5) << __func__ << " failing forwarded command from a (presumably) "       << "pre-octopus peer" << dendl;
dout(10) << __func__ << " current mgr proxy bytes " << mgr_proxy_bytes        << " + " << size << " > max " << max << dendl;
dout(10) << __func__ << " proxying mgr command (+" << size      << " -> " << mgr_proxy_bytes << ")" << dendl;
dout(10) << "forward_request " << rr->tid << " request " << *req      << " features " << rr->con_features << dendl;
dout(10) << "received forwarded message from "    << ceph_entity_type_name(m->client_type)    << " " << m->client_addrs    << " via " << m->get_source_inst() << dendl;
dout(0) << "forward from entity with insufficient caps! "      << session->caps << dendl;
dout(10) << " entity name '" << s->entity_name << "' type "             << s->entity_name.get_type() << dendl;
dout(2) << "send_reply no connection, dropping reply " << *reply     << " to " << req << " " << *req << dendl;
dout(2) << "send_reply no connection, dropping reply " << *reply     << " to " << req << " " << *req << dendl;
dout(15) << "send_reply routing reply to " << con->get_peer_addr()      << " via " << session->proxy_con->get_peer_addr()      << " for request " << *req << dendl;
dout(10) << "no_reply to " << req->get_source_inst()      << " via " << session->proxy_con->get_peer_addr()      << " for request " << *req << dendl;
dout(10) << "no_reply to " << req->get_source_inst()             << " " << *req << dendl;
dout(0) << "MRoute received from entity without appropriate perms! "     << dendl;
dout(10) << "handle_route tid " << m->session_mon_tid << " " << *m->msg      << dendl;
dout(10) << " resend to mon." << mon << " tid " << rr->tid << " " << *req        << dendl;
dout(10) << "remove_session " << s << " " << s->name << " " << s->addrs    << " features 0x" << std::hex << s->con_features << std::dec << dendl;
dout(10) << __func__ << " feature change for " << m->get_source_inst()               << " (was " << s->con_features               << ", now " << con->get_features() << ")" << dendl;
dout(10) << __func__ << " connection for " << m->get_source_inst()                 << " changed from session;
mark down and replace" << dendl;
dout(1) << __func__ << " dropping stray message " << *m       << " from " << m->get_source_inst() << dendl;
dout(10) << __func__ << " new session " << s << " " << *s      << " features 0x" << std::hex      << s->con_features << std::dec << dendl;
dout(20) << __func__ << " existing session " << s << " for " << s->name      << dendl;
dout(20) << " entity " << s->entity_name    << " caps " << s->caps.get_str() << dendl;
dout(5) << __func__ << " " << op->get_req()->get_source_inst()            << " is not authenticated, dropping " << *(op->get_req())            << dendl;
dout(5) << __func__ << " " << op->get_req()->get_source_inst()            << " not enough caps for " << *(op->get_req()) << " -- dropping"            << dendl;
dout(1) << __func__ << " unexpected monitor message from"            << " non-monitor entity " << op->get_req()->get_source_inst()            << " " << *(op->get_req()) << " -- dropping" << dendl;
dout(10) << __func__ << " ignore paxos msg from "            << pm->get_source_inst() << dendl;
dout(0) << "MMonElection received from entity without enough caps!"          << op->get_session()->caps << dendl;
dout(5) << __func__ << " dropping deprecated message: "       << *op->get_req() << dendl;
dout(10) << __func__               << " finish current timecheck and start new" << dendl;
dout(10) << __func__ << " " << timecheck_waiting.size()           << " peers still waiting:";
dout(10) << __func__ << " delay " << delay           << " rounds_since_clean " << timecheck_rounds_since_clean           << dendl;
dout(10) << __func__               << " " << p.first << " skew " << abs_skew << dendl;
dout(1) << __func__      << " no clock skews found after " << timecheck_rounds_since_clean      << " rounds" << dendl;
dout(25) << __func__ << " mon." << it.first                 << " latency " << latency                 << " skew " << skew << dendl;
dout(10) << __func__ << " start timecheck epoch " << get_epoch()           << " round " << timecheck_round << dendl;
dout(1) << __func__ << " got old timecheck epoch " << m->epoch            << " from " << other            << " curr " << get_epoch()            << " -- severely lagged? discard" << dendl;
dout(1) << __func__ << " got old round " << m->round            << " from " << other            << " curr " << timecheck_round << " -- discard" << dendl;
dout(1) << __func__ << " our clock was readjusted --"            << " bump round and drop current check"            << dendl;
dout(10) << __func__ << " from " << other << " ts " << m->timestamp    << " delta " << delta << " skew_bound " << skew_bound    << " latency " << latency << dendl;
dout(10) << __func__ << " got pongs from everybody ("             << timecheck_acks << " total)" << dendl;
dout(1) << __func__ << " got wrong epoch "            << "(ours " << get_epoch()            << " theirs: " << m->epoch << ") -- discarding" << dendl;
dout(1) << __func__ << " got old round " << m->round            << " current " << timecheck_round            << " (epoch " << get_epoch() << ") -- discarding" << dendl;
dout(10) << __func__ << " send " << *m           << " to " << m->get_source_inst() << dendl;
dout(5) << __func__ << " " << op->get_req()->get_source_inst()       << " not enough caps for " << *(op->get_req()) << " -- dropping"       << dendl;
dout(10) << __func__ << " start (" << *start << ")"           << " num_keys " << *num_keys << dendl;
dout(10) << __func__ << " inject missing key, skipping (" << k << ")"               << dendl;
dout(30) << __func__ << " " << k << " bl " << bl.length() << " bytes"                                     << " crc " << key_crc << dendl;
dout(20) << __func__ << " last_key (" << last_key << ")"                       << " scrubbed_keys " << scrubbed_keys                       << " has_next " << it->has_next_chunk() << dendl;
dout(1) << __func__ << " scrub event is disabled"            << " (mon_scrub_interval = " << scrub_interval            << ")" << dendl;
dout(10) << " trimming session " << s->con << " " << s->name   << " " << s->addrs   << " (timeout " << s->session_timeout   << " < now " << now << ")" << dendl;
dout(10) << " trimming session " << s->con << " " << s->name   << " because we've been out of quorum too long" << dendl;
dout(0) << __func__ << " failed to open " << os.str()      << ": " << cpp_strerror(err) << dendl;
dout(10) << "get_authorizer for " << ceph_entity_type_name(service_id)    << dendl;
dout(0) << " couldn't get secret for mon service from keyring or keyserver"       << dendl;
dout(0) << __func__ << " failed to build mon session_auth_info "       << cpp_strerror(ret) << dendl;
dout(10) << __func__ << " con " << con << (more ? " (more)":" (start)")    << " method " << auth_method    << " payload " << payload.length()    << dendl;
dout(1) << __func__ << " auth_method " << auth_method << " not supported"       << dendl;
dout(10) << __func__ << " entity " << entity_name << " method "   << auth_method << " not among supported "   << auth_cluster_required.get_supported_set() << dendl;
dout(10) << __func__ << " entity " << entity_name << " method "   << auth_method << " not among supported "   << auth_cluster_required.get_supported_set() << dendl;
dout(10) << __func__ << "  assigned global_id " << con->peer_global_id        << dendl;
dout(10) << __func__ << " con " << con << " session " << s      << " already on list" << dendl;
dout(10) << __func__ << " con " << con << " session " << s      << " registering session for "      << con->get_peer_addrs() << dendl;
dout(10) << __func__ << " adding session " << s << " to con " << con      << dendl;
dout(10) << __func__ << " session " << s << " con " << con    << " addr " << s->con->get_peer_addr()    << " " << *s << dendl;
dout(20) << "prior dead_mon_buckets: " << old_dead_buckets    << ";
down_mon_buckets: " << down_mon_buckets      dout(5) << "discarding session " << *s       << " and sending OSD to matched zone" << dendl;
ldout(fs->store->cct, 10) << __func__ << " " << path << " offset " << offset       << dendl;
ldout(fs->store->cct, 10) << __func__ << std::hex    << " offset " << offset << " hash "    << hobject_t::_reverse_bits(hash_value)    << std::dec    << "/" << hash_bits    << " first " << next << " last " << last    << dendl;
ldout(fs->store->cct, 10) << __func__ << " " << path << " offset " << offset       << " size " << size << dendl;
ldout(fs->store->cct, 10) << __func__ << " " << path << " offset " << offset       << " size " << size << dendl;
ldout(fs->store->cct, 10) << __func__ << " " << path << ": "     << stbuf->f_bavail << "/" << stbuf->f_blocks << dendl;
dout(10) << "error opening file " << (*path)->path() << " with flags="      << flags << ": " << cpp_strerror(-r) << dendl;
dout(20) << __FUNC__ << ": clearing omap on " << o        << " in cid " << cid << dendl;
dout(0) << "backend " << backend->get_name()   << " (magic 0x" << std::hex << f_type << std::dec << ")"   << dendl;
dout(0) << __FUNC__ << ": failed to lock " << basedir << "/fsid, is another ceph-osd still running? "     << cpp_strerror(err) << dendl;
dout(0) << __func__ << " VDO volume " << vdo_name << " for " << dev_node  << dendl;
dout(10) << __FUNC__ << ": was " << *version << " vs target "    << target_version << dendl;
dout(10) << __FUNC__ << ": osd_uuid not found under omap, "             << "assume as matched."             << dendl;
dout(5) << __FUNC__ << ": " << o << " seq " << o->op   << " " << *osr   << " " << o->bytes << " bytes"   << "   (queue has " << throttle_ops.get_current() << " ops and " << throttle_bytes.get_current() << " bytes)"   << dendl;
dout(10) << __FUNC__ << ": " << o << " seq " << o->op << " r = " << r    << ", finisher " << o->onreadable << " " << o->onreadable_sync << dendl;
dout(0) << __FUNC__ << ": objectstore_blackhole = TRUE, dropping transaction"     << dendl;
dout(10) << __FUNC__ << ": object has " << opos << " > current pos " << spos      << ", now or in future, SKIPPING REPLAY" << dendl;
dout(10) << __FUNC__ << ": object has " << opos << " == current pos " << spos        << ", in_progress=true, CONDITIONAL REPLAY" << dendl;
dout(10) << __FUNC__ << ": object has " << opos << " == current pos " << spos        << ", in_progress=false, SKIPPING REPLAY" << dendl;
dout(10) << __FUNC__ << ": object has " << opos << " < current pos " << spos      << ", in past, will replay" << dendl;
dout(0) << " ENOSPC on setxattr on " << cid << "/" << oid                    << " name " << name << " size " << bl.length() << dendl;
dout(10) << __FUNC__ << ": " << ch->cid << "/" << oid      << " = " << r << dendl;
dout(10) << __FUNC__ << ": " << ch->cid << "/" << oid      << " = " << r      << " (size " << st->st_size << ")" << dendl;
dout(10) << __FUNC__ << ": (" << cid << "/" << oid << ") open error: "      << cpp_strerror(r) << dendl;
dout(0) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~"       << got << " ... BAD CRC:\n" << ss.str() << dendl;
dout(10) << __FUNC__ << ": " << cid << "/" << oid << " " << offset << "~"    << got << "/" << len << dendl;
dout(10) << __FUNC__ << ": fm_mapped_extents=" << fiemap->fm_mapped_extents             << " fe_logical=" << extent->fe_logical << " fe_length=" << extent->fe_length << dendl;
dout(0) << __FUNC__ << ": couldn't open " << cid << "/"     << oid << ": "     << cpp_strerror(r) << dendl;
dout(10) << " safe_splice write to " << to << " len " << r << " got " << r << dendl;
dout(25) << " write to " << to << " len " << (r-op)   << " got " << r2 << dendl;
dout(10) << __FUNC__ << ": " << oldcid << "/" << oldoid << " -> " << newcid << "/" << newoid << " "    << srcoff << "~" << len << " to " << dstoff << " = " << r << dendl;
generic_dout(-1) << "FileStore: sync_entry timed out after "    << m_commit_timeo << " seconds.\n";
dout(20) << __FUNC__ << ": waiting for another " << t   << " to reach min interval " << min_interval << dendl;
dout(15) << __FUNC__ << ": " << cid << "/" << oid    << (incomplete_inline ? " (incomplete_inline, forcing omap)" : "")    << dendl;
dout(20) << __FUNC__ << ": pool is " << pool << " shard is " << shard      << " pgid " << pgid << dendl;
dout(10) << __FUNC__ << ": fall through to non-temp collection, start "        << start << dendl;
dout(15) << __FUNC__ << ": " << c << "/" << hoid << " = " << r    << where << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << hoid << " = 0 "      << "(get_index failed with " << cpp_strerror(r) << ")" << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << hoid << " = 0 "        << "(lfn_find failed with " << cpp_strerror(r) << ")" << dendl;
dout(15) << __FUNC__ << ": collection: " << c << " pg number: "     << pg_num << " expected number of objects: " << expected_num_objs << dendl;
dout(0) << "Failed to give an expected number of objects hint to collection : "      << c << ", only empty collection can take such type of hint. " << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << o << " from "      << oldcid << "/" << o << " (dne, continue replay) " << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << o << " from "   << oldcid << "/" << oldoid << " (dne, continue replay) " << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << o << " from "   << oldcid << "/" << oldoid << " (dne, ignoring enoent)"   << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << o << " from " << oldcid << "/" << oldoid    << " = " << r << dendl;
dout(10) << __FUNC__ << ": " << c << "/" << o << " from " << oldcid << "/" << oldoid    << " = " << r << dendl;
dout(15) << __FUNC__ << ": " << cid << " " << dest    << " bits " << bits << dendl;
dout(20) << __FUNC__ << ": " << *i << " does not belong in "     << cid << dendl;
dout(15) << __FUNC__ << ": " << cid << " " << dest << " bits " << bits    << " = " << r << dendl;
dout(20) << __FUNC__ << ": " << *i << " still in source "   << cid << dendl;
dout(20) << __FUNC__ << ": " << *i << " now in dest "   << *i << dendl;
dout(20) << __FUNC__ << ": " << cid << " target level: "            << target_level << dendl;
dout(10) << "Error getting index for " << cid << ": " << cpp_strerror(r)      << dendl;
dout(20) << __func__ << " " << o << " " << i.first << " ("        << &i.first << ")" << dendl;
dout(20) << __func__ << " " << o << " " << i.first << " ("     << &i.first << ")" << dendl;
dout(20) << __func__ << " " << oid << " waiting on " << p->second   << dendl;
dout(0) << "detect_feature: failed to unlink test file for CLONE_RANGE ioctl: "  << cpp_strerror(r) << dendl;
dout(0) << "detect_feature: failed to create test file for CLONE_RANGE ioctl: "       << cpp_strerror(r) << dendl;
dout(0) << "create_current: BTRFS_IOC_SUBVOL_CREATE failed with error "     << cpp_strerror(ret) << dendl;
dout(0) << "create_current: failed to chmod " << get_current_path() << " to 0755: "     << cpp_strerror(ret) << dendl;
dout(0) << "list_checkpoints: opendir '" << get_basedir_path() << "' failed: "     << cpp_strerror(ret) << dendl;
dout(0) << "list_checkpoints: stat '" << path << "' failed: "       << cpp_strerror(err) << dendl;
dout(0) << "list_checkpoints: statfs '" << path << "' failed: "       << cpp_strerror(err) << dendl;
dout(0) << "rollback_to: error renaming old current subvol: "       << cpp_strerror(ret) << dendl;
dout(20) << "clone_range: cloning " << srcoffclone << "~" << lenclone    << " to " << dstoffclone << " = " << r << dendl;
dout(20) << "clone_range: finished " << srcoff << "~" << len    << " to " << dstoff << " = " << r << dendl;
dout(0) << "journal_replay forcing replay from "     << cct->_conf->journal_replay_from     << " instead of " << fs_op_seq << dendl;
dout(3) << "journal_replay open failed with "     << cpp_strerror(err) << dendl;
dout(10) << "op_apply_start " << op << " open_ops " << open_ops << " -> "    << (open_ops+1) << dendl;
dout(10) << "op_apply_finish " << op << " open_ops " << open_ops << " -> "    << (open_ops-1) << ", max_applied_seq " << max_applied_seq << " -> "    << std::max(op, max_applied_seq) << dendl;
dout(0) << "op_submit_finish " << op << " expected " << (op_submitted + 1)     << ", OUT OF ORDER" << dendl;
dout(10) << "commit_start max_applied_seq " << max_applied_seq      << ", open_ops " << open_ops << dendl;
dout(10) << "commit_start waiting for " << open_ops   << " open ops to drain" << dendl;
dout(10) << "commit_start committing " << committing_seq        << ", still blocked" << dendl;
dout(10) << "commit_started committing " << committing_seq << ", unblocking"    << dendl;
dout(10) << "op_journal_transactions " << op << " reqid_t "             << (static_cast<OpRequest *>(osd_op.get()))->get_reqid() << dendl;
dout(2) << "FileJournal::_open unable to open journal "     << fn << ": " << cpp_strerror(err) << dendl;
dout(1) << "_open " << fn << " fd " << fd   << ": " << max_size   << " bytes, block size " << block_size   << " bytes, directio = " << directio   << ", aio = " << aio   << dendl;
dout(0) << __func__ << ": your block device must be at least "      << ONE_MEG << " bytes to be used for a Ceph journal." << dendl;
dout(10) << __func__ << ": ignoring osd journal size. "    << "We'll use the entire block device (size: " << bdev_sz << ")"    << dendl;
dout(10) << "_open journal is not a block device, NOT checking disk "           << "write cache on '" << fn << "'" << dendl;
dout(10) << "open header.fsid = " << header.fsid    //<< " vs expected fsid = " << fsid    << dendl;
dout(2) << "open journal max size " << header.max_size     << " not a multiple of block size " << header.block_size << dendl;
dout(0) << "open journal alignment " << header.alignment << " does not match block size "     << block_size << " (required for direct_io journal mode)" << dendl;
dout(0) << "open journal alignment " << header.alignment     << " is not multiple of minimum directio alignment "     << CEPH_DIRECTIO_ALIGNMENT << " (required for direct_io journal mode)"     << dendl;
dout(10) << "open entry " << seq << " len " << bl.length() << " > next_seq " << next_seq        << ", ignoring journal contents"        << dendl;
dout(2) << "Unable to read past sequence " << seq     << " but header indicates the journal has committed up through "     << header.committed_up_to << ", journal is corrupt" << dendl;
dout(25) << "No further valid entries found, journal is most likely valid"   << dendl;
dout(10) << "header: block_size " << header.block_size    << " alignment " << header.alignment    << " max_size " << header.max_size    << dendl;
dout(10) << "room " << room << " max_size " << max_size << " pos " << pos << " header.start " << header.start    << " top " << get_top() << dendl;
dout(1) << "check_for_full at " << pos << " : JOURNAL FULL "   << pos << " >= " << room   << " (max_size " << header.max_size << " start " << header.start << ")"   << dendl;
dout(20) << "prepare_multi_write hit max events per write "     << cct->_conf->journal_max_write_entries << dendl;
dout(20) << "prepare_multi_write hit max write size "     << cct->_conf->journal_max_write_bytes << dendl;
dout(10) << "queue_write_fin will defer seq " << seq << " callback " << fin      << " until after UNFULL" << dendl;
dout(10) << "queue_completions_thru seq " << seq      << " queueing seq " << next.seq      << " " << next.finish      << " lat " << lat << dendl;
dout(15) << "prepare_single_write " << orig_ops << " will write " << queue_pos << " : seq " << seq    << " len " << orig_len << " -> " << size << dendl;
dout(15) << "do_write writing " << write_pos << "~" << bl.length()    << (hbp.length() ? " + header":"")    << dendl;
dout(10) << "do_write wrapping, first bit at " << pos << " len " << first.length()      << " second bit len " << second.length() << " (orig len " << bl.length() << ")" << dendl;
dout(10) << "do_write NOT queueing finisher seq " << journaled_seq        << ", full_commit_seq|full_restart_seq" << dendl;
dout(20) << "do_write NOT queueing finishers through seq " << journaled_seq   << " due to completion plug" << dendl;
dout(20) << "write_thread_entry aio throttle: aio num " << aio_num << " bytes " << aio_bytes   << " ... exp " << exp << " min_new " << min_new   << " ... pending " << cur << dendl;
dout(20) << "write_thread_entry deferring until more aios complete: "   << aio_num << " aios with " << aio_bytes << " bytes needs " << min_new   << " bytes to start a new aio (currently " << cur << " pending)" << dendl;
dout(15) << "do_aio_write writing " << pos << "~" << bl.length()    << (hbp.length() ? " + header":"")    << dendl;
dout(20) << "write_aio_bl .. " << aio.off << "~" << aio.len      << " in " << n << dendl;
dout(10) << __func__ << " aio " << ai->off   << "~" << ai->len << " done" << dendl;
dout(20) << "check_aio_completion completed seq " << p->seq << " "      << p->off << "~" << p->len << dendl;
dout(10) << "check_aio_completion NOT queueing finisher seq " << journaled_seq        << ", full_commit_seq|full_restart_seq" << dendl;
dout(20) << "check_aio_completion NOT queueing finishers through seq " << journaled_seq   << " due to completion plug" << dendl;
dout(10) << " len " << bl.length() << " -> " << size       << " (head " << head_size << " pre_pad " << h.pre_pad       << " bl " << bl.length() << " post_pad " << post_pad << " tail " << head_size << ")"       << " (bl alignment " << data_align << ")"       << dendl;
dout(5) << "submit_entry seq " << seq   << " len " << e.length()   << " (" << oncommit << ")" << dendl;
dout(1) << " FULL_FULL -> FULL_WAIT.  commit_start on seq "       << seq << " > journaled_seq " << journaled_seq       << ", moving to FULL_WAIT."       << dendl;
dout(1) << "FULL_FULL commit_start on seq "       << seq << " < journaled_seq " << journaled_seq       << ", remaining in FULL_FULL"       << dendl;
dout(15) << " dropping committed but unwritten seq " << peek_write().seq      << " len " << peek_write().bl.length()      << dendl;
dout(5) << __func__ << " finished " << ops << " ops and "   << bytes << " bytes" << dendl;
dout(2) << "No further valid entries found, journal is most likely valid"   << dendl;
dout(25) << "read_entry " << init_pos      << " : bad header magic, end of journal" << dendl;
dout(2) << "read_entry " << init_pos << " : seq " << h->seq   << " " << h->len << " bytes"   << dendl;
dout(20) << __func__ << " found extra alt attr for " << candidate_path   << ", long name " << string(bp.c_str(), bp.length()) << dendl;
dout(20) << __func__ << " " << mangled_name        << " moving old name to alt attr "        << lfn        << ", new name is " << full_name << dendl;
dout(0) << "update_current_zh: zfs_mount '" << zfs.get_name(zh)  << "' got " << cpp_strerror(ret) << dendl;
dout(0) << "detect_feature: failed to create test file for extsize attr: "            << cpp_strerror(ret) << dendl;
dout(0) << "detect_feature: failed to unlink test file for extsize attr: "            << cpp_strerror(ret) << dendl;
dout(20) << __func__ << " basedir " << fn      << " rotational " << (int)m_rotational << dendl;
dout(20) << __func__ << " journal filename " << fn.c_str()      << " journal rotational " << (int)m_journal_rotational << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__        << " r " << r << " from "        << "from.list_subdirs"        << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__        << " r " << r << " from "        << "to.list_subdirs"        << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__            << " r " << r << " from "            << "move_subdir(...,"            << path << "," << i << ")"            << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__            << " r " << r << " from "            << "rec _merge_dirs"            << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__            << " r " << r << " from "            << "remove_path "            << nested            << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__        << " r " << r << " from "        << "from.list_objects"        << dendl;
lgeneric_subdout(g_ceph_context,filestore,20) << __func__          << " r " << r << " from "          << "move_object(...,"          << path << "," << i << ")"          << dendl;
dout(20) << __func__ << " " << path << " target level: "            << target_level << dendl;
dout(10) << "error looking up info for " << path << ": "      << cpp_strerror(r) << dendl;
dout(1) << __func__ << " " << path << " has " << info.objs            << " objects, " << info.hash_level             << " level, starting split in pg " << coll() << "." << dendl;
dout(10) << "error initiating split on " << path << ": "        << cpp_strerror(r) << dendl;
dout(1) << __func__ << " " << path << " split completed in pg " << coll() << "."            << dendl;
dout(10) << "error completing split on " << path << ": "        << cpp_strerror(r) << dendl;
dout(10) << "error listing subdirs of " << path << ": "      << cpp_strerror(r) << dendl;
dout(10) << __func__ << " split multiple = " << split_multiplier    << " merge threshold = " << merge_threshold    << " split rand factor = " << cct->_conf->filestore_split_rand_factor    << " target level = " << target_level    << dendl;
dout(1) << __func__ << " " << path << " has " << info.objs            << " objects, starting split in pg " << coll() << "." << dendl;
dout(1) << __func__ << " " << path << " split completed in pg " << coll() << "."            << dendl;
dout(1) << "DOBjbectMap requires an upgrade,"       << " set filestore_update_to"       << dendl;
dout(10) << "oid: " << *oid << " setting spos to "        << *spos << dendl;
dout(20) << "lookup_parent: parent " << input->parent       << " for seq " << input->seq << dendl;
dout(20) << "lookup_parent: parent seq is " << header->seq << " with parent "       << header->parent << dendl;
dout(20) << "remove_map_header: removing " << header->seq    << " oid " << oid << dendl;
dout(20) << "set_map_header: setting " << header.seq    << " oid " << oid << " parent seq "    << header.parent << dendl;
dout(10) << "oid: " << oid << " not skipping op, *spos "        << *spos << dendl;
dout(10) << "oid: " << oid << " not skipping op, *spos "        << "empty" << dendl;
dout(10) << "oid: " << oid << " skipping op, *spos " << *spos      << " <= header.spos " << header->spos << dendl;
lgeneric_dout(cct, 0) << __func__ << " " << path << " is bluestore, "     << *fsid << dendl;
lgeneric_dout(cct, 0) << __func__ << " " << path << " is filestore, "     << *fsid << dendl;
dout(10) << __func__ << ": used_bytes: " << used_bytes    << "/" << cct->_conf->memstore_device_bytes << dendl;
dout(10) << __func__ << " " << c->cid << " " << oid << " "    << offset << "~" << len << dendl;
dout(10) << __func__ << " " << ch->cid << " " << oid << " " << offset << "~"    << len << dendl;
dout(10) << __func__ << " cid " << ch->cid << " start " << start    << " end " << end << dendl;
dout(10) << __func__ << " " << cid << " " << oid << " "    << offset << "~" << len << dendl;
dout(10) << __func__ << " " << cid << " " << oid << " " << offset << "~"    << len << dendl;
dout(10) << __func__ << " " << cid << " " << oldoid    << " -> " << newoid << dendl;
dout(10) << __func__ << " " << cid << " "    << oldoid << " " << srcoff << "~" << len << " -> "    << newoid << " " << dstoff << "~" << len    << dendl;
dout(10) << __func__ << " " << cid << " " << oid << " " << first    << " " << last << dendl;
dout(10) << __func__ << " " << oldcid << " " << oldoid << " -> "    << cid << " " << oid << dendl;
dout(10) << __func__ << " " << cid << " " << bits << " " << match << " "    << dest << dendl;
dout(10) << __func__ << " " << cid << " " << bits << " "    << dest << dendl;
dout(LogLevelV) << __func__ << "  shard " << *s.shard_info      << (s.loaded ? " (loaded)" : "")      << (s.dirty ? " (dirty)" : "")      << dendl;
dout(LogLevelV) << __func__ << "      csum: " << std::hex << v << std::dec        << dendl;
dout(LogLevelV) << __func__ << "       0x" << std::hex << i.first        << "~" << i.second->length << std::dec        << " " << *i.second << dendl;
dout(LogLevelV) << __func__ << " " << &o << " " << o.oid    << " nid " << o.onode.nid    << " size 0x" << std::hex << o.onode.size    << " (" << std::dec << o.onode.size << ")"    << " expected_object_size " << o.onode.expected_object_size    << " expected_write_size " << o.onode.expected_write_size    << " in " << o.onode.extent_map_shards.size() << " shards"    << ", " << o.extent_map.spanning_blob_map.size()    << " spanning blobs"    << dendl;
dout(LogLevelV) << __func__ << "  attr " << p->first      << " len " << p->second.length() << dendl;
dout(30) << __func__ << " (hex): [" << std::hex           << lookup_start_offset << ", " << lookup_end_offset            << ")" << std::dec << dendl;
dout(30) << __func__ << " " << *it             << "alloc_units: " << alloc_unit_start << ".." << alloc_unit_end             << dendl;
dout(30) << __func__  << " --expected:"                   << alloc_unit_start << dendl;
dout(30) << __func__  << " expected_allocations="                << bi.expected_allocations << " end_au:"               << alloc_unit_end << dendl;
dout(30) << __func__ << " affected_blob:" << *b               << " unref 0x" << std::hex << it->length               << " referenced = 0x" << bi.referenced_bytes               << std::dec << dendl;
dout(30) << __func__  << " --expected_allocations:"   << alloc_unit_start << dendl;
dout(30) << __func__ << " " << *(b_it->first)               << " expected4release=" << blob_expected_for_release               << " expected_allocations=" << bi.expected_allocations               << dendl;
dout(30) << __func__ << " affected_blob:" << *b                 << " unref 0x" << std::hex << o << "~" << l                 << std::dec << dendl;
dout(30) << __func__ << " gc range(hex): [" << std::hex           << gc_start_offset << ", " << gc_end_offset            << ")" << std::dec << dendl;
dout(20) << __func__ << "  rm " << o->oid << " "               << o->nref << " " << o->cached << " " << o->pinned << dendl;
dout(20) << __func__ << " " << when << " buffer_bytes " << buffer_bytes             << " ok" << dendl;
dout(20) << __func__ << " level " << level << " near " << near             << " on " << *b             << " which has cache_private " << b->cache_private << dendl;
dout(20) << __func__ << " evicted " << byte_u_t(evicted)                 << " from warm_in list, done evicting warm_in buffers"                 << dendl;
dout(20) << __func__ << " evicted " << byte_u_t(evicted)                 << " from hot list, done evicting hot buffers"                 << dendl;
dout(20) << __func__ << " " << when << " buffer_bytes " << buffer_bytes             << " ok" << dendl;
ldout(cache->cct, 20) << __func__ << std::hex << " 0x" << offset << "~" << length           << std::dec << dendl;
ldout(cache->cct, 30) << __func__ << " " << oid << " " << o     << " raced, returning existing " << p->second     << dendl;
ldout(cache->cct, 30) << __func__ << " " << oid << " hit " << p->second                            << " " << p->second->nref                            << " " << p->second->cached                            << " " << p->second->pinned       << dendl;
ldout(cache->cct, 30) << __func__ << " " << old_oid << " -> " << new_oid   << dendl;
ldout(cache->cct, 30) << __func__ << "  removing target " << pn->second     << dendl;
ldout(cct, LogLevelV) << i.first << " : " << i.second      << " " << i.second->nref      << " " << i.second->cached      << " " << i.second->pinned      << dendl;
dout(20) << __func__ << " " << this      << " removing self from set " << get_parent()      << dendl;
dout(20) << __func__        << " raced with sb cache update, was " << cache        << ", now " << coll->cache << ", retrying"        << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos   << "~" << e.length   << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length           << std::dec << " " << *this << dendl;
dout(20) << __func__ << " init 0x" << std::hex << l << ", "             << min_release_size << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length           << std::dec << " " << *this << dendl;
dout(10) << __func__ << " 0x" << std::hex << blob_offset << std::dec    << " start " << *this << dendl;
dout(10) << __func__ << " 0x" << std::hex << blob_offset << std::dec    << " finish " << *this << dendl;
dout(10) << __func__ << " 0x" << std::hex << blob_offset << std::dec    << "    and " << *r << dendl;
dout(20) << __func__ << "  inline shard " << len << " bytes from " << n        << " extents" << dendl;
dout(20) << __func__ << "  shard 0x" << std::hex   << p->shard_info->offset << std::dec << " is " << len   << " bytes (was " << p->shard_info->bytes << ") from "   << p->extents << " extents" << dendl;
dout(10) << __func__ << " 0x[" << std::hex << needs_reshard_begin << ","    << needs_reshard_end << ")" << std::dec    << " of " << onode->onode.extent_map_shards.size()    << " shards on " << onode->oid << dendl;
dout(20) << __func__ << "   spanning blob " << p.first << " " << *p.second      << dendl;
dout(20) << __func__ << "   shards [" << si_begin << "," << si_end << ")"      << " over 0x[" << std::hex << needs_reshard_begin << ","      << needs_reshard_end << ")" << std::dec << dendl;
dout(20) << __func__ << "  extent_avg " << extent_avg << ", target " << target    << ", slop " << slop << dendl;
dout(20) << __func__ << "  new shard 0x" << std::hex << offset                 << std::dec << dendl;
dout(20) << __func__ << "  new shard 0x" << std::hex << offset        << std::dec << dendl;
dout(20) << __func__ << "  new shard 0x" << std::hex << needs_reshard_begin      << std::dec << " (singleton degenerate case)" << dendl;
dout(20) << __func__ << " checking spanning blobs 0x[" << std::hex      << spanning_scan_begin << "," << spanning_scan_end << ")" << dendl;
dout(30) << __func__ << "  shard 0x" << std::hex << shard_start   << " to 0x" << shard_end << std::dec << dendl;
dout(20) << __func__ << "    splitting blob, bstart 0x"      << std::hex << bstart << " blob_offset 0x"      << blob_offset << std::dec << " " << *b << dendl;
dout(0) << __func__       << " spanning blob count exceeds threshold, "       << spanning_blob_map.size() << " spanning blobs"       << dendl;
dout(30) << __func__ << " 0x" << std::hex << offset << "~" << length        << std::dec << " hit new spanning blob " << *p << dendl;
dout(30) << __func__ << "  getting spanning blob "        << (blobid >> BLOBID_SHIFT_BITS) << dendl;
dout(30) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(30) << __func__ << " opening shard 0x" << std::hex        << p->shard_info->offset << std::dec << dendl;
dout(20) << __func__ << " open shard 0x" << std::hex        << p->shard_info->offset        << " for range 0x" << offset << "~" << length << std::dec        << " (" << v.length() << " bytes)" << dendl;
dout(30) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(20) << __func__ << " mark shard 0x" << std::hex        << p->shard_info->offset << std::dec << " dirty" << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length        << " next shard 0x" << shard_end << std::dec        << " merging " << *p << " and " << *n << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << " end 0x" << end_pos    << " blob_offset 0x" << blob_offset << std::dec << " " << *lb    << dendl;
dout(20) << __func__ << " seq " << seq    << " 0x" << std::hex << offset << "~" << length    << " crc " << i.first->second.bl.crc32c(-1)    << std::dec << dendl;
generic_dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length     << std::dec << dendl;
dout(20) << __func__ << "  keep head " << p->second.seq        << " 0x" << std::hex << p->first << "~" << p->second.bl.length()        << " -> 0x" << head.length() << std::dec << dendl;
dout(20) << __func__ << "  keep tail " << p->second.seq   << " 0x" << std::hex << p->first << "~" << p->second.bl.length()   << " -> 0x" << tail.length() << std::dec << dendl;
dout(20) << __func__ << "  truncate front " << p->second.seq        << " 0x" << std::hex << p->first << "~" << p->second.bl.length()        << " drop_front 0x" << drop_front << " keep_tail 0x" << keep_tail        << " to 0x" << (offset + length) << "~" << keep_tail        << std::dec << dendl;
dout(20) << __func__ << "  drop " << p->second.seq        << " 0x" << std::hex << p->first << "~" << p->second.bl.length()        << std::dec << dendl;
ldout(store->cct, 10) << __func__ << " sbid 0x" << std::hex << sbid     << std::dec << " had " << *b->shared_blob << dendl;
ldout(store->cct, 10) << __func__ << " sbid 0x" << std::hex << sbid     << std::dec << " opened " << *b->shared_blob     << dendl;
ldout(store->cct, 10) << __func__ << " sbid 0x" << std::hex << sbid     << std::dec << " loaded shared_blob " << *sb << dendl;
ldout(store->cct, 20) << __func__ << " oid " << oid << " key "   << pretty_binary_string(key) << dendl;
ldout(store->cct, 20) << __func__ << " not moving " << o << " " << o->oid       << dendl;
ldout(store->cct, 20) << __func__ << " moving " << o << " " << o->oid       << dendl;
ldout(store->cct, 20) << __func__ << "  already moved " << *sb    << dendl;
ldout(store->cct, 20) << __func__    << "   moving registration " << *sb << dendl;
ldout(store->cct, 20) << __func__ << "   moving " << *i.second        << dendl;
dout(5) << __func__  << " cache_size: " << cache_size                  << " kv_alloc: " << kv_alloc                  << " kv_used: " << kv_used                  << " kv_onode_alloc: " << kv_onode_alloc                  << " kv_onode_used: " << kv_onode_used                  << " meta_alloc: " << meta_alloc                  << " meta_used: " << meta_used                  << " data_alloc: " << data_alloc                  << " data_used: " << data_used << dendl;
dout(20) << __func__  << " cache_size: " << cache_size                   << " kv_alloc: " << kv_alloc                   << " kv_used: " << kv_used                   << " kv_onode_alloc: " << kv_onode_alloc                   << " kv_onode_used: " << kv_onode_used                   << " meta_alloc: " << meta_alloc                   << " meta_used: " << meta_used                   << " data_alloc: " << data_alloc                   << " data_used: " << data_used << dendl;
dout(30) << __func__ << " max_shard_onodes: " << max_shard_onodes                 << " max_shard_buffer: " << max_shard_buffer << dendl;
dout(5) << __func__  << " updated pcm target: " << target                << " pcm min: " << min                << " pcm max: " << max                << dendl;
ldout(c->store->cct,20) << __func__ << " after " << after << " key "       << pretty_binary_string(key) << dendl;
ldout(c->store->cct,20) << __func__ << " to " << to << " key "       << pretty_binary_string(key) << dendl;
ldout(c->store->cct,20) << __func__ << " is at "       << pretty_binary_string(it->raw_key().second)       << dendl;
dout(10) << __func__ << " mode " << Compressor::get_comp_mode_name(comp_mode)    << " alg " << (compressor ? compressor->get_type_name() : "(none)")    << " min_blob " << comp_min_blob_size    << " max_blob " << comp_max_blob_size    << dendl;
dout(10) << __func__ << " csum_type "    << Checksummer::get_csum_type_string(csum_type)    << dendl;
dout(10) << __func__ << " throttle_cost_per_io " << throttle_cost_per_io    << dendl;
dout(10) << __func__ << " max_blob_size 0x" << std::hex << max_blob_size           << std::dec << dendl;
dout(10) << __func__           << " osd_memory_target " << osd_memory_target           << " osd_memory_base " << osd_memory_base           << " osd_memory_expected_fragmentation " << osd_memory_expected_fragmentation           << " osd_memory_cache_min " << osd_memory_cache_min           << dendl;
dout(1) << __func__ << " cache_size " << cache_size          << " meta " << cache_meta_ratio   << " kv " << cache_kv_ratio   << " data " << cache_data_ratio   << dendl;
dout(2) << __func__ << " unable to decode label at offset " << p.get_off()  << ": " << e.what()  << dendl;
dout(20) << __func__ << " bdev " << path << " fsid " << label.osd_uuid    << " and fsid " << fsid << " check bypassed" << dendl;
dout(10) << __func__ << " min_alloc_size 0x" << std::hex << min_alloc_size    << std::dec << " order " << (int)min_alloc_size_order    << " max_alloc_size 0x" << std::hex << max_alloc_size    << " prefer_deferred_size 0x" << prefer_deferred_size    << std::dec    << " deferred_batch_ops " << deferred_batch_ops    << dendl;
dout(1) << __func__ << " pre-fragmenting freespace, using "       << cct->_conf->bluestore_debug_prefill << " with max free extent "       << cct->_conf->bluestore_debug_prefragment_max << dendl;
dout(20) << __func__ << " free 0x" << std::hex << start << "~" << l   << " use 0x" << u << std::dec << dendl;
dout(1) << __func__          << " loaded " << byte_u_t(bytes) << " in " << num << " extents"          << std::hex          << ", allocator type " << shared_alloc.a->get_type()          << ", capacity 0x" << shared_alloc.a->get_capacity()          << ", block size 0x" << shared_alloc.a->get_block_size()          << ", free 0x" << shared_alloc.a->get_free()          << ", fragmentation " << shared_alloc.a->get_fragmentation()          << std::dec << dendl;
dout(5) << __func__ << " bluefs disabled, default to store media type"            << dendl;
dout(0) << __func__ << " read-only:" << read_only          << " repair:" << to_repair << dendl;
dout(1) << __func__ << " opened " << kv_backend   << " path " << kv_dir_fn << " options " << options << dendl;
dout(20) << __func__ << " opened " << cid << " " << c        << " " << c->cnode << dendl;
dout(30) << __func__ << " pool " << pool_id   << " statfs " << st << dendl;
dout(20) << __func__ << " name " << name << " path " << epath    << " size " << size << " create=" << (int)create << dendl;
dout(1) << __func__ << " created " << name << " symlink to "              << epath << dendl;
dout(1) << __func__ << " resized " << name << " file to "  << byte_u_t(size) << dendl;
dout(20) << __func__ << " undecodable Pool StatFS record, key:'"            << pretty_binary_string(key)     << "', removing" << dendl;
dout(20) << "fsck inf: found empty stray Pool StatFS record for pool id 0x"             << std::hex << pool_id << std::dec << dendl;
dout(30) << __func__ << " key "        << pretty_binary_string(it->key()) << dendl;
dout(20) << __func__ << "  collection " << c->cid << " " << c->cnode          << dendl;
dout(20) << __func__ << "  referenced 0x" << std::hex << i.second            << std::dec << " for " << *i.first << dendl;
dout(0) << __func__ << " partial offload"                << ", done myself " << processed_myself                << " of " << ctx.num_objects                << "objects, threads " << thread_count                << dendl;
dout(1) << __func__    << (repair ? " repair" : " check")    << (depth == FSCK_DEEP ? " (deep)" :      depth == FSCK_SHALLOW ? " (shallow)" : " (regular)")    << dendl;
dout(1) << __func__   << " <<<START>>>"   << (repair ? " repair" : " check")   << (depth == FSCK_DEEP ? " (deep)" :                depth == FSCK_SHALLOW ? " (shallow)" : " (regular)")          << " start" << dendl;
dout(20) << __func__ << " undecodable Shared Blob, key:'"              << pretty_binary_string(it->key())           << "', removing" << dendl;
dout(30) << __func__ << " key "   << pretty_binary_string(it->key()) << dendl;
dout(20) << __func__ << " check misreference for col:" << c->cid    << " obj:" << oid << dendl;
dout(10) << __func__      << " fix misreferences in oid:" << oid      << " " << *b << dendl;
dout(10) << __func__ << " release 0x" << std::hex << it.get_start()   << "~" << it.get_len() << std::dec << dendl;
dout(20) << __func__ << " " << *sbi.sb     << " is empty, removing" << dendl;
dout(20) << __func__ << " " << *sbi.sb     << " is " << bl.length() << " bytes, updating" << dendl;
dout(20) << __func__ << " undecodable deferred TXN record, key: '"       << pretty_binary_string(it->key())       << "', removing" << dendl;
dout(20) << __func__ << "  deferred " << wt.seq          << " ops " << wt.ops.size()          << " released 0x" << std::hex << wt.released << std::dec << dendl;
dout(10) << __func__ << " ignoring free extent between SUPER_RESERVED"           << " and min_alloc_size, 0x" << std::hex << offset << "~"           << length << std::dec << dendl;
dout(2) << __func__ << " " << num_objects << " objects, "   << num_sharded_objects << " of them sharded.  "   << dendl;
dout(2) << __func__ << " " << num_extents << " extents to "   << num_blobs << " blobs, "   << num_spanning_blobs << " spanning, "   << num_shared_blobs << " shared."   << dendl;
dout(1) << __func__ << " <<<FINISH>>> with " << errors << " errors, "   << warnings << " warnings, "   << repaired << " repaired, "   << (errors + warnings - (int)repaired) << " remaining in "   << duration << " seconds" << dendl;
dout(20) << __func__ << " release 0x" << std::hex << p->offset            << "~" << p->length << std::dec << dendl;
dout(1) << __func__ << " "          << cid << " " << oid          <<dendl;
dout(10) << __func__ << " bdev " << devname << " can't detect numa_node"        << dendl;
dout(10) << __func__ << " bdev " << devname << " on numa_node " << n      << dendl;
dout(10) << __func__ << " " << c << " " << c->cid << " " << o->oid       << " flush_txns " << o->flushing_count << dendl;
dout(15) << __func__ << " " << cid << " " << oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << dendl;
dout(10) << __func__ << " " << cid << " " << oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << " = " << r << dendl;
dout(30) << __func__ << "  hole 0x" << std::hex << pos << "~" << hole               << std::dec << dendl;
dout(20) << __func__ << "  blob " << *bptr << std::hex             << " need 0x" << b_off << "~" << b_len             << " cache has 0x" << cache_interval             << std::dec << dendl;
dout(30) << __func__ << "    use cache 0x" << std::hex << pos << ": 0x"                 << b_off << "~" << l << std::dec << dendl;
dout(30) << __func__ << "    will read 0x" << std::hex << pos << ": 0x"                 << b_off << "~" << l << std::dec << dendl;
dout(20) << __func__ << "  blob " << *bptr << " need "             << r2r << dendl;
dout(20) << __func__ << "    region 0x" << std::hex                 << req.regs.front().logical_offset                 << ": 0x" << req.regs.front().blob_xoffset                 << " reading 0x" << req.r_off                 << "~" << req.r_len << std::dec                 << dendl;
dout(20) << __func__ << "  blob " << *bptr << " need "             << r2r << dendl;
dout(30) << __func__ << " assemble 0x" << std::hex << pos               << ": data from 0x" << pr->first << "~" << pr->second.length()               << std::dec << dendl;
dout(30) << __func__ << " assemble 0x" << std::hex << pos               << ": zeros for 0x" << (pos + offset) << "~" << l               << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length           << " size 0x" << o->onode.size << " (" << std::dec           << o->onode.size << ")" << dendl;
dout(5) << __func__ << " read at 0x" << std::hex << offset << "~" << length            << " failed " << std::dec << retry_count << " times before succeeding" << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length      << " size 0x" << o->onode.size << std::dec << dendl;
dout(30) << __func__ << " lextent 0x" << std::hex << offset << "~"          << x_len << std::dec << " blob " << ep->blob << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length    << " size = 0x(" << destset << ")" << std::dec << dendl;
dout(15) << __func__ << " " << cid << " " << oid           << " fiemap " << m           << dendl;
dout(10) << __func__ << " " << cid << " " << oid           << " fiemap " << m << std::dec           << " = " << r << dendl;
dout(20) << __func__ << " fiemap " << m << std::hex           << " size 0x" << o->onode.size << " (" << std::dec           << o->onode.size << ")" << dendl;
dout(5) << __func__ << " read fiemap " << m            << " failed " << retry_count << " times before succeeding"            << dendl;
dout(10) << __func__ << " " << c->cid << " " << oid    << " = " << r << dendl;
dout(10) << __func__ << " " << c->cid << " " << oid << " " << name    << " = " << r << dendl;
dout(10) << __func__ << " " << c->cid << " " << oid    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid           << " start " << start << " end " << end << " max " << max << dendl;
dout(10) << __func__ << " " << c->cid    << " start " << start << " end " << end << " max " << max    << " = " << r << ", ls.size() = " << ls->size()    << ", next = " << (pnext ? *pnext : ghobject_t())  << dendl;
dout(15) << __func__ << " " << c->cid           << " start " << start << " end " << end << " max " << max << dendl;
dout(10) << __func__ << " " << c->cid    << " start " << start << " end " << end << " max " << max    << " = " << r << ", ls.size() = " << ls->size()    << ", next = " << (pnext ? *pnext : ghobject_t())  << dendl;
dout(20) << __func__    << " range " << coll_range_temp_start    << " to " << coll_range_temp_end    << " and " << coll_range_start    << " to " << coll_range_end    << " start " << start << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r    << dendl;
dout(20) << __func__ << "  got " << pretty_binary_string(it->key())          << " -> " << user_key << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r    << dendl;
dout(20) << __func__ << "  got " << pretty_binary_string(it->key())        << " -> " << user_key << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r    << dendl;
dout(30) << __func__ << "  got " << pretty_binary_string(final_key)   << " -> " << *p << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r    << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r          << dendl;
dout(30) << __func__ << "  have " << pretty_binary_string(final_key)   << " -> " << *p << dendl;
dout(30) << __func__ << "  miss " << pretty_binary_string(final_key)   << " -> " << *p << dendl;
dout(10) << __func__ << " " << c->get_cid() << " oid " << oid << " = " << r    << dendl;
dout(10) << __func__ << " ondisk_format " << ondisk_format    << " min_compat_ondisk_format " << min_compat_ondisk_format    << dendl;
dout(1) << __func__ << " ondisk_format " << ondisk_format      << " compat_ondisk_format " << compat_ondisk_format      << dendl;
dout(1) << __func__ << " min_alloc_size 0x" << std::hex << min_alloc_size      << std::dec << dendl;
dout(1) << __func__ << " from " << ondisk_format << ", latest "   << latest_ondisk_format << dendl;
dout(20) << __func__ << " osr " << osr << " = " << txc    << " seq " << txc->seq << dendl;
dout(10) << __func__ << " " << txc << " cost " << txc->cost << " ("    << ios << " ios * " << cost << " + " << txc->bytes    << " bytes)" << dendl;
dout(10) << __func__ << " txc " << txc      << " " << txc->get_state_name() << dendl;
dout(0) << __func__ << " slow aio_wait, txc = " << txc    << ", latency = " << lat    << dendl;
dout(20) << __func__     << " last_{nid,blobid} exceeds max, submit via kv thread"     << dendl;
dout(20) << __func__ << " prior txc submitted via kv thread, us too"     << dendl;
dout(20) << __func__ << " prior txc(s) with unstable ios "     << txc->osr->txc_with_unstable_io.load() << dendl;
dout(20) << __func__ << " DEBUG randomly forcing submit via kv thread"     << dendl;
dout(20) << __func__ << " " << txc << " blocked by " << &*p << " "        << p->get_state_name() << dendl;
dout(20) << __func__ << " txc " << txc    << " onodes " << txc->onodes    << " shared_blobs " << txc->shared_blobs    << dendl;
dout(20) << __func__ << " shared_blob 0x"               << std::hex << sbid << std::dec        << " is empty" << dendl;
dout(20) << __func__ << " shared_blob 0x"               << std::hex << sbid << std::dec        << " is " << bl.length() << " " << *sb << dendl;
dout(1) << __func__ << " The drive is HM-SMR but "     << cct->_conf->bluestore_allocator << " allocator is specified. "     << "Only zoned allocator can be used with HM-SMR drive." << dendl;
dout(1) << __func__ << " The drive is HM-SMR but min_alloc_size is "     << min_alloc_size << ". "     << "Please set to at least 64 KiB." << dendl;
dout(1) << __func__ << " The drive is HM-SMR but prefer_deferred_size is "     << prefer_deferred_size << ". "     << "Please set to 0." << dendl;
dout(20) << __func__ << " txc " << txc << std::hex    << " allocated 0x" << txc->allocated    << " released 0x" << txc->released    << std::dec << dendl;
dout(20) << __func__ << "  overlap 0x" << std::hex << overlap        << ", new allocated 0x" << tmp_allocated        << " released 0x" << tmp_released << std::dec        << dendl;
dout(20) << __func__ << " release 0x" << std::hex << p.get_start()      << "~" << p.get_len() << std::dec << dendl;
dout(20) << __func__ << " onode " << o << " had " << o->flushing_count        << dendl;
dout(20) << __func__ << "  txc " << txc << " " << txc->get_state_name()        << dendl;
dout(10) << __func__ << " empty zombie osr " << osr << " already reaped"        << dendl;
dout(10) << __func__ << "(queued) " << txc << " " << std::hex   << txc->released << std::dec << dendl;
dout(10) << __func__ << "(sync) " << txc << " " << std::hex             << txc->released << std::dec << dendl;
ldout(cct, 10) << __func__ << " " << c->cid     << " reusing osr " << c->osr << " from existing coll "     << q->second << dendl;
ldout(cct, 10) << __func__ << " " << c->cid       << " fresh osr " << c->osr << dendl;
ldout(cct, 10) << __func__ << " " << c->cid       << " resurrecting zombie osr " << c->osr << dendl;
dout(10) << __func__ << " empty zombie osr " << osr   << " already reaped" << dendl;
dout(10) << __func__ << " empty zombie osr " << osr   << " resurrected" << dendl;
dout(5) << __func__ << " utilization: idle "       << twait << " of " << elapsed       << ", submitted: " << kv_submitted       <<dendl;
dout(20) << __func__ << " committing " << kv_queue.size()        << " submitting " << kv_queue_unsubmitted.size()        << " deferred done " << deferred_done_queue.size()        << " stable " << deferred_stable_queue.size()        << dendl;
dout(20) << __func__ << " num_aios=" << aios   << " force_flush=" << (int)force_flush   << ", flushing, deferred done->stable" << dendl;
dout(20) << __func__ << " committed " << committing_size   << " cleaned " << deferred_size   << " in " << dur   << " (" << dur_flush << " flush + " << dur_kv << " kv commit)"   << dendl;
dout(20) << __func__ << " " << deferred_queue.size() << " osrs, "    << deferred_queue_size << " txcs" << dendl;
dout(20) << __func__ << "  osr " << osr << " already has running"   << dendl;
dout(10) << __func__ << " osr " << osr    << " " << osr->deferred_pending->iomap.size() << " ios pending "    << dendl;
dout(20) << __func__ << " write 0x" << std::hex   << start << "~" << bl.length()   << " crc " << bl.crc32c(-1) << std::dec << dendl;
dout(20) << __func__ << "   seq " << i->second.seq << " 0x"      << std::hex << pos << "~" << i->second.bl.length() << std::dec      << dendl;
dout(20) << __func__ << " replay " << pretty_binary_string(it->key())      << dendl;
dout(10) << __func__ << " failed get throttle_deferred_bytes, aggressive"      << dendl;
dout(10) << __func__ << " collection hint objects is a no-op, "     << " pg_num " << pg_num << " num_objects " << num_objs     << dendl;
dout(10) << __func__ << " op " << op->op << " got ENOENT on "        << i.get_oid(op->oid) << dendl;
dout(30) << __func__ << " 0x" << std::hex << *offset << "~" << length    << " chunk_size 0x" << chunk_size << std::dec << dendl;
dout(20) << __func__ << " pad 0x" << std::hex << front_pad << " + 0x"    << back_pad << " on front/back, now 0x" << *offset << "~"    << length << std::dec << dendl;
dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(20) << __func__ << " considering " << *b        << " bstart 0x" << std::hex << bstart << std::dec << dendl;
dout(20) << __func__ << "  write to unused 0x" << std::hex     << b_off << "~" << b_len     << " pad 0x" << head_pad << " + 0x" << tail_pad     << std::dec << " of mutable " << *b << dendl;
dout(20) << __func__ << " deferring small 0x" << std::hex         << b_len << std::dec << " unused write via deferred" << dendl;
dout(20) << __func__ << "  reading head 0x" << std::hex << head_read     << " and tail 0x" << tail_read << std::dec << dendl;
dout(20) << __func__ << "  deferred write 0x" << std::hex << b_off << "~"       << b_len << std::dec << " of mutable " << *b       << " at " << op->extents << dendl;
dout(20) << __func__ << " reuse blob " << *b << std::hex       << " (0x" << b_off0 << "~" << bl.length() << ")"       << " (0x" << b_off << "~" << length << ")"       << std::dec << dendl;
dout(20) << __func__ << " considering " << *b        << " bstart 0x" << std::hex << bstart << std::dec << dendl;
dout(20) << __func__ << " reuse blob " << *b << std::hex      << " (0x" << b_off0 << "~" << bl.length() << ")"      << " (0x" << b_off << "~" << length << ")"      << std::dec << dendl;
dout(10) << __func__ << " request GC, blobs >= " << inspected_blobs.size()            << " " << std::hex << min_off << "~" << max_off << std::dec     << dendl;
dout(20) << __func__ << " inserting for GC "              << std::hex << ep->logical_offset << "~" << ep->length       << std::dec << dendl;
dout(20) << __func__ << " inserting (last) for GC "              << std::hex << offset << "~" << length       << std::dec << dendl;
dout(20) << __func__ << "  reading head 0x" << std::hex << dctx.head_read    << " and tail 0x" << dctx.tail_read << std::dec << dendl;
dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length    << " target_blob_size 0x" << wctx->target_blob_size << std::dec    << " compress " << (int)wctx->compress    << dendl;
dout(20) << __func__ << " " << *(head_info.blob_ref)            << " deferring big " << std::hex            << " (0x" << head_info.b_off << "~" << head_info.blob_aligned_len() << ")"            << std::dec << " write via deferred"            << dendl;
dout(20) << __func__ << " " << *(tail_info.blob_ref)              << " deferring big " << std::hex              << " (0x" << tail_info.b_off << "~" << tail_info.blob_aligned_len() << ")"              << std::dec << " write via deferred"              << dendl;
dout(20) << __func__              << " deferring big fell back, head isn't continuous"              << dendl;
dout(20) << __func__                << " deferring big fell back, tail isn't continuous"                << dendl;
dout(20) << __func__ << " considering " << *(ep->blob)            << " bstart 0x" << std::hex << ep->blob_start() << std::dec << dendl;
dout(20) << __func__ << " reuse blob " << *b << std::hex       << " (0x" << b_off << "~" << l << ")" << std::dec << dendl;
dout(20) << __func__ << " considering reverse " << *(prev_ep->blob)            << " bstart 0x" << std::hex << prev_ep->blob_start() << std::dec << dendl;
dout(20) << __func__ << " reuse blob " << *b << std::hex       << " (0x" << b_off << "~" << l << ")" << std::dec << dendl;
dout(20) << __func__ << " txc " << txc    << " " << wctx->writes.size() << " blobs"    << dendl;
dout(20) << __func__ << std::hex << "  compressed 0x" << wi.blob_length     << " -> 0x" << compressed_len << " => 0x" << result_len     << " with " << c->get_type()     << std::dec << dendl;
dout(5) << __func__ << std::hex << "  0x" << wi.blob_length   << " bytes compressed using " << c->get_type_name()   << std::dec   << " failed with errcode = " << r   << ", leaving uncompressed"   << dendl;
dout(20) << __func__ << std::hex << "  0x" << wi.blob_length   << " compressed to 0x" << compressed_len << " -> 0x" << result_len   << " with " << c->get_type()   << ", which is more than required 0x" << want_len_raw   << " -> 0x" << want_len   << ", leaving uncompressed"   << std::dec << dendl;
dout(20) << __func__ << " initialize csum setting for compressed blob " << *b                 << " csum_type " << Checksummer::get_csum_type_string(csum)                 << " csum_order " << csum_order                 << " csum_length 0x" << std::hex << csum_length                 << " blob_length 0x" << wi.blob_length                 << " compressed_length 0x" << wi.compressed_len << std::dec                 << dendl;
dout(20) << __func__ << " forcing csum_order to block_size_order "                << block_size_order << dendl;
dout(20) << __func__ << " forcing blob_offset to 0x"                 << std::hex << suggested_boff << std::dec << dendl;
dout(20) << __func__ << " initialize csum setting for new blob " << *b                 << " csum_type " << Checksummer::get_csum_type_string(csum)                 << " csum_order " << csum_order                 << " csum_length 0x" << std::hex << csum_length << std::dec                 << dendl;
dout(20) << __func__ << " deferring 0x" << std::hex   << l->length() << std::dec << " write via deferred" << dendl;
dout(20) << __func__ << "  shared_blob release " << final   << " from " << *b->shared_blob << dendl;
dout(20) << __func__ << "  spanning_blob_map removing empty " << *b        << dendl;
dout(20) << __func__ << " prefer csum_order " << wctx->csum_order           << " target_blob_size 0x" << std::hex << wctx->target_blob_size    << " compress=" << (int)wctx->compress    << " buffered=" << (int)wctx->buffered           << std::dec << dendl;
dout(20) << __func__ << " processing " << std::hex            << offset << "~" << length << std::dec     << dendl;
dout(20) << __func__    << " " << o->oid    << " 0x" << std::hex << offset << "~" << length    << " - have 0x" << o->onode.size    << " (" << std::dec << o->onode.size << ")"    << " bytes" << std::hex    << " fadvise_flags 0x" << fadvise_flags    << " alloc_hint 0x" << o->onode.alloc_hint_flags           << " expected_object_size " << o->onode.expected_object_size           << " expected_write_size " << o->onode.expected_write_size           << std::dec    << dendl;
dout(20) << __func__ << " extending size to 0x" << std::hex << end             << std::dec << dendl;
dout(20) << __func__             << " perform garbage collection for compressed extents, "             << "expected benefit = " << benefit << " AUs" << dendl;
dout(20)<<__func__<<" gc range is " << std::hex << dirty_start     << "~" << dirty_end - dirty_start << std::dec << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << dendl;
dout(20) << __func__ << " extending size to " << offset + length      << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << "~" << length << std::dec    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << std::dec << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << std::dec    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " 0x" << std::hex << offset << std::dec    << " = " << r << dendl;
dout(20) << __func__ << "  removing shard 0x" << std::hex      << s.shard_info->offset << std::dec << dendl;
dout(10) << __func__ << " gen and maybe_unshared_blobs "    << maybe_unshared_blobs << dendl;
dout(20) << __func__ << " checking for unshareable blobs on " << h    << " " << h->oid << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " onode " << o.get()    << " txc "<< txc << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " (" << val.length() << " bytes)"    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " (" << val.length() << " bytes)"    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << aset.size() << " keys"    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << aset.size() << " keys"    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << name << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " = " << r << dendl;
dout(20) << __func__ << " remove range start: "           << pretty_binary_string(prefix) << " end: "           << pretty_binary_string(tail) << dendl;
dout(20) << __func__ << "  " << pretty_binary_string(final_key)      << " <- " << key << dendl;
dout(20) << __func__ << "  rm " << pretty_binary_string(final_key)        << " <- " << key << dendl;
dout(20) << __func__ << " remove range start: "             << pretty_binary_string(key_first) << " end: "             << pretty_binary_string(key_last) << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " object_size " << expected_object_size    << " write_size " << expected_write_size    << " flags " << ceph_osd_alloc_hint_flag_string(flags)    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " object_size " << expected_object_size    << " write_size " << expected_write_size    << " flags " << ceph_osd_alloc_hint_flag_string(flags)    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << dendl;
dout(30) << __func__ << "  got header/data "   << pretty_binary_string(it->key()) << dendl;
dout(10) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid    << " 0x" << std::hex << srcoff << "~" << length << " -> "    << " 0x" << dstoff << "~" << length << std::dec << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " from 0x" << std::hex << srcoff << "~" << length    << " to offset 0x" << dstoff << std::dec << dendl;
dout(10) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " from 0x" << std::hex << srcoff << "~" << length    << " to offset 0x" << dstoff << std::dec    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << new_oid << dendl;
dout(10) << __func__ << " " << c->cid << " " << old_oid << " -> "    << new_oid << " = " << r << dendl;
dout(1) << __func__ << " " << o->oid << " " << o         << " exists in onode_map" << dendl;
dout(1) << __func__ << " " << *it   << " exists in db, "   << (!onode ? "not present in ram" : "present in ram")   << dendl;
dout(10) << __func__ << " " << cid                 << " is non-empty" << dendl;
dout(15) << __func__ << " " << c->cid << " to " << d->cid << " "    << " bits " << bits << dendl;
dout(10) << __func__ << " " << c->cid << " to " << d->cid << " "    << " bits " << bits << " = " << r << dendl;
dout(15) << __func__ << " " << (*c)->cid << " to " << d->cid    << " bits " << bits << dendl;
dout(10) << __func__ << " " << cid << " to " << d->cid << " "    << " bits " << bits << " = " << r << dendl;
dout(0) << __func__ << " slow operation observed for " << name      << ", latency = " << l      << info      << dendl;
dout(0) << __func__ << " slow operation observed for " << name      << ", latency = " << l      << fn(l)      << dendl;
dout(20) << __func__ << "  can pad head 0x" << std::hex << head_pad       << " tail 0x" << tail_pad << std::dec << dendl;
dout(20) << __func__ << " warning: still wants reshard, check options?"  << dendl;
dout(20) << __func__  << " onode " << o->oid << " is " << bl.length()     << " (" << onode_part << " bytes onode + "     << blob_part << " bytes spanning blobs + "     << extent_part << " bytes inline extents)"     << dendl;
dout(0) << " allocation stats probe "    << probe_count << ":"    << " cnt: " << std::get<0>(t0)    << " frags: " << std::get<1>(t0)    << " size: " << std::get<2>(t0)    << dendl;
dout(0) << " probe -"      << base + (probe_count % base) << ": "      << std::get<0>(t)      << ",  " << std::get<1>(t)      << ", " << std::get<2>(t)      << dendl;
ldout(cct, 30) << __func__ << " len 0x" << std::hex << orig_len   << std::dec << " -> " << bin << dendl;
ldout(cct, 30) << __func__ << " 0x" << std::hex << off << "~" << len   << std::dec << " in bin " << bin << dendl;
ldout(cct, 30) << __func__ << " promoting 0x" << std::hex << off << "~" << len     << std::dec << " to bin " << newbin << dendl;
ldout(cct, 10) << __func__ << " want_size 0x" << std::hex << want_size      << " alloc_unit 0x" << alloc_unit      << " hint 0x" << hint << std::dec      << dendl;
ldout(cct, 10) << __func__ << " shortening allocation of 0x" << std::hex              << *length << " -> 0x"              << max << " due to debug_small_allocations" << std::dec       << dendl;
ldout(cct, 30) << __func__ << " got 0x" << std::hex << *offset << "~" << *length      << " from bin " << std::dec << bin << dendl;
ldout(cct, 30) << __func__ << " demoting 0x" << std::hex << off << "~" << len              << std::dec << " to bin " << newbin << dendl;
ldout(cct, 30) << __func__ << " demoting 0x" << std::hex << off << "~" << len              << std::dec << " to bin " << newbin << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << length     << std::dec << dendl;
ldout(cct, 30) << __func__ << " " << intervals << "/" << max_intervals                  << dendl;
ldout(cct, 0) << __func__ << " free bin " << bin << ": "        << free[bin].num_intervals() << " extents" << dendl;
ldout(cct, 0) << __func__ << "  0x" << std::hex << p.get_start() << "~"            << p.get_len() << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << length   << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << length      << std::dec << dendl;
ldout(cct, 20) << __func__ << " bin " << i << " rm 0x" << std::hex << overlap       << std::dec << dendl;
ldout(cct, 30) << __func__ << " demoting1 0x" << std::hex << off << "~" << len                             << std::dec << " to bin " << newbin << dendl;
ldout(cct, 10) << __func__ << std::hex                 << " want 0x" << want                 << " unit 0x" << unit                 << " max_alloc_size 0x" << max_alloc_size                 << " hint 0x" << hint                 << std::dec << dendl;
ldout(cct, 0) << __func__    << " avl_free: " << _get_free()    << " bmap_free: " << (bmap_alloc ? bmap_alloc->get_free() : 0)    << dendl;
ldout(cct, 10) << __func__ << std::hex                 << " offset 0x" << offset                 << " length 0x" << length                 << std::dec << dendl;
dout(20) << __func__    << std::hex << " "    << start << "~" << size    << std::dec    << dendl;
dout(1) << __func__      << std::hex      << " constructing fallback allocator"      << dendl;
dout(1) << __func__ << std::hex   << " size 0x" << size   << " bytes_per_block 0x" << bytes_per_block   << " zone size 0x " << zone_size   << " num_zones 0x" << num_zones   << " starting_zone 0x" << starting_zone_num << dendl;
dout(10) << __func__ << std::hex    << " size 0x" << size    << " bytes_per_block 0x" << bytes_per_block    << " zone size 0x" << zone_size    << " num_zones 0x" << num_zones    << " starting_zone 0x" << starting_zone_num    << std::dec << dendl;
dout(30) << __func__ << std::hex << " 0x" << *offset << "~" << *length    << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length      << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << capacity << "/"   << alloc_unit << std::dec << dendl;
ldout(cct, 10) << __func__ << std::hex << " 0x" << want_size   << "/" << alloc_unit << "," << max_alloc_size << "," << hint   << std::dec << dendl;
ldout(cct, 10) << __func__                     << " extent: 0x" << std::hex << e.offset << "~" << e.length       << "/" << alloc_unit << "," << max_alloc_size << "," << hint       << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << len                     << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
ldout(cct, 10) << __func__ << " 0x" << std::hex << offset << "~" << length   << std::dec << dendl;
ldout(cct, 0) << __func__             << " bin " << it->first      << "(< " << byte_u_t((1 << (it->first + 1)) * get_min_alloc_size()) << ")"      << " : " << it->second << " extents"      << dendl;
dout(10) << __func__ << " bdev " << id << " path " << path << " "           << reserved << dendl;
dout(1) << __func__ << " bdev " << id << " path " << path   << " size " << byte_u_t(b->get_size()) << dendl;
dout(1) << __func__   << " osd_uuid " << osd_uuid   << dendl;
dout(1) << __func__ << " shared, id " << id << std::hex              << ", capacity 0x" << bdev[id]->get_size()              << ", block size 0x" << alloc_size[id]              << std::dec << dendl;
dout(1) << __func__ << " new, id " << id << std::hex              << ", allocator name " << name              << ", allocator type " << cct->_conf->bluefs_allocator              << ", capacity 0x" << bdev[id]->get_size()              << ", block size 0x" << alloc_size[id]              << std::dec << dendl;
dout(10) << __func__ << " dev " << int(ndev)           << ": 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " buffered" : "")    << dendl;
dout(10) << __func__ << " dev " << int(ndev)           << ": 0x" << std::hex << off << "~" << len << std::dec    << (buffered ? " buffered" : "")    << dendl;
dout(1) << __func__ << " shared_bdev_used = "            << shared_alloc->bluefs_used << dendl;
dout(1) << __func__ << " shared bdev not used"            << dendl;
dout(10) << __func__ << " log write pos set to 0x"           << std::hex << log_writer->pos << std::dec           << dendl;
dout(10) << __func__ << " no memorized_layout in bluefs superblock"             << dendl;
dout(20) << __func__ << " v " << super.version           << " crc 0x" << std::hex << crc           << " offset 0x" << get_super_offset() << std::dec           << dendl;
dout(10) << __func__ << " 0x" << std::hex << pos << std::dec   << ": stop: uuid " << uuid << " != super.uuid " << super.uuid   << dendl;
dout(10) << __func__ << " 0x" << std::hex << pos << std::dec   << ": stop: seq " << seq << " != expected " << log_seq + 1   << dendl;
;
dout(20) << __func__ << " need 0x" << std::hex << more << std::dec               << " more bytes" << dendl;
dout(10) << __func__ << " 0x" << std::hex << pos                 << ": stop: len is 0x" << bl.length() + more << std::dec                 << ", which is past eof" << dendl;
dout(10) << __func__ << " 0x" << std::hex << pos << std::dec             << ": " << t << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                 << ":  op_init" << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec     << ":  op_jump seq " << next_seq     << " offset 0x" << std::hex << offset << std::dec << dendl;
dout(10) << __func__ << " 0x" << std::hex << read_pos         << ": stop: failed to skip to " << offset         << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_jump_seq " << next_seq << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_dir_link " << " " << dirname << "/" << filename                   << " to " << ino     << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_dir_unlink " << " " << dirname << "/" << filename                   << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_dir_create " << dirname << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_dir_remove " << dirname << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_file_update " << " " << fnode << " " << dendl;
dout(20) << __func__ << " 0x" << std::hex << pos << std::dec                   << ":  op_file_remove " << ino << dendl;
dout(10) << __func__ << " log file size was 0x"           << std::hex << log_file->fnode.size << std::dec << dendl;
dout(10) << __func__ << " devs_source " << devs_source    << " dev_target " << dev_target << dendl;
dout(20) << __func__ << "  " << " ... adjusting extent 0x"     << std::hex << ext.offset << std::dec     << " bdev " << dev_target << " -> " << dev_target_new     << dendl;
dout(0) << __func__ << " log moved from " << new_log_dev_cur      << " to " << new_log_dev_next << dendl;
dout(10) << __func__ << " devs_source " << devs_source    << " dev_target " << dev_target << dendl;
dout(30) << __func__ << " ino " << ino << " = " << f      << " (new)" << dendl;
dout(20) << __func__ << " had refs " << file->refs    << " on " << file->fnode << dendl;
dout(10) << __func__ << " h " << h           << " 0x" << std::hex << off << "~" << len << std::dec    << " from " << h->file->fnode << dendl;
dout(20) << __func__ << " reaching (or past) eof, len clipped to 0x"      << std::hex << len << std::dec << dendl;
dout(20) << __func__ << " read random 0x"        << std::hex << x_off << "~" << l << std::dec        << " of " << *p << dendl;
dout(20) << __func__ << " left 0x" << std::hex << left       << " 0x" << off << "~" << len << std::dec       << dendl;
dout(30) << __func__ << " result chunk (0x"        << std::hex << r << std::dec << " bytes):\n";
dout(10) << __func__ << " h " << h           << " 0x" << std::hex << off << "~" << len << std::dec    << " from " << h->file->fnode    << (prefetch ? " prefetch" : "")    << dendl;
dout(20) << __func__ << " reaching (or past) eof, len clipped to 0x"      << std::hex << len << std::dec << dendl;
dout(5) << __func__ << " reading less then required "    << ret << "<" << ret + len << dendl;
dout(20) << __func__ << " fetching 0x"                 << std::hex << x_off << "~" << l << std::dec                 << " of " << *p << dendl;
dout(20) << __func__ << " left 0x" << std::hex << left             << " len 0x" << len << std::dec << dendl;
dout(30) << __func__ << " result chunk (0x"             << std::hex << r << std::dec << " bytes):\n";
dout(10) << __func__ << " file " << f->fnode    << " 0x" << std::hex << offset << "~" << length << std::dec           << dendl;
dout(20) << __func__  << " 0x" << std::hex << x_off << "~" << x_len             << std:: dec << " of " << *p << dendl;
dout(10) << __func__ << " current 0x" << std::hex << current    << " expected " << expected << std::dec    << " ratio " << ratio    << (new_log ? " (async compaction in progress)" : "")    << dendl;
dout(20) << __func__ << " op_dir_link " << path << "/" << fname        << " to " << file_ref->fnode.ino << dendl;
dout(20) << __func__ << " super_dev:" << super_dev                       << " log_dev:" << log_dev                       << " log_dev_new:" << log_dev_new         << " flags:" << flags         << dendl;
dout(10) << __func__ << " old_log_jump_to 0x" << std::hex << old_log_jump_to           << " need 0x" << (old_log_jump_to + cct->_conf->bluefs_max_log_runway) << std::dec << dendl;
dout(10) << __func__ << " new_log_jump_to 0x" << std::hex << new_log_jump_to    << std::dec << dendl;
dout(10) << __func__ << " remove 0x" << std::hex << old_log_jump_to << std::dec    << " of " << log_file->fnode.extents << dendl;
dout(10) << __func__ << " padding with 0x" << std::hex      << super.block_size - partial << " zeros" << std::dec << dendl;
dout(10) << __func__ << " want_seq " << want_seq      << " log is currently flushing, waiting" << dendl;
dout(10) << __func__ << " want_seq " << want_seq << " <= log_seq_stable "      << log_seq_stable << ", done" << dendl;
dout(10) << __func__ << " want_seq " << want_seq      << " " << log_t << " not dirty, dirty_files empty, no-op" << dendl;
dout(10) << __func__ << " allocating more log runway (0x"      << std::hex << runway << std::dec  << " remaining)" << dendl;
dout(10) << __func__ << " jumping log offset from 0x" << std::hex      << log_writer->pos << " -> 0x" << jump_to << std::dec << dendl;
dout(20) << __func__ << " log_seq_stable " << log_seq_stable             << " already >= out seq " << seq             << ", we lost a race against another log flush, done" << dendl;
dout(20) << " leaving 0x" << std::hex << buffer.length() << std::dec             << " unflushed" << dendl;
dout(20) << __func__ << " caching tail of 0x"             << std::hex << tail             << " and padding block with 0x" << padding_len             << " buffer.length() " << buffer.length()             << std::dec << dendl;
dout(10) << __func__ << " " << h << " pos 0x" << std::hex << h->pos    << " 0x" << offset << "~" << length << std::dec    << " to " << h->file->fnode << dendl;
dout(10) << " still need 0x"             << std::hex << offset << "~" << length << std::dec             << dendl;
dout(20) << __func__ << " dirty_seq = " << log_seq + 1        << " (was clean)" << dendl;
dout(20) << __func__ << " dirty_seq = " << log_seq + 1                 << " (was " << h->file->dirty_seq << ")" << dendl;
dout(20) << __func__ << " dirty_seq = " << log_seq + 1                 << " (unchanged, do nothing) " << dendl;
dout(20) << __func__ << " in " << *p << " x_off 0x"           << std::hex << x_off << std::dec << dendl;
dout(20) << __func__ << " using partial tail 0x"             << std::hex << partial << std::dec << dendl;
dout(20) << __func__ << " h " << h << " pos now 0x"           << std::hex << h->pos << std::dec << dendl;
dout(10) << __func__ << " " << h << " ignoring, length " << length      << " < min_flush_size " << cct->_conf->bluefs_min_flush_size      << dendl;
dout(10) << __func__ << " " << h << " no dirty data on "      << h->file->fnode << dendl;
dout(10) << __func__ << " " << h << " 0x"           << std::hex << offset << "~" << length << std::dec    << " to " << h->file->fnode << dendl;
dout(10) << __func__ << " 0x" << std::hex << offset << std::dec           << " file " << h->file->fnode << dendl;
dout(20) << __func__ << " tossing out last " << offset - h->pos      << " unflushed bytes" << dendl;
dout(20) << __func__ << " file metadata was dirty (" << old_dirty_seq      << ") on " << h->file->fnode << ", flushing log" << dendl;
dout(10) << __func__ << " len 0x" << std::hex << len << std::dec           << " from " << (int)id << dendl;
dout(10) << __func__ << " len 0x" << std::hex << len << std::dec           << " from " << (int)id << dendl;
dout(1) << __func__ << " unable to allocate 0x" << std::hex << need       << " on bdev " << (int)id              << ", allocator name " << alloc[id]->get_name()              << ", allocator type " << alloc[id]->get_type()              << ", capacity 0x" << alloc[id]->get_capacity()              << ", block size 0x" << alloc[id]->get_block_size()              << ", free 0x" << alloc[id]->get_free()              << ", fragmentation " << alloc[id]->get_fragmentation()              << ", allocated 0x" << (alloc_len > 0 ? alloc_len : 0)       << std::dec << dendl;
dout(20) << __func__ << " fallback to bdev "               << (int)id + 1        << dendl;
dout(10) << __func__ << " file " << f->fnode << " 0x"    << std::hex << off << "~" << len << std::dec << dendl;
dout(20) << __func__ << "  dir " << dirname      << " does not exist" << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir        << ") file " << filename        << " does not exist" << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir        << ") file " << filename        << " already exists, overwrite in place" << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir        << ") file " << filename        << " already exists, truncate + overwrite" << dendl;
dout(20) << __func__ << " mapping " << dirname << "/" << filename    << " vsel_hint " << file->vselector_hint    << dendl;
dout(10) << __func__ << " " << dirname << "/" << filename    << (random ? " (random)":" (sequential)") << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir      << ") file " << filename      << " not found" << dendl;
dout(10) << __func__ << " " << old_dirname << "/" << old_filename    << " -> " << new_dirname << "/" << new_filename << dendl;
dout(20) << __func__ << " dir " << old_dirname << " (" << old_dir      << ") file " << old_filename      << " not found" << dendl;
dout(20) << __func__ << " dir " << new_dirname << " (" << old_dir      << ") file " << new_filename      << " already exists, unlinking" << dendl;
dout(10) << __func__ << " " << new_dirname << "/" << new_filename << " "    << " " << file->fnode << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir      << ") file " << filename      << " not found" << dendl;
dout(10) << __func__ << " " << dirname << "/" << filename    << " " << file->fnode << dendl;
dout(20) << __func__ << " dir " << dirname << " (" << dir      << ") file " << filename      << " not found, creating" << dendl;
dout(10) << __func__ << " locked " << file->fnode    << " with " << *plock << dendl;
dout(20) << __func__ << " file " << dirname << "/" << filename      << " not found" << dendl;
dout(20) << __func__ << " file " << dirname << "/" << filename             << " is locked" << dendl;
dout(1) << __func__ << " replay_pos=0x" << std::hex << replay_pos <<    " needs 0x" << read_offset << "~" << read_len << std::dec << dendl;
dout(5) << __func__ << " read "  << get_device_name(dev) << ":0x" << std::hex << pos << "+" << chunk_len << std::dec << dendl;
dout(10) << __func__ << " rounding blocks up from 0x" << std::hex << size      << " to 0x" << (blocks * bytes_per_block)      << " (0x" << blocks << " blocks)" << std::dec << dendl;
dout(1) << __func__    << " size 0x" << std::hex << size    << " bytes_per_block 0x" << bytes_per_block    << " blocks 0x" << blocks    << " blocks_per_key 0x" << blocks_per_key    << std::dec << dendl;
dout(10) << __func__ << " rounding1 blocks up from 0x" << std::hex             << old_size << " to 0x" << (blocks0 * bytes_per_block)      << " (0x" << blocks0 << " blocks)" << std::dec << dendl;
dout(10) << __func__ << " rounding2 blocks up from 0x" << std::hex             << size << " to 0x" << (blocks * bytes_per_block)      << " (0x" << blocks << " blocks)" << std::dec << dendl;
dout(10) << __func__    << " size 0x" << std::hex << size    << " bytes_per_block 0x" << bytes_per_block    << " blocks 0x" << blocks    << " blocks_per_key 0x" << blocks_per_key    << std::dec << dendl;
dout(10) << __func__ << " bytes_per_block 0x" << std::hex        << bytes_per_block << std::dec << dendl;
dout(10) << __func__ << " blocks 0x" << std::hex << blocks << std::dec        << dendl;
dout(10) << __func__ << " size 0x" << std::hex << size << std::dec        << dendl;
dout(10) << __func__ << " blocks_per_key 0x" << std::hex << blocks_per_key        << std::dec << dendl;
dout(10) << __func__ << std::hex    << " size 0x" << size    << " bytes_per_block 0x" << bytes_per_block    << " blocks 0x" << blocks    << " blocks_per_key 0x" << blocks_per_key    << std::dec << dendl;
dout(10) << __func__ << std::hex << " bytes_per_key 0x" << bytes_per_key    << ", key_mask 0x" << key_mask << std::dec    << dendl;
dout(1) << __func__ << " committing new size 0x" << std::hex << size      << std::dec << dendl;
dout(30) << __func__ << " found clear bit, key 0x" << std::hex        << enumerate_offset << " bit 0x" << enumerate_bl_pos        << " offset 0x" << *offset        << std::dec << dendl;
dout(30) << " no more clear bits in 0x" << std::hex << enumerate_offset      << std::dec << dendl;
dout(30) << " no key at 0x" << std::hex << next << ", got 0x"        << enumerate_offset << std::dec << dendl;
dout(30) << __func__ << " found set bit, key 0x" << std::hex   << enumerate_offset << " bit 0x" << enumerate_bl_pos   << " offset 0x" << end << std::dec   << dendl;
dout(10) << __func__ << std::hex << " 0x" << *offset << "~" << *length   << std::dec << dendl;
dout(30) << " no more set bits in 0x" << std::hex << enumerate_offset        << std::dec << dendl;
dout(10) << __func__ << std::hex << " 0x" << *offset << "~" << *length      << std::dec << dendl;
dout(20) << __func__ << " 0x" << std::hex << offset << "~" << length      << std::dec << dendl;
dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(10) << __func__ << " 0x" << std::hex << offset << "~" << length    << std::dec << dendl;
dout(20) << __func__ << " first_key 0x" << std::hex << first_key    << " last_key 0x" << last_key << std::dec << dendl;
dout(30) << __func__ << " 0x" << std::hex << first_key << std::dec        << ": ";
ldout(cct, 10) << __func__ << " size 0x" << std::hex << size   << " zone size 0x" << zone_size << std::dec   << " number of zones " << num_zones   << " first sequential zone " << starting_zone_num   << dendl;
ldout(cct, 10) << __func__ << " trying to allocate "   << std::hex << want_size << dendl;
ldout(cct, 10) << __func__ << " skipping zone " << zone_num     << " because there is not enough space: "     << " want_size = " << want_size     << " available = " << get_remaining_space(zone_num)     << dendl;
ldout(cct, 10) << __func__ << " advancing zone " << std::hex   << zone_num << " write pointer from " << offset   << " to " << offset + want_size << dendl;
ldout(cct, 10) << __func__ << std::hex << " zone " << zone_num   << " offset is now " << get_write_pointer(zone_num) << dendl;
ldout(cct, 10) << __func__ << " allocated " << std::hex << want_size   << " bytes at offset " << offset   << " located at zone " << zone_num   << " and zone offset " << offset % zone_size << dendl;
ldout(cct, 40) << __func__ << " " << std::hex   << offset << "~" << length << dendl;
ldout(cct, 40) << __func__ << " 0x" << std::hex   << offset << "~" << length << dendl;
ldout(cct, 40) << __func__ << " set zone 0x" << std::hex   << zone_num << " write pointer to 0x" << zone_size << dendl;
ldout(cct, 40) << __func__ << " set zone 0x" << std::hex     << zone_num << " write pointer to 0x" << zone_size << dendl;
ldout(cct, 10) << __func__ << std::hex      << " offset 0x" << offset      << " length 0x" << length      << std::dec << dendl;
ldout(cct, 10) << __func__ << std::hex      << " offset 0x" << e.offset      << " length 0x" << e.length      << std::dec << dendl;
ldout(cct, 10) << __func__ << std::hex                 << " want 0x" << want                 << " unit 0x" << unit                 << " max_alloc_size 0x" << max_alloc_size                 << " hint 0x" << hint                 << std::dec << dendl;
ldout(cct, 0) << std::hex      << "0x" << rs.start << "~" << rs.end      << std::dec      << dendl;
ldout(cct, 0) << std::hex      << "0x" << rs.start << "~" << rs.end      << std::dec      << dendl;
ldout(cct, 10) << __func__ << std::hex                 << " offset 0x" << offset                 << " length 0x" << length                 << std::dec << dendl;
ldout(cct, 10) << __func__ << std::hex                 << " offset 0x" << offset                 << " length 0x" << length                 << std::dec << dendl;
dout(20) << __func__ << " max " << max    << " size " << onode_map.size() << dendl;
dout(20) << __func__ << "  " << o->oid << " has " << refs        << " refs;
stopping with " << num << " left to trim" << dendl;
ldout(store->cct, 20) << __func__ << " oid " << oid << " key "   << pretty_binary_string(key) << dendl;
dout(1) << __func__ << " opened " << kv_backend   << " path " << fn << " options " << options << dendl;
dout(10) << __func__ << " " << c->cid << " " << next.second->oid     << " flush_txns " << next.second->flush_txns << dendl;
dout(15) << __func__ << " " << ch->cid << " " << oid    << " " << offset << "~" << length    << dendl;
dout(10) << __func__ << " " << ch->cid << " " << oid    << " " << offset << "~" << length    << " = " << r << dendl;
dout(20) << __func__ << " " << offset << "~" << length << " size "    << o->onode.size << " nid " << o->onode.nid << dendl;
dout(30) << __func__ << " stripe " << offset - stripe_off << " got "      << stripe.length() << dendl;
dout(20) << __func__ << " " << offset << "~" << len << " size "    << o->onode.size << dendl;
dout(20) << __func__ << " " << offset << "~" << len    << " size = 0 (" << destmap << ")" << dendl;
dout(10) << __func__ << " " << ch->cid << " " << oid << " " << name    << " = " << r << dendl;
dout(10) << __func__ << " " << ch->cid << " " << oid    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid           << " start " << start << " end " << end << " max " << max << dendl;
dout(10) << __func__ << " " << c->cid    << " start " << start << " end " << end << " max " << max    << " = " << r << ", ls.size() = " << ls->size()    << ", next = " << (pnext ? *pnext : ghobject_t())  << dendl;
dout(20) << __func__    << " range " << pretty_binary_string(temp_start_key)    << " to " << pretty_binary_string(temp_end_key)    << " and " << pretty_binary_string(start_key)    << " to " << pretty_binary_string(end_key)    << " start " << start << dendl;
dout(20) << " start from " << pretty_binary_string(k)      << " temp=" << (int)temp << dendl;
dout(20) << __func__ << " key " << pretty_binary_string(it->key())   << " > " << end << dendl;
dout(30) << __func__ << "  got " << pretty_binary_string(it->key())   << " -> " << user_key << dendl;
dout(30) << __func__ << "  got " << pretty_binary_string(it->key())        << " -> " << user_key << dendl;
dout(30) << __func__ << "  got " << pretty_binary_string(key)        << " -> " << *p << dendl;
dout(30) << __func__ << "  have " << pretty_binary_string(key)        << " -> " << *p << dendl;
dout(30) << __func__ << "  miss " << pretty_binary_string(key)        << " -> " << *p << dendl;
dout(10) << __func__ << " txc " << txc      << " " << txc->get_state_name() << dendl;
dout(20) << __func__ << " osr " << osr << " txc " << txc    << " onodes " << txc->onodes << dendl;
dout(20) << __func__ << " onode " << *p << " had " << (*p)->flush_txns      << dendl;
dout(20) << __func__ << "  txc " << txc << " " << txc->get_state_name()      << dendl;
dout(20) << __func__ << " committed " << kv_committing.size()        << " in " << dur << dendl;
dout(10) << __func__ << " collection hint objects is a no-op, "     << " pg_num " << pg_num << " num_objects " << num_objs     << dendl;
dout(10) << __func__ << " op " << op->op << " got ENOENT on "     << oid << dendl;
dout(0) << " error " << cpp_strerror(r) << " not handled on operation " << op->op  << " (op " << pos << ", counting from 0)" << dendl;
dout(30) << __func__ << " " << o    << " nid " << o->onode.nid    << " size " << o->onode.size    << " expected_object_size " << o->onode.expected_object_size    << " expected_write_size " << o->onode.expected_write_size    << dendl;
dout(30) << __func__ << "  attr " << p->first      << " len " << p->second.length() << dendl;
dout(20) << __func__    << " " << o->oid << " " << offset << "~" << length    << " - have " << o->onode.size    << " bytes, nid " << o->onode.nid << dendl;
dout(20) << __func__ << " read previous stripe " << stripe_off      << ", got " << prev.length() << dendl;
dout(20) << __func__ << " extending size to " << offset + length      << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << offset << "~" << length    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << offset << "~" << length    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << offset << "~" << length    << dendl;
dout(30) << __func__ << " stripe " << pos - stripe_off << " got "   << stripe.length() << dendl;
dout(20) << __func__ << " truncated stripe " << pos - stripe_off     << " to " << bl.length() << dendl;
dout(20) << __func__ << " extending size to " << offset + length      << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << offset << "~" << length    << " = " << r << dendl;
dout(30) << __func__ << " stripe " << pos - stripe_off << " got "   << stripe.length() << dendl;
dout(20) << __func__ << " truncated stripe " << pos - stripe_off   << " to " << t.length() << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << offset    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << offset    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " (" << val.length() << " bytes)"    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " (" << val.length() << " bytes)"    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << aset.size() << " keys"    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << aset.size() << " keys"    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " " << name << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " " << name << " = " << r << dendl;
dout(30) << __func__ << "  " << pretty_binary_string(final_key)      << " <- " << key << dendl;
dout(30) << __func__ << "  rm " << pretty_binary_string(final_key)      << " <- " << key << dendl;
dout(30) << __func__ << "  stop at " << pretty_binary_string(key_last)        << dendl;
dout(15) << __func__ << " " << c->cid << " " << o->oid    << " object_size " << expected_object_size    << " write_size " << expected_write_size    << " flags " << flags    << dendl;
dout(10) << __func__ << " " << c->cid << " " << o->oid    << " object_size " << expected_object_size    << " write_size " << expected_write_size    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << dendl;
dout(30) << __func__ << "  got header/data "   << pretty_binary_string(it->key()) << dendl;
dout(10) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " from " << srcoff << "~" << length    << " to offset " << dstoff << dendl;
dout(10) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << newo->oid << " from " << srcoff << "~" << length    << " to offset " << dstoff    << " = " << r << dendl;
dout(15) << __func__ << " " << c->cid << " " << oldo->oid << " -> "    << new_oid << dendl;
dout(10) << __func__ << " " << c->cid << " " << old_oid << " -> "    << new_oid << " = " << r << dendl;
dout(10) << __func__ << " " << *it                   << " exists in db" << dendl;
dout(10) << __func__ << " " << cid                 << " is non-empty" << dendl;
dout(15) << __func__ << " " << c->cid << " to " << d->cid << " "    << " bits " << bits << dendl;
dout(10) << __func__ << " " << c->cid << " to " << d->cid << " "    << " bits " << bits << " = " << r << dendl;
dout(15) << __func__ << " " << (*c)->cid << " to " << d->cid << " "    << " bits " << bits << dendl;
dout(10) << __func__ << " " << cid << " to " << d->cid << " "    << " bits " << bits << " = " << r << dendl;
ldout(cct,1) << "<== " << m->get_source_inst()        << " " << m->get_seq()        << " ==== " << *m        << " ==== " << m->get_payload().length()        << "+" << m->get_middle().length()        << "+" << m->get_data().length()        << " (" << ceph_con_mode_name(m->get_connection()->get_con_mode())        << " " << m->get_footer().front_crc << " "        << m->get_footer().middle_crc        << " " << m->get_footer().data_crc << ")"        << " " << m << " con " << m->get_connection()        << dendl;
ldout(cct,10) << __func__ << " " << msize << " to dispatch throttler "     << dispatch_throttler.get_current() << "/"     << dispatch_throttler.get_max() << dendl;
ldout(cct, 1) << "DispatchQueue::entry  inject delay of " << t   << dendl;
ldout(cct, 0) << "bad crc in front " << front_crc << " != exp " << footer.front_crc        << " from " << conn->get_peer_addr() << dendl;
ldout(cct, 0) << "bad crc in middle " << middle_crc << " != exp " << footer.middle_crc        << " from " << conn->get_peer_addr() << dendl;
ldout(cct, 0) << "bad crc in data " << data_crc << " != exp " << footer.data_crc   << " from " << conn->get_peer_addr() << dendl;
ldout(cct, 0) << "will not decode message of type " << type      << " version " << header.version      << " because compat_version " << header.compat_version      << " > supported version " << m->get_header().version << dendl;
ldout(cct, ceph::dout::need_dynamic( cct->_conf->ms_dump_corrupt_message_level)) << "dump: \n";
ldout(cct, 10) << __func__ << " unable to bind to " << sa.get_sockaddr()                   << ": " << cpp_strerror(r) << dendl;
ldout(cct, 20) << __func__ << " process events failed: "                         << cpp_strerror(errno) << dendl;
ldout(c, 0) << __func__ << " max thread limit is "                  << EventCenter::MAX_EVENTCENTER << ", switching to this now. "                  << "Higher thread values are unnecessary and currently unsupported."                  << dendl;
ldout(cct, 5) << __func__ << " requeueing message m=" << m                  << " seq=" << m->get_seq() << " type=" << m->get_type() << " "                  << *m << dendl;
ldout(cct, 5) << __func__ << " discarding message m=" << m                  << " seq=" << m->get_seq() << " ack_seq=" << seq << " "                  << *m << dendl;
ldout(cct, 5) << "reset_recv_state (warped) reseting crypto handlers"                    << dendl;
ldout(cct, 10) << __func__ << " releasing " << 1                   << " message to policy throttler "                   << connection->policy.throttler_messages->get_current()                   << "/" << connection->policy.throttler_messages->get_max()                   << dendl;
ldout(cct, 10) << __func__ << " releasing " << cur_msg_size                     << " bytes to policy throttler "                     << connection->policy.throttler_bytes->get_current() << "/"                     << connection->policy.throttler_bytes->get_max() << dendl;
ldout(cct, 10)        << __func__ << " releasing " << cur_msg_size        << " bytes to dispatch_queue throttler "        << connection->dispatch_queue->dispatch_throttler.get_current() << "/"        << connection->dispatch_queue->dispatch_throttler.get_max() << dendl;
ldout(cct, 2) << __func__ << " with nothing to send and in the half "                   << " accept state just closed" << dendl;
ldout(cct, 1) << __func__ << " with nothing to send, going to standby"                  << dendl;
ldout(cct, 20) << __func__ << (m->empty_payload() ? " encoding features " : " half-reencoding features ")   << features << " " << m  << " " << *m << dendl;
ldout(cct, 10) << __func__ << " clear encoded buffer previous " << f                   << " != " << connection->get_features() << dendl;
ldout(cct, 10) << __func__ << " connection closed."                   << " Drop message " << m << dendl;
ldout(cct, 5) << __func__ << " enqueueing message m=" << m                  << " type=" << m->get_type() << " " << *m << dendl;
ldout(cct, 15) << __func__ << " inline write is denied, reschedule m=" << m                   << dendl;
ldout(cct, 5) << __func__ << " sending message m=" << m                << " seq=" << m->get_seq() << " " << *m << dendl;
ldout(cct, 20) << __func__ << " sending m=" << m << " seq=" << m->get_seq()                 << " src=" << entity_name_t(messenger->get_myname())                 << " off=" << header2.data_off                 << dendl;
ldout(cct, 1) << __func__ << " error sending " << m << ", "                  << cpp_strerror(rc) << dendl;
ldout(cct, 10) << __func__ << " sending " << m                   << (rc ? " continuely." : " done.") << dendl;
ldout(cct, 25) << __func__ << " assembled frame " << bl.length()                 << " bytes " << tx_frame_asm << dendl;
ldout(cct, 10) << __func__ << " got ack seq " << seq                   << " >= " << m->get_seq() << " on " << m << " " << *m                   << dendl;
ldout(cct, 10) << __func__ << " try send msg ack, acked " << left                       << " messages" << dendl;
ldout(cct, 25) << __func__ << " assembled frame " << bl.length()                 << " bytes " << tx_frame_asm << dendl;
ldout(cct, 1) << __func__ << " " << desc << " write failed r=" << r                        << " (" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 1) << __func__ << " " << desc << " write failed r=" << r                  << " (" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 1) << __func__ << " read peer banner failed r=" << r << " ("                  << cpp_strerror(r) << ")" << dendl;
ldout(cct, 1) << __func__ << " read peer banner payload failed r=" << r                  << " (" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 1) << __func__ << " supported=" << std::hex                << peer_supported_features << " required=" << std::hex                << peer_required_features << std::dec << dendl;
ldout(cct, 1) << __func__ << " peer does not support all required features"                  << " required=" << std::hex << required_features                  << " supported=" << std::hex << peer_supported_features                  << std::dec << dendl;
ldout(cct, 1) << __func__ << " we do not support all peer required features"                  << " required=" << std::hex << peer_required_features                  << " supported=" << supported_features << std::dec << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__ << " received hello:"                << " peer_type=" << (int)hello.entity_type()                << " peer_addr_for_me=" << hello.peer_addr() << dendl;
ldout(cct, 5) << __func__ << " getsockname says I am " << (sockaddr *)&ss  << " when talking to " << connection->target_addr << dendl;
ldout(cct, 10) << __func__ << " accept of host_type "                   << (int)hello.entity_type()                   << ", policy.lossy=" << connection->policy.lossy                   << " policy.server=" << connection->policy.server                   << " policy.standby=" << connection->policy.standby                   << " policy.resetcheck=" << connection->policy.resetcheck                   << dendl;
ldout(cct, 1) << __func__ << " connection peer type does not match what"                    << " peer advertises " << connection->get_peer_type()                    << " != " << (int)hello.entity_type() << dendl;
ldout(cct, 1) << __func__ << " peer " << connection->target_addr      << " says I am " << hello.peer_addr() << " (socket says "      << (sockaddr*)&ss << ")" << dendl;
ldout(cct, 1) << __func__ << " socket to  " << connection->target_addr      << " says I am " << (sockaddr*)&ss      << " (peer says " << hello.peer_addr() << ")" << dendl;
ldout(cct, 10) << __func__ << " sleep for "                       << cct->_conf->ms_inject_internal_delays << dendl;
ldout(cct, 1) << __func__                    << " state changed while learned_addr, mark_down or "                    << " replacing must be happened just now" << dendl;
ldout(cct, 1) << __func__ << " read frame preamble failed r=" << r                  << " (" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 25) << __func__ << " disassembled preamble " << rx_frame_asm                 << dendl;
ldout(cct, 10) << __func__                 << " tag=" << static_cast<uint32_t>(next_tag) << dendl;
ldout(cct, 1) << __func__ << " can't allocate aligned rx_buffer"                  << " len=" << onwire_len                  << " align=" << align                  << dendl;
ldout(cct, 1) << __func__ << " read frame segment failed r=" << r << " ("                  << cpp_strerror(r) << ")" << dendl;
ldout(cct, 1) << __func__ << " entity=" << peer_name << " client_cookie="                << std::hex << client_cookie << " server_cookie="                << server_cookie << std::dec << " in_seq=" << in_seq                << " out_seq=" << out_seq << dendl;
ldout(cct, 1) << __func__ << " read frame epilogue failed r=" << r                  << " (" << cpp_strerror(r) << ")" << dendl;
ldout(cct, 5) << __func__  << " got " << msg_frame.front_len()  << " + " << msg_frame.middle_len()  << " + " << msg_frame.data_len()  << " byte message."  << " envelope type=" << current_header.type  << " src " << peer_name  << " off " << current_header.data_off                << dendl;
ldout(cct, 0) << __func__ << " got old message " << message->get_seq()                  << " <= " << cur_seq << " " << message << " " << *message                  << ", discarding" << dendl;
ldout(cct, 0) << __func__ << " missed message?  skipped from seq "                  << cur_seq << " to " << message->get_seq() << dendl;
ldout(cct, 5) << __func__ << " received message m=" << message                << " seq=" << message->get_seq()                << " from=" << message->get_source() << " type=" << header.type                << " " << *message << dendl;
ldout(cct, 1) << "queue_received will delay after "                    << (ceph_clock_now() + delay_period) << " on " << message                    << " " << *message << dendl;
ldout(cct, 10) << __func__ << " wants " << 1                   << " message from policy throttler "                   << connection->policy.throttler_messages->get_current()                   << "/" << connection->policy.throttler_messages->get_max()                   << dendl;
ldout(cct, 10) << __func__ << " wants 1 message from policy throttle "                     << connection->policy.throttler_messages->get_current()                     << "/" << connection->policy.throttler_messages->get_max()                     << " failed, just wait." << dendl;
ldout(cct, 10) << __func__ << " wants " << cur_msg_size                     << " bytes from policy throttler "                     << connection->policy.throttler_bytes->get_current() << "/"                     << connection->policy.throttler_bytes->get_max() << dendl;
ldout(cct, 10) << __func__ << " wants " << cur_msg_size                       << " bytes from policy throttler "                       << connection->policy.throttler_bytes->get_current()                       << "/" << connection->policy.throttler_bytes->get_max()                       << " failed, just wait." << dendl;
ldout(cct, 10)          << __func__ << " wants " << cur_msg_size          << " bytes from dispatch throttle "          << connection->dispatch_queue->dispatch_throttler.get_current() << "/"          << connection->dispatch_queue->dispatch_throttler.get_max()          << " failed, just wait." << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 20) << __func__ << " got KEEPALIVE2 "                 << keepalive_frame.timestamp() << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 20) << __func__ << " peer_type " << (int)connection->peer_type   << " auth_client " << messenger->auth_client << dendl;
ldout(cct, 0) << __func__ << " get_initial_auth_request returned " << r    << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 1) << __func__ << " method=" << bad_method.method()  << " result " << cpp_strerror(bad_method.result())                << ", allowed methods=" << bad_method.allowed_methods()  << ", allowed modes=" << bad_method.allowed_modes()                << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__                << " auth reply more len=" << auth_more.auth_payload().length()                << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__ << " sending identification: "                << "addrs=" << messenger->get_myaddrs()                << " target=" << connection->target_addr                << " gid=" << messenger->get_myname().num()                << " global_seq=" << global_seq                << " features_supported=" << std::hex                << connection->policy.features_supported                << " features_required="              << (connection->policy.features_required | msgr2_required)                << " flags=" << flags                << " cookie=" << client_cookie << std::dec << dendl;
ldout(cct, 5) << __func__ << " reconnect to session: client_cookie="                << std::hex << client_cookie << " server_cookie="                << server_cookie << std::dec                << " gs=" << global_seq << " cs=" << connect_seq                << " ms=" << in_seq << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 1) << __func__ << " received session reset full=" << reset.full()                << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 1) << __func__                << " received session retry connect_seq=" << retry.connect_seq()                << ", inc to cs=" << connect_seq << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 1) << __func__ << " received session retry global global_seq="                << retry.global_seq() << ", choose new gs=" << global_seq                << dendl;
ldout(cct, 20) << __func__   << " received WAIT (connection race)"   << " payload.length()=" << payload.length()   << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__                << " reconnect accepted: sms=" << reconnect_ok.msg_seq()                << dendl;
ldout(cct, 10) << __func__ << " reconnect success " << connect_seq                 << ", lossy = " << connection->policy.lossy << ", features "                 << connection->get_features() << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__ << " received server identification:"                << " addrs=" << server_ident.addrs()                << " gid=" << server_ident.gid()                << " global_seq=" << server_ident.global_seq()                << " features_supported=" << std::hex                << server_ident.supported_features()                << " features_required=" << server_ident.required_features()                << " flags=" << server_ident.flags()                << " cookie=" << server_ident.cookie() << std::dec << dendl;
ldout(cct,1) << __func__ << " peer identifies as " << server_ident.addrs()   << ", does not include " << connection->target_addr << dendl;
ldout(cct, 10) << __func__ << " connect success " << connect_seq                 << ", lossy = " << connection->policy.lossy << ", features "                 << connection->get_features() << dendl;
ldout(cct, 20) << __func__ << " payload.length()=" << payload.length()                 << dendl;
ldout(cct, 10) << __func__ << " AuthRequest(method=" << request.method()   << ", preferred_modes=" << request.preferred_modes()                 << ", payload_len=" << request.auth_payload().length() << ")"                 << dendl;
ldout(cct, 1) << __func__ << " auth_method " << auth_meta->auth_method  << " r " << cpp_strerror(r)  << ", allowed_methods " << allowed_methods  << ", allowed_modes " << allowed_modes  << dendl;
ldout(cct, 1) << __func__                  << " state changed while accept, it must be mark_down"                  << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 2) << __func__ << " pre-auth signature mismatch"                  << " actual_tx_sig=" << actual_tx_sig                  << " sig_frame.signature()=" << sig_frame.signature()                  << dendl;
ldout(cct, 20) << __func__ << " pre-auth signature success"                   << " sig_frame.signature()=" << sig_frame.signature()                   << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__ << " received client identification:"                << " addrs=" << client_ident.addrs()              << " target=" << client_ident.target_addr()                << " gid=" << client_ident.gid()                << " global_seq=" << client_ident.global_seq()                << " features_supported=" << std::hex                << client_ident.supported_features()                << " features_required=" << client_ident.required_features()                << " flags=" << client_ident.flags()                << " cookie=" << client_ident.cookie() << std::dec << dendl;
ldout(cct,5) << __func__ << " peer is trying to reach "   << client_ident.target_addr()   << " which is not us (" << messenger->get_myaddrs() << ")"   << dendl;
ldout(cct, 1) << __func__ << " peer missing required features " << std::hex                  << feat_missing << std::dec << dendl;
ldout(cct,1) << __func__ << " existing " << existing << " proto "     << existing->protocol.get() << " version is "     << existing->protocol->proto_type << ", marking down"     << dendl;
ldout(cct, 1) << __func__      << " state changed while accept, it must be mark_down"      << dendl;
ldout(cct, 20) << __func__   << " payload.length()=" << payload.length() << dendl;
ldout(cct, 5) << __func__                << " received reconnect:"                 << " client_cookie=" << std::hex << reconnect.client_cookie()                << " server_cookie=" << reconnect.server_cookie() << std::dec                << " gs=" << reconnect.global_seq()                << " cs=" << reconnect.connect_seq()                << " ms=" << reconnect.msg_seq()              << dendl;
ldout(cct,1) << __func__ << " existing " << existing << " proto "   << existing->protocol.get() << " version is "   << existing->protocol->proto_type << ", marking down" << dendl;
ldout(cct, 1) << __func__                  << " state changed while accept, it must be mark_down"                  << dendl;
ldout(cct, 0) << __func__                  << " no existing connection exists, reseting client" << dendl;
ldout(cct, 5) << __func__ << " existing " << existing                  << " already closed. Reseting client" << dendl;
ldout(cct, 1) << __func__                  << " existing racing replace happened while replacing."                  << " existing=" << existing << dendl;
ldout(cct, 1) << __func__ << " existing=" << existing                  << " client cookie mismatch, I must have reseted:"                  << " cc=" << std::hex << exproto->client_cookie                  << " rcc=" << reconnect.client_cookie()                  << ", reseting client." << std::dec                  << dendl;
ldout(cct, 1) << __func__ << " I was a client and didn't received the"                  << " server_ident. Asking peer to resume session"                  << " establishment" << dendl;
ldout(cct, 5) << __func__                  << " stale global_seq: sgs=" << exproto->peer_global_seq                  << " cgs=" << reconnect.global_seq()                  << ", ask client to retry global" << dendl;
ldout(cct, 5) << __func__                  << " stale connect_seq scs=" << exproto->connect_seq                  << " ccs=" << reconnect.connect_seq()                  << " , ask client to retry" << dendl;
ldout(cct, 1)          << __func__          << " reconnect race detected, this connection loses to existing="          << existing << dendl;
ldout(cct, 1) << __func__                    << " reconnect race detected, replacing existing="                    << existing << " socket by this connection's socket"                    << dendl;
ldout(cct, 1) << __func__ << " existing " << existing << " already closed."                  << dendl;
ldout(cct, 1) << __func__                  << " existing racing replace happened while replacing."                  << " existing=" << existing << dendl;
ldout(cct, 1) << __func__ << " this is a stale connection, peer_global_seq="                  << peer_global_seq                  << " existing->peer_global_seq=" << exproto->peer_global_seq                  << ", stopping this connection." << dendl;
ldout(cct, 1)        << __func__ << " existing=" << existing        << " is a lossy channel. Stopping existing in favor of this connection"        << dendl;
ldout(cct, 1) << __func__ << " found previous session existing=" << existing                  << ", peer must have reseted." << dendl;
ldout(cct, 1) << __func__ << " found previous session existing=" << existing                  << ", continuing session establishment." << dendl;
ldout(cct, 1) << __func__ << " existing=" << existing                  << " is READY/STANDBY, lets reuse it" << dendl;
ldout(cct, 1) << __func__                  << " connection race detected, replacing existing="                  << existing << " socket by this connection's socket" << dendl;
ldout(cct, 1)        << __func__        << " connection race detected, this connection loses to existing="        << existing << dendl;
ldout(cct, 20) << __func__ << " existing=" << existing                 << " reconnect=" << reconnecting << dendl;
ldout(messenger->cct, 5) << __func__ << " stop myself to swap existing"                           << dendl;
ldout(cct, 5) << __func__ << " sending identification:"                << " addrs=" << messenger->get_myaddrs()                << " gid=" << messenger->get_myname().num()                << " global_seq=" << gs << " features_supported=" << std::hex                << connection->policy.features_supported                << " features_required="              << (connection->policy.features_required | msgr2_required)                << " flags=" << flags                << " cookie=" << server_cookie << std::dec << dendl;
ldout(cct, 1) << __func__ << " existing race replacing process for addr = "                  << connection->peer_addrs->msgr2_addr()                  << " just fail later one(this)" << dendl;
ldout(cct, 1) << __func__                  << " state changed while accept_conn, it must be mark_down"                  << dendl;
ldout(cct, 1) << __func__ << " existing race replacing process for addr = "                  << connection->peer_addrs->msgr2_addr()                  << " just fail later one(this)" << dendl;
ldout(cct, 1) << __func__                  << " state changed while accept_conn, it must be mark_down"                  << dendl;
ldout(cct,0) << "couldn't set TOS to " << iptos   << ": " << cpp_strerror(r) << dendl;
ldout(cct, 0) << __func__ << " couldn't set SO_PRIORITY to " << prio    << ": " << cpp_strerror(r) << dendl;
ldout(cct, 10) << __func__ << " reconnect: " << r                   << " " << strerror(r) << dendl;
ldout(cct, 10) << __func__ << " with nothing to send and in the half "                   << " accept state just closed" << dendl;
ldout(cct, 10) << __func__ << " with nothing to send, going to standby"                   << dendl;
ldout(cct, 5) << __func__ << " clear encoded buffer previous " << f                  << " != " << connection->get_features() << dendl;
ldout(cct, 10) << __func__ << " connection closed."                   << " Drop message " << m << dendl;
ldout(cct, 15) << __func__ << " inline write is denied, reschedule m=" << m                   << dendl;
ldout(cct, 20) << __func__ << (m->empty_payload() ? " encoding features " : " half-reencoding features ")   << features << " " << m  << " " << *m << dendl;
ldout(cct, 10) << __func__ << " try send msg ack, acked " << left                       << " messages" << dendl;
ldout(cct, 10) << __func__ << " got ack seq " << seq                   << " >= " << m->get_seq() << " on " << m << " " << *m                   << dendl;
ldout(cct, 20) << __func__ << " got envelope type=" << current_header.type << " src "                 << entity_name_t(current_header.src) << " front=" << current_header.front_len                 << " data=" << current_header.data_len << " off " << current_header.data_off                 << dendl;
ldout(cct, 0) << __func__ << " got bad header crc " << header_crc                    << " != " << current_header.crc << dendl;
ldout(cct, 10) << __func__ << " wants " << 1                   << " message from policy throttler "                   << connection->policy.throttler_messages->get_current()                   << "/" << connection->policy.throttler_messages->get_max()                   << dendl;
ldout(cct, 10) << __func__ << " wants 1 message from policy throttle "                     << connection->policy.throttler_messages->get_current()                     << "/" << connection->policy.throttler_messages->get_max()                     << " failed, just wait." << dendl;
ldout(cct, 10) << __func__ << " wants " << cur_msg_size                     << " bytes from policy throttler "                     << connection->policy.throttler_bytes->get_current() << "/"                     << connection->policy.throttler_bytes->get_max() << dendl;
ldout(cct, 10) << __func__ << " wants " << cur_msg_size                       << " bytes from policy throttler "                       << connection->policy.throttler_bytes->get_current()                       << "/" << connection->policy.throttler_bytes->get_max()                       << " failed, just wait." << dendl;
ldout(cct, 10)          << __func__ << " wants " << cur_msg_size          << " bytes from dispatch throttle "          << connection->dispatch_queue->dispatch_throttler.get_current() << "/"          << connection->dispatch_queue->dispatch_throttler.get_max()          << " failed, just wait." << dendl;
ldout(cct, 10) << __func__ << " seleting rx buffer v " << p->second.second                     << " at offset " << data_off << " len "                     << p->second.first.length() << dendl;
ldout(cct, 20) << __func__ << " allocating new rx buffer at offset "                     << data_off << dendl;
ldout(cct, 20) << __func__ << " allocating new rx buffer at offset "     << data_off << dendl;
ldout(cct, 0) << __func__ << " got " << front.length() << " + "                  << middle.length() << " + " << data.length()                  << " byte message.. ABORTED" << dendl;
ldout(cct, 20) << __func__ << " got " << front.length() << " + "                 << middle.length() << " + " << data.length() << " byte message"                 << dendl;
ldout(cct, 0) << __func__ << " got old message " << message->get_seq()                  << " <= " << cur_seq << " " << message << " " << *message                  << ", discarding" << dendl;
ldout(cct, 0) << __func__ << " missed message?  skipped from seq "                  << cur_seq << " to " << message->get_seq() << dendl;
ldout(cct, 5) << " rx " << message->get_source() << " seq "                << message->get_seq() << " " << message << " " << *message                << dendl;
ldout(cct, 1) << "queue_received will delay after "                    << (ceph_clock_now() + delay_period) << " on " << message                    << " " << *message << dendl;
ldout(cct, 20) << __func__ << " failed to sign m=" << m                     << "): sig = " << footer.sig << dendl;
ldout(cct, 20) << __func__ << " signed m=" << m                     << "): sig = " << footer.sig << dendl;
ldout(cct, 20) << __func__ << " sending message type=" << header.type                 << " src " << entity_name_t(header.src)                 << " front=" << header.front_len << " data=" << header.data_len                 << " off " << header.data_off << dendl;
ldout(cct, 20) << __func__ << " sending " << m->get_seq() << " " << m                 << dendl;
ldout(cct, 1) << __func__ << " error sending " << m << ", "                  << cpp_strerror(rc) << dendl;
ldout(cct, 10) << __func__ << " sending " << m                   << (rc ? " continuely." : " done.") << dendl;
ldout(cct, 10) << __func__ << " " << *m << " for resend "                   << " (" << m->get_seq() << ")" << dendl;
ldout(cct, 10) << __func__ << " " << *(p.second) << " for resend seq "                   << p.second->get_seq() << " <= " << seq << ", discarding"                   << dendl;
ldout(cct, 5) << "reset_recv_state (warped) reseting security handlers"                    << dendl;
ldout(cct, 10) << __func__ << " releasing " << 1                   << " message to policy throttler "                   << connection->policy.throttler_messages->get_current()                   << "/" << connection->policy.throttler_messages->get_max()                   << dendl;
ldout(cct, 10) << __func__ << " releasing " << cur_msg_size                     << " bytes to policy throttler "                     << connection->policy.throttler_bytes->get_current() << "/"                     << connection->policy.throttler_bytes->get_max() << dendl;
ldout(cct, 10)        << __func__ << " releasing " << cur_msg_size        << " bytes to dispatch_queue throttler "        << connection->dispatch_queue->dispatch_throttler.get_current() << "/"        << connection->dispatch_queue->dispatch_throttler.get_max() << dendl;
ldout(cct, 10) << __func__ << " connect write banner done: "                 << connection->get_peer_addr() << dendl;
ldout(cct, 1) << __func__ << " read banner and identify addresses failed"                  << dendl;
ldout(cct, 0) << __func__ << " connect protocol error (bad banner) on peer "                  << connection->get_peer_addr() << dendl;
ldout(cct, 20) << __func__ << " connect read peer addr " << paddr                 << " on socket " << connection->cs.fd() << dendl;
ldout(cct, 0) << __func__ << " connect claims to be " << paddr << " not "                    << peer_addr << " - presumably this is the same node!"                    << dendl;
ldout(cct, 10) << __func__ << " connect claims to be " << paddr << " not "                     << peer_addr << dendl;
ldout(cct, 20) << __func__ << " connect peer addr for me is "                 << peer_addr_for_me << dendl;
ldout(cct, 1) << __func__ << " peer " << connection->target_addr      << " says I am " << peer_addr_for_me << " (socket says "      << (sockaddr*)&ss << ")" << dendl;
ldout(cct, 1) << __func__ << " socket to  " << connection->target_addr      << " says I am " << (sockaddr*)&ss      << " (peer says " << peer_addr_for_me << ")" << dendl;
ldout(cct, 10) << __func__ << " sleep for "         << cct->_conf->ms_inject_internal_delays << dendl;
ldout(cct, 1) << __func__                  << " state changed while learned_addr, mark_down or "      << " replacing must be happened just now" << dendl;
ldout(cct, 2) << __func__ << " connect couldn't write my addr, "                  << cpp_strerror(r) << dendl;
ldout(cct, 10) << __func__ << " connect sent my addr "                 << messenger->get_myaddr_legacy() << dendl;
ldout(cct,10) << __func__ << " using augmented (challenge) auth payload"      << dendl;
ldout(cct, 10) << __func__                   << " connect_msg.authorizer_len=" << auth_bl.length()                   << " protocol=" << auth_meta->auth_method << dendl;
ldout(cct, 10) << __func__ << " connect sending gseq=" << global_seq                 << " cseq=" << connect_seq                 << " proto=" << connect.protocol_version << dendl;
ldout(cct, 2) << __func__ << " connect couldn't send reply "                  << cpp_strerror(r) << dendl;
ldout(cct, 20) << __func__                 << " connect wrote (self +) cseq, waiting for reply" << dendl;
ldout(cct, 20) << __func__ << " connect got reply tag "                 << (int)connect_reply.tag << " connect_seq "                 << connect_reply.connect_seq << " global_seq "                 << connect_reply.global_seq << " proto "                 << connect_reply.protocol_version << " flags "                 << (int)connect_reply.flags << " features "                 << connect_reply.features << dendl;
ldout(cct, 10) << __func__                 << " reply.authorizer_len=" << connect_reply.authorizer_len                 << dendl;
ldout(cct, 1) << __func__ << " read connect reply authorizer failed"                  << dendl;
ldout(cct, 0) << __func__ << " connect protocol feature mismatch, my "                  << std::hex << connection->policy.features_supported                  << " < peer " << connect_reply.features << " missing "                  << (connect_reply.features &                      ~connection->policy.features_supported)                  << std::dec << dendl;
ldout(cct, 0) << __func__ << " connect protocol version mismatch, my "                  << messenger->get_proto_version(connection->peer_type, true)                  << " != " << connect_reply.protocol_version << dendl;
ldout(cct, 5) << __func__ << " connect got RETRY_GLOBAL "                  << connect_reply.global_seq << " chose new " << global_seq                  << dendl;
ldout(cct, 5) << __func__ << " connect got RETRY_SESSION " << connect_seq                  << " -> " << connect_reply.connect_seq << dendl;
ldout(cct, 1) << __func__ << " missing required features " << std::hex                  << feat_missing << std::dec << dendl;
ldout(cct, 10)        << __func__        << " got CEPH_MSGR_TAG_SEQ, reading acked_seq and writing in_seq"        << dendl;
ldout(cct, 2) << __func__ << " got newly_acked_seq " << newly_acked_seq                << " vs out_seq " << out_seq << dendl;
ldout(cct, 10) << __func__ << " connect success " << connect_seq                 << ", lossy = " << connection->policy.lossy << ", features "                 << connection->get_features() << dendl;
ldout(cct, 10) << __func__ << " setting up session_security with auth "     << auth_meta->authorizer.get() << dendl;
ldout(cct, 10) << __func__ << " no authorizer, clearing session_security"     << dendl;
ldout(cct, 1) << __func__ << " sd=" << connection->cs.fd()  << " legacy " << legacy  << " socket_addr " << connection->socket_addr  << " target_addr " << connection->target_addr  << dendl;
ldout(cct, 10) << __func__ << " write banner and addr done: "                 << connection->get_peer_addr() << dendl;
ldout(cct, 1) << __func__ << " accept peer sent bad banner '" << buffer                  << "' (should be '" << CEPH_BANNER << "')" << dendl;
ldout(cct, 0) << __func__ << " accept peer addr is really " << peer_addr                  << " (socket is " << connection->target_addr << ")" << dendl;
ldout(cct, 20) << __func__ << " accept got peer connect_seq "                 << connect_msg.connect_seq << " global_seq "                 << connect_msg.global_seq << dendl;
ldout(cct, 10) << __func__ << " accept of host_type " << connect_msg.host_type                 << ", policy.lossy=" << connection->policy.lossy                 << " policy.server=" << connection->policy.server                 << " policy.standby=" << connection->policy.standby                 << " policy.resetcheck=" << connection->policy.resetcheck   << " features 0x" << std::hex << (uint64_t)connect_msg.features   << std::dec                 << dendl;
ldout(cct, 10) << __func__ << " accept my proto " << reply.protocol_version                 << ", their proto " << connect_msg.protocol_version << dendl;
ldout(cct, 10)            << __func__            << " using cephx, requiring MSG_AUTH feature bit for cluster"            << dendl;
ldout(cct, 10)            << __func__            << " using cephx, requiring cephx v2 feature bit for cluster"            << dendl;
ldout(cct, 10)            << __func__            << " using cephx, requiring MSG_AUTH feature bit for service"            << dendl;
ldout(cct, 10)            << __func__            << " using cephx, requiring cephx v2 feature bit for service"            << dendl;
ldout(cct, 1) << __func__ << " peer missing required features " << std::hex                  << feat_missing << std::dec << dendl;
ldout(cct,10) << __func__ << " authorizor_protocol "  << connect_msg.authorizer_protocol  << " len " << auth_bl_copy.length()  << dendl;
ldout(cct, 0) << __func__ << ": got bad authorizer, auth_reply_len="    << authorizer_reply.length() << dendl;
ldout(cct,1) << __func__ << " existing " << existing << " proto "   << existing->protocol.get() << " version is "   << existing->protocol->proto_type << ", marking down" << dendl;
ldout(cct,10) << __func__ << " existing=" << existing << " exproto="    << existing->protocol.get() << dendl;
ldout(cct, 1) << __func__ << " existing " << existing      << " already closed." << dendl;
ldout(cct, 1) << __func__                    << " existing racing replace happened while replacing."                    << " existing_state="                    << connection->get_state_name(existing->state) << dendl;
ldout(cct, 10) << __func__ << " accept existing " << existing << ".gseq "                     << exproto->peer_global_seq << " > "                     << connect_msg.global_seq << ", RETRY_GLOBAL" << dendl;
ldout(cct, 10) << __func__ << " accept existing " << existing << ".gseq "                     << exproto->peer_global_seq                     << " <= " << connect_msg.global_seq << ", looks ok"                     << dendl;
ldout(cct, 0)          << __func__          << " accept replacing existing (lossy) channel (new one lossy="          << connection->policy.lossy << ")" << dendl;
ldout(cct, 1) << __func__ << " accept connect_seq "                  << connect_msg.connect_seq                  << " vs existing csq=" << exproto->connect_seq                  << " existing_state="                  << connection->get_state_name(existing->state) << dendl;
ldout(cct, 0)          << __func__          << " accept peer reset, then tried to connect to us, replacing"          << dendl;
ldout(cct, 10) << __func__ << " accept existing " << existing << ".cseq "                     << exproto->connect_seq << " > " << connect_msg.connect_seq                     << ", RETRY_SESSION" << dendl;
ldout(cct, 10) << __func__ << " accept connection race, existing "                       << existing << ".cseq " << exproto->connect_seq                       << " == " << connect_msg.connect_seq                       << ", OPEN|STANDBY, RETRY_SESSION " << dendl;
ldout(cct, 10) << __func__ << " accept connection race, existing "                       << existing << ".cseq " << exproto->connect_seq                       << " == " << connect_msg.connect_seq                       << ", or we are server, replacing my attempt" << dendl;
ldout(messenger->cct, 10)            << __func__ << " accept connection race, existing " << existing            << ".cseq " << exproto->connect_seq            << " == " << connect_msg.connect_seq << ", sending WAIT" << dendl;
ldout(cct, 0) << __func__ << " accept we reset (peer sent cseq "                    << connect_msg.connect_seq << ", " << existing                    << ".cseq = " << exproto->connect_seq                    << "), sending RESETSESSION " << dendl;
ldout(cct, 10) << __func__ << " accept peer sent cseq "                   << connect_msg.connect_seq << " > " << exproto->connect_seq                   << dendl;
ldout(cct, 0) << __func__ << " accept we reset (peer sent cseq "                  << connect_msg.connect_seq << "), sending RESETSESSION"                  << dendl;
ldout(cct, 10) << __func__ << " reply features 0x" << std::hex   << reply.features << " = (policy sup 0x"   << connection->policy.features_supported   << " & connect 0x" << (uint64_t)connect_msg.features   << ") | policy req 0x"   << connection->policy.features_required   << dendl;
ldout(cct, 1) << __func__ << " replacing on lossy channel, failing existing"                  << dendl;
ldout(messenger->cct, 1)        << __func__ << " stop myself to swap existing" << dendl;
ldout(cct, 10) << __func__ << " accept success, connect_seq = " << connect_seq                 << " in_seq=" << in_seq << ", sending READY" << dendl;
ldout(cct, 10) << __func__ << " accept features "                 << connection->get_features()   << " authorizer_protocol "   << connect_msg.authorizer_protocol << dendl;
ldout(cct, 1) << __func__ << " existing race replacing process for addr = "                  << connection->peer_addrs->legacy_addr()                  << " just fail later one(this)" << dendl;
ldout(cct, 1) << __func__                  << " state changed while accept_conn, it must be mark_down"                  << dendl;
ldout(cct, 1) << __func__ << " write ready connect message reply failed"                  << dendl;
ldout(cct, 2) << __func__ << " accept get newly_acked_seq " << newly_acked_seq                << dendl;
ldout(cct, 20) << __func__ << " session_security is "   << session_security   << dendl;
ldout(msgr->cct, 1) << __func__ << " setting up a delay queue"         << dendl;
ldout(async_msgr->cct, 20) << __func__                             << (pendingReadLen ? " continue" : " start")                             << " len=" << len << dendl;
ldout(async_msgr->cct, 25) << __func__ << " len is " << len << " state_offset is "                             << state_offset << dendl;
ldout(async_msgr->cct, 25) << __func__ << " got " << to_read << " in buffer "                               << " left is " << left << " buffer still has "                               << recv_end - recv_start << dendl;
ldout(async_msgr->cct, 25) << __func__ << " read_bulk recv_end is " << recv_end                                 << " left is " << left << " got " << r << dendl;
ldout(async_msgr->cct, 25) << __func__ << " need len " << len << " remaining "                             << len - state_offset << " bytes" << dendl;
ldout(async_msgr->cct, 1) << __func__ << " reading from fd=" << cs.fd()                          << " : "<< nread << " " << strerror(nread) << dendl;
ldout(async_msgr->cct, 1) << __func__ << " peer close file descriptor "                              << cs.fd() << dendl;
ldout(async_msgr->cct, 25) << __func__ << " cs.send " << outgoing_bl.length()                             << " bytes" << dendl;
ldout(async_msgr->cct, 10) << __func__ << " sent bytes " << r                             << " remaining bytes " << outgoing_bl.length() << dendl;
ldout(async_msgr->cct, 10) << __func__ << " sleep for " <<      async_msgr->cct->_conf->ms_inject_internal_delays << dendl;
ldout(async_msgr->cct, 1) << __func__ << " reconnect failed to "                                  << target_addr << dendl;
ldout(async_msgr->cct, 2)              << __func__ << " connection refused!" << dendl;
ldout(async_msgr->cct, 10)            << __func__ << " nonblock connect inprogress" << dendl;
ldout(async_msgr->cct, 10)          << __func__ << " connect successfully, ready to send banner" << dendl;
ldout(async_msgr->cct, 10) << __func__ << " sd=" << socket.fd()        << " listen_addr " << listen_addr        << " peer_addr " << peer_addr << dendl;
lgeneric_subdout(async_msgr->cct, ms,     1) << "-- " << async_msgr->get_myaddrs() << " --> "        << get_peer_addrs() << " -- "        << *m << " -- " << m << " con "        << this        << dendl;
lgeneric_subdout(async_msgr->cct, ms, 0) << __func__ << ceph_entity_type_name(peer_type)      << " blackhole " << *m << dendl;
ldout(async_msgr->cct, 10) << __func__ << " loopback connection closed."                                 << " Drop message " << m << dendl;
ldout(async_msgr->cct,10) << __func__ << " " << av << " -> nothing to match "       << socket_addr << dendl;
ldout(async_msgr->cct, 20) << __func__ << " last_id=" << last_tick_id                             << " last_active=" << last_active << dendl;
ldout(async_msgr->cct, 1) << __func__ << " see no progress in more than "                                << connect_timeout_us                                << " us during connecting, fault."                                << dendl;
ldout(async_msgr->cct, 1) << __func__ << " idle (" << idle_period                                << ") for more than " << inactive_timeout_us                                << " us, fault."                                << dendl;
ldout(cct, 10) << __func__ << " get " << std::hex << int(h.ip_proto)                 << std::dec << " packet from "                 << h.src_ip << " -> " << h.dst_ip << " id=" << h.id                 << " ip_len=" << ip_len << " ip_hdr_len=" << ip_hdr_len                 << " pkt_len=" << pkt_len << " offset=" << offset << dendl;
ldout(cct, 20) << " ipv4::send " << " id=" << iph->id << " " << _host_address << " -> " << to                   << " len " << pkt.len() << dendl;
ldout(cct, 20) << __func__ << " add event fd=" << fd << " cur_mask=" << cur_mask         << " add_mask=" << add_mask << dendl;
ldout(cct, 20) << __func__ << " del event fd=" << fd << " cur_mask=" << cur_mask         << " delmask=" << delmask << dendl;
ldout(this->cct, 10) << "=== tx === proto " << std::hex << uint16_t(l3pv.proto_num)                       << " " << _hw_address << " -> " << l3pv.to                       << " length " << std::dec << l3pv.p.len() << dendl;
ldout(cct, 10) << __func__ << " === rx === proto " << std::hex << ::ntoh(eh->eth_proto)                     << " "<< eh->src_mac.ntoh() << " -> " << eh->dst_mac.ntoh()                     << " length " << std::dec << p.len() << " rss_hash " << *p.rss_hash() << dendl;
ldout(cct, 10) << __func__ << " === rx === proto " << std::hex << ::ntoh(eh->eth_proto)                     << " "<< eh->src_mac.ntoh() << " -> " << eh->dst_mac.ntoh()                     << " length " << std::dec << p.len() << dendl;
ldout(cct, 20) << __func__ << " tcp header rst=" << bool(rth->f_rst) << " fin=" << bool(rth->f_fin)                 << " syn=" << bool(rth->f_syn) << dendl;
ldout(_tcp.cct, 20) << __func__ << " tcp header seq " << seg_seq.raw << " ack " << seg_ack.raw                      << " fin=" << bool(th->f_fin) << " syn=" << bool(th->f_syn) << dendl;
ldout(_tcp.cct, 20) << __func__ << " tcp header seq " << seg_seq.raw << " ack " << seg_ack.raw                      << " snd next " << _snd.next.raw << " unack " << _snd.unacknowledged.raw                      << " rcv next " << _rcv.next.raw << " len " << seg_len                      << " fin=" << bool(th->f_fin) << " syn=" << bool(th->f_syn) << dendl;
ldout(_tcp.cct, 10) << __func__ << " out of order, expect " << _rcv.next.raw                        << " actual " << seg_seq.raw                        << " out of order size " << _rcv.out_of_order.map.size()                        << dendl;
ldout(_tcp.cct, 20) << __func__ << " window update seg_seq=" << seg_seq                          << " seg_ack=" << seg_ack << " old window=" << th->window                          << " new window=" << int(_snd.window_scale) << dendl;
ldout(_tcp.cct, 5) << __func__ << " syn retransmit exceed max "                         << _max_nr_retransmit << dendl;
ldout(_tcp.cct, 5) << __func__ << " fin retransmit exceed max "                         << _max_nr_retransmit << dendl;
ldout(_tcp.cct, 20) << __func__ << " unack data size " << _snd.data.size()                      << " nr=" << unacked_seg.nr_transmits << dendl;
ldout(_tcp.cct, 5) << __func__ << " seg retransmit exceed max "                       << _max_nr_retransmit << dendl;
ldout(cct, 5) << __func__ << " Port " << int(_port_idx) << ": max_rx_queues "                << _dev_info.max_rx_queues << "  max_tx_queues "                << _dev_info.max_tx_queues << dendl;
ldout(cct, 5) << __func__ << " Port " << int(_port_idx) << ": using "                << _num_queues << " queues" << dendl;
ldout(cct, 5) << __func__ << " Port " << int(_port_idx)                    << ": RSS table size is " << _dev_info.reta_size << dendl;
ldout(cct, 1) << __func__ << " port " << int(_port_idx)                  << ": not support to get hardware flow control settings: " << ret << dendl;
ldout(cct, 1) << __func__ << " port " << int(_port_idx)                  << ": not support to set hardware flow control settings: " << ret << dendl;
ldout(cct, 0) << __func__ << " Port " << _port_idx                  << ": flow rss func configuration is unsupported"                  << dendl;
ldout(cct, 1) << __func__ << " Creating Rx mbuf pool '" << name.c_str()                  << "' [" << mbufs_per_queue_rx << " mbufs] ..."<< dendl;
ldout(cct, 5) << __func__ << " done port "                      << static_cast<unsigned>(_port_idx)                      << " link Up - speed " << link.link_speed                      << " Mbps - "                      << ((link.link_duplex == ETH_LINK_FULL_DUPLEX) ? ("full-duplex") : ("half-duplex\n"))                      << dendl;
ldout(cct, 10) << __func__ << " free segs " << _num_rx_free_segs                   << " thresh " << rx_gc_thresh                   << " free pkts " << _rx_free_pkts.size()                   << dendl;
ldout(cct, 0) << __func__ << " rx count=" << rx_count << " avg rx=" << Cycles::to_nanoseconds(rx_cycles)/rx_count << "ns "                    << " tx count=" << tx_count << " avg tx=" << Cycles::to_nanoseconds(tx_cycles)/tx_count << "ns"                    << dendl;
ldout(cct, 0) << __func__ << " Creating Tx mbuf pool '" << name.c_str()                  << "' [" << mbufs_per_queue_tx << " mbufs] ..." << dendl;
ldout(cct, 20) << __func__ << " activing=" << int(impl->activating_mask)                 << " listening=" << int(impl->listening_mask)                 << " waiting_idx=" << int(impl->waiting_idx) << dendl;
ldout(cct, 20) << __func__ << " activing=" << int(impl->activating_mask)                 << " listening=" << int(impl->listening_mask)                 << " waiting_idx=" << int(impl->waiting_idx) << " done " << dendl;
ldout(cct, 15) << __func__   << " plaintext.length()=" << plaintext.length()   << " buffer.length()=" << buffer.length()   << dendl;
ldout(cct, 15) << __func__   << " buffer.length()=" << buffer.length()   << " final_len=" << final_len   << dendl;
ldout(cct, 0) << "Select isn't suitable for production env, just avoid "                << "compiling error or special purpose" << dendl;
ldout(cct, 10) << __func__ << " add event to fd=" << fd << " mask=" << add_mask                 << dendl;
ldout(cct, 10) << __func__ << " del event fd=" << fd << " cur mask=" << cur_mask                 << dendl;
ldout(cct, 20) << __func__ << " nonblock:" << opts.nonblock << ", nodelay:"                 << opts.nodelay << ", rbuf_size: " << opts.rcbuf_size << dendl;
ldout(cct, 20) << __func__ << " notify_fd : " << event_val << " in " << local_qpn                 << " r = " << r << dendl;
ldout(cct, 25) << __func__ << " read chunk " << *pchunk << " bytes length" << tmp << " offset: "                   << (*pchunk)->get_offset() << " ,bound: " << (*pchunk)->get_bound() << dendl;
ldout(cct, 20) << __func__ << " we need " << bytes << " bytes. iov size: "                 << pending_bl.get_num_buffers() << dendl;
ldout(cct, 20) << __func__ << " left bytes: " << pending_bl.length() << " in buffers "                 << pending_bl.get_num_buffers() << " tx chunks " << tx_buffers.size() << dendl;
ldout(cct, 1) << __func__ << " failed to send data"                  << " (most probably should be peer not ready): "                  << cpp_strerror(errno) << dendl;
ldout(cct, 1) << __func__ << " failed to send message="                  << " ibv_post_send failed(most probably should be peer not ready): "                  << cpp_strerror(errno) << dendl;
ldout(cct, 10) << __func__ << " unable to bind to " << sa.get_sockaddr()                   << " on port " << sa.get_port() << ": " << cpp_strerror(errno) << dendl;
ldout(cct, 1) << __func__ << " looking for local GID " << (cct->_conf->ms_async_rdma_local_gid)    << " of type " << (cct->_conf->ms_async_rdma_roce_ver) << dendl;
ldout(cct, 10) << __func__ << " port " << port_id << " is not what we want. state: "                     << ibv_port_state_str(port->get_port_attr()->state) << dendl;
ldout(cct, 20) << __func__ << " successfully create queue pair: "                 << "qp=" << qp << dendl;
ldout(cct, 20) << __func__ << " initialize no SRQ Queue Pair, qp number: "                   << qp->qp_num << " post SQ WR " << rq_wrs << dendl;
ldout(cct, 5) << __func__ << " recevd: " << peer_cm_meta.lid << ", " << peer_cm_meta.local_qpn                  << ", " << peer_cm_meta.psn << ", " << peer_cm_meta.peer_qpn << ", " << gid << dendl;
ldout(cct, 10) << __func__ << " sending: " << local_cm_meta.lid << ", " << local_cm_meta.local_qpn                 << ", " << local_cm_meta.psn << ", " << local_cm_meta.peer_qpn << ", "  << gid  << dendl;
ldout(cct, 20) << __func__ << " force trigger error state Queue Pair, qp number: " << local_cm_meta.local_qpn                 << " bound remote QueuePair, qp number: " << local_cm_meta.peer_qpn << dendl;
ldout(cct, 1) << __func__ << " device allow " << device->device_attr.max_cqe                << " completion entries" << dendl;
ldout(cct, 10) << __func__ << " unable to bind to " << sa.get_sockaddr()                   << " on port " << sa.get_port() << ": " << cpp_strerror(errno) << dendl;
ldout(cct, 10) << __func__ << " unable to listen to " << sa.get_sockaddr()                   << " on port " << sa.get_port() << ": " << cpp_strerror(errno) << dendl;
ldout(cct, 20) << __func__ << " event name: " << rdma_event_str(event->event)                             << " (cm id: " << cm_id << ")" << dendl;
ldout(cct, 20) << __func__ << " Connection's QP maybe entered into dead status. "                           << " qp number: " << qpn << dendl;
ldout(cct, 20) << __func__ << " tx completion queue got " << tx_ret                     << " responses."<< dendl;
ldout(cct, 20) << __func__ << " rx completion queue got " << rx_ret                     << " responses."<< dendl;
ldout(cct, 20) << __func__ << " QP number: " << response->qp_num << " len: " << response->byte_len                   << " status: " << ib->wc_status_to_string(response->status) << dendl;
ldout(cct, 1) << __func__ << " Responder ACK timeout, possible disconnect, or Remote QP in bad state "                          << " WCE status(" << response->status << "): " << ib->wc_status_to_string(response->status)                          << " WCE QP number " << response->qp_num << " Opcode " << response->opcode                          << " wr_id: 0x" << std::hex << response->wr_id << std::dec << dendl;
ldout(cct, 1) << __func__ << " SQ WR return error, remote Queue Pair, qp number: "                            << conn->get_peer_qpn() << dendl;
ldout(cct, 1) << __func__ << " SQ WR return error, remote Queue Pair, qp number: "                              << conn->get_peer_qpn() << dendl;
ldout(cct, 20) << __func__ << " SQ WR return error Queue Pair error state is : " << conn->get_qp_state()                             << " remote Queue Pair, qp number: " << conn->get_peer_qpn() << dendl;
ldout(cct, 30) << __func__ << " release " << chunks.size()                 << " chunks, inflight " << inflight << dendl;
ldout(cct, 1) << __func__ << " csi with qpn " << response->qp_num << " may be dead. chunk 0x"                        << std::hex << chunk << " will be back." << std::dec << dendl;
ldout(cct, 1) << __func__ << " RQ WR return error,"                     << " WCE status(" << response->status << "): " << ib->wc_status_to_string(response->status)                     << " WCE QP number " << response->qp_num << " Opcode " << response->opcode                     << " wr_id: 0x" << std::hex << response->wr_id << std::dec << dendl;
ldout(cct, 1) << __func__ << " RQ WR return error, remote Queue Pair, qp number: "                       << conn->get_peer_qpn() << dendl;
ldout(cct, 1) << __func__ << " RQ WR return error,"                      << " WCE status(" << response->status << "): " << ib->wc_status_to_string(response->status)                      << " WCE QP number " << response->qp_num << " Opcode " << response->opcode                      << " wr_id: 0x" << std::hex << response->wr_id << std::dec << dendl;
ldout(cct,0) << __func__ << " invalid kqfd = " << kqfd                  << cpp_strerror(errno) << dendl;
ldout(cct,30) << __func__ << " restore kqfd = " << kqfd                   << " fd = " << i << " mask " << sav_events[i].mask << dendl;
ldout(cct,0) << __func__ << " unable to add event: "                     << cpp_strerror(errno) << dendl;
ldout(cct,20) << funcname << " We changed thread from " << mythread                  << " to " << pthread_self() << dendl;
ldout(cct,0) << funcname << " Warning: Recreating old kqfd. "                 << "This should not happen!!!"  << dendl;
ldout(cct,30) << funcname << " kqueue: new kqfd = " << kqfd                  << " (was: " << oldkqfd << ")"                  << dendl;
ldout(cct,30) << __func__ << " add event kqfd = " << kqfd << " fd = " << fd  << " cur_mask = " << cur_mask << " add_mask = " << add_mask  << dendl;
ldout(cct,30) << __func__ << " delete event kqfd = " << kqfd  << " fd = " << fd << " cur_mask = " << cur_mask  << " del_mask = " << del_mask << dendl;
ldout(cct,30) << __func__ << " kqfd = " << kqfd << "newsize = " << newsize                 << dendl;
ldout(cct,20) << __func__ << " "  << timeout.tv_sec << " sec "  << timeout.tv_nsec << " nsec"  << dendl;
ldout(cct,5) << __func__ << " Hit timeout("                 << timeout.tv_sec << " sec "                 << timeout.tv_nsec << " nsec"   << ")." << dendl;
ldout(cct, 20) << __func__ << " add event fd=" << fd << " cur_mask=" << cur_mask                 << " add_mask=" << add_mask << " to " << epfd << dendl;
ldout(cct, 20) << __func__ << " del event fd=" << fd << " cur_mask=" << cur_mask                 << " delmask=" << delmask << " to " << epfd << dendl;
ldout(msgr->cct, 10) << __func__ << " bound on random port "        << listen_addr << dendl;
ldout(msgr->cct, 1) << __func__                 << " Error: processor restart after listen_socket.fd closed. "                 << this << dendl;
ldout(msgr->cct, 10) << __func__ << " listen_fd=" << listen_socket.fd()    << dendl;
ldout(msgr->cct, 10) << __func__ << " accepted incoming on sd "        << cli_socket.fd() << dendl;
ldout(msgr->cct, 0) << __func__ << " it was closed because of rst arrived sd = " << listen_socket.fd()         << " errno " << r << " " << cpp_strerror(r) << dendl;
ldout(cct, 10) << __func__ << " new nonce " << nonce   << " and addr " << get_myaddrs() << dendl;
ldout(cct, 10) << __func__ << " will try " << bind_addrs   << " and avoid ports " << new_avoid << dendl;
ldout(cct, 10) << __func__ << " " << addrs      << ", creating connection and registering" << dendl;
ldout(cct, 10) << __func__ << " " << conn << " " << addrs << " "     << *conn->peer_addrs << dendl;
ldout(cct, 1) << __func__ << "--> " << ceph_entity_type_name(type) << " "      << addrs << " -- " << *m << " -- ?+"      << m->get_data().length() << " " << m << dendl;
ldout(cct,0) << __func__ <<  " message " << *m        << " with empty dest " << addrs << dendl;
ldout(cct,1) << __func__ << " assuming my addr " << a         << " matches provided addr " << b << dendl;
ldout(cct, 1) << __func__ << " learned my addr " << *my_addrs    << " (peer_addr_for_me " << peer_addr_for_me << ")" << dendl;
ldout(cct, 20) << __func__ << " create event started fd=" << fd << " mask=" << mask                 << " original mask is " << event->mask << dendl;
ldout(cct, 20) << __func__ << " create event end fd=" << fd << " mask=" << mask                 << " current mask is " << event->mask << dendl;
ldout(cct, 1) << __func__ << " delete event fd=" << fd << " is equal or greater than nevent=" << nevent                  << "mask=" << mask << dendl;
ldout(cct, 30) << __func__ << " delete event started fd=" << fd << " mask=" << mask                 << " original mask is " << event->mask << dendl;
ldout(cct, 30) << __func__ << " delete event end fd=" << fd << " mask=" << mask                 << " current mask is " << event->mask << dendl;
ldout(cct, 1) << __func__ << " write notify pipe failed: "                    << cpp_strerror(ceph_sock_errno()) << dendl;
ldout(cct, 30) << __func__ << " event_wq process is " << fired_events[event_id].fd                   << " mask is " << fired_events[event_id].mask << dendl;
dout(20) << __func__ << " want_to_read " << want_to_read    << " available_chunks " << available_chunks << dendl;
dout(20) << __func__ << " minimum == want_to_read == "        << want_to_read << dendl;
dout(20) << __func__ << " minimum == available_chunks == "        << available_chunks << dendl;
dout(20) << "get_chunk_size: chunk_size " << chunk_size      << " must be modulo " << alignment << dendl;
dout(10) << "get_chunk_size: " << chunk_size        << " padded to " << chunk_size + alignment - modulo << dendl;
dout(20) << "get_chunk_size: chunk_size " << chunk_size           << " must be modulo " << alignment << dendl;
dout(10) << "get_chunk_size: " << chunk_size             << " padded to " << chunk_size + alignment - modulo << dendl;
dout(20) << "isa_decode: reconstruct using region xor [" <<      erasures[0] << "]" << dendl;
dout(20) << "isa_decode: reconstruct using region xor [" <<      erasures[0] << "]" << dendl;
dout(10) << "[ cache tables ] creating coeff for k=" <<      k << " m=" << m << dendl;
dout(10) << "[ cache tables ] creating tables for k=" <<      k << " m=" << m << dendl;
dout(10) << "[ cache memory ] = " << memory_lru_cache << " bytes" <<    " [ matrix ] = " <<    ((matrixtype == kVandermonde) ? "Vandermonde" : "Cauchy") << dendl;
dout(10) << "(k, m, c) default to " << "(" << DEFAULT_K      << ", " << DEFAULT_M << ", " << DEFAULT_C << ")" << dendl;
dout(10) << "(k, m, c) set to " << "(" << k << ", " << m << ", "    << c << ")"<< dendl;
dout(10) << "[ cache tables ] creating coeff for k=" <<      k << " m=" << m << " c=" << c << " w=" << w << dendl;
dout(10) << " [ technique ] = " <<    ((technique == MULTIPLE) ? "multiple" : "single") << dendl;
dout(10) << __func__    << " (q,t,nu)=(" << q << "," << t << "," << nu <<")" << dendl;
dout(15) << "launched non-blocking read tid=" << tid           << " oid=" << oid << " oloc=" << oloc << dendl;
dout(10) << __func__ << " enqueuing " << *dir                       << " (fast=" << fast << ")" << dendl;
dout(7) << " load_fac is " << load_fac       << " <- " << m->second.auth << " " << metald       << " / " << mdsld       << dendl;
dout(7) << "  mds." << i  << " " << load  << " = " << load.mds_load()  << " ~ " << l << dendl;
dout(7) << "my load " << my_load     << "   target " << target_load     << "   total " << total_load     << dendl;
dout(5) << " exporting idle (" << pop << ") import " << *dir       << " back to mds." << from << dendl;
dout(5) << "want to send " << amount << " to mds." << target      //<< " .. " << (*it).second << " * " << load_fac     << " -> " << amount     << dendl;
//" .. fudge is " << fudge << dendl;
dout(7) << "reexporting " << *dir << " pop " << pop    << " back to mds." << target << dendl;
dout(5) << "reexporting " << *dir << " pop " << pop  << " to mds." << target << dendl;
dout(5) << "   - exporting " << dir->pop_auth_subtree       << " " << dir->pop_auth_subtree.meta_load()       << " to mds." << target << " " << *dir << dendl;
dout(10) << ": fragment already enqueued to split: "                   << *dir << dendl;
dout(20) << type << " pop is " << v << ", frag " << dir->get_frag()           << " size " << dir->get_frag_size() << " " << dir->pop_me << dendl;
dout(20) << type << " pop " << dir_pop << " spread " << pop_sp       << " " << dir->pop_spread.last[0]       << " " << dir->pop_spread.last[1]       << " " << dir->pop_spread.last[2]       << " " << dir->pop_spread.last[3]       << " in " << *dir << dendl;
dout(1) << "asok_command: " << command << " " << cmdmap   << " (starting...)" << dendl;
dout(1) << __func__      << ": received command from client without `tell` capability: "      << *m->get_connection()->peer_addrs << dendl;
dout(5) << "handle_mds_map old map epoch " << epoch << " <= "            << mdsmap->get_epoch() << ", discarding" << dendl;
dout(0) << "handle_mds_map mdsmap compatset " << mdsmap->compat     << " not writeable with daemon features " << mdsmap_compat     << ", killing myself" << dendl;
dout(10) << "map says I am mds." << whoami << "." << incarnation    << " state " << ceph_mds_state_name(new_state) << dendl;
dout(1) << "Map removed me " << oldinfo            << " from cluster;
respawning! See cluster/monitor logs for details." << dendl;
dout(10) <<  __func__ << ": initializing MDS rank "               << mds_rank->get_nodeid() << dendl;
dout(10) <<  __func__ << ": handling map as rank "             << mds_rank->get_nodeid() << dendl;
dout(1) << "suicide! Wanted state "          << ceph_mds_state_name(beacon.get_want_state()) << dendl;
dout(0) << "respawn execv " << orig_argv[0]   << " failed with " << cpp_strerror(errno) << dendl;
dout(0) << __FILE__ << "." << __LINE__ << ": filtered out request, peer=" \              << m->get_connection()->get_peer_type() << " allowing="   \              << #peers << " message=" << *m << dendl;
\    dout(10) << " new session " << s << " for " << s->info.inst      << " con " << con << dendl;
dout(10) << " existing session " << s << " for " << s->info.inst      << " existing con " << s->get_connection()      << ", new/authorizing con " << con << dendl;
dout(10) << " session connection " << s->get_connection()        << " -> " << con << dendl;
dout(10) << "check_cache rebuilt " << cached_snaps    << " seq " << seq    << " cached_seq " << cached_seq    << " cached_last_created " << cached_last_created    << " cached_last_destroyed " << cached_last_destroyed    << ")" << dendl;
dout(10) << "get_snaps " << cached_snaps    << " (seq " << srnode.seq << " cached_seq " << cached_seq << ")"    << dendl;
dout(10) << "split_at " << *child     << " on " << *child->inode << dendl;
dout(10) << "build_snap_trace prior_parent_snaps from [1," << *past.rbegin() << "] "        << info.prior_parent_snaps << dendl;
dout(5) << __func__ << ": waiting for " << expiry_gather.num_subs_created()            << " segments to expire" << dendl;
dout(5) << __func__ << ": expiry complete, expire_pos/trim_pos is now "            << std::hex << mdlog->get_journaler()->get_expire_pos() << "/"            << mdlog->get_journaler()->get_trimmed_pos() << dendl;
dout(5) << __func__ << ": trim complete, expire_pos/trim_pos is now "            << std::hex << mdlog->get_journaler()->get_expire_pos() << "/"            << mdlog->get_journaler()->get_trimmed_pos() << dendl;
dout(10) << __func__             << (throttled ? " (throttled)" : "")             << " trimmed " << count << " caps" << dendl;
dout(10) << __func__             << (throttled ? " (throttled)" : "")             << " recalled " << count << " caps" << dendl;
dout(0) << __func__ << ": mon command " << cmd << " failed with errno " << r     << " (" << outs << ")" << dendl;
dout(7) << "shutdown_pass=true, but still waiting for purge queue"                << dendl;
dout(7) << "shutdown_pass=true, finished w/ shutdown, moving to "                   "down:stopped" << dendl;
dout(0) << __FILE__ << "." << __LINE__ << ": filtered out request, peer=" << m->get_connection()->get_peer_type() \              << " allowing=" << #peers << " message=" << *m << dendl;
\ dout(5) << " mds." << from << " should be " << c << " "  << c->get_peer_addrs() << " but this message is "  << m->get_connection() << " " << m->get_source_addrs()  << dendl;
dout(5) << "got " << *m << " from old/bad/imposter mds " << m->get_source()  << ", but it's an mdsmap, looking at it" << dendl;
dout(5) << "got " << *m << " from down mds " << m->get_source()  << ", but it's a cache_expire, looking at it" << dendl;
dout(5) << "got " << *m << " from down/old/bad/imposter mds " << m->get_source()  << ", dropping" << dendl;
dout(20) << "get_session have " << session << " " << session->info.inst      << " state " << session->get_state_name() << dendl;
dout(10) << __func__ << " replacing connection bootstrap session "   << session << " with imported session " << imported_session   << dendl;
dout(10) << "send_message_client_counted " << session->info.inst.name << " seq "    << seq << " " << *m << dendl;
dout(0) << "boot_start encountered an error CEPHFS_EAGAIN"              << ", respawning since we fell behind journal" << dendl;
dout(1) << " waiting for osdmap " << mdsmap->get_last_failure_osd_epoch()     << " (which blocklists prior instance)" << dendl;
dout(1) << " waiting for osdmap " << mdsmap->get_last_failure_osd_epoch()       << " (which blocklists prior instance)" << dendl;
dout(4) << "reconnect_start: killed " << killed << " blocklisted sessions ("          << blocklist.size() << " blocklist entries, "          << sessionmap.get_sessions().size() << ")" << dendl;
dout(1) << " still have " << replay_queue.size() + (int)!replaying_requests_done     << " requests need to be replayed, " << server->get_num_pending_reclaim()     << " sessions need to be reclaimed" << dendl;
dout(15) << " peer " << m->get_source()      << " has mdsmap epoch >= " << epoch      << dendl;
dout(1) << "handle_mds_map i am now mds." << mds_gid << "." << incarnation       << " replaying mds." << whoami << "." << incarnation << dendl;
dout(1) << "handle_mds_map state change "     << ceph_mds_state_name(oldstate) << " --> "     << ceph_mds_state_name(state) << dendl;
dout(4) << "handle_osd_map epoch " << epoch << ", "          << newly_blocklisted.size() << " new blocklist entries" << dendl;
dout(1) << "session " << session_id << " was removed while we waited "      "for blocklist" << dendl;
dout(1) << "session " << session_id << " was removed while we waited "                 "for blocklist" << dendl;
dout(10) << file_recover_queue_size << " queued, "    << file_recover_queue_front_size << " prioritized, "    << file_recovering.size() << " recovering" << dendl;
dout(10) << "starting " << pi->size << " " << pi->client_ranges      << " " << *in << dendl;
dout(10) << "_recovered r=" << r << " size=" << size << " mtime=" << mtime    << " for " << *in << dendl;
//      pdout(10,g_conf()->debug_mds) << (mdsco_db_line_prefix(this))//                                 << "take_waiting mask " << hex << mask << dec << " took " << it->second//                                 << " tag " << hex << it->first << dec//                                 << " on " << *this//                                 << dendl;
//      pdout(10,g_conf()->debug_mds) << "take_waiting mask " << hex << mask << dec << " SKIPPING " << it->second//                                 << " tag " << hex << it->first << dec//                                 << " on " << *this //                                 << dendl;
dout(4) << "Writing pointer object '" << object_id << "': 0x"    << std::hex << front << ":0x" << back << std::dec << dendl;
dout(10) << " must xlock " << *lock << " " << *object     << ", waiting for cluster recovered" << dendl;
dout(15) << " will also auth_pin " << *object   << " in case we need to request a scatter" << dendl;
dout(20) << " must remote_wrlock on mds." << p.wrlock_target << " "        << *lock << " " << *object << dendl;
dout(15) << " will also auth_pin " << *object   << " in case we need to request a rdlock" << dendl;
dout(10) << " rejoin recovering " << *lock << " " << *lock->get_parent()       << ", waiting for cluster recovered" << dendl;
dout(10) << " next state is " << lock->get_state_name(next)       << " issued/allows loner " << gcap_string(loner_issued)      << "/" << gcap_string(lock->gcaps_allowed(CAP_LONER, next))      << " xlocker " << gcap_string(xlocker_issued)      << "/" << gcap_string(lock->gcaps_allowed(CAP_XLOCKER, next))      << " other " << gcap_string(other_issued)      << "/" << gcap_string(lock->gcaps_allowed(CAP_ANY, next))      << dendl;
dout(7) << "eval_gather finished gather on " << *lock     << " on " << *lock->get_parent() << dendl;
dout(7) << "eval_gather finished gather, but still rejoining "  << *lock->get_parent() << dendl;
dout(10) << "requesting rdlock from auth on "   << *lock << " on " << *lock->get_parent() << dendl;
dout(7) << "wrlock_force  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(10) << "requesting scatter from auth on "   << *lock << " on " << *lock->get_parent() << dendl;
dout(7) << "remote_wrlock_finish releasing remote wrlock on mds." << target   << " " << *lock->get_parent()  << dendl;
dout(7) << "issue_caps loner client." << loner     << " allowed=" << ccap_string(loner_allowed)      << ", xlocker allowed=" << ccap_string(xlocker_allowed)     << ", others allowed=" << ccap_string(all_allowed)     << " on " << *in << dendl;
dout(7) << "issue_caps allowed=" << ccap_string(all_allowed)      << ", xlocker allowed=" << ccap_string(xlocker_allowed)     << " on " << *in << dendl;
dout(20) << " client." << it->first      << " pending " << ccap_string(pending)       << " allowed " << ccap_string(allowed)       << " wanted " << ccap_string(wanted)      << dendl;
dout(7) << "   sending MClientCaps to client." << it->first  << " seq " << seq << " re-issue " << ccap_string(pending) << dendl;
dout(7) << "   sending MClientCaps to client." << it->first       << " seq " << seq << " new pending " << ccap_string(after)       << " was " << ccap_string(before) << dendl;
dout(7) << "request_inode_file_caps " << ccap_string(wanted)            << " was " << ccap_string(in->replica_caps_wanted)             << " on " << *in << " to mds." << auth << dendl;
dout(10) << "check_inode_max_size new_ranges " << new_ranges    << " update_size " << update_size    << " on " << *in << dendl;
dout(10) << "check_inode_max_size client_ranges "      << in->get_previous_projected_inode()->client_ranges      <<  " -> " << pi.inode->client_ranges << dendl;
dout(10) << " wanted " << ccap_string(cap->wanted())      << " -> " << ccap_string(wanted) << dendl;
dout(10) << " wanted " << ccap_string(cap->wanted())      << " -> " << ccap_string(wanted)      << " (added caps even though we had seq mismatch!)" << dendl;
dout(10) << " NOT changing wanted " << ccap_string(cap->wanted())      << " -> " << ccap_string(wanted)      << " (issue_seq " << issue_seq << " != last_issue "      << cap->get_last_issue() << ")" << dendl;
dout(7) << "handle_client_caps "   << " on " << m->get_ino()   << " tid " << m->get_client_tid() << " follows " << follows   << " op " << ceph_cap_op_name(op)   << " flags 0x" << std::hex << m->flags << std::dec << dendl;
dout(7) << "handle_client_caps already flushed tid " << m->get_client_tid()     << " for client." << client << dendl;
dout(7) << "handle_client_caps on unknown ino " << m->get_ino() << ", will try again after replayed client requests" << dendl;
dout(7) << "handle_client_caps mseq " << m->get_mseq() << " < " << cap->get_mseq()     << ", dropping" << dendl;
dout(7) << " flushsnap snap " << snap       << " client." << client << " on " << *in << dendl;
dout(10) << " follows " << follows      << " retains " << ccap_string(m->get_caps())      << " dirty " << ccap_string(dirty)      << " on " << *in << dendl;
dout(7) << " flush client." << client << " dirty " << ccap_string(dirty)       << " seq " << m->get_seq() << " on " << *in << dendl;
dout(7) << __func__ << " client." << client    << " doesn't have lease on " << *dn << dendl;
dout(7) << __func__ << " client." << client << " released lease on dn "  << dir->dirfrag() << "/" << dname << " which dne" << dendl;
dout(10) << __func__ << " client." << client << " " << ccap_string(caps) << " on " << *in    << (mdr ? "" : " (DEFERRED, no mdr)")    << dendl;
dout(10) << "kick_issue_caps released at current seq " << seq    << ", reissuing" << dendl;
dout(10) << "_do_snap_update dirty " << ccap_string(dirty)    << " follows " << follows << " snap " << snap    << " on " << *in << dendl;
dout(10) << " wow, the snap following " << follows      << " was already deleted.  nothing to record, just ack." << dendl;
dout(7) << " xattrs v" << i->xattr_version << " -> " << m->head.xattr_version     << " len " << m->xattrbl.length() << dendl;
dout(7) << "  ctime " << pi->ctime << " -> " << m->get_ctime()     << " for " << *in << dendl;
dout(7) << "  change_attr " << pi->change_attr << " -> " << m->get_change_attr()     << " for " << *in << dendl;
dout(7) << "  mtime " << pi->mtime << " -> " << mtime       << " for " << *in << dendl;
dout(7) << "  size " << pi->size << " -> " << size       << " for " << *in << dendl;
dout(7) << "  atime " << pi->atime << " -> " << atime       << " for " << *in << dendl;
dout(7) << "  time_warp_seq " << pi->time_warp_seq << " -> " << m->get_time_warp_seq()       << " for " << *in << dendl;
dout(7) << "  uid " << pi->uid       << " -> " << m->head.uid       << " for " << *in << dendl;
dout(7) << "  gid " << pi->gid       << " -> " << m->head.gid       << " for " << *in << dendl;
dout(7) << "  mode " << oct << pi->mode       << " -> " << m->head.mode << dec       << " for " << *in << dendl;
dout(7) << "  btime " << oct << pi->btime       << " -> " << m->get_btime() << dec       << " for " << *in << dendl;
dout(10) << "_do_cap_update dirty " << ccap_string(dirty)    << " issued " << ccap_string(cap ? cap->issued() : 0)    << " wanted " << ccap_string(cap ? cap->wanted() : 0)    << " on " << *in << dendl;
dout(10) << "client requests file_max " << m->get_max_size()   << " > max " << old_max << dendl;
dout(7) << "  max_size " << old_max << " -> " << new_max     << " for " << *in << dendl;
dout(1) << __func__ << " more than " << MAX_WARN_CAPS << " caps are late"          << "revoking, ignoring subsequent caps" << dendl;
dout(7) << "handle_client_lease client." << client       << " on " << *dn << dendl;
dout(7) << "handle_client_lease client." << client << " renew on " << *dn       << (!dn->lock.can_lease(client)?", revoking lease":"") << dendl;
dout(20) << "issue_client_lease seq " << lstat.seq << " dur " << lstat.duration_ms << "ms "      << " on " << *dn << dendl;
dout(7) << "handle_reqrdlock got rdlock request on " << *lock     << " on " << *parent << dendl;
dout(7) << "handle_reqrdlock dropping rdlock request on " << *lock     << " on " << *parent << dendl;
dout(10) << "handle_simple_lock " << *m    << " on " << *lock << " " << *lock->get_parent() << dendl;
dout(7) << "handle_simple_lock still rejoining " << *lock->get_parent()       << ", dropping " << *m << dendl;
dout(7) << "handle_simple_lock " << *lock << " on " << *lock->get_parent() << " from " << from       << ", still gathering " << lock->get_gather_set() << dendl;
dout(7) << "handle_simple_lock " << *lock << " on " << *lock->get_parent() << " from " << from       << ", last one" << dendl;
dout(7) << "simple_eval stable, going to excl " << *lock      << " on " << *lock->get_parent() << dendl;
dout(7) << "simple_eval stable, syncing " << *lock      << " on " << *lock->get_parent() << dendl;
dout(10) << "scatter_eval scatter_wanted, bump to mix " << *lock      << " on " << *lock->get_parent() << dendl;
dout(10) << "mark_updated_scatterlock " << *lock      << " - already on list since " << lock->get_update_stamp() << dendl;
dout(10) << "mark_updated_scatterlock " << *lock      << " - added at " << now << dendl;
dout(10) << "scatter_nudge replica, requesting scatter/unscatter of "       << *lock << " on " << *p << dendl;
dout(10) << " removing from updated_scatterlocks "         << *lock << " " << *lock->get_parent() << dendl;
dout(10) << "scatter_tempsync " << *lock    << " on " << *lock->get_parent() << dendl;
dout(7) << "local_wrlock_grab  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(7) << "local_wrlock_start  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(7) << "local_wrlock_finish  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(7) << "local_xlock_start  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(7) << "local_xlock_finish  on " << *lock   << " on " << *lock->get_parent() << dendl;
dout(7) << "file_eval wanted=" << gcap_string(wanted)   << " loner_wanted=" << gcap_string(loner_wanted)   << " other_wanted=" << gcap_string(other_wanted)   << "  filelock=" << *lock << " on " << *lock->get_parent()   << dendl;
dout(7) << "file_eval loner_issued=" << gcap_string(loner_issued)            << " other_issued=" << gcap_string(other_issued)     << " xlocker_issued=" << gcap_string(xlocker_issued)     << dendl;
dout(7) << "file_eval stable, bump to loner " << *lock     << " on " << *lock->get_parent() << dendl;
dout(7) << "file_eval stable, bump to mixed " << *lock     << " on " << *lock->get_parent() << dendl;
dout(7) << "file_eval stable, bump to sync " << *lock      << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock still rejoining " << *in       << ", dropping " << *m << dendl;
dout(7) << "handle_file_lock a=" << lock->get_lock_action_name(m->get_action())   << " on " << *lock   << " from mds." << from << " "    << *in << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", still gathering " << lock->get_gather_set() << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", last one" << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", still gathering " << lock->get_gather_set() << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", last one" << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", still gathering " << lock->get_gather_set() << dendl;
dout(7) << "handle_file_lock " << *in << " from " << from       << ", last one" << dendl;
dout(7) << "handle_file_lock got scatter request on " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock got scatter request, !stable, marking scatter_wanted on " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock got unscatter request on " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock ignoring unscatter request on " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock IGNORING nudge on non-auth " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock IGNORING nudge on non-replicated " << *lock       << " on " << *lock->get_parent() << dendl;
dout(7) << "handle_file_lock trying nudge on " << *lock       << " on " << *lock->get_parent() << dendl;
dout(10) << ": sending ping with sequence=" << last_seq << " to rank="           << rank << dendl;
dout(10) << ": received pong from rank=" << rank << " to which ping was never"             << " sent (ignoring...)." << dendl;
dout(10) << ": pong received for unknown ping sequence " << seq             << ", rank " << rank << " should catch up soon." << dendl;
dout(5) << ": rank=" << rank << " is lagging a pong response (last ack time is "            <<  it->second.last_acked_time << ")" << dendl;
dout(0) << "got commit for tid " << tid << " <= " << version     << ", already committed, sending ack." << dendl;
dout(10) << __func__ << " session auth_name " << session->info.auth_name        << " != target auth_name " << target->info.auth_name << dendl;
dout(10) << "old push seq " << m->get_seq() << " < " << session->get_push_seq()    << ", dropping" << dendl;
dout(0) << "old push seq " << m->get_seq() << " != " << session->get_push_seq()  << ", BUGGY!" << dendl;
dout(10) << "_session_logged " << session->info.inst    << " state_seq " << state_seq    << " " << (open ? "open":"close") << " " << pv    << " inos_to_free " << inos_to_free << " inotablev " << piv    << " inos_to_purge " << inos_to_purge << dendl;
dout(10) << " journaled state_seq " << state_seq << " != current " << session->get_state_seq()      << ", noop" << dendl;
dout(10) << "prepare_force_open_sessions " << pv     << " on " << cm.size() << " clients"    << dendl;
dout(10) << " ignoring blocklisted client." << p->first       << " (" <<  p->second.addr << ")" << dendl;
dout(10) << "finish_force_open_sessions on " << smap.size() << " clients,"    << " initial v " << mds->sessionmap.get_version() << dendl;
dout(10) << " last cleared laggy " << last_cleared_laggy << "s ago (< cutoff " << cutoff      << "), not marking any client stale" << dendl;
dout(20) << "laggiest active session is " << session->info.inst   << " and renewed caps recently (" << last_cap_renew_span << "s ago)" << dendl;
dout(20) << "laggiest active session is " << session->info.inst     << " and renewed caps recently (" << last_cap_renew_span << "s ago)" << dendl;
dout(20) << "evicting session " << session->info.inst << " since autoclose "      "has arrived" << dendl;
dout(20) << "deferring marking session " << session->info.inst << " stale "      "since it holds no caps" << dendl;
dout(10) << "skipping session " << session->info.inst     << ", infinite timeout specified" << dendl;
dout(10) << "skipping session " << session->info.inst     << ", timeout (" << timeout << ") specified"     << " and renewed caps recently (" << last_cap_renew_span << "s ago)" << dendl;
dout(10) << "new stale session " << session->info.inst   << " last renewed caps " << last_cap_renew_span << "s ago" << dendl;
dout(20) << "oldest stale session is " << session->info.inst   << " and recently renewed caps " << last_cap_renew_span << "s ago" << dendl;
dout(10) << "autoclosing stale session " << session->info.inst      << " last renewed caps " << last_cap_renew_span << "s ago" << dendl;
dout(1) << __func__ << ": evicting cap revoke non-responder client id "            << client << dendl;
dout(20) << __func__ << " cap revoke eviction timeout changed to "            << cap_revoke_eviction_timeout << dendl;
dout(20) << __func__ << " max snapshots per directory changed to "            << max_snaps_per_dir << dendl;
dout(10) << __func__ << " : "    << session->info.inst    << " pending_prealloc_inos " << session->pending_prealloc_inos    << " free_prealloc_inos " << session->free_prealloc_inos    << " delegated_inos " << session->delegated_inos << dendl;
dout(7) << "handle_client_reconnect " << m->get_source()   << (m->has_more() ? " (more)" : "") << dendl;
dout(15) << "open snaprealm (w/o inode) on " << inodeno_t(r.realm.ino)        << " seq " << r.realm.seq << dendl;
dout(15) << "open cap realm " << inodeno_t(p.second.capinfo.snaprealm)        << " on " << *in << dendl;
dout(7) << "reconnect_tick: last seen " << elapse2            << " seconds ago, extending reconnect interval" << dendl;
dout(7) << "reconnect timed out, " << remaining_sessions.size()          << " clients have not reconnected in time" << dendl;
dout(1) << "reconnect keeps " << session->info.inst       << ", need to be reclaimed" << dendl;
dout(7) << __func__ << ":"           << " min=" << min_caps_per_client           << " max=" << max_caps_per_client           << " total=" << Capability::count()           << " flags=" << flags           << dendl;
dout(10) << __func__ << ":"             << " session " << session->info.inst      << " caps " << num_caps      << ", leases " << session->leases.size()      << dendl;
dout(15) << "  2*session_release < session_recall"                      " (2*" << session_release << " < " << session_recall << ") &&"                      " 2*session_recall < recall_max_decay_threshold"                      " (2*" << session_recall << " > " << recall_max_decay_threshold << ")"                      " Skipping because we are unlikely to get more released." << dendl;
dout(15) << "  2*recall < session_recall "                      " (2*" << recall << " < " << session_recall << ") &&"                      " recall < recall_max_caps (" << recall << " < " << recall_max_caps << ");
"  dout(10) << "early_reply " << reply->get_result()     << " (" << cpp_strerror(reply->get_result())    << ") " << *req << dendl;
dout(7) << "reply_client_request " << reply->get_result()    << " (" << cpp_strerror(reply->get_result())    << ") " << *req << dendl;
dout(10) << " completed request which created new inode " << created   << ", convert it to lookup request" << dendl;
dout(7) << __func__ << ": full = " << is_full << " epoch = "       << o.get_epoch() << dendl;
dout(10) << "local request " << *mdr << " attempt " << mdr->attempt << " > " << m->get_attempt()        << ", dropping " << *m << dendl;
dout(10) << "local request " << *mdr << " attempt " << mdr->attempt << " < " << m->get_attempt()        << ", closing out" << dendl;
dout(10) << "missing peer request for " << m->get_reqid()        << " OP_FINISH, must have lost race with a forward" << dendl;
dout(10) << "handle_peer_request_reply ignoring peer reply from mds."        << from << " reqid " << r << dendl;
dout(10) << "handle_peer_request_reply " << *mdr << " ignoring reply from other attempt "      << m->get_attempt() << dendl;
dout(10) << "not auth for remote xlock attempt, dropping on "    << *lock << " on " << *lock->get_parent() << dendl;
dout(10) << "prepare_new_inode used_prealloc " << mdr->used_prealloc_ino      << " (" << mdr->session->info.prealloc_inos.size() << " left)"      << dendl;
dout(20) << "journal_allocated_inos sessionmapv " << mds->sessionmap.get_projected()    << " inotablev " << mds->inotable->get_projected_version()    << dendl;
dout(10) << "apply_allocated_inos " << mdr->alloc_ino    << " / " << mdr->prealloc_inos    << " / " << mdr->used_prealloc_ino << dendl;
dout(7) << "try_open_auth_dirfrag: not auth for " << *dir << ", fw to mds." << auth << dendl;
dout(10) << "open flags = " << flags    << ", filemode = " << cmode    << ", need_auth = " << need_auth    << dendl;
dout(10) << " waiting for pending truncate from " << pi->truncate_from        << " to " << pi->truncate_size << " to complete on " << *cur << dendl;
dout(12) << "open issued caps " << ccap_string(cap->pending())   << " for " << req->get_source()   << " on " << *cur << dendl;
dout(12) << "open issued IMMUTABLE SNAP caps " << ccap_string(caps)        << " for " << req->get_source()        << " snapid " << mdr->snapid        << " on " << *cur << dendl;
dout(20) << "readdir throttled. max_caps_per_client: " << max_caps_per_client << " num_caps: " << num_caps        << " session_cap_acquistion: " << session_cap_acquisition << " cap_acquisition_throttle: " << cap_acquisition_throttle << dendl;
dout(10) << " frag " << fg << " offset '" << offset_str << "'"    << " offset_hash " << offset_hash << " flags " << req_flags << dendl;
dout(10) << " open remote dentry after caps were issued, stopping at "     << dnbl.length() << " < " << bytes_left << dendl;
dout(10) << "reply to " << *req << " readdir num=" << numfiles    << " bytes=" << dirbl.length()    << " start=" << (int)start    << " end=" << (int)end    << dendl;
dout(10) << "got unknown lock type " << set_lock.type      << ", dropping request!" << dendl;
dout(10) << " waiting for pending truncate from " << pip->truncate_from        << " to " << pip->truncate_size << " to complete on " << *cur << dendl;
dout(10) << " client_ranges "  << cur->get_previous_projected_inode()->client_ranges        << " -> " << pi.inode->client_ranges << dendl;
dout(10) << "handle_set_vxattr " << name           << " val " << value.length()           << " bytes on " << *cur           << dendl;
dout(10) << "xattr kv pairs size too big. cur_xattrs_size " << cur_xattrs_size << ", inc " << inc << dendl;
dout(7) << "handle_client_link " << req->get_filepath()   << " to " << req->get_filepath2()   << dendl;
dout(10) << "_link_remote "     << (inc ? "link ":"unlink ")    << *dn << " to " << *targeti << dendl;
dout(10) << "_link_remote_finish "    << (inc ? "link ":"unlink ")    << *dn << " to " << *targeti << dendl;
dout(10) << "handle_peer_link_prep " << *mdr    << " on " << mdr->peer_request->get_object_info()    << dendl;
dout(10) << "_logged_peer_link " << *mdr    << " " << *targeti << dendl;
dout(10) << "_commit_peer_link " << *mdr    << " r=" << r    << " " << *targeti << dendl;
dout(10) << "do_link_rollback on " << rollback.reqid     << (rollback.was_inc ? " inc":" dec")     << " ino " << rollback.ino    << dendl;
dout(10) << "handle_peer_link_prep_ack " << *mdr    << " " << *m << dendl;
dout(10) << "handle_peer_rmdir_prep " << *mdr    << " " << mdr->peer_request->srcdnpath    << " to " << mdr->peer_request->destdnpath    << dendl;
dout(10) << "handle_peer_rmdir_prep_ack " << *mdr    << " " << *ack << dendl;
dout(10) << "dir_is_nonempty_unlocked dirstat has "    << dir->get_projected_fnode()->fragstat.size() << " items " << *dir << dendl;
dout(10) << "dir_is_nonempty dirstat has "        << pf->fragstat.size() << " items " << *dir << dendl;
dout(10) << " frag " << dir->get_frag() << " contains (maybe) auth subtree, will force journal "       << *subtree << dendl;
dout(10) << "handle_peer_rename_prep " << *mdr    << " " << mdr->peer_request->srcdnpath    << " to " << mdr->peer_request->destdnpath    << dendl;
dout(10) << " still waiting for rename notify acks from "        << mdr->more()->waiting_on_peer << dendl;
dout(10) << "handle_peer_rename_prep_ack " << *mdr    << " witnessed by " << ack->get_source()    << " " << *ack << dendl;
dout(10) << "handle_peer_rename_notify_ack " << *mdr << " from mds."    << ack->get_source() << dendl;
dout(10) << " still waiting for rename notify acks from "        << mdr->more()->waiting_on_peer << dendl;
dout(10) << " still waiting for rename notify acks from " << mdr->more()->waiting_on_peer << dendl;
mantle_dout(ceph::dout::need_dynamic(level)) << lua_tostring(L, 2)            << mantle_dendl;
mantle_dout(0) << "WARNING: mantle could not load balancer: "            << lua_tostring(L, -1) << mantle_dendl;
mantle_dout(0) << "WARNING: mantle could not execute script: "            << lua_tostring(L, -1) << mantle_dendl;
dout(10) << "submit_entry also starting new segment: last = "      << ls->seq  << "/" << ls->offset << ", event seq = " << event_seq << dendl;
dout(5) << "_submit_thread " << write_pos << "~" << bl.length()       << " : " << *le << dendl;
dout(10) << "trim "     << segments.size() << " / " << max_segments << " segments, "     << num_events << " / " << max_events << " events"    << ", " << expiring_segments.size() << " (" << expiring_events << ") expiring"    << ", " << expired_segments.size() << " (" << expired_events << ") expired"    << dendl;
dout(5) << "trim segment " << ls->seq << "/" << ls->offset << ", not fully flushed yet, safe "       << journaler->get_write_safe_pos() << " < end " << ls->end << dendl;
dout(5) << "trim already expiring segment " << ls->seq << "/" << ls->offset       << ", " << ls->num_events << " events" << dendl;
dout(5) << "trim already expired segment " << ls->seq << "/" << ls->offset       << ", " << ls->num_events << " events" << dendl;
dout(10) << __func__ << ": "    << segments.size()           << "/" << expiring_segments.size()           << "/" << expired_segments.size() << dendl;
dout(5) << "trim already expiring segment " << ls->seq << "/" << ls->offset       << ", " << ls->num_events << " events" << dendl;
dout(5) << "trim already expired segment " << ls->seq << "/" << ls->offset       << ", " << ls->num_events << " events" << dendl;
dout(10) << "_maybe_expired segment " << ls->seq << "/" << ls->offset    << ", " << ls->num_events << " events" << dendl;
dout(10) << "_trim_expired_segments waiting for " << ls->seq << "/" << ls->offset        << " to expire" << dendl;
dout(10) << "_trim_expired_segments open file table committedseq " << oft_committed_seq        << " <= " << ls->seq << "/" << ls->offset << dendl;
dout(10) << "_trim_expired_segments trimming expired "      << ls->seq << "/0x" << std::hex << ls->offset << std::dec << dendl;
dout(5) << "_expired segment " << ls->seq << "/" << ls->offset   << ", " << ls->num_events << " events" << dendl;
dout(5) << "_expired not expiring " << ls->seq << "/" << ls->offset     << ", last one and !capped" << dendl;
dout(10) << "replay start, from " << journaler->get_read_pos()    << " to " << journaler->get_write_pos() << dendl;
dout(0) << "Configuration value for mds_journal_format is out of bounds, max is "              << JOURNAL_FORMAT_MAX << dendl;
dout(1) << "Journal " << jp.front << " is being rewritten, "        << "cannot replay in standby until an active MDS completes rewrite" << dendl;
dout(0) << "Journal " << jp.front << " is in unknown format " << front_journal->get_stream_format()            << ", does this MDS daemon require upgrade?" << dendl;
dout(1) << "Journal " << jp.front << " has old format "      << front_journal->get_stream_format() << ", it will now be updated" << dendl;
dout(20) << __func__ << " discovered segment seq mapping "            << le_pos << " -> " << new_journal->get_write_pos() << dendl;
dout(20) << __func__ << " zeroing expire_pos in subtreemap event at "          << le_pos << " seq=" << sle.event_seq << dendl;
dout(1) << __func__ << " transcribing un-decodable LogEvent at old position "        << old_journal->get_read_pos() << ", new position " << new_journal->get_write_pos()        << dendl;
dout(1) << "Journal header went away while in standby replay, journal rewritten?"                      << dendl;
dout(0) << "got error while reading head: " << cpp_strerror(err)                        << dendl;
dout(0) << "_replay " << pos << "~" << bl.length() << " / " << journaler->get_write_pos()        << " -- unable to decode event" << dendl;
dout(10) << "_replay " << pos << "~" << bl.length() << " / " << journaler->get_write_pos()         << " " << le->get_stamp() << " -- waiting for subtree_map.  (skipping " << *le << ")" << dendl;
dout(10) << "_replay " << pos << "~" << bl.length() << " / " << journaler->get_write_pos()         << " " << le->get_stamp() << ": " << *le << dendl;
dout(10) << "_replay - complete, " << num_events      << " events" << dendl;
dout(10) << " segment seq=" << seg->seq << " " << seg->offset <<      "~" << seg->end - seg->offset << dendl;
dout(1) << "Purge Queue not found, assuming this is an upgrade and "                 "creating it." << dendl;
dout(20) << ops_in_flight << "/" << max_purge_ops << " ops, "           << in_flight.size() << "/" << g_conf()->mds_max_purge_files           << " files" << dendl;
dout(20) << "Throttling on op limit " << ops_in_flight << "/"             << max_purge_ops << dendl;
dout(20) << "Throttling on item limit " << in_flight.size()             << "/" << cct->_conf->mds_max_purge_files << dendl;
dout(10) << " 0~" << item.size << " objects 0~" << num               << " snapc " << item.snapc << " on " << item.ino << dendl;
dout(10) << " remove backtrace object " << oid               << " pool " << oloc.pool << " snapc " << item.snapc << dendl;
dout(10) << " remove backtrace object " << oid               << " old pool " << p << " snapc " << item.snapc << dendl;
dout(10) << " 0~" << item.size << " objects 0~" << num      << " snapc " << item.snapc << " on " << item.ino << dendl;
dout(10) << "left purge items in journal: " << item_num     << " (purge_item_journal_size/write_pos/read_pos/expire_pos) now at "     << "(" << purge_item_journal_size << "/" << write_pos << "/" << read_pos     << "/" << expire_pos << ")" << dendl;
dout(4) << "maybe start work again (max_purge_files="              << g_conf()->mds_max_purge_files << dendl;
dout(10) << p->first << " " << p->second      << " state " << p->second->get_state_name()      << " completed " << p->second->info.completed_requests      << " free_prealloc_inos " << p->second->free_prealloc_inos      << " delegated_inos " << p->second->delegated_inos      << dendl;
dout(10) << __func__ << ": continue omap load from '"             << last_key << "'" << dendl;
dout(10) << __func__ << ": v " << version     << ", " << session_map.size() << " sessions" << dendl;
dout(10) << "_load_finish v " << version     << ", " << session_map.size() << " sessions, "    << bl.length() << " bytes"    << dendl;
dout(20) << __func__ << " s=" << s << " name=" << s->info.inst.name    << " v=" << version << dendl;
dout(20) << __func__ << " s=" << s << " name=" << s->info.inst.name    << " v=" << version << dendl;
dout(20) << __func__ << " s=" << s << " name=" << s->info.inst.name    << " pv=" << projected << " -> " << projected + 1 << dendl;
dout(10) << "stray agree on " << reqid << " tid " << tid        << ", already committing, will resend COMMIT" << dendl;
dout(10) << "stray agree on " << reqid << " tid " << tid        << ", sending ROLLBACK" << dendl;
ldout(cct, 10) << __func__ << " inode(path /" << inode_path     << " owner " << inode_uid << ":" << inode_gid     << " mode 0" << std::oct << inode_mode << std::dec     << ") by caller " << caller_uid << ":" << caller_gid// << "[" << caller_gid_list << "]";
dout(10) << "try_to_expire saving inotable table, need " << inotablev       << ", committed is " << mds->inotable->get_committed_version()       << " (" << mds->inotable->get_committing_version() << ")"       << dendl;
dout(10) << "try_to_expire saving sessionmap, need " << sessionmapv        << ", committed is " << mds->sessionmap.get_committed()       << " (" << mds->sessionmap.get_committing() << ")"       << dendl;
dout(10) << "try_to_expire " << get_mdstable_name(p->first) << " transaction " << *q         << " pending commit (not yet acked), waiting" << dendl;
dout(10) << "try_to_expire waiting for " << get_mdstable_name(p->first)         << " to save, need " << p->second << dendl;
dout(20) << "EMetaBlob::add_dir_context(" << dir << ") reached unambig auth subtree, don't need " << maybe       << " at " << *dir << dendl;
dout(20) << "EMetaBlob::add_dir_context(" << dir << ") reached ambig or !auth subtree, need " << maybe     << " at " << *dir << dendl;
dout(20) << "EMetaBlob::add_dir_context(" << dir << ") already have diri in this segment ("    << diri->last_journaled << " >= " << last_subtree_map << "), setting maybenot flag "   << *diri << dendl;
dout(10) << "EMetaBlob::fullbit::update_inode dft " << in->dirfragtree << " -> "        << dirfragtree << " on " << *in << dendl;
dout(0) << "EMetaBlob.replay invalid layout on ino " << *in              << ": " << in->get_inode()->layout << dendl;
dout(10) << "EMetaBlob.replay noting " << get_mdstable_name(p.first)      << " transaction " << p.second << dendl;
dout(10) << "EMetaBlob.replay inotable tablev " << inotablev        << " <= table " << mds->inotable->get_version() << dendl;
dout(10) << "EMetaBlob.replay inotable v " << inotablev        << " - 1 == table " << mds->inotable->get_version()        << " allocated+used " << allocated_ino        << " prealloc " << preallocated_inos        << dendl;
dout(10) << "EMetaBlob.replay sessionmap v " << sessionmapv        << " <= table " << mds->sessionmap.get_version() << dendl;
dout(10) << "EMetaBlob.replay sessionmap v " << sessionmapv        << " - " << diff << " == table " << mds->sessionmap.get_version()        << " prealloc " << preallocated_inos        << " used " << used_preallocated_ino        << dendl;
dout(10) << "EPurged.replay inotable " << mds->inotable->get_version()        << " >= " << inotablev << ", noop" << dendl;
dout(10) << "EPurged.replay inotable " << mds->inotable->get_version()        << " < " << inotablev << " " << dendl;
dout(10) << "ESession.replay sessionmap " << mds->sessionmap.get_version()       << " >= " << cmapv << ", noop" << dendl;
dout(10) << "ESession.replay sessionmap " << mds->sessionmap.get_version()      << " < " << cmapv << " " << (open ? "open":"close") << " " << client_inst << dendl;
dout(10) << "ESession.replay inotable " << mds->inotable->get_version()        << " >= " << inotablev << ", noop" << dendl;
dout(10) << "ESession.replay inotable " << mds->inotable->get_version()        << " < " << inotablev << " " << (open ? "add":"remove") << dendl;
dout(10) << "ESessions.replay sessionmap " << mds->sessionmap.get_version()      << " >= " << cmapv << ", noop" << dendl;
dout(10) << "ESessions.replay sessionmap " << mds->sessionmap.get_version()      << " < " << cmapv << dendl;
dout(10) << "ETableServer.replay " << get_mdstable_name(table)      << " " << get_mdstableserver_opname(op)      << " event " << version      << " <= table " << server->get_version() << dendl;
dout(10) << " ETableServer.replay " << get_mdstable_name(table)    << " " << get_mdstableserver_opname(op)    << " event " << version << " - 1 == table " << server->get_version() << dendl;
dout(10) << " ETableClient.replay " << get_mdstable_name(table)    << " op " << get_mdstableserver_opname(op)    << " tid " << tid << dendl;
dout(10) << "ESnap.replay event " << version      << " <= table " << mds->snaptable->get_version() << dendl;
dout(10) << " ESnap.replay event " << version    << " - 1 == table " << mds->snaptable->get_version() << dendl;
dout(10) << "EUpdate.replay sessionmap v " << cmapv        << " <= table " << mds->sessionmap.get_version() << dendl;
dout(10) << "EUpdate.replay sessionmap " << mds->sessionmap.get_version()        << " < " << cmapv << dendl;
dout(10) << "EPeerUpdate.replay prepare " << reqid << " for mds." << leader      << ": applying commit, saving rollback info" << dendl;
dout(10) << "EPeerUpdate.replay abort " << reqid << " for mds." << leader      << ": applying rollback commit blob" << dendl;
dout(10) << "EImportStart.replay sessionmap " << mds->sessionmap.get_version()       << " >= " << cmapv << ", noop" << dendl;
dout(10) << "EImportStart.replay sessionmap " << mds->sessionmap.get_version()       << " < " << cmapv << dendl;
dout(10) << "EImportFinish.replay " << base << " success=" << success      << " on subtree not marked as ambiguous"       << dendl;
dout(20) << __func__ << " applying segment seq mapping "        << p.second << " -> " << q->second << dendl;
dout(20) << __func__ << " no segment seq mapping found for "        << p.second << dendl;
dout(10) << "save v " << version << " - already saving "      << committing_version << " >= needed " << v << dendl;
dout(10) << ": metric lus=" << lus << ", last_updated_seq=" << last_updated_seq             << dendl;
dout(20) << ": current sequence number " << next_seq << ", setting next sequence number "           << seq << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(CapInfoPayload::METRIC_TYPE)    << ", session=" << session << ", hits=" << payload.cap_hits << ", misses="    << payload.cap_misses << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(ReadLatencyPayload::METRIC_TYPE)    << ", session=" << session << ", latency=" << payload.lat << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(WriteLatencyPayload::METRIC_TYPE)    << ", session=" << session << ", latency=" << payload.lat << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(MetadataLatencyPayload::METRIC_TYPE)    << ", session=" << session << ", latency=" << payload.lat << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(DentryLeasePayload::METRIC_TYPE)    << ", session=" << session << ", hits=" << payload.dlease_hits << ", misses="    << payload.dlease_misses << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(OpenedFilesPayload::METRIC_TYPE)           << ", session=" << session << ", opened_files=" << payload.opened_files           << ", total_inodes=" << payload.total_inodes << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(PinnedIcapsPayload::METRIC_TYPE)           << ", session=" << session << ", pinned_icaps=" << payload.pinned_icaps           << ", total_inodes=" << payload.total_inodes << dendl;
dout(20) << ": type=" << static_cast<ClientMetricType>(OpenedInodesPayload::METRIC_TYPE)           << ", session=" << session << ", opened_inodes=" << payload.opened_inodes           << ", total_inodes=" << payload.total_inodes << dendl;
dout(20) << ": sending metric updates for " << update_client_metrics_map.size()           << " clients to rank 0 (address: " << *addr_rank0 << ") with sequence number "           << next_seq << ", last updated sequence number " << last_updated_seq << dendl;
dout(10) << __func__ << ": purging this dentry immediately: "    << *dn << dendl;
dout(20) << "  directory has past parents "   << in->snaprealm << dendl;
dout(20) << " file has past parents "        << in->snaprealm << dendl;
dout(7) << "exporting to mds." << dest            << " empty import " << *dir << dendl;
dout(10) << "cleaning up export state (" << p->second.state << ")"        << get_export_statename(p->second.state) << " of " << *dir << dendl;
dout(10) << "faking export_warning_ack from mds." << who     << " on " << *dir << " to mds." << p->second.peer     << dendl;
dout(10) << "faking export_notify_ack from mds." << who   << " on " << *dir << " to mds." << p->second.peer   << dendl;
dout(10) << "cleaning up import state (" << q->second.state << ")"   << get_import_statename(q->second.state) << " of " << *dir << dendl;
dout(10) << "cleaning up import state (" << q->second.state << ")"   << get_import_statename(q->second.state) << " of " << df << dendl;
dout(10) << "faking export_notify_ack from mds." << who     << " on aborting import " << *dir << " from mds." << q->second.peer     << dendl;
dout(10) << " importing from " << p->second.peer        << ": (" << p->second.state << ") " << get_import_statename(p->second.state)        << " " << p->first << " " << *dir << dendl;
dout(10) << " importing from " << p->second.peer        << ": (" << p->second.state << ") " << get_import_statename(p->second.state)        << " " << p->first << dendl;
dout(10) << " exporting to " << state.peer      << ": (" << state.state << ") " << get_export_statename(state.state)      << " " << dir->dirfrag() << " " << *dir << dendl;
dout(7) << "subtree's children all are under exporting, retry rest parts of parent export "     << parent->dirfrag << dendl;
dout(7) << "from " << m->get_source()   << " on " << *dir << dendl;
dout(7) << "export_dir couldn't acquire all needed locks, failing. "     << *dir << dendl;
dout(7) << p.first     << " exported caps on " << *in << dendl;
dout(7) << "from " << m->get_source()       << ": exporting, processing warning on " << *dir << dendl;
dout(7) << "from " << m->get_source()       << ": exporting, processing notify on " << *dir << dendl;
dout(7) << "from " << m->get_source()       << ": cancelling export, processing notify on " << *dir << dendl;
dout(7) << "from " << m->get_source()   << ": aborting import on " << *dir << dendl;
dout(7) << old_auth << " -> " << new_auth     << " on missing dir " << m->get_dirfrag() << dendl;
dout(7) << "old_auth was " << dir->authority()      << " != " << old_auth << " -> " << new_auth     << " on " << *dir << dendl;
dout(7) << old_auth << " -> " << new_auth     << " on " << *dir << dendl;
dout(10) << *ack << " from "      << ack->get_source() << " on " << *in << dendl;
dout(7) << " telling client." << it.first       << " exported caps on " << *in << dendl;
dout(10) << *m << " from " << m->get_source()           << " on " << *in << dendl;
dout(3) << "check_rstats " << (scrub ? "(scrub) " : "")            << "bailing out -- incomplete or non-auth or frozen dir on "             << *this << dendl;
dout(1) << "get_num_head_items() = " << get_num_head_items()             << ";
fnode.fragstat.nfiles=" << fnode->fragstat.nfiles    dout(20) << "get_num_head_items() = " << get_num_head_items()             << ";
fnode.fragstat.nfiles=" << fnode->fragstat.nfiles    dout(10) << " rstat " << _fnode->rstat << " fragstat " << _fnode->fragstat      << " on " << *f << dendl;
dout(10) << " giving rstatdiff " << rstatdiff << " fragstatdiff" << fragstatdiff        << " to " << *subfrags[0] << dendl;
dout(10) << __func__ << " dentry " << dname    << " snap " << snapid    << " " << c << " on " << *this << dendl;
dout(10) << __func__ << " " << dname      << " [" << first << "," << last << "] found waiter on snap "      << it->first.snapid      << " on " << *this << dendl;
dout(10) << "take_waiting dentry " << p.first.name        << " snap " << p.first.snapid << " on " << *this << dendl;
dout(20) << "_fetched pos " << pos << " marker '" << type << "' dname '" << dname           << " [" << first << "," << last << "]"           << dendl;
dout(0) << "_fetched  badness: got (but i already had) " << *in                << " mode " << in->get_inode()->mode                << " mtime " << in->get_inode()->mtime << dendl;
dout(10) << "_fetched header " << hdrbl.length() << " bytes "    << omap.size() << " keys for " << *this << dendl;
dout(10) << " snap_purged_thru " << fnode->snap_purged_thru      << " < " << realm->get_last_destroyed()      << ", snap purge based on " << *snaps << dendl;
dout(10) << " snap_purged_thru " << fnode->snap_purged_thru      << " < " << realm->get_last_destroyed()      << ", snap purge based on " << *snaps << dendl;
//dout(10) << "is_subtree_root false " << dir_auth << " != " << CDIR_AUTH_DEFAULT    //<< " on " << ino() << dendl;
//dout(10) << "is_subtree_root true " << dir_auth << " != " << CDIR_AUTH_DEFAULT    //<< " on " << ino() << dendl;
dout(10) << "setting dir_auth=" << a    << " from " << dir_auth    << " on " << *this << dendl;
dout(15) << __func__ << " " << dirinc << " on " << *this    << " by " << by << " count now "    << auth_pins << "/" << dir_auth_pins << dendl;
dout(1) << "discarding unexpected beacon reply " << ceph_mds_state_name(m->get_state())     << " seq " << m->get_seq() << " dne" << dendl;
dout(20) << __func__ << ": awaiting " << awaiting_seq           << " for up to " << duration << "s" << dendl;
dout(5) << __func__ << ": "      << ceph_mds_state_name(want_state) << " -> "      << ceph_mds_state_name(newstate) << dendl;
dout(2) << "Session " << *session <<             " is not releasing caps fast enough. Recalled caps at " << recall_caps          << " > " << recall_warning_threshold << " (mds_recall_warning_threshold)." << dendl;
dout(10) << __func__ << (early ? " (early) " : " ")      << next_snaprealm << " seq " << next_snaprealm->seq << dendl;
dout(0) << "have open dirfrag " << p.first << " but not leaf in " << dirfragtree       << ": " << *p.second << dendl;
dout(0) << "have open dirfrag " << p.first << " but not leaf in " << dirfragtree       << ": " << *p.second << dendl;
dout(10) << " magic is '" << magic << "' (expecting '"             << CEPH_FS_ONDISK_MAGIC << "')" << dendl;
dout(0) << "on disk magic '" << magic << "' != my magic '" << CEPH_FS_ONDISK_MAGIC              << "'" << dendl;
dout(4) << __func__ << " got CEPHFS_ENOENT: a data pool was deleted "                 "beneath us!" << dendl;
dout(10) << fg << " first " << dir->first << " -> " << fgfirst               << " on " << *dir << dendl;
dout(10) << fg << " first " << dir->first << " -> " << fgfirst                 << " on " << *dir << dendl;
dout(10) << fg << " first " << dir->first << " -> " << fgfirst               << " on " << *dir << dendl;
dout(10) << fg << " first " << dir->first << " -> " << fgfirst                 << " on " << *dir << dendl;
dout(10) << __func__ << " try to assimilate dirty rstat on "      << *dir << dendl;
dout(10) << __func__ << " finish assimilating dirty rstat on "           << *dir << dendl;
dout(10) << __func__ << " " << fg << " accounted " << *lock        << " scatter stat unchanged at v" << dir_accounted_version << dendl;
dout(10) << __func__ << " tag " << std::hex << tag << std::dec << " " << c    << " !ambig " << !state_test(STATE_AMBIGUOUSAUTH)    << " !frozen " << !is_frozen_inode()    << " !freezing " << !is_freezing_inode()    << dendl;
dout(10) << __func__ << " " << (cow_head ? "head" : "previous_head" )    << " to [" << old.first << "," << follows << "] on "    << *this << dendl;
dout(10) << __func__ << " " << snaprealm        << " parent is " << parent        << dendl;
dout(10) << __func__ << " joining realm " << *realm    << ", leaving realm " << *containing_realm << dendl;
dout(15) << __func__ << " snapid " << snapid     << " to old_inode [" << it->second.first << "," << it->first << "]"     << " " << it->second.inode.rstat     << dendl;
dout(0) << __func__ << " old_inode for snapid " << snapid    << " not found" << dendl;
dout(0) << __func__ << " [" << first << "," << last << "]"       << " not match snapid " << snapid << dendl;
dout(20) << __func__ << " no caps"      << (!valid?", !valid":"")      << (session->is_stale()?", session stale ":"")      << ((dir_realm && realm != dir_realm)?", snaprealm differs ":"")      << (is_frozen()?", frozen inode":"")      << (state_test(CInode::STATE_EXPORTINGCAPS)?", exporting caps":"")      << dendl;
dout(20) << " pfile " << pfile << " pauth " << pauth    << " plink " << plink << " pxattr " << pxattr    << " plocal " << plocal    << " ctime " << any_i->ctime    << " valid=" << valid << dendl;
dout(10) << "encode_inodestat issuing " << ccap_string(issue)        << " seq " << cap->get_last_seq() << dendl;
dout(10) << "encode_inodestat issuing " << ccap_string(issue)        << " seq " << cap->get_last_seq()        << "(stale&new caps)" << dendl;
dout(10) << "encode_inodestat caps " << ccap_string(ecap.caps)    << " seq " << ecap.seq << " mseq " << ecap.mseq    << " xattrv " << xattr_version << dendl;
dout(20) << __func__ << " pfile " << pfile    << " pauth " << pauth << " plink " << plink << " pxattr " << pxattr    << " ctime " << i->ctime << dendl;
dout(10) << "scrub: inotable free says "          << inotable->is_marked_free(in->ino()) << dendl;
dout(10) << "set ephemeral (" << (dist ? "dist" : "")      << (rand ? " rand" : "") << ") pin on " << *this << dendl;
dout(10) << "clear ephemeral (" << (dist ? "dist" : "")      << (rand ? " rand" : "") << ") pin on " << *this << dendl;
dout(15) << __func__ << " rand " << n << " <?= " << threshold           << " " << *this << dendl;
ldout(cct,15) << "overlapping lock, and this lock is exclusive, can't set"              << dendl;
} else ldout(cct,15) << "attempt to remove lock at " << removal_lock.start                 << " but no locks there!" << dendl;
ldout(cct,15) << "examining " << self_overlapping_locks.size()          << " self-overlapping locks for removal" << dendl;
else ldout(cct,15) << "get_lower_bound returning iterator pointing to "                << lower_bound->second << dendl;
else ldout(cct,15) << "get_last_before returning iterator pointing to "               << last->second << dendl;
ldout(cct,15) << "share_space got start: " << start << ", end: " << end          << ", lock: " << iter->second << ", returning " << ret << dendl;
ldout(cct,15) << "failure, something not equal in this group "              << (*iter)->second.client << ":" << owner.client << ","       << (*iter)->second.owner << ":" << owner.owner << ","       << (*iter)->second.pid << ":" << owner.pid << dendl;
dout(4) << "MDSIOContextBase::complete: dropping for stopping "            << typeid(*this).name() << dendl;
dout(10) << "advance_stray to index " << stray_index    << " fragmenting index " << stray_fragmenting_index << dendl;
dout(7) << "adjust_subtree_auth " << dir->get_dir_auth() << " -> " << auth   << " on " << *dir << dendl;
dout(7) << "adjust_bounded_subtree_auth " << dir->get_dir_auth() << " -> " << auth   << " on " << *dir   << " bounds " << bounds   << dendl;
dout(7) << "adjust_bounded_subtree_auth " << dir->get_dir_auth() << " -> " << auth   << " on " << *dir << " bound_dfs " << bound_dfs << dendl;
dout(15) << "map_dirfrag_set " << p->second << " -> " << fgs      << " on " << *in << dendl;
dout(10) << "project_subtree_rename " << *diri << " from " << *olddir    << " to " << *newdir << dendl;
dout(10) << "projected_rstat_inode_to_frag first " << first << " linkunlink " << linkunlink    << " " << *cur << dendl;
dout(10) << "  target snapped and not fully accounted, cow to dirty_old_rstat ["   << parent->first << "," << (first-1) << "] "   << " " << *prstat << "/" << pf->accounted_rstat   << dendl;
dout(10) << " projecting to newly split dirty_old_fnode [" << first << "," << last << "] "        << " " << *prstat << "/" << pf->accounted_rstat << dendl;
dout(10) << " splitting right old_inode [" << first << "," << it->first << "] to ["     << (last+1) << "," << it->first << "]" << dendl;
dout(10) << " splitting left old_inode [" << first << "," << last << "] to ["   << first << "," << ofirst-1 << "]" << dendl;
dout(10) << "predirty_journal_parents"    << (do_parent_mtime ? " do_parent_mtime":"")    << " linkunlink=" <<  linkunlink    << (primary_dn ? " primary_dn":" remote_dn")    << (shallow ? " SHALLOW":"")    << " follows " << cfollows    << " " << *in << dendl;
dout(20) << " unwritable parent nestlock " << pin->nestlock << ", marking dirty rstat on " << *cur << dendl;
dout(10) << "predirty_journal_parents last prop " << since_last_prop   << " < " << g_conf()->mds_dirstat_min_interval   << ", stopping" << dendl;
dout(10) << "predirty_journal_parents can't wrlock one of " << pin->versionlock << " or " << pin->nestlock        << " on " << *pin << dendl;
dout(10) << "create_subtree_map " << num_subtrees() << " subtrees, "     << num_subtrees_fullauth() << " fullauth"    << dendl;
dout(15) << "parent unchanged for " << dir->dirfrag() << " at "     << oldparent->dirfrag() << dendl;
dout(10) << "send_resolves still waiting for resolve ack from ("      << resolve_ack_gather << ")" << dendl;
dout(10) << "send_resolves still waiting for rollback to commit on ("      << resolve_need_rollback << ")" << dendl;
dout(10) << " peer request " << *mdr << " no longer need rename notity ack from mds."   << who << dendl;
dout(10) << " leader request " << *mdr << " waiting for rename srcdn's auth mds."   << who << " to recover" << dendl;
dout(10) << " leader request " << *mdr << " waiting for rename srcdn's auth mds."     << mdr->more()->srcdn_auth_mds << " to reply" << dendl;
dout(10) << " leader request " << *mdr << " no longer witnessed by peer mds."     << who << " to recover" << dendl;
dout(10) << " leader request " << *mdr << " waiting for peer mds." << who   << " to recover" << dendl;
dout(10) << " noting " << get_mdstable_name(p.type)      << " pending_commits " << p.pending_commits << dendl;
dout(10) << "maybe_resolve_finish still waiting for resolves ("      << resolve_gather << ")" << dendl;
dout(10) << "cancel_ambiguous_import " << df    << " bounds " << my_ambiguous_imports[df]    << " " << *dir    << dendl;
dout(10) << "finish_ambiguous_import " << df    << " bounds " << bounds    << dendl;
dout(7) << "rejoin_send_rejoins still waiting for resolves ("     << resolve_gather << ")" << dendl;
dout(7) << "handle_cache_rejoin " << *m << " from " << m->get_source()    << " (" << m->get_payload().length() << " bytes)"   << dendl;
dout(15) << " inode caps_wanted " << ccap_string(is.caps_wanted)        << " on " << *in << dendl;
dout(10) << " had bad linkage for " << *(in->get_parent_dn())         << ", unlinking " << *in << dendl;
dout(7) << "still need rejoin from (" << rejoin_gather << ")"       << ", rejoin_ack from (" << rejoin_ack_gather << ")" << dendl;
dout(10) << " still missing ino " << p->first          << ", will try again after replayed client requests" << dendl;
dout(10) << " client." << p.first        << " split " << p.second->head.split        << " inos " << p.second->split_inos        << dendl;
dout(10) << "rejoin_import_cap for client." << client << " from mds." << frommds    << " on " << *in << dendl;
dout(10) << "try_reconnect_cap client." << client      << " reconnect wanted " << ccap_string(rc->capinfo.wanted)      << " issue " << ccap_string(rc->capinfo.issued)      << " on " << *in << dendl;
dout(10) << "open_undef_inodes_dirfrags "    << rejoin_undef_inodes.size() << " inodes "    << rejoin_undef_dirfrags.size() << " dirfrags" << dendl;
dout(10) << "finish_snaprealm_reconnect client." << client << " has old seq " << seq << " < "       << realm->get_newest_seq() << " on " << *realm << dendl;
dout(10) << "finish_snaprealm_reconnect client." << client << " up to date"      << " on " << *realm << dendl;
dout(10) << "truncate_inode "    << pi->truncate_from << " -> " << pi->truncate_size    << " on " << *in    << dendl;
dout(10) << "_truncate_inode "    << pi->truncate_from << " -> " << pi->truncate_size    << " on " << *in << dendl;
dout(20) << "add_recovered_truncate " << *in << " in log segment "    << ls->seq << "/" << ls->offset << dendl;
dout(20) << "remove_recovered_truncate " << *in << " in log segment "    << ls->seq << "/" << ls->offset << dendl;
dout(7) << "trim_lru trimming " << count          << " items from LRU"          << " size=" << lru.lru_get_size()          << " mid=" << lru.lru_get_top()          << " pintail=" << lru.lru_get_pintail()          << " pinned=" << lru.lru_get_num_pinned()          << dendl;
dout(7) << "trim bytes_used=" << bytes2str(used)          << " limit=" << bytes2str(limit)          << " reservation=" << cache_reservation          << "% count=" << count << dendl;
dout(0) << " inode expire on " << q.first << " from " << from   << ", don't have it" << dendl;
dout(7) << " inode expire on " << *in << " from mds." << from   << " cached_by was " << in->get_replicas() << dendl;
dout(7) << " inode expire on " << *in << " from mds." << from  << " with old nonce " << nonce  << " (current " << in->get_replica_nonce(from) << "), dropping"   << dendl;
dout(7) << " dir expire on dirfrag " << q.first << " from mds." << from      << " while rejoining, inode isn't replicated" << dendl;
dout(7) << " dir expire on dirfrag " << q.first << " from mds." << from      << " have " << *other << ", mismatched frags, dropping" << dendl;
dout(0) << " dir expire on " << q.first << " from " << from  << ", don't have it" << dendl;
dout(7) << " dir expire on " << *dir << " from mds." << from  << " replicas was " << dir->get_replicas() << dendl;
dout(7) << " dir expire on " << *dir << " from mds." << from   << " with old nonce " << nonce << " (current " << dir->get_replica_nonce(from)  << "), dropping" << dendl;
dout(0) << " dn expires on " << pd.first << " from " << from  << ", must have refragmented" << dendl;
dout(7) << "  dentry_expire on " << *dn << " from mds." << from    << " with old nonce " << nonce << " (current " << dn->get_replica_nonce(from)    << "), dropping" << dendl;
dout(10) << "trim_client_leases pool " << pool << " trimmed "      << (before-after) << " leases, " << after << " left" << dendl;
dout(2) << "Memory usage: "    << " total " << last.get_total()    << ", rss " << last.get_rss()    << ", heap " << last.get_heap()    << ", baseline " << baseline.get_heap()    << ", " << num_inodes_with_caps << " / " << CInode::count() << " inodes have caps"    << ", " << Capability::count() << " caps, " << caps_per_inode << " caps per inode"    << dendl;
dout(5) << "check_memory_usage: releasing unused space from tcmalloc"       << dendl;
dout(7) << "waiting for log to flush.. " << mds->mdlog->get_num_events()      << " in " << mds->mdlog->get_num_segments() << " segments" << dendl;
dout(10) << "shutdown_export_strays " << shutdown_export_next.first    << " '" << shutdown_export_next.second << "'" << dendl;
dout(12) << "traverse: path seg depth " << depth << " '" << path[depth]      << "' snapid " << snapid << dendl;
dout(4) << "traverse: stopped lookup at damaged dentry "              << *curdir << "/" << path[depth] << " snap=" << snapid << dendl;
dout(4) << "traverse: remote dentry points to damaged ino "                    << *dn << dendl;
dout(4) << "traverse: damaged dirfrag " << *curdir                  << ", blocking fetch" << dendl;
dout(7) << "traverse: snap " << snapid << " and depth " << depth  << " < fwd " << mdr->client_request->get_num_fwd()  << ", discovering instead of forwarding" << dendl;
dout(10) << " old object in pool " << info.pool        << ", retrying pool " << backtrace.pool << dendl;
dout(10) << " no object in pool " << info.pool        << ", retrying pool " << meta_pool << dendl;
dout(10) << "do_open_ino_peer " << ino << " active " << active    << " all " << all << " checked " << info.checked << dendl;
dout(10) << "open_ino " << ino << " pool " << pool << " want_replica "    << want_replica << dendl;
dout(10) << "_do_find_ino_peer " << fip.tid << " " << fip.ino    << " active " << active << " all " << all    << " checked " << fip.checked    << dendl;
dout(0) << "handle_find_ino_reply failed with " << r << " on " << m->path        << ", retrying" << dendl;
dout(7) << "request_forward " << *mdr << " to mds." << who << " req "            << *mdr->client_request << dendl;
dout(7) << "request_forward drop " << *mdr << " req " << *mdr->client_request            << " was from mds" << dendl;
dout(10) << "request_drop_foreign_locks forgetting lock " << *lock        << " on " << lock->get_parent() << dendl;
dout(10) << "request_drop_foreign_locks forgetting remote_wrlock " << *lock        << " on mds." << it->wrlock_target << " on " << *lock->get_parent() << dendl;
dout(7) << "discover_dir_frag " << df   << " from mds." << from << dendl;
dout(7) << "discover_path " << base->ino() << " " << want_path << " snap " << snap << " from mds." << from   << (path_locked ? " path_locked":"")   << dendl;
dout(7) << "discover_path " << base->dirfrag() << " " << want_path << " snap " << snap << " from mds." << from   << (path_locked ? " path_locked":"")   << dendl;
dout(7) << "handle_discover from mds." << from     << " wants base + " << dis->get_want().get_path()     << " snap " << snapid     << dendl;
dout(7) << "handle_discover mds." << from        << " don't have base ino " << dis->get_base_ino() << "." << snapid       << dendl;
dout(7) << "handle_discover mds." << from        << " wants basedir+" << dis->get_want().get_path()        << " has " << *cur        << dendl;
dout(7) << "handle_discover mds." << from        << " wants " << dis->get_want().get_path()       << " has " << *cur       << dendl;
dout(7) << " dirfrag not open, not inode auth, setting dir_auth_hint for "     << *cur << dendl;
dout(7) << "dentry " << dis->get_dentry(i) << " snap " << snapid  << " dne, non-empty reply, stopping" << dendl;
dout(7) << "dentry " << dis->get_dentry(i) << " dne, returning null in "       << *curdir << dendl;
dout(7) << " doing nothing, have dir but nobody is waiting on dentry "  << m->get_error_dentry() << dendl;
dout(7) << __func__ << " forcing frag " << df.frag << " to leaf in the fragtree "       << diri->dirfragtree << dendl;
dout(10) << "adjust_dir_fragments " << basefrag << " " << bits     << " on " << *diri << dendl;
dout(10) << "adjust_dir_fragments " << basefrag << " bits " << bits    << " srcfrags " << srcfrags    << " on " << *diri << dendl;
dout(10) << "fragment_frozen " << basedirfrag.frag << " by " << info.bits    << " on " << info.dirs.front()->get_inode() << dendl;
dout(10) << "dispatch_fragment_dir " << basedirfrag << " bits " << info.bits    << " on " << *diri << dendl;
dout(10) << " can't auth_pin " << *diri << ", requeuing dir "      << info.dirs.front()->dirfrag() << dendl;
dout(10) << "fragment_logged " << basedirfrag << " bits " << info.bits    << " on " << *diri << dendl;
dout(10) << "fragment_stored " << basedirfrag << " bits " << info.bits    << " on " << *diri << dendl;
dout(10) << " dft " << diri->dirfragtree << " state doesn't match " << base << " by " << bits        << ", must have found out during resolve/rejoin?  ignoring. " << *diri << dendl;
dout(10) << "finish_uncommitted_fragments: base dirfrag " << basedirfrag    << " op " << EFragment::op_name(op) << dendl;
dout(10) << "rollback_uncommitted_fragment: base dirfrag " << basedirfrag           << " old_frags (" << old_frags << ")" << dendl;
dout(ceph::dout::need_dynamic(dbl)) << "show_subtrees - no subtrees"     << dendl;
dout(ceph::dout::need_dynamic(dbl)) << indent << "|_" << pad << s     << " " << auth << *dir << dendl;
dout(10) << __func__ << " failed to fix fragstat/rstat on "      << *diri << dendl;
dout(10) << " delayed export_pin=" << export_pin << " on " << *in              << " max_mds=" << max_mds << dendl;
dout(10) << __func__ << " with {" << *in << "}"      << ", conflicting tag " << header->get_tag() << dendl;
dout(10) << __func__ << ": in progress scrub operations finished, "               << stack_size << " in the stack" << dendl;
dout(20) << __func__ << " entering with " << scrubs_in_progress << " in "              "progress and " << stack_size << " in the stack" << dendl;
dout(15) << __func__ << " skip dentry " << it->first   << ", no change since last scrub" << dendl;
dout(20) << __func__ << ", from state=" << state << ", to state="               << next_state << dendl;
dout(10) << __func__ << ": aborting with " << scrubs_in_progress           << " scrubs in progress and " << stack_size << " in the"           << " stack" << dendl;
dout(10) << __func__ << ": pausing with " << scrubs_in_progress           << " scrubs in progress and " << stack_size << " in the"           << " stack" << dendl;
dout(20) << ": client=" << client << ", rank=" << rank << ", metrics="           << metrics << dendl;
dout(20) << ": rank=" << rank << " has " << p.size() << " connected"             << " client(s)" << dendl;
dout(20) << ": rank=" << rank << " has " << p.size() << " connected"             << " client(s)" << dendl;
dout(20) << ": applying " << client_metrics_map.size() << " updates for rank="           << rank << " with sequence number " << seq << dendl;
dout(10) << ": active rank=" << rank << " (mds." << mdsmap.get_mds_info(rank).name             << ") has addr=" << rank_addr << dendl;
dout(20) << ": packing perf_metric_key=" << p.first << ", perf_counter="               << p.second << dendl;
ldout(cct, 10) << __func__ << " completed notify (linger op "                   << linger_op << "), ec = " << ec << dendl;
ldout(cct, 10) << __func__ << " linger op " << oncomplete->linger_op << " "                   << "acked (" << r << ")" << dendl;
ldout(client->cct, 10) << "set snap write context: seq = " << seq    << " and snaps = " << snaps << dendl;
ldout(client->cct, 20) << "queue_aio_write " << this << " completion " << c    << " write_seq " << aio_write_seq << dendl;
ldout(client->cct, 20) << " next outstanding write is " << aio_write_list.front()->aio_write_seq        << " <= waiter " << waiters->first        << ", stopping" << dendl;
ldout(client->cct, 20) << "flush_aio_writes_async " << this    << " completion " << c << dendl;
ldout(client->cct, 20) << "flush_aio_writes_async no writes. (tid "      << seq << ")" << dendl;
ldout(client->cct, 20) << "flush_aio_writes_async " << aio_write_list.size()      << " writes in flight;
waiting on tid " << seq << dendl;
ldout(client->cct, 10) << ceph_osd_op_name(op) << " oid=" << oid    << " nspace=" << oloc.nspace << dendl;
ldout(client->cct, 10) << "Objecter returned from " << ceph_osd_op_name(op) << " r=" << r << dendl;
ldout(client->cct, 10) << "Objecter returned from " << ceph_osd_op_name(op) << " r=" << r << dendl;
ldout(client->cct, 10) << "Returned length " << bl.length()      << " less than original length "<< len << dendl;
ldout(ioctx->client->cct, 10) << __func__ << " " << notify_id      << " cookie " << cookie      << " notifier_id " << notifier_id      << " len " << bl.length()      << dendl;
ldout(ioctx->client->cct, 10) << __func__ << " cookie " << cookie      << " err " << err      << dendl;
ldout(client->cct, 10) << __func__ << " linger op " << linger_op    << " acked (" << r << ")" << dendl;
ldout(client->cct, 10) << __func__ << " waiting for watch_notify finish "      << linger_op << dendl;
ldout(client->cct, 10) << __func__ << " failed to initiate notify, r = "      << r << dendl;
ldout(cct, 10) << __func__ << " registering as " << service_name << "."     << daemon_name << dendl;
ldout(cct, 10) << __func__ << " removing cb " << (void*)log_cb     << " " << (void*)log_cb2 << dendl;
ldout(cct, 10) << __func__ << " add cb " << (void*)cb << " " << (void*)cb2   << " level " << level << dendl;
ldout(cct, 10) << "calc_snap_set_diff start " << start << " end " << end   << ", snap_set seq " << snap_set.seq << dendl;
ldout(cct, 1) << "clone " << r->cloneid                    << ": empty snaps, return whole object" << dendl;
ldout(cct, 20) << " clone " << r->cloneid << " snaps " << r->snaps     << " -> [" << a << "," << b << "]"     << " size " << r->size << " overlap to next " << r->overlap << dendl;
ldout(cct,10) << __func__ << " removing " << i.first << " bucket "     << (-1-j) << " ids" << dendl;
ldout(cct,10) << __func__ << " removing " << i.first << " bucket "     << (-1-j) << " weight_sets" << dendl;
ldout(cct, 5) << "remove_item " << item  << (unlink_only ? " unlink_only":"") << dendl;
ldout(cct, 1) << "remove_item bucket " << item << " does not exist"      << dendl;
ldout(cct, 1) << "remove_item bucket " << item << " has " << t->size      << " items, not empty" << dendl;
ldout(cct, 5) << "remove_item removing item " << item        << " from bucket " << b->id << dendl;
ldout(cct, 5) << "_remove_item_under " << item << " under " << ancestor  << (unlink_only ? " unlink_only":"") << dendl;
ldout(cct, 5) << "_remove_item_under removing item " << item      << " from bucket " << b->id << dendl;
ldout(cct, 5) << "remove_item_under " << item << " under " << ancestor  << (unlink_only ? " unlink_only":"") << dendl;
ldout(cct, 1) << "remove_item_under bucket " << item                    << " does not exist" << dendl;
ldout(cct, 1) << "remove_item_under bucket " << item << " has " << t->size      << " items, not empty" << dendl;
ldout(cct, 2) << "warning: did not specify location for '" << p->second << "' level (levels are "      << type_map << ")" << dendl;
ldout(cct, 5) << "check_item_loc requested " << q->second << " for type " << p->second      << " is a device, not bucket" << dendl;
ldout(cct, 1) << __func__ << " unable to get parent of osd." << osd                          << ", skipping for now"                          << dendl;
ldout(cct, 1) << __func__ << " unable to get parent of osd." << osd                          << ", skipping for now"                          << dendl;
ldout(cct, 5) << "insert_item item " << item << " weight " << weight  << " name " << name << " loc " << loc << dendl;
ldout(cct, 10) << "device name '" << name << "' already exists as id "       << get_item_id(name) << dendl;
ldout(cct, 2) << "warning: did not specify location for '"      << p->second << "' level (levels are "      << type_map << ")" << dendl;
ldout(cct, 1) << "add_bucket failure error: " << cpp_strerror(r)        << dendl;
ldout(cct, 1) << "insert_item item " << cur << " already exists beneath "      << id << dendl;
ldout(cct, 1) << "insert_item existing bucket has type " << "'" << type_map[b->type] << "' != " << "'" << type_map[p->first] << "'" << dendl;
ldout(cct, 1) << "insert_item " << cur << " already contains " << b->id      << ";
cannot form loop" << dendl;
ldout(cct, 5) << "insert_item adding " << cur << " weight " << weight    << " to bucket " << id << dendl;
ldout(cct, 5) << "insert_item max_devices now " << crush->max_devices      << dendl;
ldout(cct, 0) << __func__ << " unable to rebuild roots with classes: "                    << cpp_strerror(r) << dendl;
ldout(cct, 1) << "error: didn't find anywhere to add item " << item  << " in " << loc << dendl;
ldout(cct, 5) << "create_or_move_item " << item << " already at " << loc    << dendl;
ldout(cct, 10) << "create_or_move_item " << item       << " exists with weight " << weight << dendl;
ldout(cct, 5) << "create_or_move_item adding " << item    << " weight " << weight    << " at " << loc << dendl;
ldout(cct, 5) << "update_item item " << item << " weight " << weight  << " name " << name << " loc " << loc << dendl;
ldout(cct, 5) << "update_item " << item << " adjusting weight "      << ((float)old_iweight/(float)0x10000) << " -> " << weight      << dendl;
ldout(cct, 0) << __func__ << " unable to rebuild roots with classes: "        << cpp_strerror(ret) << dendl;
ldout(cct, 5) << "update_item setting " << item << " name to " << name      << dendl;
ldout(cct, 5) << "update_item adding " << item << " weight " << weight    << " at " << loc << dendl;
ldout(cct, 5) << __func__ << " " << id << " weight " << weight  << " update_weight_sets=" << (int)update_weight_sets  << dendl;
ldout(cct, 5) << __func__ << " " << id << " weight " << weight  << " in bucket " << bucket_id  << " update_weight_sets=" << (int)update_weight_sets  << dendl;
ldout(cct, 5) << __func__ << " " << id << " diff " << diff      << " in bucket " << bucket_id << dendl;
ldout(cct,5) << __func__ << "  adjusting bucket " << bucket_id   << " cmap " << p.first << " weights to " << w << dendl;
ldout(cct, 5) << "adjust_item_weight_in_loc " << id << " weight " << weight  << " in " << loc  << " update_weight_sets=" << (int)update_weight_sets  << dendl;
ldout(cct, 0) << __func__ << " unable to rebuild roots with classes: "    << cpp_strerror(ret) << dendl;
ldout(cct, 1) << "loc["                    << l->first << "] = '"                    << l->second << "' not a valid crush name ([A-Za-z0-9_-.]+)"                    << dendl;
ldout(cct, 10) << __func__ << " stack " << stack   << " orig " << orig   << " at " << *i   << " pw " << *pw   << dendl;
ldout(cct, 10) << __func__ << " cumulative_fanout " << cumulative_fanout   << dendl;
ldout(cct, 10) << __func__ << " underfull " << osd << " type " << type       << " is " << item << dendl;
ldout(cct, 10) << " level " << j << ": type " << type << " fanout " << fanout     << " cumulative " << cum_fanout     << " w " << w << dendl;
ldout(cct, 10) << __func__ << "   from " << *tmpi << " got " << item    << " of type " << type << " over leaves " << leaves[pos] << dendl;
ldout(cct, 10) << __func__ << " pos " << pos        << " was " << *i << " considering " << item        << dendl;
ldout(cct, 10) << __func__ << " pos " << pos << " replace "        << *i << " -> " << item << dendl;
ldout(cct, 10) << __func__ << " more underfull pos " << pos          << " was " << *i << " considering " << item          << dendl;
ldout(cct, 10) << __func__ << " pos " << pos << " replace "          << *i << " -> " << item << dendl;
ldout(cct, 10) << __func__ << " pos " << pos << " keep " << *i      << dendl;
ldout(cct, 10) << " bucket " << o[pos] << " has no underfull targets and "        << ">0 leaves " << leaves[pos] << " is overfull;
alts "        ldout(cct, 10) << "  replacing " << o[pos]         << " (which has no underfull leaves) with " << alt         << " (same parent "         << get_parent_of_type(alt, stack[j-1].first, rule) << " type "         << type << ")" << dendl;
ldout(cct, 10) << "  replacing " << o[pos]         << " (which has no underfull leaves) with " << alt         << " (first level)" << dendl;
ldout(cct, 30) << "  alt " << alt << " for " << o[pos]       << " has different parent, skipping" << dendl;
ldout(cct, 10) << __func__ << " ruleno " << ruleno  << " numrep " << maxout << " overfull " << overfull  << " underfull " << underfull  << " more_underfull " << more_underfull  << " orig " << orig  << dendl;
ldout(cct, 10) << __func__ << "  no crush_choose_arg for bucket " << b->id     << dendl;
ldout(cct, 10) << __func__ << "  weight_set_positions != " << weight.size()     << " for bucket " << b->id << dendl;
ldout(cct, 5) << __func__ << "  set " << id << " to " << weight      << " in bucket " << b->id << dendl;
ldout(g_ceph_context, 0) << __func__ << " readdir on bucket "        << bucket_name << dendl;
dout(15) << "rgw_getattr on " << object_name << " size = "      << st.st_size << dendl;
dout(0) << "Writing " << cfg.size      << " in blocks of " << cfg.block_size << dendl;
dout(0) << "Wrote " << total << " in "      << duration.count() << "us, at a rate of " << rate << "/s and "      << iops << " iops" << dendl;
dout(15) << "rgw_getattr on " << object_name << " size = "    << st.st_size << dendl;
generic_dout(0) << "this is a typical log line.  set "        << myset << " and map " << mymap << dendl;
ldout(cct, 20) << "notify_id=" << notify_id << ", handle=" << handle   << ", gid=" << gid << dendl;
ldout(cct, 20) << "oid=" << o << ", gid=" << gid << ": handle=" << *handle          << dendl;
ldout(cct, 1) << "oid=" << oid << ", notify_id=" << notify_id    << ", WatcherID=" << watcher_id << ": not found" << dendl;
ldout(cct, 20) << "oid=" << oid << ", notify_id=" << notify_id   << ", WatcherID=" << watcher_id << dendl;
ldout(cct, 1) << "oid=" << oid << ", notify_id=" << notify_id           << ": not found" << dendl;
ldout(cct, 10) << "oid=" << oid << ", notify_id=" << notify_id            << ": pending watchers, returning" << dendl;
ldout(cct, 20) << "oid=" << oid << ", notify_id=" << notify_id   << ": completing" << dendl;
ldout(cct, 20) << "seq=" << out_snaps->seq << ", "                 << "clones=[";
ldout(cct, 20) << "extent=" << off << "~" << len << ", snapc=" << snapc                 << dendl;
ldout(cct, 20) << "extent=" << off << "~" << len << ", snapc=" << snapc                 << dendl;
ldout(g_ceph_context, 0) << __func__ << " readdir on bucket " << get<0>(fid)        << dendl;
ldout(g_ceph_context, 2) << "election epoch " << logic.get_epoch()  << " timed out for " << rank  << ", electing me:" << logic.electing_me  << ", acked_me:" << logic.acked_me << dendl;
ldout(g_ceph_context, 2) << "victory epoch " << logic.get_epoch()  << " timed out for " << rank  << ", electing me:" << logic.electing_me  << ", acked_me:" << logic.acked_me << dendl;
ldout(g_ceph_context, 1) << "quorum_stable? last formed:" << last_quorum_formed       << ", last changed " << last_quorum_change       << ", last reported members " << last_quorum_reported << dendl;
ldout(g_ceph_context, 10) << "rank " << i.first << " has different leader "    << i.second->logic.get_election_winner() << dendl;
ldout(g_ceph_context, 10) << "that leader is disallowed! member of "         << disallowed_leaders << dendl;
generic_dout(20) << "C_Tick::" << __func__   << " shutdown" << dendl;
dout(10) << __func__ << " error shutting down: "        << cpp_strerror(-r) << dendl;
dout(10) << "ClientStub::" << __func__ << " starting messenger at "     << messenger->get_myaddrs() << dendl;
generic_dout(20) << "C_CreatePGs::" << __func__   << " shutdown" << dendl;
dout(20) << __func__ << " auth supported: "      << cct->_conf->auth_supported << dendl;
dout(1) << __func__ << " fsid " << monc.monmap.fsid     << " osd_fsid " << g_conf()->osd_uuid << dendl;
dout(10) << __func__      << ": " << (has_pgs ? "has pgs;
ignore" : "create pgs") << dendl;
dout(1) << __func__       << " still don't have osdmap;
reschedule pg creation" << dendl;
dout(20) << __func__   << " no crush rule for pool id " << pool_id   << " rule no " << ruleno << dendl;
dout(20) << __func__        << " pool num pgs " << pool.get_pg_num()        << " epoch " << pool_epoch << dendl;
dout(20) << __func__   << " pgid " << pgid << " parent " << parent << dendl;
dout(0) << __func__               << " cannot statfs ." << cpp_strerror(ret) << dendl;
dout(10) << __func__      << " pgs " << pgs.size() << " osdmap " << osdmap << dendl;
dout(20) << __func__        << " pg " << pgid << " stats:\n";
dout(10) << __func__        << " pg " << pgid << " changed in the last 10s" << dendl;
dout(1) << __func__       << " no pgs available! don't attempt to modify." << dendl;
dout(20) << __func__        << " pg at pos " << at << ": " << it->first << dendl;
dout(10) << __func__      << " send " << num_entries << " log messages" << dendl;
dout(0) << __func__              << " message fsid " << m->fsid << " != " << monc.get_fsid()              << dendl;
dout(0) << __func__ << " " << m              << " from " << m->get_source_inst()              << dendl;
dout(5) << __func__     << " epochs [" << first << "," << last << "]"     << " current " << osdmap.get_epoch() << dendl;
dout(5) << __func__       << osdmap.get_epoch() + 1 << ".." << (first-1) << dendl;
dout(5) << __func__  << " full epoch " << start_full << dendl;
dout(20) << __func__        << " incremental epoch " << e        << " on full epoch " << start_full << dendl;
dout(1) << __func__       << " got into the osdmap and we're up!" << dendl;
dout(1) << __func__       << " they have more maps;
requesting them!" << dendl;
dout(0) << __func__ << " starting messenger at "            << msg->get_myaddrs() << dendl;
ldout(cct, 0) << "[!TestPeer] got op from Test(conn "                    << conn << "not tracked yet)" << dendl;
ldout(cct, 0) << "[!TestPeer] reset(invalid event): conn(" << conn                    << ") != tracked_conn(" << tracked_conn                    << ")" << dendl;
ldout(cct, 0) << "[!TestPeer] reset(invalid event): conn(" << conn                    << ") != tracked_conn(" << tracked_conn                    << ")" << dendl;
ldout(cct, 0) << "[TestPeer] flush sending "                    << pending_send << " ops" << dendl;
ldout(cct, 0) << "[TestPeer] this is a new session " << conn.get()                      << ", replacing old one " << tracked_conn << dendl;
ldout(cct, 0) << "[!CmdSrv] got msg from CmdCli(conn "                    << conn << "not tracked yet)" << dendl;
ldout(cct, 0) << "[!CmdSrv] reset(invalid event): conn(" << conn                    << ") != cmd_conn(" << cmd_conn                    << ")" << dendl;
ldout(cct, 0) << "[CmdSrv] suite starting (" << p                    <<", " << test_peer_addr << ") ..." << dendl;
lsubdout(cct, rgw, 10) << __func__      << " bucket=" << rgw_fh->bucket_name()      << " dir=" << rgw_fh->full_object_name()      << " called back name=" << name      << " flags=" << flags      << dendl;
lsubdout(cct, rgw, 10)   << "rgw_lookup:"   << " parent object_name()=" << pfh->object_name()   << " parent full_object_name()=" << pfh->full_object_name()   << " elt.name=" << elt.name   << dendl;
lsubdout(cct, rgw, 10)   << "rgw_lookup result:"   << " elt object_name()=" << efh->object_name()   << " elt full_object_name()=" << efh->full_object_name()   << " elt.name=" << elt.name   << dendl;
lsubdout(cct, rgw, 10)       << "readdir in"       << " bucket: " << elt.rgw_fh->bucket_name()       << " object_name: " << elt.rgw_fh->object_name()       << " full_name: " << elt.rgw_fh->full_object_name()       << dendl;
lsubdout(cct, rgw, 10) << __func__      << " bucket=" << bucket_name      << " dir=" << marker_dir      << " iv count=" << dvec.count      << " called back name=" << name      << " flags=" << flags      << dendl;
dout(5) << "init create collection " << entry->m_cid        << " meta " << entry->m_meta_obj << dendl;
dout(5) << "get_coll_at pos " << pos << ": "      << entry->m_cid << "(removed: " << erase << ")" << dendl;
dout(5) << "touch_obj coll id " << m_cid        << " name " << it->second->oid.name << dendl;
dout(5) << "get_obj coll " << m_cid        << " obj #" << id << " non-existent" << dendl;
dout(5) << "get_obj coll " << m_cid << " id " << id      << ": " << obj->oid.name << "(removed: " << remove << ")" << dendl;
dout(5) << "get_obj_at coll " << m_cid << " pos " << pos        << " in an empty collection" << dendl;
dout(5) << "get_obj_at coll " << m_cid << " pos " << pos        << " non-existent" << dendl;
dout(5) << "get_obj_at coll id " << m_cid << " pos " << pos      << ": " << ret->oid.name << "(removed: " << remove << ")" << dendl;
dout(0) << "do_write " << entry->m_cid << "/" << obj   << " 0~" << size << dendl;
dout(0) << "_prepare_clone coll " << entry->m_cid     << " doesn't have 2 or more objects" << dendl;
dout(0) << "do_clone " << entry->m_cid << "/" << orig_obj      << " => " << entry->m_cid << "/" << new_obj << dendl;
dout(0) << "do_clone_range " << entry->m_cid << "/" << orig_obj      << " (0~" << size << ")"      << " => " << entry->m_cid << "/" << new_obj      << " (0)" << dendl;
dout(0) << "do_coll_move " << entry->m_cid << "/" << orig_obj        << " => " << entry->m_cid << "/" << new_obj << dendl;
dout(0) << "Give collection: " << entry->m_cid   << " a hint, pg_num is: " << pg_num << ", num_objs is: "   << num_objs << dendl;
generic_dout(0) << "turning on heap profiler with prefix "    << profile_name << dendl;
ldout(oc->cct, 20) << "split  moving waiters at byte " << p->first    << " to right bh" << dendl;
ldout(oc->cct, 10) << "map_read " << ex.oid << " "                     << ex.offset << "~" << ex.length << dendl;
ldout(oc->cct, 10) << "map_write oex " << ex.oid              << " " << ex.offset << "~" << ex.length << dendl;
ldout(oc->cct, 10) << "discard " << *this << " " << off << "~" << len       << dendl;
ldout(cct, 7) << "bh_read on " << *bh << " outstanding reads "  << reads_outstanding << dendl;
ldout(cct, 7) << "bh_read_finish "  << oid  << " tid " << tid  << " " << start << "~" << length  << " (bl is " << bl.length() << ")"  << " returned " << r  << " outstanding reads " << reads_outstanding  << dendl;
ldout(cct, 7) << "bh_read_finish " << oid << " padding " << start << "~"    << length << " with " << length - bl.length() << " bytes of zeroes"    << dendl;
ldout(cct, 7)   << "bh_read_finish ENOENT, marking complete and !exists on " << *ob   << dendl;
ldout(cct, 10)     << "bh_read_finish ENOENT and allzero, getting rid of "     << "bhs for " << *ob << dendl;
ldout(cct, 20) << "break due to opos " << opos << " >= start+length "         << start << "+" << length << "=" << start+(loff_t)length         << dendl;
ldout(cct, 1) << "bh_read_finish skipping gap "        << opos << "~" << bh->start() - opos        << dendl;
ldout(cct, 10) << "bh_read_finish bh->last_read_tid "         << bh->last_read_tid << " != tid " << tid         << ", skipping" << dendl;
ldout(cct, 10) << "skipping unstrusted -ENOENT and will retry for "    << *bh << dendl;
ldout(cct, 7) << "bh_write_commit " << oid << " tid " << tid  << " ranges " << ranges << " returned " << r << dendl;
ldout(cct, 10) << "bh_write_commit may copy on write, clearing "   "complete on " << *ob << dendl;
ldout(cct, 10) << "bh_write_commit marking dirty again due to error "         << *bh << " r = " << r << " " << cpp_strerror(-r)         << dendl;
ldout(cct, 10) << "trim  start: bytes: max " << max_size << "  clean "   << get_stat_clean() << ", objects: max " << max_objects   << " current " << ob_lru.lru_get_size() << dendl;
ldout(cct, 10) << "trim finish:  max " << max_size << "  clean "   << get_stat_clean() << ", objects: max " << max_objects   << " current " << ob_lru.lru_get_size() << dendl;
ldout(cct, 10) << "readx  waiting on tid " << o->last_write_tid    << " on " << *o << dendl;
ldout(cct, 10) << "readx  ob has all zero|rx, returning ENOENT"         << dendl;
ldout(cct, 10) << "readx missed, waiting on cache to complete "      << waitfor_read.size() << " blocked reads, "      << (std::max(rx_bytes, max_size) - max_size)      << " read bytes" << dendl;
ldout(cct, 10) << "readx missed, waiting on " << *last->second   << " off " << last->first << dendl;
ldout(cct, 10) << "readx missed, waiting on " << *bh_it->second    << " off " << bh_it->first << dendl;
ldout(cct, 10) << "readx rmap opos " << opos << ": " << *bh << " +"    << bhoff << " frag " << f_it->first << "~"    << f_it->second << " +" << foff << "~" << len    << dendl;
ldout(cct, 20) << "readx drop " << rd << " (no complete, but no waiter)"       << dendl;
ldout(cct, 10) << "readx  adding buffer len " << i->second.length()       << " at " << pos << dendl;
ldout(cct, 10) << "writex writing " << f_it->first << "~"       << f_it->second << " into " << *bh << " at " << opos       << dendl;
ldout(cct, 10) << __func__ << " waiting for dirty|tx "     << (get_stat_dirty() + get_stat_tx()) << " >= max "     << max_dirty << " + dirty_waiting "     << get_stat_dirty_waiting() << dendl;
ldout(cct, 10) << "wait_for_write waiting on write-thru of " << len     << " bytes" << dendl;
ldout(cct, 10) << "wait_for_write " << get_stat_dirty() << " > target "     << target_dirty << ", nudging flusher" << dendl;
ldout(cct, 11) << "flusher "     << all << " / " << max_size << ":  "     << get_stat_tx() << " tx, "     << get_stat_rx() << " rx, "     << get_stat_clean() << " clean, "     << get_stat_dirty() << " dirty ("     << target_dirty << " target, "     << max_dirty << " max)"     << dendl;
ldout(cct, 10) << "flusher " << get_stat_dirty() << " dirty + "       << get_stat_dirty_waiting() << " dirty_waiting > target "       << target_dirty << ", flushing some dirty bhs" << dendl;
ldout(cct, 10) << "Waiting for all reads to complete. Number left: "       << reads_outstanding << dendl;
ldout(cct, 10) << "flush_set " << oset << " will wait for ack tid "     << ob->last_write_tid << " on " << *ob << dendl;
ldout(cct, 10) << "flush_set " << oset << " on " << exv.size()   << " ObjectExtents" << dendl;
ldout(cct, 20) << "flush_set " << oset << " ex " << ex << " ob " << soid     << " " << ob << dendl;
ldout(cct, 10) << "flush_set " << oset << " will wait for ack tid "       << ob->last_write_tid << " on " << *ob << dendl;
ldout(cct, 10) << "flush_all will wait for ack tid "     << ob->last_write_tid << " on " << *ob << dendl;
ldout(cct, 10) << "release_set " << oset << " " << *ob       << " has " << o_unclean << " bytes left"       << dendl;
ldout(cct, 10) << "release_set " << oset     << ", " << unclean << " bytes left" << dendl;
ldout(cct, 10) << "release_all " << *ob         << " has " << o_unclean << " bytes left"         << dendl;
ldout(cct, 10) << "release_all unclean " << unclean << " bytes left"     << dendl;
ldout(cct, 10) << " clean " << clean << " rx " << rx << " tx " << tx   << " dirty " << dirty << " missing " << missing   << " error " << error << dendl;
ldout(cct, 10) << "probe " << (fwd ? "fwd ":"bwd ")    << hex << ino << dec    << " starting from " << start_from    << dendl;
ldout(cct, 10) << "probe " << (fwd ? "fwd ":"bwd ")    << hex << ino << dec    << " starting from " << start_from    << dendl;
ldout(cct, 10) << "_probe " << hex << probe->ino << dec   << " " << probe->probing_off << "~" << probe->probing_len   << dendl;
ldout(cct, 10) << "_probed " << probe->ino << " object " << oid    << " has size " << size << " mtime " << mtime << dendl;
ldout(cct, 10) << "_probed  " << probe->ino << " object " << hex     << p->oid << dec << " should be " << shouldbe     << ", actual is " << probe->known_size[p->oid]     << dendl;
ldout(cct, 10) << "_probed  end is in buffer_extent " << i->first    << "~" << i->second << " off " << oleft    << ", from was " << probe->probing_off << ", end is "    << end << dendl;
ldout(cct, 10) << "_do_purge_range " << pr->ino << " objects " << pr->first   << "~" << pr->num << " uncommitted " << pr->uncommitted   << dendl;
ldout(cct, 10) << "_do_truncate_range " << tr->ino << " objects " << tr->offset   << "~" << tr->length << " uncommitted " << tr->uncommitted   << dendl;
ldout(cct, 1) << "created blank journal at inode 0x" << std::hex << ino  << std::dec << ", format=" << stream_format << dendl;
ldout(cct, 1) << "_finish_read_head r=" << r    << " read 0 bytes, assuming empty log" << dendl;
ldout(cct, 0) << "on disk magic '" << h.magic << "' != my magic '"      << magic << "'" << dendl;
ldout(cct, 1) << "_finish_read_head " << h  << ".  probing for end of log (from " << write_pos << ")..."  << dendl;
ldout(cct, 1) << "_finish_reprobe new_end = " << new_end   << " (header had " << write_pos << ")."   << dendl;
ldout(cct, 1) << "_finish_probe_end write_pos = " << end << " (header had "    << write_pos << "). log was empty. recovered." << dendl;
ldout(cct, 1) << "_finish_probe_end write_pos = " << end    << " (header had " << write_pos << "). recovered."    << dendl;
ldout(cct, 10) << "_finish_flush safe from " << start   << ", pending_safe " << pending_safe   << ", (prezeroing/prezero)/write/flush/safe positions now "   << "(" << prezeroing_pos << "/" << prezero_pos << ")/"   << write_pos << "/" << flush_pos << "/" << safe_pos   << dendl;
ldout(cct, 10) << "append_entry len " << s << " to " << write_pos << "~"   << wrote << dendl;
ldout(cct, 10) << " flushing completed object(s) (su " << su << " wro "     << write_obj << " flo " << flush_obj << ")" << dendl;
ldout(cct, 10) << "_do_flush wanted to do " << flush_pos << "~" << len       << " already too close to prezero_pos " << prezero_pos       << ", zeroing first" << dendl;
ldout(cct, 10) << "_do_flush wanted to do " << flush_pos << "~" << len       << " but hit prezero_pos " << prezero_pos       << ", will do " << flush_pos << "~" << newlen << dendl;
ldout(cct, 10)    << "_do_flush (prezeroing/prezero)/write/flush/safe pointers now at "    << "(" << prezeroing_pos << "/" << prezero_pos << ")/" << write_pos    << "/" << flush_pos << "/" << safe_pos << dendl;
ldout(cct, 10)      << "flush nothing to flush, (prezeroing/prezero)/write/flush/safe "      "pointers at " << "(" << prezeroing_pos << "/" << prezero_pos << ")/"      << write_pos << "/" << flush_pos << "/" << safe_pos << dendl;
ldout(cct, 10) << "flush nothing to flush, (prezeroing/prezero)/write/"      "flush/safe pointers at " << "(" << prezeroing_pos << "/" << prezero_pos     << ")/" << write_pos << "/" << flush_pos << "/" << safe_pos     << dendl;
ldout(cct, 20) << "_issue_prezero target " << to << " <= prezeroing_pos "     << prezeroing_pos << dendl;
ldout(cct, 10) << "_issue_prezero removing " << prezeroing_pos << "~"       << period << " (full period)" << dendl;
ldout(cct, 10) << "_issue_prezero zeroing " << prezeroing_pos << "~"       << len << " (partial period)" << dendl;
ldout(cct, 10) << "_prezeroed to " << start << "~" << len   << ", prezeroing/prezero was " << prezeroing_pos << "/"   << prezero_pos << ", pending " << pending_zero   << dendl;
ldout(cct, 10) << "_prezeroed prezeroing/prezero now " << prezeroing_pos   << "/" << prezero_pos   << ", pending " << pending_zero   << dendl;
ldout(cct, 10) << "_finish_read got " << offset << "~" << bl.length()     << dendl;
ldout(cct, 0) << "_finish_read got less than expected (" << length << ")"      << dendl;
ldout(cct, 10) << "_assimilate_prefetch gap of " << gap       << " from received_pos " << received_pos       << " to first prefetched buffer " << p->first << dendl;
ldout(cct, 10) << "_assimilate_prefetch " << p->first << "~"     << p->second.length() << dendl;
ldout(cct, 10) << "_assimilate_prefetch read_buf now " << read_pos << "~"     << read_buf.length() << ", read pointers read_pos=" << read_pos                    << " received_pos=" << received_pos << " requested_pos=" << requested_pos     << dendl;
ldout(cct, 10) << "_finish_read now readable (or at journal end) readable="                   << readable << " read_pos=" << read_pos << " write_pos="                   << write_pos << dendl;
ldout(cct, 10) << "_issue_read requested_pos = safe_pos = " << safe_pos     << ", waiting" << dendl;
ldout(cct, 10) << "_issue_read reading only up to safe_pos " << safe_pos     << dendl;
ldout(cct, 10) << "_issue_read reading " << requested_pos << "~" << len   << ", read pointers read_pos=" << read_pos << " received_pos=" << received_pos   << " requested_pos+len=" << (requested_pos+len) << dendl;
ldout(cct, 10) << "_prefetch " << pf << " requested_pos " << requested_pos     << " < target " << target << " (" << raw_target     << "), prefetching " << len << dendl;
ldout(cct, 10) << "_prefetch: requested_pos=" << requested_pos                     << ", read_pos=" << read_pos                     << ", write_pos=" << write_pos                     << ", safe_pos=" << safe_pos << dendl;
ldout(cct, 10) << "is_readable() detected partial entry at tail, "      "adjusting write_pos to " << read_pos << dendl;
ldout(cct, 10) << "_is_readable noting temp_fetch_len " << temp_fetch_len     << dendl;
ldout(cct, 10) << "try_read_entry at " << read_pos << " not readable"     << dendl;
ldout(cct, 10) << "try_read_entry at " << read_pos << " read "   << read_pos << "~" << consumed << " (have "   << read_buf.length() << ")" << dendl;
ldout(cct, 10) << "wait_for_readable at " << read_pos << " onreadable "     << onreadable << dendl;
ldout(cct, 10) << "trim last_commited head was " << last_committed    << ", can trim to " << trim_to    << dendl;
ldout(cct, 10) << "trim already trimmed/trimming to "     << trimmed_pos << "/" << trimming_pos << dendl;
ldout(cct, 10) << "trim already trimming atm, try again later.  "      "trimmed/trimming is " << trimmed_pos << "/" << trimming_pos << dendl;
ldout(cct, 10) << "trim trimming to " << trim_to   << ", trimmed/trimming/expire are "   << trimmed_pos << "/" << trimming_pos << "/" << expire_pos   << dendl;
ldout(cct, 10) << "_finish_trim trimmed_pos was " << trimmed_pos    << ", trimmed/trimming/expire now "    << to << "/" << trimming_pos << "/" << expire_pos    << dendl;
ldout(cct, 15) << "send_linger " << info->linger_id << " reconnect"     << dendl;
ldout(cct, 15) << "send_linger " << info->linger_id << " register"     << dendl;
ldout(cct, 10) << "_linger_commit  notify_id=" << info->notify_id       << dendl;
ldout(cct, 10) << __func__ << " " << info->linger_id << " = " << ec    << " (last_error " << info->last_error << ")" << dendl;
ldout(cct, 10) << __func__ << " " << info->linger_id << " SKIPPING"     << dendl;
ldout(cct, 10) << __func__ << " " << info->linger_id << " now " << now   << dendl;
ldout(cct, 10) << __func__ << " " << info->linger_id   << " sent " << sent << " gen " << register_gen << " = " << ec   << " (last_error " << info->last_error   << " register_gen " << info->register_gen << ")" << dendl;
ldout(cct, 10) << __func__ << " " << info->linger_id   << " err " << info->last_error   << " age " << age << dendl;
ldout(cct, 10) << __func__ << " info " << info   << " linger_id " << info->linger_id   << " cookie " << info->get_cookie()   << dendl;
ldout(cct, 10) << __func__ << " reply notify " << m->notify_id       << " != " << info->notify_id << ", ignoring" << dendl;
ldout(cct, 10) << " need to unregister linger op "         << op->linger_id << dendl;
ldout(cct, 0) << "handle_osd_map fsid " << m->fsid    << " != " << monc->get_fsid() << dendl;
ldout(cct, 3) << "handle_osd_map ignoring epochs ["    << m->get_first() << "," << m->get_last()    << "] <= " << osdmap->get_epoch() << dendl;
ldout(cct, 3) << "handle_osd_map got epochs ["    << m->get_first() << "," << m->get_last()    << "] > " << osdmap->get_epoch() << dendl;
ldout(cct, 3) << "handle_osd_map decoding incremental epoch " << e   << dendl;
ldout(cct, 3) << "handle_osd_map requesting missing epoch "     << osdmap->get_epoch()+1 << dendl;
ldout(cct, 3) << "handle_osd_map missing epoch "   << osdmap->get_epoch()+1   << ", jumping to " << m->get_oldest() << dendl;
ldout(cct, 3) << "handle_osd_map decoding full epoch "        << m->get_last() << dendl;
ldout(cct, 3) << "handle_osd_map hmm, i want a full map, requesting"        << dendl;
lgeneric_subdout(objecter->cct, objecter, 10)    << "op_map_latest r=" << e << " tid=" << tid    << " latest " << latest << dendl;
lgeneric_subdout(objecter->cct, objecter, 10)      << "op_map_latest op "<< tid << " not found" << dendl;
lgeneric_subdout(objecter->cct, objecter, 20)    << "op_map_latest op "<< op << dendl;
ldout(cct, 10) << "check_op_pool_dne tid " << op->tid     << " pool previously exists but now does not"     << dendl;
ldout(cct, 10) << "check_op_pool_dne tid " << op->tid     << " current " << osdmap->get_epoch()     << " map_dne_bound " << op->map_dne_bound     << dendl;
ldout(cct, 10) << "check_op_pool_dne tid " << op->tid       << " concluding pool " << op->target.base_pgid.pool()       << " dne" << dendl;
ldout(cct, 10) << "_check_linger_pool_dne linger_id " << op->linger_id     << " pool previously existed but now does not"     << dendl;
ldout(cct, 10) << "_check_linger_pool_dne linger_id " << op->linger_id     << " current " << osdmap->get_epoch()     << " map_dne_bound " << op->map_dne_bound     << dendl;
ldout(cct, 10) << "_check_command_map_dne tid " << c->tid   << " current " << osdmap->get_epoch()   << " map_dne_bound " << c->map_dne_bound   << dendl;
ldout(cct, 20) << __func__ << " osd=" << osd << " returning homeless"     << dendl;
ldout(cct, 20) << __func__ << " s=" << s << " osd=" << osd << " "     << s->get_nref() << dendl;
ldout(cct, 20) << __func__ << " s=" << s << " osd=" << osd << " "   << s->get_nref() << dendl;
ldout(cct, 20) << __func__ << " s=" << s << " osd=" << s->osd << " "     << s->get_nref() << dendl;
ldout(cct, 20) << __func__ << " s=" << s << " osd=" << s->osd << " "     << s->get_nref() << dendl;
ldout(cct, 10) << "reopen_session osd." << s->osd << " session, addr now "   << addrs << dendl;
ldout(cct, 10) << "_maybe_request_map subscribing (continuous) to next "      "osd map (FULL flag is set)" << dendl;
ldout(cct, 10)      << "_maybe_request_map subscribing (onetime) to next osd map" << dendl;
ldout(cct, 2) << " tid " << p->first << " on osd." << op->session->osd        << " is laggy" << dendl;
ldout(cct, 10) << " pinging osd that serves lingering tid " << p->first       << " (osd." << op->session->osd << ")" << dendl;
ldout(cct, 10) << " pinging osd that serves command tid " << p->first       << " (osd." << op->session->osd << ")" << dendl;
ldout(cct, 10) << __func__ << " relock raced with osdmap, recalc target"       << dendl;
ldout(cct, 10) << " tid " << op->tid << " op " << op << " is paused"     << dendl;
ldout(cct, 10) << "_op_submit oid " << op->target.base_oid   << " '" << op->target.base_oloc << "' '"   << op->target.target_oloc << "' " << op->ops << " tid "   << op->tid << " osd." << (!s->is_homeless() ? s->osd : -1)   << dendl;
ldout(cct, 10) << __func__ << " tid " << tid << " dne in session "     << s->osd << dendl;
ldout(cct, 20) << " revoking rx ceph::buffer for " << tid     << " on " << s->con << dendl;
ldout(cct, 10) << __func__ << " tid " << tid << " in session " << s->osd   << dendl;
ldout(cct, 5) << __func__ << ": cancelling tid " << tid << " r=" << r  << dendl;
ldout(cct, 5) << __func__ << ": tid " << tid  << " not found in live sessions" << dendl;
ldout(cct, 5) << __func__ << ": tid " << tid  << " not found in homeless session" << dendl;
ldout(cct,10) << __func__ << " op " << op->tid << " snapc " << op->snapc      << " (was " << new_snaps << ")" << dendl;
ldout(cct,20) << __func__ << " epoch " << t->epoch  << " base " << t->base_oid << " " << t->base_oloc  << " precalc_pgid " << (int)t->precalc_pgid  << " pgid " << t->base_pgid  << (is_read ? " is_read" : "")  << (is_write ? " is_write" : "")  << dendl;
ldout(cct,30) << __func__ << "  base pi " << pi  << " pg_num " << pi->get_pg_num() << dendl;
ldout(cct,20) << __func__ << " target " << t->target_oid << " "  << t->target_oloc << " -> pgid " << pgid << dendl;
ldout(cct,30) << __func__ << "  target pi " << pi  << " pg_num " << pi->get_pg_num() << dendl;
ldout(cct, 10) << __func__ << " paused " << t->paused     << " -> " << should_be_paused << dendl;
ldout(cct, 10) << __func__ << " "     << " raw pgid " << pgid << " -> actual " << t->actual_pgid     << " acting " << acting     << " primary " << acting_primary << dendl;
ldout(cct, 10) << " chose random osd." << osd << " of " << acting         << dendl;
ldout(cct, 20) << __func__ << " localize: rank " << i    << " osd." << acting[i]    << " locality " << locality << dendl;
ldout(cct, 15) << __func__ << " " << to->osd << " " << op->linger_id   << dendl;
ldout(cct, 15) << __func__ << " " << from->osd << " " << op->linger_id   << dendl;
ldout(cct, 10) << "recalc_linger_op_target tid " << linger_op->linger_id     << " pgid " << linger_op->target.pgid     << " acting " << linger_op->target.acting << dendl;
ldout(cct, 20) << __func__ << " ? " << q->first << " [" << q->second.begin       << "," << q->second.end << ")" << dendl;
ldout(cct, 10) << __func__ << " backoff " << op->target.actual_pgid         << " id " << q->second.id << " on " << hoid         << ", queuing " << op << " tid " << op->tid << dendl;
ldout(cct, 10) << __func__ << " " << op->tid << " pgid change from "     << m->get_spg() << " to " << op->target.actual_pgid     << ", updating and reencoding" << dendl;
ldout(cct, 15) << "_send_op " << op->tid << " to "   << op->target.actual_pgid << " on osd." << op->session->osd   << dendl;
ldout(cct, 20) << " revoking rx ceph::buffer for " << op->tid << " on "     << op->con << dendl;
ldout(cct, 20) << " posting rx ceph::buffer for " << op->tid << " on " << con     << dendl;
ldout(cct, 7) << "handle_osd_op_reply " << tid    << (m->is_ondisk() ? " ondisk" : (m->is_onnvram() ?          " onnvram" : " ack"))    << " ... stray" << dendl;
ldout(cct, 7) << "handle_osd_op_reply " << tid  << (m->is_ondisk() ? " ondisk" :      (m->is_onnvram() ? " onnvram" : " ack"))  << " uv " << m->get_user_version()  << " in " << m->get_pg()  << " attempt " << m->get_retry_attempt()  << dendl;
ldout(cct, 7) << " ignoring reply from attempt "      << m->get_retry_attempt()      << " from " << m->get_source_inst()      << ";
last attempt " << (op->attempts - 1) << " sent to "      ldout(cct,10) << __func__ << " copying resulting " << bl.length()      << " into existing ceph::buffer of length " << op->outbl->length()      << dendl;
ldout(cct, 0) << "WARNING: tid " << op->tid << " reply ops " << out_ops    << " != request ops " << op->ops    << " from " << m->get_source_inst() << dendl;
ldout(cct, 10) << " op " << i << " rval " << p->rval     << " len " << p->outdata.length() << dendl;
ldout(cct, 10) << __func__ << " unblock backoff " << b->pgid         << " id " << b->id         << " [" << b->begin << "," << b->end         << ")" << dendl;
ldout(cct, 20) << __func__ <<  " contained_by " << r << " on "      << q.second->target.get_hobj() << dendl;
ldout(cct, 10) << __func__ << " " << list_context   << " pos " << pos << " -> " << list_context->pos << dendl;
ldout(cct, 10) << __func__ << " pool_id " << list_context->pool_id   << " pool_snap_seq " << list_context->pool_snap_seq   << " max_entries " << list_context->max_entries   << " list_context " << list_context   << " onfinish " << onfinish   << " current_pg " << list_context->current_pg   << " pos " << list_context->pos << dendl;
ldout(cct, 10) << " hobject sort order changed, restarting this pg at "     << list_context->pos << dendl;
ldout(cct, 20) << __func__ << " end of pool, list "     << list_context->list << dendl;
ldout(cct, 20) << " response.entries.size " << response_size   << ", response.entries " << response.entries   << ", handle " << response.handle   << ", tentative new pos " << list_context->pos << dendl;
ldout(cct, 20) << " hit max, returning results so far, "     << list_context->list << dendl;
ldout(cct, 10) << " release listing context's budget " <<      list_context->ctx_budget << dendl;
ldout(cct, 10) << "have request " << tid << " at " << op << " Op: "     << ceph_pool_op_name(op->pool_op) << dendl;
ldout(cct, 20) << "waiting for client to reach epoch " << m->epoch         << " before calling back" << dendl;
ldout(cct, 1) << "ms_handle_reset " << con << " session " << session      << " osd." << session->osd << dendl;
ldout(cct, 20) << op->tid << "\t" << op->target.pgid     << "\tosd." << (op->session ? op->session->osd : -1)     << "\t" << op->target.base_oid     << "\t" << op->ops << dendl;
ldout(cct, 20) << "dump_active .. " << num_homeless_ops << " homeless"   << dendl;
ldout(cct, 10) << "handle_command_reply tid " << m->get_tid()     << " not found" << dendl;
ldout(cct, 10) << "handle_command_reply tid " << m->get_tid()     << " got reply from wrong connection "     << m->get_connection() << " " << m->get_source_inst()     << dendl;
ldout(cct,10) << __func__ << " tid " << m->get_tid()    << " got EAGAIN, requesting map and resending" << dendl;
ldout(cct, 20) << "_recalc_command_target " << c->tid << " no change, "   << c->session << dendl;
ldout(cct, 10) << "_finish_command " << c->tid << " = " << ec << " "   << rs << dendl;
ldout(cct, 7) << __func__ << ": barrier " << epoch << " (was "  << epoch_barrier << ") current epoch " << osdmap->get_epoch()  << dendl;
ldout(cct, 20) << "  t " << tofs << "~" << tlen                   << " bl has " << bl.length()                   << " off " << *bl_off << dendl;
ldout(cct, 20) << " su " << su << " sc " << stripe_count << " os "   << object_size << " stripes_per_object " << stripes_per_object   << dendl;
ldout(cct, 20) << " off " << cur << " blockno " << blockno << " stripeno "     << stripeno << " stripepos " << stripepos << " objectsetno "     << objectsetno << " objectno " << objectno     << " block_start " << block_start << " block_off "     << block_off << " " << x_offset << "~" << x_len     << dendl;
// ldout(cct, 0) << "map: ino " << ino << " oid " << ex.oid << " osd "    //    << ex.osd << " offset " << ex.offset << " len " << ex.len    //    << " ... left " << left << dendl;
ldout(cct, 10) << "extent_to_file " << objectno << " " << off << "~"   << len << dendl;
ldout(cct, 20) << " object " << off << "~" << extent_len     << " -> file " << extent_off << "~" << extent_len     << dendl;
ldout(cct, 20) << "object_truncate_size " << objectno << " "   << trunc_size << "->" << obj_trunc_size << dendl;
ldout(cct, 10) << "add_partial_result(" << this << ") " << bl.length()   << " to " << buffer_extents << dendl;
ldout(cct, 10) << "add_partial_result(" << this << ") " << bl.length()   << " to " << buffer_extents << dendl;
ldout(cct, 10) << "add_partial_sparse_result(" << this << ") " << bl.length()   << " covering " << bl_map << " (offset " << bl_off << ")"   << " to " << buffer_extents << dendl;
ldout(cct, 10) << "add_partial_sparse_result(" << this << ") " << bl.length()   << " covering " << bl_map << " (offset " << bl_off << ")"   << " to " << buffer_extents << dendl;
ldout(cct, 10) << "assemble_result(" << this << ") zero_tail=" << zero_tail   << dendl;
ldout(cct, 20) << "assemble_result(" << this << ") " << p->first << "~" << p->second.second     << " " << p->second.first.length() << " bytes"     << dendl;
