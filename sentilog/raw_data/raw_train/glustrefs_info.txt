./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:    gf_log("mgmt", GF_LOG_INFO, "Volume file changed");
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:    gf_log(this->name, GF_LOG_INFO, "got attach for %s", xlator_req.name);
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:    gf_log(THIS->name, GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:    gf_log(THIS->name, GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:    gf_log(THIS->name, GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:            gf_log("glusterfsd-mgmt", GF_LOG_DEBUG, "Reconfigure failed !!");
./glusterfs/glusterfsd/src/glusterfsd.c:                cmd_args->logger = gf_logger_glusterlog;
./glusterfs/glusterfsd/src/glusterfsd.c:                cmd_args->logger = gf_logger_syslog;
./glusterfs/glusterfsd/src/glusterfsd.c:                cmd_args->log_format = gf_logformat_traditional;
./glusterfs/glusterfsd/src/glusterfsd.c:                cmd_args->log_format = gf_logformat_withmsgid;
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_disable_suppression_before_exit(ctx);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_logrotate(1);
./glusterfs/glusterfsd/src/glusterfsd.c:    cmd_args->logger = gf_logger_glusterlog;
./glusterfs/glusterfsd/src/glusterfsd.c:    cmd_args->log_format = gf_logformat_withmsgid;
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_loglevel(ctx, cmd_args->log_level);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_localtime(cmd_args->localtime_logging);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_logger(cmd_args->logger);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_logformat(cmd_args->log_format);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_log_buf_size(cmd_args->log_buf_size);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_set_log_flush_timeout(cmd_args->log_flush_timeout);
./glusterfs/glusterfsd/src/glusterfsd.c:    ret = gf_log_inject_timer_event(ctx);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_log_dump_graph(fp, graph);
./glusterfs/api/src/glfs-mgmt.c:    gf_log_dump_graph(fp, graph);
./glusterfs/api/src/glfs.c:        gf_log_globals_init(ctx, GF_LOG_NONE);
./glusterfs/api/src/glfs.c:        gf_log_set_loglevel(fs->ctx, loglevel);
./glusterfs/api/src/glfs.c:    ret = gf_log_init(fs->ctx, tmplog, NULL);
./glusterfs/api/src/glfs.c:    ret = gf_log_inject_timer_event(fs->ctx);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:            gf_log(this->name, GF_LOG_INFO, "lost connection in %s", __func__);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:    gf_log(this->name, GF_LOG_DEBUG, "peer CN = %s", peer_CN);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:                gf_log(this->name, GF_LOG_TRACE, "error getting cname");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:                    gf_log(this->name, GF_LOG_TRACE, "ssl_accepted!");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:                    gf_log(this->name, GF_LOG_TRACE, "ssl_connected!");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_TRACE, "***** reading over SSL");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_TRACE, "***** reading over non-SSL");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(THIS->name, GF_LOG_TRACE, "NODELAY enabled for socket %d", fd);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_TRACE, ">>> disconnecting SSL socket");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:            gf_log(this->name, GF_LOG_TRACE, ">>> completed client connect");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_DEBUG, "re-enabling SSL for I/O connection");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log_callingfn(this->name, GF_LOG_DEBUG, "already listening");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:            gf_log(this->name, GF_LOG_DEBUG, "already listening");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_TRACE, "found old SSL context!");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_INFO, "using cipher list %s", cipher_list);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_INFO, "using DH parameters %s", dh_param);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_INFO, "using EC curve %s", ec_curve);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:            gf_log(this->name, GF_LOG_DEBUG, "disabling nodelay");
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_TRACE, "transport %p destroyed", this);
./glusterfs/rpc/rpc-transport/socket/src/socket.c:        gf_log(this->name, GF_LOG_DEBUG, "socket_init() failed");
./glusterfs/rpc/rpc-transport/socket/src/name.c:    gf_log(this->name, GF_LOG_TRACE, "using connect-path %s", connect_path);
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:            gf_log(conn->name, GF_LOG_TRACE, "attempting reconnect");
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:            gf_log(conn->name, GF_LOG_TRACE, "breaking reconnect chain");
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:        gf_log(name, GF_LOG_DEBUG, "defaulting frame-timeout to 30mins");
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:        gf_log(name, GF_LOG_DEBUG, "disable ping-timeout");
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:        gf_log("rpc-clnt", GF_LOG_DEBUG, "Failed to create RPC request");
./glusterfs/rpc/rpc-lib/src/rpc-clnt.c:        gf_log_callingfn(clnt->conn.name, GF_LOG_DEBUG, "already registered");
./glusterfs/rpc/rpc-lib/src/rpc-transport.c:            gf_log("dict", GF_LOG_DEBUG, "setting transport-type failed");
./glusterfs/rpc/rpc-lib/src/rpc-transport.c:                gf_log("dict", GF_LOG_DEBUG, "setting address-family failed");
./glusterfs/rpc/rpc-lib/src/rpc-transport.c:                gf_log("dict", GF_LOG_DEBUG, "setting transport-type failed");
./glusterfs/rpc/rpc-lib/src/rpc-transport.c:    gf_log("rpc-transport", GF_LOG_DEBUG, "attempt to load file %s", name);
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:        gf_log("rpcsvc", GF_LOG_TRACE, "Client port: %d", (int)port);
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:    gf_log(GF_RPCSVC, GF_LOG_TRACE, "Tx message: %zu", msglen);
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:    gf_log_callingfn("", GF_LOG_DEBUG, "sending a RPC error reply");
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:    gf_log(GF_RPCSVC, GF_LOG_TRACE, "rx pool: %d", poolcount);
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:    gf_log(GF_RPCSVC, GF_LOG_DEBUG, "RPC service inited.");
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:    gf_log(GF_RPCSVC, GF_LOG_TRACE, "Client port: %d", (int)port);
./glusterfs/rpc/rpc-lib/src/rpcsvc.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "Unprivileged port allowed");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "rb tree creation failed");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "initialization of drc client failed");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "drc client is NULL");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "Failed to add op to drc cache");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:        gf_log(GF_RPCSVC, GF_LOG_INFO, "drc user options need second look");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:    gf_log(GF_RPCSVC, GF_LOG_INFO, "DRC is turned %s", (ret ? "ON" : "OFF"));
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:    gf_log(GF_RPCSVC, GF_LOG_DEBUG, "drc init successful");
./glusterfs/rpc/rpc-lib/src/rpc-drc.c:    gf_log(GF_RPCSVC, GF_LOG_INFO, "DRC is turned %s", (ret ? "ON" : "OFF"));
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:            gf_log("rpc-auth", GF_LOG_DEBUG, "dict_set failed for 'auth-nill'");
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:            gf_log("rpc-auth", GF_LOG_DEBUG, "dict_set failed for 'auth-unix'");
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:            gf_log("rpc-auth", GF_LOG_DEBUG, "dict_set failed for 'auth-unix'");
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:        gf_log(GF_RPCSVC, GF_LOG_DEBUG, "Addr-Name lookup enabled");
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:    gf_log(GF_RPCSVC, GF_LOG_TRACE, "No auth handler: %d", req->cred.flavour);
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:    gf_log(GF_RPCSVC, GF_LOG_TRACE, "Auth handler: %s", auth->authname);
./glusterfs/rpc/rpc-lib/src/rpcsvc-auth.c:            gf_log("rpc", GF_LOG_DEBUG, "auth type not unix or glusterfs");
./glusterfs/tests/basic/logchecks.c:    ret = gf_log_init(ctx, TEST_FILENAME, "logchecks");
./glusterfs/tests/basic/logchecks.c:        printf("Error from gf_log_init [%s]\n", strerror(errno));
./glusterfs/tests/basic/logchecks.c:    gf_log_logrotate(0);
./glusterfs/tests/basic/logchecks.c:    gf_log_flush();
./glusterfs/tests/basic/logchecks.c:    gf_log_set_logformat(gf_logformat_traditional);
./glusterfs/tests/basic/logchecks.c:    gf_log_set_logformat(gf_logformat_withmsgid);
./glusterfs/tests/basic/logchecks.c:    gf_log_set_loglevel(ctx, GF_LOG_INFO);
./glusterfs/tests/basic/logchecks.c:    gf_log_set_logger(gf_logger_syslog);
./glusterfs/tests/basic/logchecks.c:    gf_log_set_logformat(gf_logformat_traditional);
./glusterfs/tests/basic/logchecks.c:    gf_log_fini(ctx);
./glusterfs/tests/basic/logchecks.c:    gf_log_globals_fini();
./glusterfs/contrib/umountd/umountd.c:        gf_log_logrotate (1);
./glusterfs/contrib/umountd/umountd.c:        ret = gf_log_init (ctx, log_file, "umountd");
./glusterfs/contrib/umountd/umountd.c:                fprintf (stderr, "gf_log_init failed\n");
./glusterfs/contrib/umountd/umountd.c:                        gf_log ("umountd", GF_LOG_INFO, "Unmounted %s", path);
./glusterfs/xlators/storage/posix/src/posix-entry-ops.c:    gf_loglevel_t level = GF_LOG_NONE;
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_loglevel_t log_level = gf_log_get_loglevel();
./glusterfs/xlators/features/namespace/src/namespace.c:        gf_log(this->name, GF_LOG_DEBUG, "%s: FD  retrieved path %s", fn, path);
./glusterfs/xlators/features/namespace/src/namespace.c:    gf_log(this->name, GF_LOG_INFO, "Namespace xlator loaded");
./glusterfs/xlators/features/barrier/src/barrier.c:    gf_log(this->name, GF_LOG_INFO, "Dequeuing all the barriered fops");
./glusterfs/xlators/features/gfid-access/src/gfid-access.c:        gf_log(this->name, GF_LOG_DEBUG, "dangling volume. check volfile ");
./glusterfs/xlators/features/locks/src/entrylk.c:            gf_log(this->name, GF_LOG_INFO, "pl_ctx_get() failed");
./glusterfs/xlators/features/locks/src/posix.c:            gf_log(this->name, GF_LOG_DEBUG, "failed to set fd ctx");
./glusterfs/xlators/features/locks/src/posix.c:    gf_log(this->name, GF_LOG_DEBUG, "%s", lk_summary);
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_DEBUG, "Could not get inode.");
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_DEBUG, "Could not get inode.");
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_TRACE, "Releasing all locks with fd %p", fd);
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(THIS->name, GF_LOG_DEBUG, "fdctx lock list empty");
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(THIS->name, GF_LOG_DEBUG, "marking EOL in reqlock");
./glusterfs/xlators/features/locks/src/posix.c:            gf_log(this->name, GF_LOG_DEBUG, "fd=%p has no active locks", fd);
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_DEBUG, "There are active locks on fd");
./glusterfs/xlators/features/locks/src/posix.c:                gf_log(this->name, GF_LOG_DEBUG, "getting locks on fd failed");
./glusterfs/xlators/features/locks/src/posix.c:                gf_log(this->name, GF_LOG_DEBUG, "returning EAGAIN");
./glusterfs/xlators/features/locks/src/posix.c:    gf_log(this->name, GF_LOG_TRACE, "Releasing all locks with fd %p", fd);
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_DEBUG, "Could not get fdctx");
./glusterfs/xlators/features/locks/src/posix.c:        gf_log(this->name, GF_LOG_DEBUG, "Could not get fdctx");
./glusterfs/xlators/features/locks/src/inodelk.c:            gf_log(this->name, GF_LOG_INFO, "pl_ctx_get() failed");
./glusterfs/xlators/features/locks/src/inodelk.c:                    gf_log(this->name, GF_LOG_TRACE, "returning EAGAIN");
./glusterfs/xlators/features/locks/src/inodelk.c:                    gf_log(this->name, GF_LOG_TRACE, "returning %d", ret);
./glusterfs/xlators/features/locks/src/common.c:        gf_log("posix-locks", GF_LOG_TRACE, "Domain %s found", volume);
./glusterfs/xlators/features/locks/src/common.c:        gf_log("posix-locks", GF_LOG_TRACE, "Domain %s not found", volume);
./glusterfs/xlators/features/locks/src/common.c:    gf_log(this->name, GF_LOG_INFO, "[RELEASE] Lockee = {%s}", pl_lockee);
./glusterfs/xlators/features/locks/src/common.c:        gf_log(this->name, GF_LOG_TRACE, "Allocating new pl inode");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_TRACE, "No reservelks in list");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log("posix-locks", GF_LOG_TRACE, "reservelk list empty");
./glusterfs/xlators/features/locks/src/reservelk.c:            gf_log("posix-locks", GF_LOG_TRACE, "equal reservelk found");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_TRACE, "Matching reservelk found");
./glusterfs/xlators/features/locks/src/reservelk.c:            gf_log(this->name, GF_LOG_TRACE, "Conflicting reservelk found");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_DEBUG, " Matching lock not found for unlock");
./glusterfs/xlators/features/locks/src/reservelk.c:    gf_log(this->name, GF_LOG_DEBUG, " Matching lock found for unlock");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_TRACE, "No blocked locks to be granted");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_TRACE, "No blocked lock calls to be granted");
./glusterfs/xlators/features/locks/src/reservelk.c:                gf_log(this->name, GF_LOG_DEBUG, "returning EAGAIN");
./glusterfs/xlators/features/locks/src/reservelk.c:            gf_log(this->name, GF_LOG_DEBUG, "Bad Unlock issued on Inode lock");
./glusterfs/xlators/features/locks/src/reservelk.c:        gf_log(this->name, GF_LOG_TRACE, "Reservelk Unlock successful");
./glusterfs/xlators/features/leases/src/leases.c:    gf_log(this->name, GF_LOG_TRACE, "Releasing all leases with fd %p", fd);
./glusterfs/xlators/features/leases/src/leases.c:        gf_log(this->name, GF_LOG_DEBUG, "Could not get fdctx");
./glusterfs/xlators/features/marker/src/marker.c:    gf_log(this->name, GF_LOG_DEBUG, "USER:PID = %d", frame->root->pid);
./glusterfs/xlators/features/marker/src/marker.c:    gf_log(this->name, GF_LOG_DEBUG, "volume-uuid = %s", priv->volume_uuid);
./glusterfs/xlators/features/upcall/src/upcall-internal.c:        gf_log(this->name, GF_LOG_DEBUG, "failed to set inode ctx (%p)", inode);
./glusterfs/xlators/features/upcall/src/upcall.c:            gf_log(this->name, GF_LOG_DEBUG, "Upcall Notify event = %d", event);
./glusterfs/xlators/features/changelog/lib/src/gf-changelog.c:    gf_log_set_loglevel(this->ctx, (loglevel == -1) ? GF_LOG_INFO : loglevel);
./glusterfs/xlators/features/compress/src/cdc.c:        gf_log(this->name, GF_LOG_DEBUG, "CDC debug option turned on");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log("trash", GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "Bad address");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:                gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:                gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "trash xlator is off");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_INFO, "default notify event failed");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:            gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:        gf_log(this->name, GF_LOG_DEBUG, "out of memory");
./glusterfs/xlators/features/trash/src/trash.c:    gf_log(this->name, GF_LOG_DEBUG, "brick path is%s", priv->brick_path);
./glusterfs/xlators/features/read-only/src/read-only.c:    gf_log(this->name, GF_LOG_DEBUG, "returning %d", ret);
./glusterfs/xlators/features/read-only/src/worm.c:    gf_log(this->name, GF_LOG_DEBUG, "returning %d", ret);
./glusterfs/xlators/features/read-only/src/worm.c:            gf_log(this->name, GF_LOG_DEBUG, "Failed to get the fd ctx");
./glusterfs/xlators/features/read-only/src/worm-helper.c:    gf_log(this->name, GF_LOG_INFO, "Retention state reset");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:            gf_log("glusterfs-fuse", GF_LOG_DEBUG, "fd-ctx-set failed");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:    gf_log("glusterfs-fuse", GF_LOG_DEBUG, "intstat_orig=%d", intstat_orig);
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:    gf_log("glusterfs-fuse", GF_LOG_DEBUG, "intstat_orig=%d", intstat_orig);
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:        gf_log(state->this->name, GF_LOG_DEBUG, "inode already present");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:        gf_log(state->this->name, GF_LOG_DEBUG, "inode already present");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:        gf_log(state->this->name, GF_LOG_DEBUG, "inode already present");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:        gf_log(state->this->name, GF_LOG_DEBUG, "inode already present");
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:    ret = is_gf_log_command(this, name, value, fsi->size);
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:        gf_log("fuse", GF_LOG_INFO, "switched to graph %d", new_graph_id);
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:    gf_log(this->name, GF_LOG_DEBUG, "mount status is %d", kid_status);
./glusterfs/xlators/mount/fuse/src/fuse-bridge.c:            gf_log(this_xl->name, GF_LOG_INFO, "Unmounting '%s'.", mount_point);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:                    gf_log (GF_NFS3, GF_LOG_TRACE, "Cookieverf does not match");
./glusterfs/xlators/meta/src/loglevel-file.c:        gf_log_set_loglevel(this->ctx, level);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:        gf_log ("", GF_LOG_DEBUG, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_log("glusterd", GF_LOG_INFO, "add user xlator=%s to graph", type);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_log(THIS->name, GF_LOG_DEBUG, "missing option %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_log(this->name, GF_LOG_INFO, "not connected yet");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_log(this->name, GF_LOG_DEBUG, "failure forward");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_log(this->name, GF_LOG_DEBUG, "failure backward");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_log(this->name, GF_LOG_DEBUG, "all options match");
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:        int already_enabled = gf_log_get_localtime();
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:            gf_log_set_localtime(1);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:            gf_log_set_localtime(0);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    already_enabled = gf_log_get_localtime();
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:        gf_log_set_localtime(1);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:        gf_log_set_localtime(0);
./glusterfs/xlators/cluster/afr/src/afr-self-heal-common.c:    gf_loglevel_t loglevel = GF_LOG_NONE;
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_loglevel_t log_level = gf_log_get_loglevel();
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_loglevel_t loglevel = 0;
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:            gf_log(this->name, GF_LOG_INFO, "No active locks on:%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_log(this->name, GF_LOG_INFO, "migrate data called on %s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:        gf_log("dht", GF_LOG_INFO, "tmp data size =%" PRIu64, tmp_size);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_log("DHT", GF_LOG_INFO, "crawling file-system completed");
./glusterfs/xlators/debug/error-gen/src/error-gen.c:        gf_log(this->name, GF_LOG_DEBUG, "fini called");
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log(this->name, GF_LOG_DEBUG, fmt);                                 \
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log(this->name, GF_LOG_DEBUG, "No samples, dump not required.");
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log(this->name, GF_LOG_DEBUG, "returning %d", ret);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log(this->name, GF_LOG_INFO, "--- fd stats ---");
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log(this->name, GF_LOG_INFO, "      Filename : %s", iosfd->filename);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log(this->name, GF_LOG_INFO, "      Lifetime : %lf secs", usecs);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log(this->name, GF_LOG_INFO, "IO stats dump thread terminated");
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log_set_loglevel(this->ctx, log_level);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log_set_logger(logger);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log_set_logformat(log_format);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log_set_log_buf_size(log_buf_size);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log_set_log_flush_timeout(log_flush_timeout);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log(this->name, GF_LOG_DEBUG, "dangling volume. check volfile ");
./glusterfs/xlators/debug/io-stats/src/io-stats.c:            gf_log_set_loglevel(this->ctx, log_level);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log_set_logger(logger);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:        gf_log_set_logformat(log_format);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log_set_log_buf_size(log_buf_size);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log_set_log_flush_timeout(log_flush_timeout);
./glusterfs/xlators/debug/io-stats/src/io-stats.c:    gf_log(this->name, GF_LOG_INFO, "io-stats translator unloaded");
./glusterfs/xlators/debug/trace/src/trace.c:    gf_log(this->name, GF_LOG_INFO, "history size %" PRIu64, history_size);
./glusterfs/xlators/debug/trace/src/trace.c:    gf_log_set_loglevel(this->ctx, conf->trace_log_level);
./glusterfs/xlators/debug/trace/src/trace.c:    gf_log(this->name, GF_LOG_INFO, "trace translator unloaded");
./glusterfs/xlators/playground/rot-13/src/rot-13.c:    gf_log("rot13", GF_LOG_DEBUG, "rot13 xlator loaded");
./glusterfs/xlators/protocol/client/src/client.c:                    gf_log(this->name, GF_LOG_INFO, "CHILD_PING notify failed");
./glusterfs/xlators/protocol/client/src/client-rpc-fops.c:    gf_loglevel_t loglevel = GF_LOG_NONE;
./glusterfs/xlators/protocol/client/src/client-rpc-fops_v2.c:    gf_loglevel_t loglevel = GF_LOG_NONE;
./glusterfs/xlators/protocol/server/src/server-rpc-fops_v2.c:    gf_loglevel_t loglevel = GF_LOG_NONE;
./glusterfs/xlators/protocol/server/src/server-rpc-fops.c:    gf_loglevel_t loglevel = GF_LOG_NONE;
./glusterfs/cli/src/cli-cmd-volume.c:        gf_log("", GF_LOG_INFO, "geo-replication not installed");
./glusterfs/cli/src/cli-cmd-volume.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-cmd.c:        gf_log("", GF_LOG_INFO, "Exiting with: %d", ret);
./glusterfs/cli/src/cli-cmd.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/input.c:    gf_log("", GF_LOG_INFO, "Exiting with: %d", ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to probe");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to deprobe");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to list: %d", rsp.op_ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to get vol: %d", rsp.op_ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to create volume");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to delete volume");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to uuid get");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to uuid reset");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to start volume");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to stop volume");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get status");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "count %d %d", count, i);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get status");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "count %d %d", count, i);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get status");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get node-name");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get file count");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get size of xfer");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get lookedup file count");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get failures count");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get skipped count");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get run-time");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get time left");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to probe");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to reset");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to ganesha");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to set");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to add brick");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to remove brick");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to reset brick");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log(frame->this->name, GF_LOG_DEBUG, "Unknown operation");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to replace brick");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to log rotate");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to sync");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "Path not present in limit list");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to quota command");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log(frame->this->name, GF_LOG_TRACE, "failed to get type");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log(frame->this->name, GF_LOG_TRACE, "failed to get count");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to getspec");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to pmap b2p");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log(this->name, GF_LOG_DEBUG, "dict_get on operation failed");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log(this->name, GF_LOG_DEBUG, "dict_get on dst-brick failed");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log(this->name, GF_LOG_DEBUG, "dict_get on operation failed");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_INFO, "%s", errmsg);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_DEBUG, "failed to get %s from dict", key);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to profile");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to top");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to getwd");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received response to status cmd");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to mount");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to mount");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_INFO, "Received resp to heal volume");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received response to statedump");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received response to clear-locks");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get Brick Path");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get Volume Group");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get Brick Running");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get pid");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get Data Percent");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Unable to get LV Size");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get snapname from dict");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get volname1 from dict");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get snapuuid from dict");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_DEBUG, "failed to get clonename from dict");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received response to barrier");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received response to get volume option");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_INFO, "Failed to save timeout to dict");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get volume name");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get scrub state value");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get scrub impact value");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get scrub -freq value");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get bitrot log file location");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get scrubber log file location");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get scrubbed files");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get node-name");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get scrubbed files");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get unsigned files");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get last scrub duration");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get last scrub time");
./glusterfs/cli/src/cli-rpc-ops.c:            gf_log("cli", GF_LOG_TRACE, "failed to get error count");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, "Received resp to bit rot command");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get volume name");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "Failed to get scrub command");
./glusterfs/cli/src/cli-rpc-ops.c:        gf_log("cli", GF_LOG_TRACE, "failed to get command string");
./glusterfs/cli/src/cli-rpc-ops.c:    gf_log("cli", GF_LOG_DEBUG, RETURNING, ret);
./glusterfs/cli/src/registry.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:                gf_log("cli", GF_LOG_DEBUG, "Failed to get gsync status");
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:            gf_log("cli", GF_LOG_INFO, "Unable to get Brick Running");
./glusterfs/cli/src/cli-xml-output.c:            gf_log("cli", GF_LOG_INFO, "Unable to get pid");
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_TRACE, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_TRACE, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_TRACE, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_TRACE, "Returning %d", ret);
./glusterfs/cli/src/cli-xml-output.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-quotad-client.c:            gf_log(this->name, GF_LOG_TRACE, "got RPC_CLNT_CONNECT");
./glusterfs/cli/src/cli-quotad-client.c:            gf_log(this->name, GF_LOG_TRACE, "got RPC_CLNT_DISCONNECT");
./glusterfs/cli/src/cli.c:            gf_log(this->name, GF_LOG_TRACE, "got RPC_CLNT_CONNECT");
./glusterfs/cli/src/cli.c:            gf_log(this->name, GF_LOG_TRACE, "got RPC_CLNT_DISCONNECT");
./glusterfs/cli/src/cli.c:        state->log_level = (gf_loglevel_t)log_level;
./glusterfs/cli/src/cli-cmd-parser.c:        gf_log("cli", GF_LOG_INFO, "failed to set 'command' %d", command);
./glusterfs/cli/src/cli-cmd-parser.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-cmd-parser.c:    gf_log("cli", GF_LOG_DEBUG, "Returning %d", ret);
./glusterfs/cli/src/cli-cmd-parser.c:        gf_log("cli", GF_LOG_DEBUG, "Not a status op  %s", arg);
./glusterfs/cli/src/cli-cmd-parser.c:        gf_log("cli", GF_LOG_DEBUG, "Unknown statedump option  %s", arg);
./glusterfs/heal/src/glfs-heal.c:    gf_loglevel_t log_level = GF_LOG_INFO;
./glusterfs/libglusterfs/src/globals.c:    gf_log_globals_init(ctx, GF_LOG_INFO);
./glusterfs/libglusterfs/src/graph.c:        extern FILE *gf_log_logfile;
./glusterfs/libglusterfs/src/graph.c:        fprintf (gf_log_logfile, "Starting Time: %s\n", timestr);
./glusterfs/libglusterfs/src/graph.c:        fprintf (gf_log_logfile, "Command line : ");
./glusterfs/libglusterfs/src/graph.c:                fprintf (gf_log_logfile, "%s ", argv[i]);
./glusterfs/libglusterfs/src/graph.c:        fprintf (gf_log_logfile, "\nPID          : %d\n", mypid);
./glusterfs/libglusterfs/src/graph.c:        fprintf (gf_log_logfile, "\n");
./glusterfs/libglusterfs/src/graph.c:        fflush (gf_log_logfile);
./glusterfs/libglusterfs/src/graph.c:    gf_log_dump_graph(fp, graph);
./glusterfs/libglusterfs/src/xlator.c:            gf_log_enable_syslog();
./glusterfs/libglusterfs/src/xlator.c:            gf_log_disable_syslog();
./glusterfs/libglusterfs/src/xlator.c:                gf_log_get_loglevel(), NULL);
./glusterfs/libglusterfs/src/xlator.c:        gf_log_set_loglevel(this->ctx, log_level);
./glusterfs/libglusterfs/src/xlator.c:                gf_log_get_xl_loglevel(this), NULL);
./glusterfs/libglusterfs/src/xlator.c:        gf_log_set_xl_loglevel(this, log_level);
./glusterfs/libglusterfs/src/xlator.c:                    "old-value=%d", gf_log_get_xl_loglevel(trav), NULL);
./glusterfs/libglusterfs/src/xlator.c:            gf_log_set_xl_loglevel(trav, log_level);
./glusterfs/libglusterfs/src/xlator.c:    gf_log(__func__, GF_LOG_DEBUG, "copying %s to child %s", key, child->name);
./glusterfs/libglusterfs/src/common-utils.c:    gf_log_flush();
./glusterfs/libglusterfs/src/common-utils.c:    gf_log_disable_suppression_before_exit(ctx);
./glusterfs/libglusterfs/src/common-utils.c:        log_format = gf_logformat_traditional;
./glusterfs/libglusterfs/src/common-utils.c:        log_format = gf_logformat_withmsgid;
./glusterfs/libglusterfs/src/common-utils.c:        logger = gf_logger_glusterlog;
./glusterfs/libglusterfs/src/common-utils.c:        logger = gf_logger_syslog;
./glusterfs/libglusterfs/src/logging.c:    gf_log("logging-infra", GF_LOG_DEBUG, __msg, ##__args);
./glusterfs/libglusterfs/src/logging.c:gf_log_flush_timeout_cbk(void *data);
./glusterfs/libglusterfs/src/logging.c:gf_log_inject_timer_event(glusterfs_ctx_t *ctx);
./glusterfs/libglusterfs/src/logging.c:gf_log_flush_extra_msgs(glusterfs_ctx_t *ctx, uint32_t new);
./glusterfs/libglusterfs/src/logging.c:gf_log_rotate(glusterfs_ctx_t *ctx);
./glusterfs/libglusterfs/src/logging.c:        THIS->ctx->log.gf_log_syslog = 1;
./glusterfs/libglusterfs/src/logging.c:        THIS->ctx->log.gf_log_syslog = 0;
./glusterfs/libglusterfs/src/logging.c:        fflush(ctx->log.gf_log_logfile);
./glusterfs/libglusterfs/src/logging.c:        gf_log_flush_extra_msgs(ctx, buf_size);
./glusterfs/libglusterfs/src/logging.c:            ctx->log.gf_log_logfile = ctx->log.logfile = new_logfile;
./glusterfs/libglusterfs/src/logging.c:    gf_log_set_log_buf_size(0);
./glusterfs/libglusterfs/src/logging.c:    gf_log_disable_suppression_before_exit(ctx);
./glusterfs/libglusterfs/src/logging.c:    ctx->log.gf_log_syslog = 1;
./glusterfs/libglusterfs/src/logging.c:    ctx->log.logger = gf_logger_glusterlog;
./glusterfs/libglusterfs/src/logging.c:    ctx->log.logformat = gf_logformat_withmsgid;
./glusterfs/libglusterfs/src/logging.c:        ctx->log.gf_log_logfile = NULL;
./glusterfs/libglusterfs/src/logging.c:    ctx->log.gf_log_logfile = ctx->log.logfile;
./glusterfs/libglusterfs/src/logging.c:    gf_log_rotate(ctx);
./glusterfs/libglusterfs/src/logging.c:    gf_log_rotate(ctx);
./glusterfs/libglusterfs/src/logging.c:    gf_log_logger_t logger = ctx->log.logger;
./glusterfs/libglusterfs/src/logging.c:    gf_log_logger_t logger = 0;
./glusterfs/libglusterfs/src/logging.c:                                     buf->graph_id, gf_logformat_withmsgid);
./glusterfs/libglusterfs/src/logging.c:        gf_log_flush_message(iter, ctx);
./glusterfs/libglusterfs/src/logging.c:    gf_log_flush_list(&copy, ctx);
./glusterfs/libglusterfs/src/logging.c:    gf_log_flush_list(&copy, ctx);
./glusterfs/libglusterfs/src/logging.c:        ctx, timeout, gf_log_flush_timeout_cbk, (void *)ctx);
./glusterfs/libglusterfs/src/logging.c:        ret = __gf_log_inject_timer_event(ctx);
./glusterfs/libglusterfs/src/logging.c:    gf_log_flush_msgs(ctx);
./glusterfs/libglusterfs/src/logging.c:    (void)gf_log_inject_timer_event(ctx);
./glusterfs/libglusterfs/src/logging.c:                                     tv, graph_id, gf_logformat_traditional);
./glusterfs/libglusterfs/src/logging.c:        gf_log_flush_message(first, ctx);
./glusterfs/libglusterfs/src/logging.c:                                     tv, graph_id, gf_logformat_withmsgid);
./glusterfs/libglusterfs/src/logging.c:                (this->graph) ? this->graph->id : 0, gf_logformat_traditional);
./glusterfs/libglusterfs/src/logging.c:            ctx->log.gf_log_logfile = ctx->log.logfile = new_logfile;
gf_log(this->name, GF_LOG_INFO,               "terminating after loss of last child %s", xlator_req.name);
gf_log(this->name, GF_LOG_INFO,               "detaching not-only child %s "               " graceful_cleanup %d",               xlator_req.name, graceful_cleanup);
gf_log("glusterd", GF_LOG_INFO,           "Throughput %.2f Mbps time %.2f secs "           "bytes written %" PRId64,           throughput, time, total_blks);
gf_log("glusterd", GF_LOG_INFO,           "Throughput %.2f Mbps time %.2f secs "           "bytes read %" PRId64,           throughput, time, total_blks);
gf_log(frame->this->name, GF_LOG_INFO,           "Received list of available volfile servers: %s", servers_list);
gf_log(frame->this->name, GF_LOG_INFO,                           "No change in volfile,"                           "continuing");
gf_log("glusterfsd-mgmt", GF_LOG_DEBUG,                   "No need to re-load volfile, reconfigure done");
gf_log("glusterfsd-mgmt", GF_LOG_INFO,                   "connecting to next volfile server %s",                   server->volfile_server);
gf_log("fsd-mgmt", GF_LOG_DEBUG,               "portmapper signin arguments not given");
brick = %s", req.brick);
gf_log("glusterfs", GF_LOG_INFO, "Pid of current running process is %d",           getpid());
gf_log(frame->this->name, GF_LOG_INFO,           "Received list of available volfile servers: %s", servers_list);
gf_log("glfs_h_poll_upcall", GF_LOG_DEBUG,                       "UPCALL_RECALL_LEASE is not implemented yet");
gf_log(this->name, GF_LOG_TRACE,                                   \                   "partial read on non-blocking socket");
\    gf_log(log_domain, GF_LOG_TRACE,           "$$$ %s: %s (af:%d,sock:%d) %s %s (errno:%d:%s)", peer_type,           log_label, af, sock, addr, (is_ssl ? "SSL" : "non-SSL"), so_error,           strerror(so_error));
gf_log(this->name, GF_LOG_DEBUG,                   "syscall error (probably remote disconnect) "                   "errno:%d:%s",                   errno, strerror(errno));
gf_log(this->name, GF_LOG_TRACE,               "+ ssl_setup_connection_params() failed!");
gf_log(this->name, GF_LOG_TRACE,               "+ ssl_setup_connection_params() done!");
gf_log(this->name, GF_LOG_DEBUG,           "SSL verification succeeded (client: %s) (server: %s)",           this->peerinfo.identifier, this->myinfo.identifier);
gf_log(this->name, GF_LOG_DEBUG,                   "would have passed zero length to read/write");
gf_log(this->name, GF_LOG_TRACE,                   "### no priv->ssl_ssl yet;
ret = -1;
");
gf_log(this->name, GF_LOG_DEBUG,                       "EOF on socket %d (errno:%d:%s);
returning ENODATA",            gf_log(this->name, GF_LOG_DEBUG, "EOF from peer %s",                   this->peerinfo.identifier);
gf_log(this->name, GF_LOG_DEBUG, "ran out of iov, moved %d/%d",                       moved, ret);
gf_log(this->name, GF_LOG_DEBUG, "shutdown() returned %d. %s", ret,               strerror(errno));
gf_log(this->name, GF_LOG_TRACE, "disconnecting %p, sock=%d", this,           priv->sock);
gf_log(this->name, GF_LOG_DEBUG,                   "__socket_teardown_connection () failed: %s",                   strerror(errno));
gf_log(this->name, GF_LOG_INFO,                   "closing (AF_UNIX) reuse check socket %d", reuse_check_sock);
gf_log(this->name, GF_LOG_INFO,                   "process started listening on port (%d)",                   cmd_args->brick_port);
gf_log(THIS->name, GF_LOG_TRACE,           "Keep-alive enabled for socket: %d, "           "(idle: %d, interval: %d, max-probes: %d, timeout: %d)",           fd, keepaliveidle, keepaliveintvl, keepalivecnt, timeout);
gf_log(this->name, GF_LOG_TRACE,                       "__socket_ioq_churn returned -1;
gf_log(this->name, GF_LOG_TRACE,                       "partial read on non-blocking socket.");
gf_log(this->name, GF_LOG_TRACE,                           "partial "                           "fragment header read");
gf_log(this->name, GF_LOG_TRACE,                   "> ssl_setup_connection_prefix() failed!");
gf_log(this->name, GF_LOG_TRACE,                   "ssl_complete_connection returned error");
gf_log(this->name, GF_LOG_TRACE,                       "> ssl_setup_connection_prefix() "                       "failed!");
gf_log(this->name, GF_LOG_TRACE,                       ">>> retrying client connect 2");
gf_log(this->name, GF_LOG_TRACE,                       "ssl_complete_connection "                       "returned error");
gf_log("transport", GF_LOG_DEBUG,               "connect failed with some other error "               "than EINPROGRESS or ENOENT, so "               "nothing more to do;
disconnecting "        gf_log(this->name, GF_LOG_TRACE, "socket_connect_finish() returned %d",               ret);
gf_log(this->name, GF_LOG_TRACE, "%s (sock:%d) in:%d, out:%d, err:%d",           (priv->is_server ? "server" : "client"), priv->sock, poll_in,           poll_out, poll_err);
gf_log(this->name, GF_LOG_TRACE,                   "%s (sock:%d) socket is not connected, "                   "completing connection",                   (priv->is_server ? "server" : "client"), priv->sock);
gf_log(this->name, GF_LOG_TRACE,                   "(sock:%d) "                   "socket_complete_connection() returned %d",                   priv->sock, ret);
gf_log(this->name, GF_LOG_TRACE,                       "(sock:%d) returning to wait on socket", priv->sock);
gf_log(this->name, GF_LOG_TRACE,                   "%s socket (%d) is already connected", sock_type,                   priv->sock);
gf_log(this->name, GF_LOG_TRACE,               "(sock:%d) "               "socket_event_poll_out returned %d",               priv->sock, ret);
gf_log(this->name, GF_LOG_TRACE,               "(sock:%d) "               "socket_event_poll_in returned %d",               priv->sock, ret);
gf_log("transport", ((ret >= 0) ? GF_LOG_INFO : GF_LOG_DEBUG),               "EPOLLERR - disconnecting (sock:%d) (%s)", priv->sock,               (priv->use_ssl ? "SSL" : "non-SSL"));
closing newly accepted socket",        gf_log(this->name, GF_LOG_TRACE, "XXX server:%s, client:%s",               new_trans->myinfo.identifier, new_trans->peerinfo.identifier);
gf_log(this->name, GF_LOG_DEBUG, "%s SSL for portmapper connection",               priv->mgmt_ssl ? "enabling" : "disabling");
gf_log(this->name, GF_LOG_TRACE, "connecting %p, sock=%d", this,               priv->sock);
gf_log(this->name, GF_LOG_TRACE,                       ">>> connect() with non-blocking IO for ALL");
gf_log(this->name, GF_LOG_INFO,                   "intentional client shutdown(%d, SHUT_RDWR)", priv->sock);
"                gf_log(this->name, GF_LOG_INFO,                       "not connected (priv->connected = %d)", priv->connected);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.socket.keepalive");
gf_log(this->name, GF_LOG_DEBUG,           "Reconfigured transport.tcp-user-timeout=%d", priv->timeout);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.listen-backlog=%d", priv->backlog);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.socket.keepalive-time=%d",               priv->keepaliveidle);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.socket.keepalive-interval=%d",               priv->keepaliveintvl);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.socket.keepalive-count=%d",               priv->keepalivecnt);
gf_log(this->name, priv->ssl_enabled ? GF_LOG_INFO : GF_LOG_DEBUG,           "SSL support for MGMT is %s IO path is %s certificate depth is %d "           "for peer %s",           (priv->mgmt_ssl ? "ENABLED" : "NOT enabled"),           (priv->ssl_enabled ? "ENABLED" : "NOT enabled"), cert_depth,           this->peerinfo.identifier);
gf_log(this->name, GF_LOG_DEBUG, "Configured transport.tcp-user-timeout=%d",           priv->timeout);
gf_log(this->name, GF_LOG_DEBUG,               "Reconfigured transport.keepalivecnt=%d", priv->keepalivecnt);
logging socket read fails");
gf_log(this->name, GF_LOG_TRACE,                   "bind-path not specified for unix socket, "                   "letting connect to assign default value");
gf_log(this->name, GF_LOG_TRACE,               "bind-path not specified for unix socket, "               "letting connect to assign default value");
gf_log(this->name, GF_LOG_DEBUG,                   "address-family not specified, marking it as unspec "                   "for getaddrinfo to resolve from (remote-host: %s)",                   data_to_str(remote_host_data));
gf_log(this->name, GF_LOG_DEBUG,                   "address-family not specified, guessing it "                   "to be unix from (transport.unix.connect-path: %s)",                   data_to_str(connect_path_data));
gf_log(this->name, GF_LOG_TRACE,               "option remote-port missing in volume %s. Defaulting to %d",               this->name, GF_DEFAULT_SOCKET_LISTEN_PORT);
gf_log(this->name, GF_LOG_DEBUG,                           "cannot bind inet socket (%d) "                           "to port less than %d (%s)",                           sock, GF_CLIENT_PORT_CEILING, strerror(errno));
gf_log(this->name, GF_LOG_DEBUG,                           "failed while binding to less than "                           "%d (%s)",                           GF_IANA_PRIV_PORTS_START, strerror(errno));
gf_log(this->name, GF_LOG_DEBUG,               "option address-family not specified, "               "defaulting to %s",               addr_family);
gf_log(conn->name, GF_LOG_TRACE,           "received rpc message (RPC XID: 0x%x"           " Program: %s, ProgVers: %d, Proc: %d) from rpc-transport (%s)",           saved_frame->rpcreq->xid, saved_frame->rpcreq->prog->progname,           saved_frame->rpcreq->prog->progver, saved_frame->rpcreq->procnum,           conn->name);
gf_log(clnt->conn.name, GF_LOG_TRACE,           "receivd rpc message (XID: 0x%" GF_PRI_RPC_XID           ", "           "Ver: %" GF_PRI_RPC_VERSION ", Program: %" GF_PRI_RPC_PROG_ID           ", "           "ProgVers: %" GF_PRI_RPC_PROG_VERS ", Proc: %" GF_PRI_RPC_PROC           ") "           "from rpc-transport (%s)",           rpc_call_xid(&rpcmsg), rpc_call_rpcvers(&rpcmsg),           rpc_call_program(&rpcmsg), rpc_call_progver(&rpcmsg),           rpc_call_progproc(&rpcmsg), clnt->conn.name);
gf_log(name, GF_LOG_INFO, "setting frame-timeout to %d",               conn->frame_timeout);
gf_log(name, GF_LOG_DEBUG, "setting ping-timeout to %d",               conn->ping_timeout);
gf_log("rpc-clnt", GF_LOG_TRACE,           "Request fraglen %zu, payload: %zu, "           "rpc hdr: %zu",           fraglen, payload, requesthdr.iov_len);
gf_log(clnt->conn.name, GF_LOG_DEBUG,           "New program registered: %s, Num: %d, Ver: %d", program->progname,           program->prognum, program->progver);
gf_log("rpc-clnt", GF_LOG_TRACE,                   "submitted request "                   "(unique: %" PRIu64                   ", XID: 0x%x, Program: %s, "                   "ProgVers: %d, Proc: %d) to rpc-transport (%s)",                   cframe->root->unique, rpcreq->xid, rpcreq->prog->progname,                   rpcreq->prog->progver, rpcreq->procnum, conn->name);
gf_log(rpc->conn.name, GF_LOG_INFO,                   "changing ping timeout to %d (from %d)",                   config->ping_timeout, rpc->conn.ping_timeout);
gf_log(rpc->conn.name, GF_LOG_INFO,                   "changing timeout to %d (from %d)", config->rpc_timeout,                   rpc->conn.config.rpc_timeout);
gf_log(rpc->conn.name, GF_LOG_INFO, "changing port to %d (from %d)",                   config->remote_port, rpc->conn.config.remote_port);
gf_log(rpc->conn.name, GF_LOG_INFO,                       "changing hostname to %s (from %s)", config->remote_host,                       rpc->conn.config.remote_host);
gf_log(rpc->conn.name, GF_LOG_INFO, "setting hostname to %s",                   config->remote_host);
gf_log(trans->name, GF_LOG_TRACE,                   "ping timer expired but transport activity "                   "detected - not bailing transport");
gf_log(THIS->name, GF_LOG_DEBUG, "Ping latency is %" PRIu64 "ms",           latency_msec);
gf_log(THIS->name, GF_LOG_DEBUG,               "ping timeout is 0,"               " returning");
gf_log(THIS->name, GF_LOG_DEBUG,                   "returning as transport is already disconnected"                   " OR there are no frames (%d || %d)",                   !conn->connected, frame_count);
gf_log("rpc-transport", GF_LOG_DEBUG,                   "missing 'option transport-type'. defaulting to "                   "\"socket\"");
gf_log("rpc-transport", GF_LOG_DEBUG,               "dlsym (gf_rpc_transport_reconfigure) on %s", dlerror());
gf_log("rpc-transport", GF_LOG_DEBUG,               "volume option validation not specified");
gf_log("fsd-mgmt", GF_LOG_DEBUG,               "portmapper signout arguments not given");
gf_log(GF_RPCSVC, GF_LOG_TRACE, "Actor found: %s - %s for %s",           program->progname, actor->procname, peername);
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "received rpc-message "           "(XID: 0x%" GF_PRI_RPC_XID ", Ver: %" GF_PRI_RPC_VERSION           ", Program: %" GF_PRI_RPC_PROG_ID           ", "           "ProgVers: %" GF_PRI_RPC_PROG_VERS ", Proc: %" GF_PRI_RPC_PROC           ") "           "from rpc-transport (%s)",           rpc_call_xid(&rpcmsg), rpc_call_rpcvers(&rpcmsg),           rpc_call_program(&rpcmsg), rpc_call_progver(&rpcmsg),           rpc_call_progproc(&rpcmsg), trans->name);
gf_log(GF_RPCSVC, GF_LOG_INFO,               "not queuing duplicate event thread death. "               "queue %d program %s",               num, prog->progname);
gf_log(GF_RPCSVC, GF_LOG_INFO,           "queuing event thread death request to queue %d of program %s", num,           prog->progname);
gf_log(GF_RPCSVC, GF_LOG_INFO,                       "duplicate request:"                       " XID: 0x%x",                       req->xid);
gf_log(GF_RPCSVC, GF_LOG_INFO,                       "op in transit,"                       " discarding. XID: 0x%x",                       req->xid);
gf_log(GF_RPCSVC, GF_LOG_INFO,                           "spawned a request handler thread for queue %d",                           (int)num);
gf_log(                        GF_RPCSVC, GF_LOG_INFO,                        "spawning a request handler thread for queue %d failed",                        (int)num);
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "Reply fraglen %zu, payload: %zu, "           "rpc hdr: %zu",           fraglen, payload, replyhdr.iov_len);
gf_log("rpcsvc", GF_LOG_TRACE,           "Request fraglen %zu, payload: %zu, "           "rpc hdr: %zu",           fraglen, payload, requesthdr.iov_len);
gf_log(GF_RPCSVC, GF_LOG_TRACE,               "submitted reply for rpc-message (XID: 0x%x, "               "Program: %s, ProgVers: %d, Proc: %d) to rpc-transport "               "(%s)",               req->xid, req->prog ? req->prog->progname : "-",               req->prog ? req->prog->progver : 0, req->procnum,               trans ? trans->name : "");
gf_log(GF_RPCSVC, GF_LOG_DEBUG, "invalid address family (%d)",                   listener->trans->myinfo.sockaddr.ss_family);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,           "Program unregistered: %s, Num: %d,"           " Ver: %d, Port: %d",           prog->progname, prog->prognum, prog->progver, prog->progport);
gf_log(GF_RPCSVC, GF_LOG_INFO,                                   "event thread died, exiting request handler "                                   "thread for queue %d of program %s",                                   (int)(queue - &program->request_queue[0]),                                   program->progname);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,           "New program registered: %s, Num: %d,"           " Ver: %d, Port: %d",           newprog->progname, newprog->prognum, newprog->progver,           newprog->progport);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "Portmap registration "               "disabled");
gf_log(GF_RPCSVC, GF_LOG_INFO, "Configured %s with value %d", rpclimkey,               rpclim);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "Unprivileged port not"               " allowed");
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "Auth Info: machine name: %s, uid: %d"           ", gid: %d",           machname, req->uid, req->gid);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,           "sending cached reply: xid: %d, "           "client: %s",           req->xid, req->trans->peerinfo.identifier);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "DRC is "               "uninitialized, not dumping its state");
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "drc type not set. Continuing with default");
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "drc size not set. Continuing with default size");
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "drc lru factor not set. Continuing with policy default");
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "Auth Info: pid: %u, uid: %d"           ", gid: %d, owner: %s",           req->pid, req->uid, req->gid, lkowner_utoa(&req->lk_owner));
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "Auth Info: pid: %u, uid: %d"           ", gid: %d, owner: %s",           req->pid, req->uid, req->gid, lkowner_utoa(&req->lk_owner));
gf_log(GF_RPCSVC, GF_LOG_TRACE,           "Auth Info: pid: %u, uid: %d"           ", gid: %d, owner: %s, flags: %d",           req->pid, req->uid, req->gid, lkowner_utoa(&req->lk_owner),           req->flags);
gf_log(GF_RPCSVC, GF_LOG_TRACE, "Authentication enabled: %s",           authitem->auth->authname);
gf_log("rpc-auth", GF_LOG_DEBUG,                   "dict_set failed for 'allow-insecure'");
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "root squashing enabled "               "(uid=%d, gid=%d)",               svc->anonuid, svc->anongid);
gf_log(GF_RPCSVC, GF_LOG_DEBUG,               "all squashing enabled "               "(uid=%d, gid=%d)",               svc->anonuid, svc->anongid);
gf_log("glusterfs-fuse", GF_LOG_INFO,               "OSXFUSE kext version supported %s", version);
gf_log(this->name, GF_LOG_INFO, "Sending CHILD_DOWN for brick %s",                   victim->name);
gf_log(THIS->name, GF_LOG_INFO,                   "detaching not-only "                   " child %s",                   priv->base_path);
gf_log(this->name, GF_LOG_DEBUG, "G>P %s retrieved path %s",               uuid_utoa(local->loc.gfid), path);
gf_log(this->name, GF_LOG_DEBUG, "G>P %s %10u namespace found %s",               uuid_utoa(local->loc.inode->gfid), info->hash, path);
gf_log(this->name, GF_LOG_DEBUG, "%s: LOC retrieved path %s", fn,               loc->path);
gf_log(this->name, GF_LOG_DEBUG, "%s: LOC retrieved path %s", fn,                   path);
gf_log(this->name, GF_LOG_DEBUG,               "%s: LOC %s %10u namespace found for %s", fn,               uuid_utoa(loc->inode->gfid), info->hash, loc->path);
gf_log(this->name, GF_LOG_DEBUG, "%s: LOC %s winding, looking for path",               fn, uuid_utoa(loc->inode->gfid));
gf_log(this->name, GF_LOG_DEBUG, "%s: FD  %s %10u namespace found", fn,               uuid_utoa(fd->inode->gfid), info->hash);
gf_log(this->name, GF_LOG_DEBUG, "%s: FD  %s winding, looking for path",               fn, uuid_utoa(fd->inode->gfid));
gf_log(this->name, GF_LOG_DEBUG, "    %s winding, looking for path",   \               uuid_utoa(inode->gfid));
gf_log(this->name, GF_LOG_INFO,           "Dequeuing the barriered fops is "           "finished");
gf_log(this->name, GF_LOG_INFO,           "Disabling barriering and dequeuing "           "all the queued fops");
gf_log(this->name, GF_LOG_DEBUG,                   "retry connecting to "                   "quotad (retry count %d)",                   local->quotad_conn_retry);
gf_log(this->name, GF_LOG_DEBUG,               "connected to quotad after "               "retry count %d",               local->quotad_conn_retry);
gf_log(this->name, GF_LOG_INFO,                   "Notify GF_EVENT_PARENT_DOWN for brick %s", victim->name);
gf_log(this->name, GF_LOG_INFO,               "Notify GF_EVENT_PARENT_DOWN for brick %s", victim->name);
gf_log(this->name, GF_LOG_INFO,               "Notify GF_EVENT_CHILD_DOWN for brick %s", victim->name);
gf_log(this->name, GF_LOG_DEBUG,               "As there are more callcnt (%d) returning without WIND",               this_call_cnt);
gfid: %s;
domain: %s;
"    gf_log(this->name, GF_LOG_INFO,           "[REQUEST] Locker = {%s} Lockee = {%s} Lock = {%s}", pl_locker,           pl_lockee, pl_entrylk);
gf_log(this->name, GF_LOG_INFO,           "[%s] Locker = {%s} Lockee = {%s} Lock = {%s}", verdict, pl_locker,           pl_lockee, pl_entrylk);
gf_log(this->name, GF_LOG_INFO,           "[BLOCKED] Locker = {%s} Lockee = {%s} Lock = {%s}", pl_locker,           pl_lockee, pl_entrylk);
gf_log(this->name, GF_LOG_DEBUG,                   "Lock is grantable, but blocking to prevent "                   "starvation");
gf_log("locks", GF_LOG_TRACE,                   "returning EAGAIN"                   " because fd is O_NONBLOCK");
gf_log("posix-locks", GF_LOG_TRACE,                   " Flushing lock"                   "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64                   " state: %s",                   l->fl_type == F_UNLCK ? "Unlock" : "Lock", l->client_pid,                   lkowner_utoa(&l->owner), l->user_flock.l_start,                   l->user_flock.l_len, l->blocked == 1 ? "Blocked" : "Active");
gf_log(this->name, GF_LOG_TRACE,                   "no fdctx -> copying all locks on fd");
gf_log(this->name, GF_LOG_TRACE,                   "fdctx present -> returning the next lock");
gf_log(this->name, GF_LOG_DEBUG,                       "could not get next lock of fd");
gf_log(this->name, GF_LOG_DEBUG,                       "Lock flags received "                       "in a non-mandatory locking environment, "                       "continuing");
gf_log(this->name, GF_LOG_DEBUG,                       "Lock flags received, "                       "continuing");
gf_log(this->name, GF_LOG_TRACE,                   "Replying with a lock on fd for healing");
gf_log(this->name, GF_LOG_TRACE,                       "Lock blocked due to conflicting reserve lock");
gf_log("posix-locks", GF_LOG_TRACE, " Cleaning up domain: %s",                   dom->domain);
gfid: %s;
domain: %s;
"            gf_log(this->name, GF_LOG_DEBUG,                   "Lock is grantable, but blocking to prevent "                   "starvation");
gf_log(this->name, GF_LOG_DEBUG,           " Matching lock found for unlock %llu-%llu, by %s on %p for gfid:%s",           (unsigned long long)lock->fl_start, (unsigned long long)lock->fl_end,           lkowner_utoa(&lock->owner), lock->client,           inode ? uuid_utoa(inode->gfid) : "UNKNOWN");
gf_log(this->name, GF_LOG_TRACE,                   "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64                   " => Granted",                   lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                   lock->client_pid, lkowner_utoa(&lock->owner),                   lock->user_flock.l_start, lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,                       "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64                       " => OK",                       lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                       lock->client_pid, lkowner_utoa(&lock->owner),                       lock->fl_start, lock->fl_end);
gf_log(this->name, GF_LOG_TRACE,                       "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64                       " => NOK",                       lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                       lock->client_pid, lkowner_utoa(&lock->owner),                       lock->user_flock.l_start, lock->user_flock.l_len);
gf_log(this->name, GF_LOG_DEBUG,                       "Bad Unlock issued on Inode lock");
gf_log(this->name, GF_LOG_DEBUG,                   "Lock command F_GETLK not supported for [f]inodelk "                   "(cmd=%d)",                   cmd);
gf_log("posix-locks", GF_LOG_TRACE, "New domain allocated: %s",           dom->domain);
gf_log(this->name, GF_LOG_INFO,           "[REQUEST] Locker = {%s} Lockee = {%s} Lock = {%s}", pl_locker,           pl_lockee, pl_lock);
gf_log(this->name, GF_LOG_INFO,           "[%s] Locker = {%s} Lockee = {%s} Lock = {%s}", verdict, pl_locker,           pl_lockee, pl_lock);
gf_log(this->name, GF_LOG_INFO,           "[BLOCKED] Locker = {%s} Lockee = {%s} Lock = {%s}", pl_locker,           pl_lockee, pl_lock);
gf_log(this->name, GF_LOG_INFO, "[FLUSH] Locker = {%s} Lockee = {%s}",           pl_locker, pl_lockee);
gf_log(this->name, GF_LOG_TRACE,                   "%s (pid=%d) lk-owner:%s %" PRId64 " - %" PRId64                   " => Granted",                   l->fl_type == F_UNLCK ? "Unlock" : "Lock", l->client_pid,                   lkowner_utoa(&l->owner), l->user_flock.l_start,                   l->user_flock.l_len);
gf_log(this->name, GF_LOG_DEBUG,                       "Could not send pre-lock "                       "unlock");
gf_log(this->name, GF_LOG_TRACE,                   "%s (pid=%d) lk-owner:%s %" PRId64 " - %" PRId64 " => OK",                   lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                   lock->client_pid, lkowner_utoa(&lock->owner),                   lock->user_flock.l_start, lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,                   "%s (pid=%d) lk-owner:%s %" PRId64 " - %" PRId64                   " => Blocked",                   lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                   lock->client_pid, lkowner_utoa(&lock->owner),                   lock->user_flock.l_start, lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,                   "%s (pid=%d) lk-owner:%s %" PRId64 " - %" PRId64 " => NOK",                   lock->fl_type == F_UNLCK ? "Unlock" : "Lock",                   lock->client_pid, lkowner_utoa(&lock->owner),                   lock->user_flock.l_start, lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,                   "Removing the matching reservelk for setlk to progress");
gf_log(this->name, GF_LOG_TRACE,                   "Found conflicting reservelk. Blocking until reservelk is "                   "unlocked.");
gf_log(this->name, GF_LOG_TRACE,           "no conflicting reservelk found. Call continuing");
gf_log(this->name, GF_LOG_TRACE,               "%s (pid=%d) lk-owner:%s %" PRId64 " - %" PRId64 " => Blocked",               lock->fl_type == F_UNLCK ? "Unlock" : "Lock", lock->client_pid,               lkowner_utoa(&lock->owner), lock->user_flock.l_start,               lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,               "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64 " => Granted",               lock->fl_type == F_UNLCK ? "Unlock" : "Lock", lock->client_pid,               lkowner_utoa(&lock->owner), lock->user_flock.l_start,               lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,               "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64 " => NOK",               lock->fl_type == F_UNLCK ? "Unlock" : "Lock", lock->client_pid,               lkowner_utoa(&lock->owner), lock->user_flock.l_start,               lock->user_flock.l_len);
gf_log(this->name, GF_LOG_TRACE,               "%s (pid=%d) (lk-owner=%s) %" PRId64 " - %" PRId64 " => OK",               lock->fl_type == F_UNLCK ? "Unlock" : "Lock", lock->client_pid,               lkowner_utoa(&lock->owner), lock->fl_start, lock->fl_end);
gf_log(this->name, GF_LOG_DEBUG,               "inode quota disabled. "               "inode quota self heal will not be performed");
gf_log(this->name, GF_LOG_DEBUG, "set lock type %d on %s", l_type,           loc->path);
gf_log(this->name, GF_LOG_DEBUG,                   "contribution for the node %s is NULL", loc->path);
gf_log(this->name, GF_LOG_DEBUG,                   "rollback "                   "contri updation");
gf_log(this->name, GF_LOG_INFO,           "calculated size = %" PRId64 ", original size = %" PRIu64           ", diff = %" PRIu64 ", path = %s ",           contri_sum.size, size.size, delta.size, loc->path);
gf_log(this->name, GF_LOG_INFO,           "calculated f_count = %" PRId64 ", original f_count = %" PRIu64           ", diff = %" PRIu64 ", path = %s ",           contri_sum.file_count, size.file_count, delta.file_count, loc->path);
gf_log(this->name, GF_LOG_INFO,           "calculated d_count = %" PRId64 ", original d_count = %" PRIu64           ", diff = %" PRIu64 ", path = %s ",           contri_sum.dir_count, size.dir_count, delta.dir_count, loc->path);
gf_log(this->name, GF_LOG_DEBUG,               "Filtering the quota extended attributes");
gf_log(this->name, GF_LOG_DEBUG,               "Error occurred "               "while traversing to the parent, stopping marker");
gf_log(this->name, GF_LOG_TRACE,               "error occurred "               "while creating directory %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "error occurred "               "while creating file %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "error occurred "               "while write, %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "error occurred "               "rmdir %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "%s occurred in unlink",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "dict get failed %s ",                       strerror(-ret));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "linking a file ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "renaming a file ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "truncating a file ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "truncating a file ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "creating symlinks ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred with "               "mknod ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "fallocating a file ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "%s occurred during discard",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "%s occurred during zerofill",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred in "               "setxattr ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred in "               "fsetxattr",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred in "               "fsetattr ",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "%s occurred during setattr of %s",               strerror(op_errno), (local ? local->loc.path : "<nul>"));
gf_log(this->name, GF_LOG_TRACE,               "%s occurred while "               "removing extended attribute",               strerror(op_errno));
gf_log(this->name, GF_LOG_TRACE, "lookup failed with %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG, "the timestamp-file is = %s",           priv->timestamp_file);
gf_log(THIS->name, GF_LOG_DEBUG, "upcall_entry_t client added - %s",           up_client_entry->client_uid);
gf_log(THIS->name, GF_LOG_TRACE, "Cleaning up client_entry(%s)",                       up_client->client_uid);
gf_log("upcall", GF_LOG_DEBUG,                   "upcall_inode_ctx_get of linked inode (%p)", inode);
gf_log(THIS->name, GF_LOG_TRACE,               "Cache invalidation notification sent to %s",               up_client_entry->client_uid);
gf_log(THIS->name, GF_LOG_TRACE,               "Cache invalidation notification NOT sent to %s",               up_client_entry->client_uid);
gf_log(this->name, GF_LOG_INFO,               "cleanup changelog rpc connection of brick %s",               priv->victim->name);
gf_log("changelog", GF_LOG_INFO,                       "Send disconnect"                       " on socket %d",                       sockpriv->sock);
gf_log(this->name, GF_LOG_INFO,                   "BitRot scrub ondemand "                   "called");
gf_log(this->name, GF_LOG_DEBUG, "CDC xlator loaded in (%s) mode",           temp_str);
gf_log(this->name, GF_LOG_DEBUG, "dump'd %zu bytes to %s", total_written,           GF_CDC_DEBUG_DUMP_FILE);
gf_log(this->name, GF_LOG_DEBUG, "crc=%lu len=%d buffer_size=%d", ci->crc,           ci->stream.avail_in, ci->buffer_size);
gf_log(this->name, GF_LOG_DEBUG, "Compressed %ld to %ld bytes",           ci->stream.total_in, ci->stream.total_out);
gf_log(this->name, GF_LOG_DEBUG, "crc=%lu len=%lu buffer_size=%d",           computed_crc, computed_len, ci->buffer_size);
gf_log(this->name, GF_LOG_DEBUG,               "Content not deflated, passing through ...");
gf_log(this->name, GF_LOG_DEBUG, "Inflated %ld to %ld bytes",           ci->stream.total_in, ci->stream.total_out);
gf_log("trash", GF_LOG_DEBUG,               "stat on %s failed"               " using default",               path);
gf_log(this->name, GF_LOG_DEBUG,           "old trash directory path "           "is %s",           priv->oldtrash_dir);
gf_log(this->name, GF_LOG_DEBUG, "inode found with gfid %s",               uuid_utoa(buf->ia_gfid));
gf_log(this->name, GF_LOG_DEBUG,               "Creating trash "               "directory %s ",               priv->newtrash_dir);
gf_log(this->name, GF_LOG_DEBUG,           "nameless lookup for"           "old trash directory");
gf_log(this->name, GF_LOG_DEBUG,               "target(%s) exists, cannot keep the copy, deleting",               local->newpath);
gf_log(this->name, GF_LOG_DEBUG,               "target(%s) exists as directory, cannot keep copy, "               "deleting",               local->newpath);
gf_log(this->name, GF_LOG_DEBUG, "%s: %s", local->loc.path,               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG,               "%s: file size too big (%" PRId64               ") to "               "move into trash directory",               local->loc.path, buf->ia_size);
gf_log(this->name, GF_LOG_DEBUG,                   "%s is a file comes under an eliminate path, "                   "so it is not moved to trash",                   loc->name);
gf_log(this->name, GF_LOG_DEBUG, "deleting the newly created file: %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG,               "readv on the existing file failed: %s", strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG,               "writev on the existing file failed: %s", strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG, "open on the existing file failed: %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG,               "creation of new file in trash-dir failed, "               "when truncate was called: %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG, "fstat on the file failed: %s",               strerror(op_errno));
gf_log(this->name, GF_LOG_DEBUG,               "%s: file is too large to move to trash", local->loc.path);
gf_log(this->name, GF_LOG_DEBUG,                   "%s: file not moved to trash as per option "                   "'eliminate path'",                   loc->path);
gf_log(this->name, GF_LOG_DEBUG,                   "%s: file matches eliminate path, "                   "not moved to trash",                   pathbuf);
gf_log(this->name, GF_LOG_INFO,               "Disable of trash feature is not allowed "               "during graph reconfigure");
gf_log(this->name, GF_LOG_DEBUG,                   "Renaming %s -> %s from reconfigure", priv->oldtrash_dir,                   priv->newtrash_dir);
gf_log(this->name, GF_LOG_DEBUG, "%" GF_PRI_SIZET " max-size",               priv->max_trash_file_size);
gf_log(this->name, GF_LOG_DEBUG,               "no option specified for 'eliminate', using NULL");
gf_log(this->name, GF_LOG_INFO,               "no option specified for 'trash-dir', "               "using \"/.trashcan/\"");
gf_log(this->name, GF_LOG_INFO,               "no option specified for 'eliminate', using NULL");
gf_log(this->name, GF_LOG_DEBUG, "%" GF_PRI_SIZET " max-size",               priv->max_trash_file_size);
gf_log(state->this->name, GF_LOG_DEBUG,                   "basefd (ptr:%p inode-gfid:%s) migrated "                   "successfully in resolver "                   "(old-subvolume:%s-%d new-subvolume:%s-%d)",                   basefd, uuid_utoa(basefd->inode->gfid), active_subvol->name,                   active_subvol->graph->id, state->active_subvol->name,                   state->active_subvol->graph->id);
gf_log(this->name, GF_LOG_DEBUG, "Invalidate inode id %" GF_PRI_INODE ".",           nodeid);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "writev() result %d/%d %s", res,           fouh->len, res == -1 ? strerror(errno) : "");
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "INVALIDATE entry: %" PRIu64 "/%s (gfid:%s)", fnieo->parent,               dentry->name, gfid_str);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "INVALIDATE inode: %" PRIu64 "(gfid:%s)", fuse_ino,           uuid_utoa(inode->gfid));
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "unique %" PRIu64 " INTERRUPT for %" PRIu64, finh->unique,           fii->unique);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "unique %" PRIu64 " INTERRUPT for %" PRIu64               ": handler triggered",               finh->unique, fii->unique);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "unique %" PRIu64 " INTERRUPT for %" PRIu64 ": no handler found",               finh->unique, fii->unique);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s() %s => %" PRIu64, frame->root->unique,               gf_fop_list[frame->root->op], state->loc.path, buf->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": LOOKUP %s(%s)",               state->finh->unique, state->loc.path,               uuid_utoa(state->loc.inode->gfid));
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": LOOKUP %s",               state->finh->unique, state->loc.path);
gf_log("fuse", GF_LOG_TRACE,           "%" PRIu64 ": FORGET %" PRIu64 "/%" PRIu64 " gfid: (%s)", unique,           nodeid, nlookup, uuid_utoa(fuse_inode->gfid));
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": BATCH_FORGET %" PRIu64 "/%" PRIu32, finh->unique,           finh->nodeid, fbfi->count);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s() %s => %" PRIu64, frame->root->unique,               gf_fop_list[frame->root->op],               state->loc.path ? state->loc.path : "ERR", prebuf->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s() %s => %" PRIu64, frame->root->unique,               gf_fop_list[frame->root->op],               state->loc.path ? state->loc.path : "ERR", buf->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": GETATTR %" PRIu64 " (%s)", state->finh->unique,               state->finh->nodeid, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": FGETATTR %" PRIu64 " (%s/%p)", state->finh->unique,               state->finh->nodeid, state->loc.path, state->fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": %s() %s => %p",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path, fd);
gf_log("glusterfs-fuse", GF_LOG_DEBUG, "open(%s) got EINTR",                   state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s() %s => %" PRIu64, frame->root->unique,               gf_fop_list[frame->root->op],               state->loc.path ? state->loc.path : "ERR", statpost->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": SETATTR (%" PRIu64 ")%s", state->finh->unique,           state->finh->nodeid, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": %s() %s => 0",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path ? state->loc.path : "ERR");
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": %s() %s => 0",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path ? state->loc.path : "ERR");
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": %s() %s => 0",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 " ACCESS %s/%" PRIu64 " mask=%d", state->finh->unique,           state->loc.path, state->finh->nodeid, state->mask);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s => %s (size:%d)", frame->root->unique,               state->loc.path, linkname, op_ret);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 " READLINK %s/%s",           state->finh->unique, state->loc.path,           uuid_utoa(state->loc.inode->gfid));
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": MKNOD %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": MKDIR %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": UNLINK %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": RMDIR %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": SYMLINK %s -> %s",           state->finh->unique, state->loc.path, state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s -> %s => 0 (buf->ia_ino=%" PRIu64 ")",               frame->root->unique, state->loc.path, state->loc2.path,               buf->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": RENAME `%s (%s)' -> `%s (%s)'", state->finh->unique,           state->loc.path, loc_uuid, state->loc2.path, loc2_uuid);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": LINK() %s -> %s",           state->finh->unique, state->loc2.path, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": %s() %s => %p (ino=%" PRIu64 ")",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path, fd, buf->ia_ino);
gf_log("glusterfs-fuse", GF_LOG_DEBUG, "create(%s) got EINTR",                   state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": CREATE %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": OPEN %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": READ => %d/%" GF_PRI_SIZET ",%" PRId64 "/%" PRIu64,               frame->root->unique, op_ret, state->size, state->off,               stbuf->ia_size);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": READ (%p, size=%zu, offset=%" PRIu64 ")",           state->finh->unique, state->fd, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": WRITE => %d/%" GF_PRI_SIZET ",%" PRId64               "/%" PRIu64,               frame->root->unique, op_ret, state->size, state->off,               stbuf->ia_size);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": WRITE (%p, size=%" GF_PRI_SIZET ", offset=%" PRId64           ")",           state->finh->unique, state->fd, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": WRITE => %d/%" GF_PRI_SIZET ",%" PRIu64               " , %" PRIu64 " ,%" PRIu64 ",%" PRIu64,               frame->root->unique, op_ret, state->size, state->off_in,               state->off_out, stbuf->ia_size, postbuf_dst->ia_size);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64           ": COPY_FILE_RANGE "           "(input fd: %p (gfid: %s), "           "output fd: %p (gfid: %s) size=%zu, "           "offset_in=%" PRIu64 ", offset_out=%" PRIu64 ")",           state->finh->unique, state->fd,           uuid_utoa_r(state->fd->inode->gfid, fd_uuid_str), state->fd_dst,           uuid_utoa_r(state->fd_dst->inode->gfid, fd_dst_uuid_str),           state->size, state->off_in, state->off_out);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,           "FLUSH unique %" PRIu64 ": interrupt handler triggered",           fir->fuse_in_header.unique);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": FLUSH %p",           finh->unique, fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "finh->unique: %" PRIu64 ": RELEASE %p", finh->unique, state->fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": FSYNC %p",           state->finh->unique, state->fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": OPENDIR %s",           state->finh->unique, state->loc.path);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": READDIR => %d/%" GF_PRI_SIZET ",%" PRId64,           frame->root->unique, op_ret, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "%" PRIu64 ": READDIR => -1 (%s)", frame->root->unique,               strerror(ENOMEM));
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": READDIR (%p, size=%" GF_PRI_SIZET ", offset=%" PRId64           ")",           state->finh->unique, state->fd, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": READDIRP => %d/%" GF_PRI_SIZET ",%" PRId64,           frame->root->unique, op_ret, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "%" PRIu64 ": READDIRP => -1 (%s)", frame->root->unique,               strerror(ENOMEM));
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "%" PRIu64 ": READDIRP (%p, size=%" GF_PRI_SIZET ", offset=%" PRId64           ")",           state->finh->unique, state->fd, state->size, state->off);
gf_log(        "glusterfs-fuse", GF_LOG_TRACE,        "%" PRIu64 ": FALLOCATE (%p, flags=%d, size=%zu, offset=%" PRId64 ")",        state->finh->unique, state->fd, state->flags, state->size, state->off);
gf_log("glusterfs-fuse", GF_LOG_TRACE,           "finh->unique: %" PRIu64 ": RELEASEDIR %p", finh->unique, state->fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": STATFS",           state->finh->unique);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": SETXATTR %p/%" PRIu64 " (%s)", state->finh->unique,               state->fd, state->finh->nodeid, state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": SETXATTR %s/%" PRIu64 " (%s)", state->finh->unique,               state->loc.path, state->finh->nodeid, state->name);
gf_log("fuse", GF_LOG_TRACE, "got request to invalidate %" PRIu64,               finh->nodeid);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": %s() %s => %d",               frame->root->unique, gf_fop_list[frame->root->op],               state->loc.path, op_ret);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                   "%" PRIu64 ": %s(%s) %s => -1 (%s)", frame->root->unique,                   gf_fop_list[frame->root->op], state->name, state->loc.path,                   strerror(op_errno));
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": GETXATTR %p/%" PRIu64 " (%s)", state->finh->unique,               state->fd, state->finh->nodeid, state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": GETXATTR %s/%" PRIu64 " (%s)", state->finh->unique,               state->loc.path, state->finh->nodeid, state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": LISTXATTR %p/%" PRIu64, state->finh->unique,               state->fd, state->finh->nodeid);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": LISTXATTR %s/%" PRIu64, state->finh->unique,               state->loc.path, state->finh->nodeid);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "%" PRIu64 ": REMOVEXATTR %s/%" PRIu64               " (%s) "               "resolution failed",               state->finh->unique, uuid_utoa(state->resolve.gfid),               state->finh->nodeid, state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": REMOVEXATTR %p/%" PRIu64 " (%s)",               state->finh->unique, state->fd, state->finh->nodeid,               state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "%" PRIu64 ": REMOVEXATTR %s/%" PRIu64 " (%s)",               state->finh->unique, state->loc.path, state->finh->nodeid,               state->name);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": ERR => 0",               frame->root->unique);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": GETLK %p",           state->finh->unique, state->fd);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": ERR => 0",               frame->root->unique);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                   "Returning EAGAIN Flock: "                   "start=%llu, len=%llu, pid=%llu, lk-owner=%s",                   (unsigned long long)state->lk_lock.l_start,                   (unsigned long long)state->lk_lock.l_len,                   (unsigned long long)state->lk_lock.l_pid,                   lkowner_utoa(&frame->root->lk_owner));
gf_log("glusterfs-fuse", GF_LOG_DEBUG,           "SETLK%s unique %" PRIu64 ": interrupt handler triggered",           fir->fuse_in_header.opcode == FUSE_SETLK ? "" : "W",           fir->fuse_in_header.unique);
gf_log("glusterfs-fuse", GF_LOG_TRACE, "%" PRIu64 ": SETLK%s %p",           state->finh->unique, state->finh->opcode == FUSE_SETLK ? "" : "W",           state->fd);
gf_log("glusterfs-fuse", GF_LOG_INFO, "len: %u, rv: %zd, errno: %d",                   len, rv, errno);
gf_log("glusterfs-fuse", GF_LOG_TRACE,               "sending timed "               "message of unique %" PRIu64,               dmsg->fuse_out_header.unique);
gf_log("glusterfs-fuse", GF_LOG_INFO,                   "len: %zu, rv: %zd, errno: %d", len, rv, errno);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                   "Detected "                   "support for FUSE_AUTO_INVAL_DATA. Enabling "                   "fopen_keep_cache automatically.");
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                       "No support for FUSE_AUTO_INVAL_DATA. Disabling "                       "fopen_keep_cache.");
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                   "fopen_keep_cache "                   "is explicitly set. Enabling FUSE_AUTO_INVAL_DATA");
gf_log("glusterfs-fuse", GF_LOG_INFO,               "FUSE inited with protocol versions:"               " glusterfs %d.%d kernel %d.%d",               FUSE_KERNEL_VERSION, FUSE_KERNEL_MINOR_VERSION, fini->major,               fini->minor);
gf_log("glusterfs-fuse", GF_LOG_INFO,           "migrated basefd (%p) to newfd (%p) (inode-gfid:%s)"           "(old-subvolume:%s-%d new-subvolume:%s-%d)",           basefd, newfd, uuid_utoa(basefd->inode->gfid), old_subvol->name,           old_subvol->graph->id, new_subvol->name, new_subvol->graph->id);
gf_log(this->name, GF_LOG_INFO,               "No lockinfo present on any of the bricks "               "(oldfd: %p newfd:%p inode-gfid:%s) "               "(old-subvol:%s-%d new-subvol:%s-%d)",               oldfd, newfd, uuid_utoa(newfd->inode->gfid), old_subvol->name,               old_subvol->graph->id, new_subvol->name, new_subvol->graph->id);
gf_log("glusterfs-fuse", GF_LOG_INFO,               "create call on fd (%p) is in progress "               "(basefd-ptr:%p basefd-inode.gfid:%s), "               "hence deferring migration till application does an "               "fd based operation on this fd"               "(old-subvolume:%s-%d, new-subvolume:%s-%d)",               oldfd, basefd, uuid_utoa(basefd->inode->gfid), old_subvol->name,               old_subvol->graph->id, new_subvol->name, new_subvol->graph->id);
gf_log(this->name, GF_LOG_DEBUG,                       "timedwait returned non zero value "                       "ret: %d errno: %d",                       ret, errno);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                       "terminating upon getting %s when "                       "reading /dev/fuse",                       errno == ENODEV ? "ENODEV" : "EBADF");
gf_log(this->name, GF_LOG_INFO, "initiating unmount of %s",               mount_point);
gf_log("fuse", GF_LOG_DEBUG, "got event %d on graph %d", event,           ((graph) ? graph->id : 0));
gf_log(this->name, GF_LOG_DEBUG,                               "pthread_create() failed (%s)", strerror(errno));
gf_log(this_xl->name, GF_LOG_DEBUG, "%s %s : stat returned %s",                   ZR_MOUNTPOINT_OPT, value_string, strerror(errno));
gf_log(this_xl->name, GF_LOG_INFO,               "setting congestion control as 75%% of "               "background-queue length (ie, (.75 * %d) = %d",               priv->background_qlen, priv->congestion_threshold);
gf_log(this_xl->name, GF_LOG_INFO,               "setting congestion control same as "               "background-queue length (%d)",               priv->background_qlen);
gf_log(this_xl->name, GF_LOG_INFO, "Closing fuse connection to '%s'.",               mount_point);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,                   "inode_path failed for %s/%s",                   (parent) ? uuid_utoa(parent->gfid) : "0", name);
gf_log("glusterfs-fuse", GF_LOG_DEBUG, "inode_path failed for %s",                   (inode) ? uuid_utoa(inode->gfid) : "0");
gf_log("fuse-bridge", GF_LOG_DEBUG,               "failed to search parent for %" PRId64 "/%s (%" PRId64 ")",               (ino_t)par, name, (ino_t)ino);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "PID: %d, checking xattr(s): "               "volume-mark*, *xtime",               priv->client_pid);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,               "flipping %s to " PRIV_XA_NS " equivalent", okey);
gf_log("glusterfs-fuse", GF_LOG_DEBUG,           "%s setxattr: key [%s], "           " client pid [%d]",           (ret ? "disallowing" : "allowing"), key, priv->client_pid);
gf_log(this->name, GF_LOG_TRACE,               "option transport.address-family is not set in xlator options");
gf_log(this->name, GF_LOG_INFO,               "glusterd already received a SIGTERM, "               "dropping the event %d for peer %s",               event, peerctx->peername);
gf_log(this->name, GF_LOG_INFO,           "Setting stage deleted flag to true for "           "volume %s",           volinfo->volname);
gf_log(this->name, GF_LOG_INFO,               "unlock timer is cancelled for volume_type"               " %s",               key);
gf_log(this->name, GF_LOG_INFO,               "Volume %s still exist, setting "               "stage deleted flag to false for the volume",               volinfo->volname);
gf_log(THIS->name, GF_LOG_INFO,               "failed to get 'features.acl' flag from dict");
gf_log("glusterd", GF_LOG_INFO,               "found insert position of user-xlator(%s)", key);
gf_log("glusterd", GF_LOG_DEBUG, "set user xlator option %s = %s", key,           value->data);
gf_log(THIS->name, GF_LOG_DEBUG, "option mismatch, %s, %s != %s", key,               value1->data, value2->data);
gf_log(this->name, GF_LOG_INFO,                   "Detach request for "                   "brick %s:%s is sent successfully with graceful cleanup %d",                   brickinfo->hostname, brickinfo->path, graceful_enabled);
gf_log(this->name, GF_LOG_INFO,                   "Create thread %d to populate dict data for volume"                   " start index is %d end index is %d",                   (i + 1), arg->start, arg->end);
gf_log(this->name, GF_LOG_INFO,               "Finished dictionary population in all threads");
gf_log(this->name, GF_LOG_INFO,               "Merged multiple dictionaries into a single one");
gf_log(this->name, GF_LOG_INFO, "Serialize dictionary data returned %d",               ret);
gf_log(this->name, GF_LOG_DEBUG,               "The volume%d does"               " not have any peer change",               count);
gf_log(this->name, GF_LOG_INFO, "brick %s is attached successfully",               brickinfo->path);
gf_log(this->name, GF_LOG_INFO,               "attach_brick failed pidfile"               " is %s for brick_path %s",               pidfile2, brickinfo->path);
gf_log(this->name, GF_LOG_INFO, "add brick %s to existing process for %s",           brickinfo->path, other_brick->path);
gf_log(this->name, GF_LOG_DEBUG, "comparing options for %s and %s",               comp_vol->volname, srch_vol->volname);
gf_log(this->name, GF_LOG_INFO,                   "brick has not come up so cleaning up dead brick %s:%s",                   other_brick->hostname, other_brick->path);
gf_log(this->name, GF_LOG_INFO,                       "Either pid %d is not running or brick"                       " path %s is not consumed so cleanup pidfile",                       pid, brickinfo->path);
gf_log(this->name, GF_LOG_INFO,                       "Either pid %d is not running or does "                       "not match with any running brick "                       "processes",                       pid);
gf_log(this->name, GF_LOG_INFO,                   "discovered already-running brick %s", brickinfo->path);
gf_log(this->name, GF_LOG_DEBUG,                   "Using %s as sockfile for brick %s of volume %s ",                   socketpath, brickinfo->path, volinfo->volname);
gf_log(this->name, GF_LOG_INFO,           "starting a fresh brick process for "           "brick %s",           brickinfo->path);
gf_log(this->name, GF_LOG_INFO,                           "brick path %s is not consumed", brickinfo->path);
gf_log(this->name, GF_LOG_DEBUG,                   "peer %s not found in auth.allow list", peerinfo->hostname);
gf_log(this->name, GF_LOG_INFO,               "Regenerating volfiles due to a max op-version mismatch or "               "glusterd.upgrade file not being present, op_version retrieved:"               "%d, max op_version: %d",               op_version, GD_OP_VERSION_MAX);
gf_log(child_xlator->name, GF_LOG_INFO,                   "Overriding halo threshold, "                   "min replicas: %d",                   priv->halo_min_replicas);
gf_log(child_xlator->name, GF_LOG_INFO,                   "Child latency (%" PRId64                   " ms) "                   "exceeds halo threshold (%" PRId64                   "), "                   "marking child down.",                   child_latency_msec, halo_max_latency_msec);
gf_log(child_xlator->name, GF_LOG_INFO,                   "Child latency (%" PRId64                   " ms) "                   "below halo threshold (%" PRId64                   "), "                   "marking child up.",                   child_latency_msec, halo_max_latency_msec);
gf_log(child_xlator->name, GF_LOG_INFO,                   "Not marking child %d up, "                   "max replicas (%d) reached.",                   idx, priv->halo_max_replicas);
gf_log(this->name, GF_LOG_INFO,               "Conflicting locks held on file %s. FD reopen is not allowed.",               local->loc.path);
gf_log(this->name, GF_LOG_INFO,               "Failed to get the lock information "               "on file %s. FD reopen is not allowed.",               local->loc.path);
_gf_log(const char *domain, const char *file, const char *function,        int32_t line, gf_loglevel_t level, const char *fmt, ...){    return 0;
gf_log(this->name, GF_LOG_INFO,           "Attempting to migrate hardlink %s "           "with gfid %s from %s -> %s",           loc->name, uuid_utoa(loc->gfid), cached_subvol->name,           hashed_subvol->name);
gf_log(this->name, log_level, "%s: attempting to move from %s to %s",           loc->path, cached_subvol->name, hashed_subvol->name);
gf_log(this->name, GF_LOG_INFO,               "Migration of "               "file:%s size:%" PRIu64               " bytes took %.2f"               "secs and ret: %d",               entry_loc.name, iatt.ia_size, elapsed / 1e6, ret);
gf_log(this->name, GF_LOG_INFO,           "Migration operation on dir %s took "           "%.2f secs",           loc->path, elapsed / 1e6);
gf_log("DHT", GF_LOG_INFO,                   "Thread[%d] "                   "creation successful",                   index);
gf_log(this->name, GF_LOG_INFO, "%s using commit hash %u", __func__,           conf->vol_commit_hash);
gf_log(THIS->name, GF_LOG_INFO,           "TIME: (size) total_processed=%" PRIu64 " tmp_cnt = %" PRIu64           ","           "rate_processed=%f, elapsed = %f",           total_processed, tmp_count, rate_processed, elapsed);
gf_log(THIS->name, GF_LOG_INFO,               "TIME: Estimated total time to complete (size)= %" PRIu64               " seconds, seconds left = %" PRIu64 "",               time_to_complete, time_left);
gf_log(this->name, GF_LOG_DEBUG, "STATFS cache age = %u secs",               cache_age);
gf_log(this->name, GF_LOG_DEBUG,                   "Cache age %u secs exceeded timeout %u secs", cache_age,                   conf->timeout);
gf_log(this->name, GF_LOG_INFO, "Dropping poisoned request %p.",                       stub);
gf_log(this->name, GF_LOG_INFO,                   "Notify GF_EVENT_PARENT_DOWN for brick %s", victim->name);
gf_log(this->name, GF_LOG_INFO,                   "Notify GF_EVENT_CHILD_DOWN for brick %s", victim->name);
gf_log(this->name, GF_LOG_INFO,                   "poisoning %s fop at %p for client %s",                   gf_fop_list[curr->fop], curr, client->client_uid);
gf_log(this ? this->name : "error-gen", GF_LOG_DEBUG,           "reconfigure returning %d", ret);
gf_log(this->name, GF_LOG_INFO, "     BytesRead : %" PRId64 " bytes",               data_read);
gf_log(this->name, GF_LOG_INFO, "  BytesWritten : %" PRId64 " bytes",               data_written);
gf_log(this->name, GF_LOG_INFO,                   " Read %06db+ :"                   "%" PRId64,                   (1 << i), block_count_read);
gf_log(this->name, GF_LOG_INFO, "Write %06db+ : %" PRId64, (1 << i),                   block_count_write);
gf_log(this->name, GF_LOG_DEBUG,               "taking io-stats dump using setxattr not permitted on brick."               " Use 'gluster profile' instead");
gf_log(this->name, GF_LOG_INFO,           "IO stats dump thread started, "           "polling IO stats every %d seconds",           conf->ios_dump_interval);
gf_log(name, GF_LOG_INFO,           "Configure ios_sample_buf "           " size is 1024 because ios_sample_interval is 0");
gf_log(this ? this->name : "io-stats", GF_LOG_DEBUG,           "reconfigure returning %d", ret);
gf_log(this->name, GF_LOG_INFO, "logging to file %s",           (conf->log_file == _gf_true) ? "enabled" : "disabled");
gf_log(this->name, GF_LOG_DEBUG, "logging to history %s",           (conf->log_history == _gf_true) ? "enabled" : "disabled");
gf_log("auth/login", GF_LOG_INFO, "connecting user name: %s",               username_data->data);
gf_log("auth/login", GF_LOG_DEBUG,                       "username not found, strict auth"                       " configured returning REJECT");
gf_log("auth/login", GF_LOG_DEBUG,                       "username not found, returning"                       " DONT-CARE");
gf_log("auth/login", GF_LOG_DEBUG,                       "password not found, strict auth"                       " configured returning REJECT");
gf_log("auth/login", GF_LOG_INFO, "allowed user names: %s",               allow_user->data);
gf_log(subvol, GF_LOG_INFO, "%s = \"%s\", received addr = \"%s\"",               (status == AUTH_ACCEPT) ? "allowed" : "rejected", addr_str,               peer_addr);
gf_log(subvol, GF_LOG_INFO,               "Found an entry for dir %s (%s),"               " performing validation",               subdir, addr);
gf_log("authenticate/addr", GF_LOG_DEBUG,               "remote-subvolume not specified");
gf_log("auth/addr", GF_LOG_DEBUG,               "asprintf failed while setting search string");
gf_log("auth/addr", GF_LOG_DEBUG,               "none of the options auth.addr.%s.allow or "               "auth.addr.%s.reject specified, returning auth_dont_care",               name, name);
gf_log(this->name, GF_LOG_INFO, "Create graph janitor thread for brick %s",           victim_name);
gf_log(THIS->name, GF_LOG_INFO,               "Start call fini for brick"               " %s stack",               victim->name);
gf_log(THIS->name, GF_LOG_INFO,               "Going to Cleanup ctx pool memory and exit the process %s",               ctx->cmdlinestr);
gf_log(this->name, GF_LOG_INFO,                       "Getting CHILD_DOWN event for brick %s", victim->name);
gf_log(this->name, GF_LOG_INFO, "disconnecting %s",                           xprt->peerinfo.identifier);
gf_log("cli", GF_LOG_TRACE,               "Unable to open "               "quota.conf");
gf_log(frame->this->name, GF_LOG_TRACE,               "failed to get default soft limit");
gf_log(frame->this->name, GF_LOG_TRACE,                   "failed to set default soft limit");
gf_log("cli", GF_LOG_DEBUG,                   "failed to get soft-limit-reach from dict");
gf_log("cli", GF_LOG_DEBUG,               "User cancelled snapshot delete operation for snap delete");
gf_log(this->name, GF_LOG_DEBUG,               "failed to get serialized length of dict");
gf_log(this->name, GF_LOG_TRACE, "got some other RPC event %d",                   event);
gf_log(this->name, GF_LOG_TRACE, "got some other RPC event %d",                   event);
gf_log("cli", GF_LOG_INFO,               "Connecting to glusterd using "               "sockfile %s",               state->glusterd_sock);
gf_log("cli", GF_LOG_INFO,               "Connecting to remote glusterd at "               "%s",               state->remote_host);
gf_log("cli", GF_LOG_DEBUG,               "Connecting to glusterd using "               "default socket");
gf_log("cli", GF_LOG_INFO, "Started running %s with version %s", argv[0],           PACKAGE_VERSION);
gf_log("cli", GF_LOG_INFO,                       "Operation "                       "cancelled, exiting");
gf_log("cli", GF_LOG_DEBUG,               "User cancelled "               "snapshot deactivate operation");
gf_log("cli", GF_LOG_DEBUG,                   "User cancelled "                   "snapshot delete operation for snap %s",                   (char *)words[2]);
gf_log("cli", GF_LOG_DEBUG,                   "User cancelled "                   "snapshot config operation");
_gf_log(const char *domain, const char *file, const char *function,        int32_t line, gf_loglevel_t level, const char *fmt, ...){    return 0;
_gf_log(const char *domain, const char *file, const char *function, int line,        gf_loglevel_t level, const char *fmt, ...){    const char *basename = NULL;
./glusterfs/glusterfsd/src/glusterfsd-mgmt.c:            gf_msg_debug("glusterfsd-mgmt", EINVAL, "Reconfigure failed !!");
./glusterfs/glusterfsd/src/glusterfsd.c:        gf_msg_debug("glusterfsd", 0, "failed to initialize fuse translator");
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_msg_debug("glusterfsd", 0, "loading volume file %s", cmd_args->volfile);
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_msg_trace("gluster", 0, "received reincarnate request (sig:HUP)");
./glusterfs/glusterfsd/src/glusterfsd.c:    gf_msg_trace("glusterfsd", 0, "pidfile %s cleanup", cmd_args->pid_file);
./glusterfs/api/src/glfs-resolve.c:    gf_msg_debug(subvol->name, 0, "first lookup complete %d", ret);
./glusterfs/api/src/glfs-primary.c:            gf_msg_debug(this->name, 0, "got notify event %d", event);
./glusterfs/api/src/glfs-mgmt.c:    gf_msg_trace("glfs", 0, "statedump requested for pid: %d", target_pid.pid);
./glusterfs/api/src/glfs-mgmt.c:        gf_msg_debug("glfs", 0, "Taking statedump for pid: %d", target_pid.pid);
./glusterfs/api/src/glfs-mgmt.c:        gf_msg_debug(frame->this->name, 0, "Volume Id: %s", volume_id_str);
./glusterfs/api/src/glfs-mgmt.c:    gf_msg_debug(frame->this->name, 0, "Returning: %d", ret);
./glusterfs/api/src/glfs-mgmt.c:        gf_msg_debug(THIS->name, 0, "volumeid/size is null");
./glusterfs/api/src/glfs-mgmt.c:        gf_msg_debug("glusterfsd-mgmt", 0, "Reconfigure failed !!");
./glusterfs/api/src/glfs-handleops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-handleops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs.c:    gf_msg_debug("glfs", 0, "loading volume file %s", cmd_args->volfile);
./glusterfs/api/src/glfs.c:        gf_msg_trace("glfs", 0, "copying %zu to %p", len, buf);
./glusterfs/api/src/glfs.c:        gf_msg_trace("glfs", 0, "buffer is %zd too short", -res);
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:        gf_msg_debug("gfapi", 0, "Getting leaseid from thread failed");
./glusterfs/api/src/glfs-fops.c:                gf_msg_trace(THIS->name, 0, "glfd (%p) has held lease", glfd);
./glusterfs/api/src/glfs-fops.c:    gf_msg_debug(THIS->name, 0, "Upcall gfapi callback is called");
./glusterfs/tests/basic/logchecks.c:    gf_msg_vplain(level, fmt, ap);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_INFO, 0, logchecks_msg_1);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_INFO, 22, logchecks_msg_2, 42, "Forty-Two", 42);
./glusterfs/tests/basic/logchecks.c:    gf_msg_nomem("logchecks", GF_LOG_ALERT, 555);
./glusterfs/tests/basic/logchecks.c:    gf_msg_nomem("logchecks", GF_LOG_INFO, 555);
./glusterfs/tests/basic/logchecks.c:    go_log_vargs(GF_LOG_INFO, "Informational: gf_msg_vplain: No args!!!");
./glusterfs/tests/basic/logchecks.c:    go_log_vargs(GF_LOG_INFO, "Critical: gf_msg_vplain: No args!!!");
./glusterfs/tests/basic/logchecks.c:    gf_msg_plain_nomem(GF_LOG_INFO, "Informational: gf_msg_plain_nomem");
./glusterfs/tests/basic/logchecks.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "Alert: gf_msg_plain_nomem");
./glusterfs/tests/basic/logchecks.c:    gf_msg_backtrace_nomem(GF_LOG_INFO, 5);
./glusterfs/tests/basic/logchecks.c:    gf_msg_backtrace_nomem(GF_LOG_ALERT, 5);
./glusterfs/tests/basic/logchecks.c:    gf_msg_callingfn("logchecks", GF_LOG_INFO, 0, logchecks_msg_7);
./glusterfs/tests/basic/logchecks.c:    gf_msg_debug("logchecks", 0, "Debug: Hello World!!!");
./glusterfs/tests/basic/logchecks.c:    gf_msg_trace("logchecks", 0, "Trace: Hello World!!!");
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_19);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_12);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_13);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_14);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_15);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_16);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_14);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_15);
./glusterfs/tests/basic/logchecks.c:    gf_msg("logchecks", GF_LOG_ALERT, 0, logchecks_msg_11);
./glusterfs/xlators/storage/posix/src/posix-entry-ops.c:            gf_msg_debug(this->name, 0, "Moving %s to %s", real_path, tmp_path);
./glusterfs/xlators/storage/posix/src/posix-common.c:            gf_msg_debug(this->name, 0, "'statfs()' returns dummy size");
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            errno = op_errno; /*gf_msg could have changed errno*/
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            errno = op_errno; /*gf_msg could have changed errno*/
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_debug(this->name, 0, "%s: %s", newpath, strerror(ENOENT));
./glusterfs/xlators/storage/posix/src/posix-helpers.c:        gf_msg_debug(this->name, 0, "%s: %s", newpath, strerror(ENOENT));
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_trace(THIS->name, 0, "unlinking %s", fpath);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:                gf_msg_debug(THIS->name, 0, "removing directory %s", fpath);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:        gf_msg_trace(xl->name, 0, "janitor: closing file fd=%d", pfd->fd);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:        gf_msg_debug(xl->name, 0, "janitor: closing dir fd=%p", pfd->dir);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_msg_debug(this->name, 0, "health-check thread exiting");
./glusterfs/xlators/storage/posix/src/posix-helpers.c:        gf_msg_debug(this->name, 0, "picked %d fsyncs", count);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_msg_debug("posix", 0, "The value of mode is %u", mode);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_msg_debug("posix", 0, "The value of mode is %u", mode);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_msg_debug(this->name, 0, "heal state returned %d", state);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:        gf_msg_debug(this->name, 0, "status is REPAIR");
./glusterfs/xlators/storage/posix/src/posix-helpers.c:    gf_msg_debug(this->name, 0, "state returned is %d", state);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_debug(this->name, 0, "state : %d", state);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_debug(this->name, 0, "state : %d", state);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_debug(this->name, 0, "state : %d", state);
./glusterfs/xlators/storage/posix/src/posix-helpers.c:            gf_msg_debug(this->name, 0, "state : %d", state);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "%s (%s)", path, strerror(errno));
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "%s (%s)", path, strerror(errno));
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "pfd is NULL from fd=%p", fd);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "pfd is NULL from fd=%p", fd);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "pfd is NULL from fd=%p", fd);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "pfd is NULL from fd=%p", fd);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug(this->name, 0, "pfd from fd=%p is NULL", fd);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:            gf_msg_debug(this->name, -ret, "Unable to get sync_backend_xattrs");
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_debug("remove_xattr", 0, "key %s => %s", key, newkey);
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:    gf_msg_debug("posix", 0, "(key/val) = (%s/%d)", key, data_to_int32(value));
./glusterfs/xlators/storage/posix/src/posix-inode-fd-ops.c:        gf_msg_trace(this->name, 0, "null xdata passed, fd %p", fd);
./glusterfs/xlators/features/snapview-client/src/snapview-client.c:        gf_msg_debug(this->name, 0, "pfd from fd=%p is NULL", fd);
./glusterfs/xlators/features/snapview-server/src/snapview-server-helpers.c:    gf_msg_debug(this->name, 0, "gfid generated is %s ", uuid_utoa(gfid));
./glusterfs/xlators/features/snapview-server/src/snapview-server-mgmt.c:    gf_msg_debug(this->name, 0, "svs mgmt init successful");
./glusterfs/xlators/features/snapview-server/src/snapview-server.c:        gf_msg_debug(this->name, 0, "pfd from fd=%p is NULL", fd);
./glusterfs/xlators/features/snapview-server/src/snapview-server.c:        gf_msg_debug(this->name, 0, "pfd from fd=%p is NULL", fd);
./glusterfs/xlators/features/snapview-server/src/snapview-server.c:        gf_msg_debug(this->name, 0, "dangling volume. check volfile ");
./glusterfs/xlators/features/quota/src/quota-enforcer-client.c:            gf_msg_trace(this->name, ENOENT, "not found on remote node");
./glusterfs/xlators/features/quota/src/quota-enforcer-client.c:            gf_msg_trace(this->name, 0, "got RPC_CLNT_CONNECT");
./glusterfs/xlators/features/quota/src/quota-enforcer-client.c:            gf_msg_trace(this->name, 0, "got RPC_CLNT_DISCONNECT");
./glusterfs/xlators/features/quota/src/quota-enforcer-client.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/features/quota/src/quota.c:    gf_msg_debug(this->name, 0, "str = %s", dir_limit);
./glusterfs/xlators/features/quota/src/quota.c:    gf_msg_debug(this->name, 0, "No limit set on the inode or it's parents.");
./glusterfs/xlators/features/index/src/index.c:        gf_msg_debug(this->name, errno, "Stat failed on %s dir ", path);
./glusterfs/xlators/features/locks/src/posix.c:        gf_msg(THIS->name, GF_LOG_INFO, 0, 0, "NULL parameter");
./glusterfs/xlators/features/leases/src/leases-internal.c:    gf_msg_debug(this->name, 0, "open fd count:%d flags:%d", fd_count, flags);
./glusterfs/xlators/features/leases/src/leases-internal.c:        gf_msg_trace(this->name, 0, "Executing fop:%d", blk_fop->stub->fop);
./glusterfs/xlators/features/leases/src/leases-internal.c:    gf_msg_debug(this->name, 0, "Started the expired_recall_cleanup thread");
./glusterfs/xlators/features/leases/src/leases-internal.c:                gf_msg_debug(this->name, 0, "Found expired recalls");
./glusterfs/xlators/features/upcall/src/upcall-internal.c:        gf_msg_debug("upcall", 0, "Internal fop - client NULL");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeue rmdir");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueue rmdir");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeue unlink");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueue unlink");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeue rename");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueue rename");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeuing link");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueued link");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeuing mkdir");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "failed to get gfid from dict");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueued mkdir");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeuing symlink");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "failed to get gfid from dict");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueued symlink");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeuing mknod");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "failed to get gfid from dict");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueued mknod");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "Dequeuing create");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "failed to get gfid from dict");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "Enqueued create");
./glusterfs/xlators/features/changelog/src/changelog.c:        gf_msg_debug(this->name, 0, "changelog reconfigured");
./glusterfs/xlators/features/changelog/src/changelog.c:    gf_msg_debug(this->name, 0, "changelog translator loaded");
./glusterfs/xlators/features/changelog/src/changelog-helpers.c:                gf_msg_debug(this->name, 0, "selecting event %d", idx);
./glusterfs/xlators/features/changelog/src/changelog-helpers.c:                gf_msg_debug(this->name, 0, "de-selecting event %d", idx);
./glusterfs/xlators/features/changelog/src/changelog-helpers.c:    gf_msg_debug(this->name, 0, "Woke up: Conditional wait on black fops");
./glusterfs/xlators/features/changelog/src/changelog-helpers.c:    gf_msg_debug(this->name, 0, "Woke up: Conditional wait on white fops");
./glusterfs/xlators/features/changelog/src/changelog-helpers.c:            gf_msg_debug(this->name, 0, "Wokeup on timeout");
./glusterfs/xlators/features/changelog/src/changelog-rpc-common.c:        gf_msg_debug(this->name, 0, "failed to create listeners");
./glusterfs/xlators/features/changelog/lib/src/gf-changelog.c:    gf_msg_debug(this->name, 0, "freeing entry %p", entry);
./glusterfs/xlators/features/changelog/lib/src/gf-history-changelog.c:    gf_msg_debug(this->name, 0, "moving %s to processed directory", file);
./glusterfs/xlators/features/changelog/lib/src/gf-changelog-api.c:    gf_msg_debug(this->name, 0, "moving %s to processed directory", file);
./glusterfs/xlators/features/bit-rot/src/bitd/bit-rot.c:    gf_msg_debug(this->name, 0, "RELEASE EVENT [GFID %s]", uuid_utoa(gfid));
./glusterfs/xlators/features/bit-rot/src/bitd/bit-rot.c:    gf_msg_trace(this->name, 0, "Notification received: %d", event);
./glusterfs/xlators/features/bit-rot/src/bitd/bit-rot.c:            gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/features/bit-rot/src/bitd/bit-rot.c:            gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/features/bit-rot/src/bitd/bit-rot-scrub.c:        gf_msg_debug(this->name, 0, "%s is not a regular file", entry->d_name);
./glusterfs/xlators/features/bit-rot/src/stub/bit-rot-stub.c:    gf_msg_debug(this->name, 0, "bit-rot stub loaded");
./glusterfs/xlators/features/cloudsync/src/cloudsync-plugins/src/cloudsyncs3/src/libcloudsyncs3.c:    gf_msg_debug("CS", 0, "resource %s", resource);
./glusterfs/xlators/features/cloudsync/src/cloudsync-plugins/src/cloudsyncs3/src/libcloudsyncs3.c:    gf_msg_debug("CS", 0, "sign_req %s date %s", sign_req, date);
./glusterfs/xlators/features/cloudsync/src/cloudsync-plugins/src/cloudsyncs3/src/libcloudsyncs3.c:            gf_msg_debug(this->name, 0, "slist for curl - %s", tmp->data);
./glusterfs/xlators/features/cloudsync/src/cloudsync-plugins/src/cloudsyncs3/src/libcloudsyncs3.c:        gf_msg_debug(this->name, 0, "response code %ld", responsecode);
./glusterfs/xlators/features/cloudsync/src/cloudsync-plugins/src/cvlt/src/libcvlt.c:    gf_msg(plugin, GF_LOG_INFO, 0, CVLT_FREE, " released xlator resources");
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:                gf_msg(this->name, GF_LOG_INFO, 0, 0, " state = %" PRIu64, val);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "state %" PRIu64, val);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "ftruncate succeed");
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:                gf_msg(this->name, GF_LOG_INFO, 0, 0, " state = %" PRIu64, val);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:                gf_msg_debug(this->name, 0, "status : %" PRIu64, val);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "status not found in dict");
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "filepath returned %s", filepath);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "NULL filepath");
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:        gf_msg_debug(this->name, 0, "status is %d", state);
./glusterfs/xlators/features/cloudsync/src/cloudsync.c:            gf_msg_debug(this->name, 0, "Winding for Final Write");
./glusterfs/xlators/features/quiesce/src/quiesce.c:        gf_msg_debug(this->name, 0, "failed to create the frame");
./glusterfs/xlators/features/quiesce/src/quiesce.c:    gf_msg_trace(this->name, 0, "Initiating failover to:%s", host->addr);
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "failed to find xlator for volume");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, -ret, "mounting not possible");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "failed to create glfs instance");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "failed to resolve %s", subdir);
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "received WebNFS request");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "Guard check required");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "Guard check not required");
./glusterfs/xlators/nfs/server/src/nfs3.c:    gf_msg_debug(GF_NFS3, 0, "inode needs fresh lookup");
./glusterfs/xlators/nfs/server/src/nfs3.c:        gf_msg_trace(GF_NFS3, 0, "Reached end-of-directory");
./glusterfs/xlators/nfs/server/src/nfs3.c:    gf_msg_trace(GF_NFS3, 0, "Initing state: %s", exp->subvol->name);
./glusterfs/xlators/nfs/server/src/nfs3.c:    gf_msg_trace(GF_NFS3, 0, "local pool: %d", localpool);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_debug(GF_NFS, 0, "Starting program: %s", prog->progname);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_debug(GF_NFS, 0, "Initing protocol versions");
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_debug(GF_NFS, 0, "Starting program: %s", prog->progname);
./glusterfs/xlators/nfs/server/src/nfs.c:                gf_msg_debug(GF_NFS, 0, "Volume already started %s", xl->name);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_trace(GF_NFS, 0, "Started %s", ((xlator_t *)cookie)->name);
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_trace(GF_NFS, 0, "Subvolume already started: %s", xl->name);
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_debug(GF_NFS, 0, "Starting subvolume: %s", cl->xlator->name);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_trace(GF_NFS, 0, "inode table lru: %d", lrusize);
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_debug(GF_NFS, 0, "Initing subvolume: %s", cl->xlator->name);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_trace(GF_NFS, 0, "Inited volumes: %d", svcount);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_trace(GF_NFS, 0, "uid: %d, gid %d, gids: %d", uid, gid, auxcount);
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_trace(GF_NFS, 0, "gid: %d", auxgids[y]);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_STARTED, "NFS service started");
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_trace(GF_NFS, 0, "Notification received: %d", event);
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_debug(GF_NFS, 0, "NFS service going down");
./glusterfs/xlators/nfs/server/src/nfs.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_debug(this->name, 0, "Statedump of DRC failed");
./glusterfs/xlators/nfs/server/src/nfs.c:        gf_msg_debug(this->name, 0, "Statedump of NLM failed");
./glusterfs/xlators/nfs/server/src/exports.c:    gf_msg_trace(GF_EXP, 0, "found hostname/netgroup: %s", item_name);
./glusterfs/xlators/nfs/server/src/exports.c:    gf_msg_trace(GF_EXP, 0, "parsing line: %s", line);
./glusterfs/xlators/nfs/server/src/exports.c:        gf_msg_trace(GF_EXP, 0, "parsing netgroup: %s", strmatch);
./glusterfs/xlators/nfs/server/src/exports.c:    gf_msg_trace(GF_EXP, 0, "parsing line: %s", line);
./glusterfs/xlators/nfs/server/src/exports.c:        gf_msg_trace(GF_EXP, 0, "parsing hostname: %s", strmatch);
./glusterfs/xlators/nfs/server/src/exports.c:        gf_msg_debug(GF_EXP, 0, "%s not found for %s", host, expdir->dir_name);
./glusterfs/xlators/nfs/server/src/exports.c:        gf_msg_debug(GF_EXP, 0, "%s not found in %s", dirdup, file->filename);
./glusterfs/xlators/nfs/server/src/mount3udp_svc.c:        gf_msg_debug(GF_MNT, 0, "PROC returned error");
./glusterfs/xlators/nfs/server/src/nfs-common.c:    gf_msg_trace(GF_NFS, 0, "Subvolume search: %s", path);
./glusterfs/xlators/nfs/server/src/nfs-common.c:            gf_msg_trace(GF_NFS, 0, "Inode needs to be created.");
./glusterfs/xlators/nfs/server/src/nfs-common.c:        gf_msg_trace(GF_NFS, 0, "Inode was found in the itable.");
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_trace(GF_NFS3, 0, "Entry: %s", entry->d_name);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:        gf_msg_trace(GF_NFS3, 0, "Bad cookie requested");
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_trace(GF_NFS3, 0, "Cookie verified");
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_debug(GF_NFS3, 0, "XID: %x, %s: args: %s", xid, op, fhstr);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:        gf_msg_debug(GF_NFS3, 0, "%s => (%s)", path, errstr);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:        gf_msg_debug(GF_NFS3, 0, "%s => (%s), %s", path, errstr, fhstr);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_trace(GF_NFS3, 0, "FH inode resolved");
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:        gf_msg_trace(GF_NFS3, 0, "Entry looked up: %s", cs->resolvedloc.path);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_trace(GF_NFS3, 0, "FH needs inode resolution");
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:        gf_msg_trace(GF_NFS3, 0, "Root looked up: %s", cs->resolvedloc.path);
./glusterfs/xlators/nfs/server/src/nfs3-helpers.c:    gf_msg_trace(GF_NFS3, 0, "Root needs lookup");
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(this->name, 0, "mapped %u => %s", root->uid, result->pw_name);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:            gf_msg_trace(GF_NFS, 0, "gid: %d", nfu->gids[x]);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Lookup: %s", loc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Access: %s", loc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Stat: %s", loc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "FStat");
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Opendir: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "readdir");
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Statfs: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Create: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Setattr: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Mkdir: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Symlink: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Readlink: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Mknod: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Rmdir: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Unlink: %s", pathloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Link: %s -> %s", newloc->path, oldloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Rename: %s -> %s", oldloc->path, newloc->path);
./glusterfs/xlators/nfs/server/src/nfs-fops.c:    gf_msg_trace(GF_NFS, 0, "Open: %s", loc->path);
./glusterfs/xlators/nfs/server/src/nlm4.c:            gf_msg_trace(GF_NLM, 0, "FH to Volume: %s", volume->name);         \
./glusterfs/xlators/nfs/server/src/nlm4.c:        gf_msg_debug(GF_NLM, 0, "NLM in grace period");
./glusterfs/xlators/nfs/server/src/nlm4.c:        gf_msg_debug(GF_NLM, 0, "NLM in grace period");
./glusterfs/xlators/nfs/server/src/nlm4.c:        gf_msg_debug(GF_NLM, 0, "client not found: %s", caller_name);
./glusterfs/xlators/nfs/server/src/nlm4.c:        gf_msg_debug(GF_NLM, 0, "error in free all; stat: %d", stat);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_trace(GF_MNT, 0, "Inserted into mountdict: %s", me->hashkey);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Read entries %s:%s", me->hostname, me->exname);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Read %d entries from '%s'", idx, sh->path);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Updated rmtab with %d entries", idx);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "MNT reply: fh %s, status: %d", fhstr, status);
./glusterfs/xlators/nfs/server/src/mount3.c:            gf_msg_debug(GF_MNT, 0, "Client mount not allowed");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Mount reply status: %d", mntstat);
./glusterfs/xlators/nfs/server/src/mount3.c:            gf_msg_debug(GF_MNT, 0, "getaddrinfo: %s\n", gai_strerror(ret));
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Export not found");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Volume %s not started", exp->vol->name);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Client mount not allowed");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "dirpath: %s", path);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Found cached FH for %s", host_addr_ip);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "dirpath: %s", path);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Volume %s not started", exp->vol->name);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Client mount not allowed");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_debug(GF_MNT, 0, "Client mount not allowed");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Building mount list:");
./glusterfs/xlators/nfs/server/src/mount3.c:            gf_msg_trace(GF_MNT, 0, "Export not found");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "dirpath: %s, hostname: %s", dirpath, hostname);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Initing volume export: %s", xl->name);
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Volume exports disabled");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Volume exports enabled");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Dir exports disabled");
./glusterfs/xlators/nfs/server/src/mount3.c:        gf_msg_trace(GF_MNT, 0, "Dir exports enabled");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_trace(GF_MNT, 0, "Checking if key %s is authorized.", key);
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Invalidating old mounts ...");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, 0, "Initing Mount v3 state");
./glusterfs/xlators/nfs/server/src/mount3.c:            gf_msg_debug(GF_MNT, GF_LOG_DEBUG, "Thread creation failed");
./glusterfs/xlators/nfs/server/src/mount3.c:            gf_msg_debug(GF_MNT, GF_LOG_DEBUG, "Thread creation failed");
./glusterfs/xlators/nfs/server/src/mount3.c:    gf_msg_debug(GF_MNT, GF_LOG_DEBUG, "Initing Mount v1 state");
./glusterfs/xlators/nfs/server/src/auth-cache.c:            gf_msg_debug(GF_NFS, 0, "could not find entry for %s", host_addr);
./glusterfs/xlators/nfs/server/src/auth-cache.c:            gf_msg_debug(GF_NFS, 0, "entry for host %s has expired", host_addr);
./glusterfs/xlators/nfs/server/src/auth-cache.c:    gf_msg_trace(GF_NFS, 0, "Caching file-handle (%s)", host_addr);
./glusterfs/xlators/nfs/server/src/netgroups.c:    gf_msg_trace(GF_NG, 0, "parsing host string: %s", ng_str);
./glusterfs/xlators/nfs/server/src/netgroups.c:        gf_msg_trace(GF_NG, 0, "found match: %s (parts=%d)", match, parts);
./glusterfs/xlators/nfs/server/src/netgroups.c:            gf_msg_debug(GF_NG, 0, "Failed to parse line %s", line);
./glusterfs/xlators/nfs/server/src/acl3.c:            gf_msg_trace(GF_ACL, 0, "FH to Volume: %s", volume->name);         \
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-set.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Acquired lock on localhost");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Received op from uuid %s", str);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "transaction ID = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:        gf_msg_debug(this->name, 0, "No transaction's opinfo set");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "transaction ID = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "Received uuid reset req");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "Received uuid get req");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_trace(this->name, 0, "Received global option request");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg(this->name, GF_LOG_INFO, 0, 0, "Received reset vol req");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "Responded, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to lock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to unlock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to mgmt_v3 lock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to mgmt_v3 unlock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Responded to stage, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Responded to commit, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(this->name, 0, "Responded to CLI, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to CLI, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:        gf_msg_debug(this->name, 0, "get-state command type not set");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:            gf_msg_debug(this->name, 0, "got RPC_CLNT_CONNECT");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handler.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "Received create volume req");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_trace(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:            gf_msg_debug(this->name, 0, "NFS-Ganesha is enabled");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_trace(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_trace(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug("glusterd", 0, "Performing statedump on volume %s", volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:        gf_msg_debug(THIS->name, 0, "%s", errstr);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:        gf_msg_debug(THIS->name, 0, "rmdir failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:        gf_msg_debug("glusterd", 0, "umount failed on maintenance client");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:        gf_msg_debug(THIS->name, 0, "Could not start glusterfs");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug(THIS->name, 0, "Started glusterfs successfully");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volume-ops.c:    gf_msg_debug("glusterd", 0, "Performing clearlocks on volume %s", volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-gfproxyd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-gfproxyd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-gfproxyd-svc.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-gfproxyd-svc.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-nfs-svc.c:            gf_msg_debug(THIS->name, 0, "nfs service initialized");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-nfs-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-nfs-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-nfs-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-quota.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-hooks.c:        gf_msg_debug(this->name, 0, "No Hooks Arguments.");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-hooks.c:        gf_msg_debug(this->name, 0, "Hooks Args = %s", hooks_args);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:                    gf_msg_trace(this->name, 0, "failed to get status");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:        gf_msg_debug(this->name, 0, "Transaction_id = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:        gf_msg_debug(this->name, 0, "Transaction_id = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:        gf_msg_debug(this->name, 0, "Transaction_id = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:        gf_msg_debug(this->name, 0, "Transaction_id = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:        gf_msg_debug(this->name, 0, "transaction ID = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rpc-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapd-svc.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-bitd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-bitd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-bitd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "old secondary: %s!", *secondary);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "parsed secondary: %s!", *secondary);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "value->data %s", value->data);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "pidfile = %s", pidfile);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d.", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "secondary_info: %s!", secondary_info);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "cnt: %d", cnt);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d.", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "secondary = %s", secondary);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:            gf_msg_debug(this->name, 0, "host = %s", host);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "secondary_info:%s !", secondary_info);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:            gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "Returning 0");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:            gf_msg_debug(this->name, 0, "op_value is already set");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "Hostname : %s", *hostname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "Secondary URL : %s", *secondary_url);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:        gf_msg_debug(this->name, 0, "Secondary Vol : %s", *secondary_vol);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-geo-rep.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:        gf_msg_debug(this->name, 0, "Unable to fetch local hostname from peer");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:        gf_msg_debug(this->name, 0, "local_node_hostname truncated");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-sm.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", op_ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:        gf_msg_debug(this->name, 0, "Unable to get mgmt_v3 lock owner");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:        gf_msg_debug(this->name, 0, "Unable to get mgmt_v3 lock owner");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-locks.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug("glusterd", 0, "rebalance command failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "volname not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "cmd not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "failed to validate");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "volname not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "cmd not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "failed to validate");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "volname not given");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "command not given");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "cmd validate failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "volname not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "cmd not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "failed to validate");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "volname not given");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "command not given");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-rebalance.c:        gf_msg_debug(this->name, 0, "cmd validate failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to mgmt_v3 lock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(this->name, 0, "Responded to pre validation, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(this->name, 0, "Responded to brick op, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(this->name, 0, "Responded to commit, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(this->name, 0, "Responded to post commit, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(this->name, 0, "Responded to post validation, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_debug(THIS->name, 0, "Responded to mgmt_v3 unlock, ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt-handler.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-ganesha.c:            gf_msg_debug(THIS->name, 0, "%s found.", sc_list[i].binary);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-ganesha.c:        gf_msg_debug(this->name, 0, "nfs-ganesha is enabled for the cluster");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-ganesha.c:        gf_msg_debug(this->name, 0, "nfs-ganesha is disabled for the cluster");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-ganesha.c:            gf_msg_debug(this->name, 0, "Error, Cannot Validate option");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-ganesha.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-bitrot.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:        gf_msg_debug("glusterd", 0, "svc_proc is null, ie shd already stopped");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:            gf_msg_debug(this->name, 0, "shd isn't running");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-shd-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug(this->name, 0, "%s:%s", parent->name, trav->name);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:            gf_msg_debug(this->name, 0, "timestamp file exist");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_trace("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_trace("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate  bricks");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate client");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate nfs");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate self-heald");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate  bricks");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate client");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate nfs");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:        gf_msg_debug("glusterd", 0, "Could not Validate self-heald");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-volgen.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handshake.c:        gf_msg_debug(this->name, 0, "No brick name present");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handshake.c:    gf_msg_debug(this->name, 0, "brick_name = %s", *brick_name);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-handshake.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-log-ops.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:    gf_msg_debug(this->name, 0, "Returning %d.", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:        gf_msg_debug(this->name, 0, "dict_get on operation failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:    gf_msg_debug(this->name, 0, "src brick=%s", src_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:        gf_msg_debug(this->name, 0, "Unable to get src-brickinfo");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:        gf_msg_debug(this->name, 0, "dst brick=%s", dst_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:            gf_msg_debug(this->name, 0, "Unable to resolve dst-brickinfo");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-reset-brick.c:            gf_msg_debug(this->name, 0, "I AM THE DESTINATION HOST");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Volume %s found", voliter->volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "Volume %s found", volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "Volume %s found", volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:                gf_msg_debug(this->name, 0, "%s is already stopped", service);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "Unable to read pidfile: %s", pidfile);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:                gf_msg_debug(this->name, 0, "%s is already stopped", service);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Unlinking pidfile %s", pidfile);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Failed to set key_prefix for quota conf");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Failed to get quota cksum");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Not importing snap volume");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with ret: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "starting the volume %s", volinfo->volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug("glusterd", 0, "No Local Bricks Present.");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "Rebalance start validate failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get file count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get size of xfer");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get lookedup file count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get status");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get failure count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get skipped count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get promoted count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get demoted count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get run-time");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_trace(this->name, 0, "failed to get time left");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug("glusterd", 0, "Source brick empty");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "No brick_count present");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "%s not present", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_trace(this->name, 0, "Returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug("glusterd", 0, "src-brick-port=%d found", src_port);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug("glusterd", 0, "dst-brick-port=%d found", dst_port);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug("glusterd", 0, "Could not set src-brick");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug("glusterd", 0, "Could not set dst-brick");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set node-uuid");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set node-uuid");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set the file count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set the size of migration");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set looked up file count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set status");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set failure count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set skipped count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set run-time");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set time-left");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set demoted count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:            gf_msg_debug(this->name, 0, "failed to set promoted count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug("glusterd", 0, "No output from source");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "transaction ID = %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Returning with ret");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:                gf_msg_debug("glusterd", 0, "Could not set dst-brick port no");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "dict get on operation type failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "src brick=%s", *src_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:        gf_msg_debug(this->name, 0, "I AM THE SOURCE HOST");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "dst brick=%s", *dst_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug(this->name, 0, "Brick order okay");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-helper.c:            gf_msg_debug(THIS->name, 0, "shd service initialized");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug(this->name, 0, "Unable to find friend: %s", hoststr);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug(THIS->name, 0, "Returning %s", (ret ? "TRUE" : "FALSE"));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:                gf_msg_debug(THIS->name, 0, "Peer %s is down. ", *down_peerstr);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-peer-utils.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Unlink failed on %s", brickpath);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Failed to rmdir: %s", trashdir);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Failed to close dir %s.", delete_path);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Failed to rmdir: %s", delete_path);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Failed to rmdir: %s", trashdir);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "No previous op_version present");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "No previous op_version present");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "No previous uuid is present");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "key = %s value = %s", key, value);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "key = %s value = %s", key, value);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:                gf_msg_debug(this->name, 0, "EOF for missed_snap_list");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Failed to retrieve missed_snaps_list");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug("glusterd", 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Version absent");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-store.c:        gf_msg_debug(this->name, 0, "Invalid version number");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-mgmt.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-mgmt.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-mgmt.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-mgmt.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-svc-mgmt.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_debug(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_debug(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_debug(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-mgmt.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:    gf_msg_debug("glusterd", 0, "listen-backlog value: %d", backlog);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:        gf_msg_debug(this->name, 0, "Failed to register notify function");
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:        gf_msg_debug(this->name, 0, "Failed to create listener");
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:    gf_msg_debug(this->name, 0, "%s function called ", __func__);
./glusterfs/xlators/mgmt/glusterd/src/glusterd.c:        gf_msg_debug(this->name, 0, "cannot get run-with-valgrind value");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:            gf_msg_debug(this->name, 0, "Not a pending delete or restore op");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(THIS->name, 0, "Returning %d", is_local);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", missed_delete);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "No missed snaps");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "volume %s is in quorum", volinfo->volname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "glusterds are in quorum");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "glusterds are in quorum");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:    gf_msg_trace(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:        gf_msg_debug(this->name, 0, "%s not found", src_path);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot-utils.c:            gf_msg_debug(this->name, 0, "%s not found", src_path);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:        gf_msg_debug(this->name, 0, "dict_get on operation failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:    gf_msg_debug(this->name, 0, "src brick=%s", src_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:        gf_msg_debug(this->name, 0, "dst brick=%s", dst_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:    gf_msg_debug(this->name, 0, "src brick=%s", src_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:    gf_msg_debug(this->name, 0, "dst brick=%s", dst_brick);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:        gf_msg_debug(this->name, 0, "dict_get on operation failed");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:        gf_msg_debug(this->name, 0, "Unable to get src-brickinfo");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-replace-brick.c:        gf_msg_debug(this->name, 0, "Unable to resolve dst-brickinfo");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", op_ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:        gf_msg_debug(this->name, 0, "No volumes");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:                gf_msg_debug(this->name, 0, "%s not present", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:                gf_msg_debug(this->name, 0, "Failed to set %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:                gf_msg_debug(this->name, 0, "Failed to set %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:                gf_msg_debug(this->name, 0, "Failed to set %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:                gf_msg_debug(this->name, 0, "Failed to set %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(THIS->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:        gf_msg_debug(this->name, 0, "removing the snap %s failed", name);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:        gf_msg_debug(this->name, 0, "No missed snaps");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:        gf_msg_debug(this->name, 0, "missed_snap_entry = %s", buf);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-snapshot.c:    gf_msg_trace(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-syncop.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-syncop.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-syncop.c:    gf_msg_debug(this->name, 0, "Sent op req to %d bricks", brick_count);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-syncop.c:    gf_msg_debug(this->name, 0, "Transaction ID : %s", uuid_utoa(*txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-scrub-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-scrub-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-scrub-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Transaction_id = %s", uuid_utoa(**txn_id));
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:            gf_msg_debug(this->name, 0, "Error, Cannot Validate option");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning: %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:            gf_msg_debug(this->name, 0, "no value set for option %s", key);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "'volume reset' returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Lock Returned %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Unlock Returned %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Unlock Returned %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:        gf_msg_debug(this->name, 0, "Got uuid %s", uuid_str);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:            gf_msg_debug(this->name, 0, "%s -> %s", uuid_str, hostname);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:                gf_msg_debug(this->name, 0, "Failed to get status cmd");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:                gf_msg_debug(this->name, 0, "Failed to get brick-index-max");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:                gf_msg_debug(this->name, 0, "Failed to get other-count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:                gf_msg_debug(this->name, 0, "Failed to get brick count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:                gf_msg_debug(this->name, 0, "Failed to get count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:            gf_msg_debug(this->name, 0, "op_ctx modification not required");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:            gf_msg_debug(this->name, 0, "Cleared local lock");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "OP = %d. Returning %d", op, ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning ret %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning ret %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:        gf_msg_debug(this->name, 0, "%s", msg);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning with %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-op-sm.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-quotad-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-quotad-svc.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-quotad-svc.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug("glusterd", 0, "Returning %d.", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug("glusterd", 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:        gf_msg_debug(this->name, 0, "Unable to get replica count");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:        gf_msg_debug(this->name, 0, "volname not found");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:                gf_msg_debug(this->name, errno, "Missing remove-brick-id");
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "returning %d ", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/mgmt/glusterd/src/glusterd-brick-ops.c:    gf_msg_debug(this->name, 0, "Returning %d", ret);
./glusterfs/xlators/cluster/afr/src/afr-common.c:            gf_msg_debug(this->name, -ret, "Unable to get link count");
./glusterfs/xlators/cluster/afr/src/afr-common.c:            gf_msg_debug(this->name, ret, "afr_inode_refresh_err failed");
./glusterfs/xlators/cluster/afr/src/afr-common.c:        gf_msg_debug(this->name, -ret, "Unable to set link-count in dict ");
./glusterfs/xlators/cluster/afr/src/afr-common.c:        gf_msg_debug(this->name, -ret, "Unable to set list-xattr in dict ");
./glusterfs/xlators/cluster/afr/src/afr-common.c:        gf_msg_debug(this->name, -ret, "Unable to set link-count in dict ");
./glusterfs/xlators/cluster/afr/src/afr-common.c:        gf_msg_debug(this->name, -ret, "Unable to set link-count in dict ");
./glusterfs/xlators/cluster/afr/src/afr-common.c:        gf_msg_debug(this->name, 0, "failed to set fd ctx (%p)", fd);
./glusterfs/xlators/cluster/afr/src/afr-common.c:    gf_msg_debug(this->name, 0, "Initiating child-down timer");
./glusterfs/xlators/cluster/afr/src/afr-lk-common.c:        gf_msg_trace(this->name, 0, "No internal locks unlocked");
./glusterfs/xlators/cluster/afr/src/afr-lk-common.c:        gf_msg_debug(this->name, 0, "we're done locking");
./glusterfs/xlators/cluster/afr/src/afr-lk-common.c:        gf_msg_trace(this->name, 0, "Last locking reply received");
./glusterfs/xlators/cluster/afr/src/afr-lk-common.c:            gf_msg_trace(this->name, 0, "All servers locked. Calling the cbk");
./glusterfs/xlators/cluster/afr/src/afr-open.c:    gf_msg_debug(this->name, 0, "need open count: %d", need_open_count);
./glusterfs/xlators/cluster/ec/src/ec-heal.c:    gf_msg_debug("EC", 0, "WIND: on child %d ", child_index);
./glusterfs/xlators/cluster/ec/src/ec-heal.c:    gf_msg_trace("ec", 0, "EC(HEAL) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-heal.c:    gf_msg_trace("ec", 0, "EC(HEAL) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-heal.c:    gf_msg_debug(ec->xl->name, 0, "getxattr on bricks is done ret %d", ret);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(FLUSH) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(FSYNC) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(FSYNCDIR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(LOOKUP) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(STATFS) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(XATTROP) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(FXATTROP) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-generic.c:    gf_msg_trace("ec", 0, "EC(IPC) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-read.c:    gf_msg_trace("ec", 0, "EC(OPENDIR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-read.c:    gf_msg_trace("ec", 0, "EC(READDIR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-read.c:    gf_msg_trace("ec", 0, "EC(READDIRP) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec.c:    gf_msg_debug(this->name, 0, "Initiating child-down timer");
./glusterfs/xlators/cluster/ec/src/ec.c:    gf_msg_trace(this->name, 0, "NOTIFY(%d): %p, %p", event, data, data2);
./glusterfs/xlators/cluster/ec/src/ec.c:    gf_msg_debug(this->name, 0, "Disperse translator initialized.");
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(ACCESS) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(GETXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(FGETXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(OPEN) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(READLINK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(READ) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(SEEK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(STAT) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-read.c:    gf_msg_trace("ec", 0, "EC(FSTAT) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-common.c:                gf_msg_debug(fop->xl->name, 0, "Lock contention detected");
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(CREATE) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(LINK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(MKDIR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(MKNOD) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(RENAME) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(RMDIR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(SYMLINK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-dir-write.c:    gf_msg_trace("ec", 0, "EC(UNLINK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-heald.c:    gf_msg_debug(healer->this->name, 0, "got entry: %s", entry->d_name);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(REMOVEXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(FREMOVEXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(SETATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(FSETATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(SETXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(FSETXATTR) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(FALLOCATE) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(DISCARD) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(TRUNCATE) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(FTRUNCATE) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-inode-write.c:    gf_msg_trace("ec", 0, "EC(WRITE) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-locks.c:    gf_msg_trace("ec", 0, "EC(ENTRYLK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-locks.c:    gf_msg_trace("ec", 0, "EC(FENTRYLK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-locks.c:    gf_msg_trace("ec", 0, "EC(INODELK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-locks.c:    gf_msg_trace("ec", 0, "EC(FINODELK) %p", frame);
./glusterfs/xlators/cluster/ec/src/ec-locks.c:    gf_msg_trace("ec", 0, "EC(LK) %p", frame);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no layout for path=%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "no layout for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-write.c:        gf_msg_debug(this->name, 0, "layout is not sane for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-selfheal.c:        gf_msg_debug(THIS->name, 0, "leaving %s alone", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug("dht", 0, "Need to update split-brain status in dict");
./glusterfs/xlators/cluster/dht/src/dht-common.c:            gf_msg_debug("dht", 0, "No need to update split-brain status");
./glusterfs/xlators/cluster/dht/src/dht-common.c:                    gf_msg_debug("dht", 0, "xattr mismatch for %s", key);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "fixing assignment on %s", local->loc.path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "winding lookup call to %d subvols", call_cnt);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "%s: No gfid-req available", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "subvol %s returned", prev->name);
./glusterfs/xlators/cluster/dht/src/dht-common.c:                gf_msg_debug(this->name, 0, "failed to get node-uuid");
./glusterfs/xlators/cluster/dht/src/dht-common.c:                gf_msg_trace(this->name, 0, "failed to set linkinfo");
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "Found a matching file.");
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "no layout for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "no layout for path=%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:        gf_msg_debug(this->name, 0, "no layout for path=%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "Processing entries from %s", prev->name);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "Processing entries from %s", prev->name);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_trace(this->name, 0, "creating %s on %s", loc->path, subvol->name);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "dht_rmdir_lookup_cbk %s", local->loc.path);
./glusterfs/xlators/cluster/dht/src/dht-common.c:    gf_msg_debug(this->name, 0, "returning for %s ", local->loc.path);
./glusterfs/xlators/cluster/dht/src/dht-shared.c:            gf_msg_debug(this->name, 0, "using regex %s = %s", name, temp_str);
./glusterfs/xlators/cluster/dht/src/dht-layout.c:            gf_msg_debug(this->name, 0, "found user-set layout");
./glusterfs/xlators/cluster/dht/src/dht-hashfn.c:            gf_msg_trace(this->name, 0, "trying regex for %s", name);
./glusterfs/xlators/cluster/dht/src/dht-hashfn.c:        gf_msg_debug(this->name, 0, "munged down to %s", rsync_friendly_name);
./glusterfs/xlators/cluster/dht/src/switch.c:            gf_msg_debug(this->name, 0, "memory allocation failed :(");
./glusterfs/xlators/cluster/dht/src/switch.c:    gf_msg_trace(this->name, 0, "creating %s on %s", loc->path, subvol->name);
./glusterfs/xlators/cluster/dht/src/switch.c:    gf_msg_trace(this->name, 0, "creating %s on %s", loc->path, subvol->name);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:        gf_msg_debug(this->name, 0, "Don't migrate %s ", entry_loc.path);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:                    gf_msg_debug("DHT", 0, "Exiting thread");
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_msg_trace(this->name, 0, "fix layout called on %s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:            gf_msg_debug("dht", 0, "total data size =%" PRIu64, g_totalsize);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_msg_debug(this->name, 0, "thread_spawn_count: %d", thread_spawn_count);
./glusterfs/xlators/cluster/dht/src/dht-rebalance.c:    gf_msg_debug("", 0, "Returning %d", ret);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no layout for path=%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no lock subvolume for path=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no cached subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no lock subvolume for path=%s", loc->path);
./glusterfs/xlators/cluster/dht/src/dht-inode-read.c:        gf_msg_debug(this->name, 0, "no lock subvolume for fd=%p", fd);
./glusterfs/xlators/cluster/dht/src/nufa.c:    gf_msg_trace(this->name, 0, "creating %s on %s", loc->path, subvol->name);
./glusterfs/xlators/cluster/dht/src/nufa.c:    gf_msg_trace(this->name, 0, "creating %s on %s", loc->path, subvol->name);
./glusterfs/xlators/performance/io-cache/src/page.c:    gf_msg_trace("io-cache", 0, "returning new page %p", page);
./glusterfs/xlators/performance/io-cache/src/page.c:            gf_msg_trace(ioc_inode->table->xl->name, 0, "op_ret = %d", op_ret);
./glusterfs/xlators/performance/io-cache/src/page.c:    gf_msg_trace(frame->this->name, 0, "fault frame %p returned", frame);
./glusterfs/xlators/performance/io-cache/src/io-cache.c:    gf_msg_debug(this->name, 0, "Max cache size is %" PRIu64, max_cache_size);
./glusterfs/xlators/performance/io-cache/src/io-cache.c:            gf_msg_trace(this->name, 0, "option path %s", option_list);
./glusterfs/xlators/performance/io-cache/src/io-cache.c:        gf_msg_trace(this->name, 0, "option path %s", option_list);
./glusterfs/xlators/performance/io-cache/src/ioc-inode.c:    gf_msg_trace(table->xl->name, 0, "adding to inode_lru[%d]", weight);
./glusterfs/xlators/performance/quick-read/src/quick-read.c:    gf_msg_debug(this->name, 0, "Max cache size is %" PRIu64, max_cache_size);
./glusterfs/xlators/performance/quick-read/src/quick-read.c:        gf_msg_trace(this->name, 0, "option path %s", option_list);
./glusterfs/xlators/playground/template/src/template.c:        gf_msg_debug(this->name, ENOMEM, "dict_set of dummy key failed");
./glusterfs/xlators/playground/template/src/template.c:            gf_msg_debug(this->name, 0, "event %d received", event);
./glusterfs/xlators/protocol/client/src/client-lk.c:    gf_msg_trace(this->name, 0, "Number of locks cleared=%d", count);
./glusterfs/xlators/protocol/client/src/client.c:        gf_msg_debug(this->name, 0, "connection in disconnected state");
./glusterfs/xlators/protocol/client/src/client.c:        gf_msg_debug(this->name, 0, "rpc_clnt_submit failed");
./glusterfs/xlators/protocol/client/src/client.c:        gf_msg_trace(this->name, 0, "key %s not present", CLIENT_CMD_CONNECT);
./glusterfs/xlators/protocol/client/src/client.c:        gf_msg_trace(this->name, 0, "name is !replace-brick");
./glusterfs/xlators/protocol/client/src/client.c:            gf_msg_debug(this->name, 0, "got RPC_CLNT_CONNECT");
./glusterfs/xlators/protocol/client/src/client.c:            gf_msg_debug(this->name, 0, "got RPC_CLNT_DISCONNECT");
./glusterfs/xlators/protocol/client/src/client.c:            gf_msg_trace(this->name, 0, "got some other RPC event %d", event);
./glusterfs/xlators/protocol/client/src/client.c:        gf_msg_debug(this->name, 0, "Client rpc conn destroyed");
./glusterfs/xlators/protocol/client/src/client.c:    gf_msg_debug(this->name, 0, "client init successful");
./glusterfs/xlators/protocol/client/src/client-helpers.c:        gf_msg_trace(this->name, 0, "sending releasedir on fd");
./glusterfs/xlators/protocol/client/src/client-helpers.c:        gf_msg_trace(this->name, 0, "sending release on fd");
./glusterfs/xlators/protocol/client/src/client-helpers.c:        gf_msg_trace(this->name, 0, "sending releasedir on fd");
./glusterfs/xlators/protocol/client/src/client-helpers.c:        gf_msg_trace(this->name, 0, "sending release on fd");
./glusterfs/xlators/protocol/client/src/client-helpers.c:        gf_msg_debug(this->name, 0, "not a valid fd");
./glusterfs/xlators/protocol/client/src/client-handshake.c:            gf_msg_debug(this->name, 0, "detected portmapper on server");
./glusterfs/xlators/protocol/client/src/client-callback.c:    gf_msg_trace(THIS->name, 0, "Upcall callback is called");
./glusterfs/xlators/protocol/client/src/client-callback.c:    gf_msg_debug(this->name, 0, "Received CHILD_UP");
./glusterfs/xlators/protocol/client/src/client-callback.c:    gf_msg_debug(this->name, 0, "Received CHILD_DOWN");
./glusterfs/xlators/protocol/client/src/client-common.c:        gf_msg_debug(this->name, ENOMEM, "Failed to get client conf");
./glusterfs/xlators/protocol/server/src/server-handshake.c:                gf_msg_debug(this->name, 0, "failed to set error msg");
./glusterfs/xlators/protocol/server/src/server-handshake.c:                gf_msg_debug(this->name, 0, "failed to set error msg");
./glusterfs/xlators/protocol/server/src/server-handshake.c:            gf_msg_debug(this->name, 0, "failed to set 'volume-id'");
./glusterfs/xlators/protocol/server/src/server-handshake.c:    gf_msg_debug(this->name, 0, "Connected to %s", client->client_uid);
./glusterfs/xlators/protocol/server/src/server-handshake.c:        gf_msg_debug(this->name, 0, "failed to set 'process-uuid'");
./glusterfs/xlators/protocol/server/src/server-handshake.c:        gf_msg_debug(this->name, 0, "failed to set 'transport-ptr'");
./glusterfs/xlators/protocol/server/src/server-handshake.c:        gf_msg_debug("server-handshake", 0, "failed to serialize reply dict");
./glusterfs/xlators/protocol/server/src/server.c:        gf_msg_trace(this->name, 0, "Reconfigured trace to %d", conf->trace);
./glusterfs/xlators/protocol/server/src/server.c:    gf_msg_debug("", 0, "returning %d", ret);
./glusterfs/xlators/protocol/server/src/server.c:        gf_msg_debug(this->name, 0, "NULL client_uid for an upcall request");
./glusterfs/xlators/protocol/server/src/server-rpc-fops_v2.c:            gf_msg_debug(THIS->name, 0, "%s", strerror(op_errno));
./glusterfs/xlators/protocol/server/src/server-rpc-fops_v2.c:            gf_msg_debug(THIS->name, 0, "%s", strerror(op_errno));
./glusterfs/xlators/protocol/server/src/server-rpc-fops_v2.c:    gf_msg_debug(bound_xl->name, 0, "frame %p, xlator %p", frame, bound_xl);
./glusterfs/xlators/protocol/server/src/server-rpc-fops_v2.c:    gf_msg_debug(bound_xl->name, 0, "frame %p, xlator %p", frame, bound_xl);
./glusterfs/xlators/protocol/server/src/server-rpc-fops.c:            gf_msg_debug(THIS->name, 0, "%s", strerror(op_errno));
./glusterfs/xlators/protocol/server/src/server-rpc-fops.c:            gf_msg_debug(THIS->name, 0, "%s", strerror(op_errno));
./glusterfs/xlators/protocol/server/src/server-rpc-fops.c:    gf_msg_debug(bound_xl->name, 0, "frame %p, xlator %p", frame, bound_xl);
./glusterfs/xlators/protocol/server/src/server-rpc-fops.c:    gf_msg_debug(bound_xl->name, 0, "frame %p, xlator %p", frame, bound_xl);
./glusterfs/xlators/protocol/server/src/server-helpers.c:    gf_msg_trace("gid-cache", 0, "mapped %u => %s", root->uid, result->pw_name);
./glusterfs/libglusterfs/src/statedump.c:    gf_msg_trace("dump", 0, "received statedump request (sig:USR1)");
./glusterfs/libglusterfs/src/rbthash.c:    gf_msg_trace(GF_RBTHASH, 0, "HASH: %u", entry->keyhash);
./glusterfs/libglusterfs/src/rbthash.c:    gf_msg_trace(GF_RBTHASH, 0, "BUCKET: %d", nbucket);
./glusterfs/libglusterfs/src/rbthash.c:    gf_msg_trace(GF_RBTHASH, 0, "HASH: %u", keyhash);
./glusterfs/libglusterfs/src/rbthash.c:    gf_msg_trace(GF_RBTHASH, 0, "BUCKET: %u", nbucket);
./glusterfs/libglusterfs/src/options.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/options.c:    gf_msg_debug(THIS->name, 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/options.c:        gf_msg_debug(THIS->name, 0, "'this' not a valid ptr");
./glusterfs/libglusterfs/src/options.c:        gf_msg_debug(xlator->name, 0, "Did not load the symbols");
./glusterfs/libglusterfs/src/options.c:    gf_msg_debug(xlator->name, 0, "Validated options");
./glusterfs/libglusterfs/src/options.c:        gf_msg_debug(trav1->xlator->name, 0, "reconfigured");
./glusterfs/libglusterfs/src/options.c:        gf_msg_debug(old_xl->name, 0, "No reconfigure() found");
./glusterfs/libglusterfs/src/graph.c:        gf_msg_debug("xlator", 0, "invalid argument");
./glusterfs/libglusterfs/src/graph.c:        gf_msg_debug("glusterfsd-mgmt", 0, "graphs are not equal");
./glusterfs/libglusterfs/src/graph.c:    gf_msg_debug("glusterfsd-mgmt", 0, "graphs are equal");
./glusterfs/libglusterfs/src/graph.c:    gf_msg_trace("glusterfsd", 0, "pidfile %s cleanup", volfile_obj->vol_id);
./glusterfs/libglusterfs/src/xlator.c:    gf_msg_trace("xlator", 0, "attempt to load file %s", name);
./glusterfs/libglusterfs/src/xlator.c:    gf_msg_debug("xlator", 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_trace("xlator", 0, "%s: struct missing (cbks)", xl->name);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_trace("xlator", 0, "%s: method missing (fini)", xl->name);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_trace("xlator", 0, "%s: method missing (reconfigure)", xl->name);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_trace("xlator", 0, "%s: method missing (notify)", xl->name);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_trace("xlator", 0, "%s: method missing (dumpops)", xl->name);
./glusterfs/libglusterfs/src/xlator.c:    gf_msg_trace("xlator", 0, "attempt to load file %s", name);
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_debug(trav->xlator->name, 0, "fini done");
./glusterfs/libglusterfs/src/xlator.c:            gf_msg_debug(xl->name, 0, "No fini() found");
./glusterfs/libglusterfs/src/xlator.c:        gf_msg_debug(xl->name, 0, "Return because it is a server graph");
./glusterfs/libglusterfs/src/compat.c:        gf_msg_debug("syscall", 0, "syscall debug: %lu", attr_len);
./glusterfs/libglusterfs/src/mem-pool.c:        gf_msg_nomem("", GF_LOG_ALERT, tot_size);
./glusterfs/libglusterfs/src/mem-pool.c:        gf_msg_nomem("", GF_LOG_ALERT, tot_size);
./glusterfs/libglusterfs/src/mem-pool.c:        gf_msg_nomem("", GF_LOG_ALERT, tot_size);
./glusterfs/libglusterfs/src/common-utils.c:        gf_msg_trace("resolver", 0, "flushing DNS cache");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "configuration details:");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "argp 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "backtrace 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "bdb->cursor->get 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "db.h 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "dlfcn 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "fdatasync 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "libpthread 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "llistxattr 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "setfsid 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "epoll.h 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "extattr.h 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "xattr.h 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "st_atim.tv_nsec 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "st_atimespec.tv_nsec 1");
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "package-string: " PACKAGE_STRING);
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, "pending frames:");
./glusterfs/libglusterfs/src/common-utils.c:            gf_msg_plain_nomem(GF_LOG_ALERT, msg);
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, msg);
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, msg);
./glusterfs/libglusterfs/src/common-utils.c:        gf_msg_plain_nomem(GF_LOG_ALERT, "time of crash: ");
./glusterfs/libglusterfs/src/common-utils.c:        gf_msg_plain_nomem(GF_LOG_ALERT, timestr);
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_backtrace_nomem(GF_LOG_ALERT, 200);
./glusterfs/libglusterfs/src/common-utils.c:    gf_msg_plain_nomem(GF_LOG_ALERT, msg);
./glusterfs/libglusterfs/src/common-utils.c:        gf_msg_debug(this->name, 0, "%s ", ip);
./glusterfs/libglusterfs/src/common-utils.c:        gf_msg_debug(this->name, 0, "%s is not local", hostname);
./glusterfs/libglusterfs/src/fd-lk.c:    gf_msg_debug("fd-lk", 0, "lock list:");
./glusterfs/libglusterfs/src/event-history.c:        gf_msg_debug("event-history", 0, "history is NULL");
./glusterfs/libglusterfs/src/run.c:    gf_msg_callingfn(dom, lvl, 0, LG_MSG_RUNNER_LOG, "%s: %s", msg, buf);
./glusterfs/libglusterfs/src/logging.c:    ret = _gf_msg_plain_internal(level, msg);
./glusterfs/libglusterfs/src/logging.c:    ret = _gf_msg_plain_internal(level, msg);
./glusterfs/libglusterfs/src/logging.c:    ret = _gf_msg_plain_internal(level, msg);
./glusterfs/libglusterfs/src/logging.c:            _gf_msg_backtrace_nomem(level, GF_LOG_BACKTRACE_DEPTH);
./glusterfs/libglusterfs/src/logging.c:        gf_msg_trace("glusterd", 0, "logging: invalid argument\n");
./glusterfs/libglusterfs/src/monitoring.c:    gf_msg_trace("monitoring", 0, "received monitoring request (sig:USR2)");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug(THIS->name, 0, "'%s' found only on one dict", key1);
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "asprintf failed");
./glusterfs/libglusterfs/src/dict.c:        gf_msg_debug("dict", 0, "dict OR buf is NULL");
./glusterfs/libglusterfs/src/store.c:        gf_msg_trace("", 0, "key %s read", iter_key);
./glusterfs/libglusterfs/src/store.c:            gf_msg_debug("", 0, "key %s found", key);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug(THIS->name, 0, "returning: %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug(THIS->name, 0, "returning: %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug("", 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug("", 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug("", 0, "Returning %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug("", 0, "Returning with %d", ret);
./glusterfs/libglusterfs/src/store.c:    gf_msg_debug("", 0, "Returning with %d", ret);
gf_msg(this->name, level, errno, P_MSG_MKNOD_FAILED,                   "mknod on %s failed", real_path);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_PREOP_CHECK_FAILED,                       "mkdir (%s/%s): getxattr on key "                       "(%s) path (%s) failed due to "                       " buffer overflow",                       pgfid, loc->name, xattr_name, par_path);
gf_msg(this->name, GF_LOG_INFO, EIO, P_MSG_PREOP_CHECK_FAILED,                       "mkdir (%s/%s): failing preop of "                       "mkdir (%s) as on-disk"                       " xattr value differs from argument "                       "value for key %s",                       pgfid, loc->name, real_path, xattr_name);
gf_msg("posix", GF_LOG_INFO, 0, P_MSG_XATTR_STATUS,               "linkto_xattr status: %" PRIu32 " for %s", skip_unlink,               real_path);
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_KEY_STATUS_INFO,               "open-fd-key-status: %" PRIu32 " for %s", skip_unlink,               real_path);
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_XATTR_NOTSUP,                   "Link count exceeded. "                   "gfid2path xattr not set (path:%s gfid:%s)",                   real_newpath, uuid_utoa(newloc->inode->gfid));
gf_msg(this->name, GF_LOG_DEBUG, errno, P_MSG_LSTAT_FAILED,                   "lstat on gfid %s failed", gfid_str);
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_UUID_NULL,               "glusterd uuid is NULL, pathinfo xattr would"               " fallback to <hostname>:<export>");
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_DISK_SPACE_CHECK_FAILED,                   "Getting disk space check from thread failed ");
gf_msg(this->name, GF_LOG_DEBUG, 0, P_MSG_XDATA_GETXATTR,               "getxattr returned %zd", size);
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_MAX_FILE_OPEN,                       "Maximum allowed "                       "open file descriptors set to 65536");
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_UUID_NULL,               "glusterd uuid is NULL, pathinfo xattr would"               " fallback to <hostname>:<export>");
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_DISK_SPACE_CHECK_FAILED,                   "Getting disk space check from thread failed ");
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_PREOP_CHECK_FAILED,                   "getxattr on key (%s) path (%s) failed due to"                   " buffer overflow",                   xattr_name, par_path);
gf_msg(this->name, GF_LOG_INFO, EIO, P_MSG_PREOP_CHECK_FAILED,               "failing preop as on-disk xattr value differs from argument "               "value for key %s",               xattr_name);
gf_msg(this->name, fop_log_level(GF_FOP_SEEK, err), err,               P_MSG_SEEK_FAILED, "seek failed on fd %d length %" PRId64,               pfd->fd, offset);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_XATTR_FAILED,                       "getxattr failed due to overflow of buffer"                       " on gfid-handle %s (path: %s) : %s ",                       real_path, loc->path, key);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_XATTR_FAILED,                   "listxattr failed due to overflow of buffer"                   " on %s (path: %s) ",                   real_path, loc->path);
gf_msg(this->name, GF_LOG_INFO, op_errno, P_MSG_XATTR_FAILED,                       "getxattr failed due to overflow of"                       "  buffer on %s (path: %s): %s ",                       real_path, loc->path, keybuffer);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_XATTR_FAILED,                       "fgetxattr failed due to overflow of"                       "buffer  on %s ",                       key);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_XATTR_FAILED,                   "listxattr failed due to overflow of buffer"                   " on %p ",                   fd);
gf_msg(this->name, GF_LOG_INFO, errno, P_MSG_XATTR_FAILED,                       "fgetxattr failed due to overflow of buffer"                       " on fd %p: for the key %s ",                       fd, key);
gf_msg(this->name, fop_log_level(GF_FOP_XATTROP, op_errno),                           op_errno, P_MSG_XATTR_FAILED,                           "getxattr failed on %s while "                           "doing xattrop: Key:%s ",                           filler->real_path, k);
gf_msg(this->name, GF_LOG_DEBUG, errno, P_MSG_XATTR_FAILED,                       "listxattr failed due to overflow of"                       " buffer on %s ",                       real_path);
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_AIO_UNAVAILABLE,           "Linux AIO not available at build-time."           " Continuing with synchronous IO");
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_AIO_UNAVAILABLE,           "Linux AIO not available at build-time."           " Continuing with synchronous IO");
gf_msg(this->name, GF_LOG_INFO, 0, P_MSG_AIO_UNAVAILABLE,           "Linux AIO not available at build-time."           " Continuing with synchronous IO");
gf_msg(frame->this->name, GF_LOG_INFO, EACCES, POSIX_ACL_MSG_EACCES,           "client: %s, gfid: %s, req(uid:%d,gid:%d,perm:%d,"           "ngrps:%" PRIu16           "), ctx(uid:%d,gid:%d,in-groups:%d,perm:%d%d%d,"           "updated-fop:%s, acl:%s)",           client ? client->client_uid : "-", uuid_utoa(inode->gfid),           frame->root->uid, frame->root->gid, want, frame->root->ngrps,           ctx->uid, ctx->gid, frame_in_group(frame, ctx->gid),           (ctx->perm & S_IRWXU) >> 6, (ctx->perm & S_IRWXG) >> 3,           ctx->perm & S_IRWXO, gf_fop_string(ctx->fop),           acl_str ? acl_str : "-");
gf_msg("mgmt", GF_LOG_INFO, 0, SVS_MSG_SNAPSHOT_LIST_CHANGED,           "list of snapshots changed");
gf_msg(this->name, GF_LOG_DEBUG, EINVAL, Q_MSG_INTERNAL_FOP_KEY_MISSING,               "No internal fop context present");
gf_msg(this->name, GF_LOG_DEBUG, 0, Q_MSG_ENFORCEMENT_SKIPPED,               "Enforcement has been skipped(internal fop).");
gf_msg(this->name, GF_LOG_INFO, EINVAL, Q_MSG_INODE_CTX_GET_FAILED,               "quota context not set inode (gfid:%s)",               uuid_utoa(local->loc.gfid));
gf_msg(this->name, GF_LOG_ALERT, 0, Q_MSG_CROSSED_SOFT_LIMIT,               "Usage crossed soft limit: "               "%s used by %s",               usage_str, path);
gf_msg(this->name, GF_LOG_ALERT, 0, Q_MSG_CROSSED_SOFT_LIMIT,               "Usage is above soft limit: %s used by %s", usage_str, path);
gf_msg(this->name, GF_LOG_DEBUG, EINVAL, 0,                    \                       "option %s would need mandatory lock to be enabled "    \                       "and feature.enforce-mandatory-lock option to be set "  \                       "to on",                                                \                       GF_ENFORCE_MANDATORY_LOCK);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "frame-root-client "               "is NULL");
gf_msg(this->name, GF_LOG_INFO, 0, 0,                       "waiting for existing fops (count %d) to drain for "                       "gfid %s",                       pl_inode->fop_wind_count, uuid_utoa(pl_inode->gfid));
gf_msg(this->name, GF_LOG_INFO, 0, LEASE_MSG_INVAL_INODE_CTX,               "failed to set inode ctx (%p)", inode);
gf_msg(this->name, GF_LOG_INFO, 0, LEASE_MSG_INVAL_UNLK_LEASE,               "Got unlock lease request from client:%s, but has no "               "corresponding lock",               client_uid);
gf_msg(this->name, GF_LOG_INFO, 0, LEASE_MSG_INVAL_UNLK_LEASE,               "Got unlock lease request from client:%s for an invalid "               "lease_type",               client_uid);
gf_msg(this->name, GF_LOG_DEBUG, 0, BRB_MSG_CHECKSUM_MISMATCH,           "Object checksum mismatch: %s [GFID: %s | Brick: %s]", loc->path,           uuid_utoa(linked_inode->gfid), child->brick_path);
gf_msg(this->name, GF_LOG_ALERT, 0, BRB_MSG_CHECKSUM_MISMATCH,           "CORRUPTION DETECTED: Object %s {Brick: %s | GFID: %s}", loc->path,           child->brick_path, uuid_utoa(linked_inode->gfid));
gf_msg(this->name, GF_LOG_ALERT, 0, BRB_MSG_MARK_CORRUPTED,           "Marking"           " %s [GFID: %s | Brick: %s] as corrupted..",           loc->path, uuid_utoa(linked_inode->gfid), child->brick_path);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Volume is under active scrubbing. Pausing scrub..");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Scrubber paused");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_START,               "Scrubbing %s at %s", sfx, timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_FINISH,               "Scrubbing %s at %s", sfx, timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,                   "Volume waiting to get rescheduled..");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,           "Scrubbing is "           "scheduled to run at %s",           timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,           "Scrubbing is "           "rescheduled to run at %s",           timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Scrubber is currently running and would be "               "rescheduled after completion");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Scrubbing rescheduled to run at %s", timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Scrubber is currently running and would be "               "rescheduled after completion");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,               "Ondemand Scrubbing scheduled to run at %s", timestr);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCALING_UP_SCRUBBER,           "Scaling up scrubbers [%d => %d]", v1, v2);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCALE_DOWN_SCRUBBER,           "Scaling down scrubbers [%d => %d]", v1, v2);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_TUNABLE,               "SCRUB TUNABLES:: [Frequency: %s, Throttle: %s]",               scrub_freq_str[fsscrub->frequency],               scrub_throttle_str[fsscrub->throttle]);
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_SCRUB_INFO,           "Waiting for all children to start and finish scrub");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_GENERIC_SSM_INFO,           "Scrubber paused");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_GENERIC_SSM_INFO,           "Scrubber paused");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_GENERIC_SSM_INFO,               "Scrubbing resumed");
gf_msg(this->name, GF_LOG_INFO, 0, BRB_MSG_GENERIC_SSM_INFO,           "Volume is under active scrubbing. Pausing scrub..");
gf_msg(plugin, GF_LOG_INFO, 0, 0,           "store id is : %s "           "product id is : %s.",           priv->store_id, priv->product_id);
gf_msg(this->name, GF_LOG_INFO, 0, 0,                   "loading library:%s successful", libname);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "state : GF_CS_LOCAL"               ", truncate successful");
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "download success, path"               " : %s",               local->remotepath);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "read success, path"               " : %s",               local->remotepath);
gf_msg(this->name, GF_LOG_INFO, 0, 0,                           " will read from remote : %" PRIu64, val);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "state : GF_CS_LOCAL"               ", readv successful");
gf_msg(this->name, GF_LOG_INFO, 0,                       SHARD_MSG_SHARD_DELETION_COMPLETED,                       "Deleted "                       "shards of gfid=%s from backend",                       entry->d_name);
gf_msg(this->name, GF_LOG_INFO, ENOTSUP, SHARD_MSG_FOP_NOT_SUPPORTED,           "seek called on %s.", uuid_utoa(fd->inode->gfid));
gf_msg(this->name, GF_LOG_INFO, 0, QUIESCE_MSG_INVAL_HOST,                       "Specified "                       "invalid internet address:%s",                       addr_tok);
gf_msg(this->name, GF_LOG_INFO, op_errno, QUIESCE_MSG_FAILOVER_FAILED,               "Initiating failover to host:%s failed:", (char *)cookie);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_NFS_MAN_DISABLE,               "NFS is manually disabled: Exiting");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_NLM_MAN_DISABLE,               "NLM is manually disabled");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_ACL_MAN_DISABLE,               "ACL is manually disabled");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_FAIL,               "Reconfiguring nfs.mem-factor needs NFS restart");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_FAIL,               "Reconfiguring nfs.rpc-statd needs NFS restart");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_WRITE_FAIL,               "Disabled writing of nfs.mount-rmtab");
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_PATH,               "Reconfigured nfs.mount-rmtab path: %s", nfs->rmtab);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_VALUE,               "Reconfigured %s with value %d", OPT_SERVER_AUX_GIDS, optbool);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_VALUE,               "Reconfigured %s with value %d", OPT_SERVER_GID_CACHE_TIMEOUT,               optuint32);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_VALUE,               "Reconfigured nfs.rdirplus with value %d", optbool);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_VOL,               "Reconfigured nfs.dynamic-volumes with value %d", optbool);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_RECONFIG_ENABLE,               "Reconfigured nfs.enable-ino32 with value %d", optbool);
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_NLM_INFO,               "NLM is"               " manually %s",               (optbool ? "enabled" : "disabled"));
gf_msg(GF_NFS, GF_LOG_INFO, 0, NFS_MSG_ACL_INFO,               "ACL is "               "manually %s",               (optbool ? "enabled" : "disabled"));
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR, "%s => (%s)", path,               errstr);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR, "%s => (%s) target: %s",               path, errstr, linkpath);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,                   "%s => (%s), count: %" PRIu32                   ", is_eof:"                   " %d, vector: count: %d, len: %zd",                   path, errstr, count, is_eof, veccount, vec->iov_len);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,               "%s => (%s), count: %" PRIu32               ", is_eof:"               " %d",               path, errstr, count, is_eof);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,               "%s => (%s), count: %" PRIu32 ", %s,wverf: %" PRIu64, path,               errstr, count, (stable == UNSTABLE) ? "UNSTABLE" : "STABLE",               wverf);
gf_msg(GF_NFS3, nfs3_loglevel(op, stat), errno, NFS_MSG_STAT_ERROR,               "%s => (%s), %s", path, errstr, fhstr);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,               "%s => (%s), count: %" PRIu32 ", cverf: %" PRIu64 ", is_eof: %d",               path, errstr, count, cverf, is_eof);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,               "%s => (%s), dircount: %" PRIu32 ", maxcount: %" PRIu32               ", cverf: %" PRIu64 ", is_eof: %d",               path, errstr, dircount, maxcount, cverf, is_eof);
gf_msg(GF_NFS3, ll, errno, NFS_MSG_STAT_ERROR,               "%s => (%s), wverf: %" PRIu64, path, errstr, wverf);
gf_msg(GF_NLM, GF_LOG_INFO, 0, NFS_MSG_SM_NOTIFY,           "sm_notify: "           "%s, state: %d",           status->mon_name, status->state);
gf_msg(GF_MNT, GF_LOG_INFO, 0, NFS_MSG_PEER_NOT_ALLOWED,               "Peer %s  not allowed", ipaddr);
gf_msg(GF_MNT, GF_LOG_INFO, errno, NFS_MSG_PEER_NOT_ALLOWED,               "Peer %s rejected. Unprivileged "               "port %d not allowed",               ipaddr, port);
gf_msg(GF_MNT, GF_LOG_DEBUG, 0, NFS_MSG_AUTH_ERROR,               "Authorization failed for IP [%s], but name "               "resolution also failed!",               host_addr_ip);
gf_msg(GF_MNT, GF_LOG_DEBUG, 0, NFS_MSG_AUTH_ERROR,           "Authorization failed for IP [%s], attempting to"           " auth hostname [%s]...",           host_addr_ip, host_addr_fqdn);
gf_msg(GF_MNT, GF_LOG_DEBUG, 0, NFS_MSG_AUTH_ERROR,               "Authorization succeeded for "               "Client [IP=%s, Hostname=%s].",               host_addr_ip, host_addr_fqdn);
gf_msg(GF_MNT, GF_LOG_INFO, 0, NFS_MSG_UPDATING_EXP,                   "File %s changed, updating exports,", exp_file_path);
gf_msg(GF_MNT, GF_LOG_INFO, 0, NFS_MSG_UPDATING_NET_GRP,                   "File %s changed,"                   "updating netgroups",                   ng_file_path);
gf_msg(GF_MNT, GF_LOG_INFO, 0, NFS_MSG_PURGING_AUTH_CACHE,               "Purging auth cache.");
gf_msg(GF_MNT, GF_LOG_INFO, 0, NFS_MSG_EXP_AUTH_DISABLED,               "Exports auth has been disabled!");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_SET_VALIDATION_INFO,               "Please note that "               "volume %s is started. This option will only get "               "effected after a brick restart.",               volinfo->volname);
gf_msg(this->name, GF_LOG_DEBUG, 0, GD_MSG_DICT_GET_FAILED,                   "dict_get_str failed on %s", GLUSTERD_QUORUM_TYPE_KEY);
gf_msg(this->name, GF_LOG_DEBUG, 0, GD_MSG_DICT_GET_FAILED,                   "dict_get_str failed on %s", GLUSTERD_QUORUM_RATIO_KEY);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_FAILED,                   "No Volume name present. "                   "Locks not being held.");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_CLI_REQ_RECVD,           "Received CLI probe req %s %d", hostname, port);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_CLI_REQ_RECVD,           "Received CLI deprobe req");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_CLI_REQ_RECVD,           "Received cli list req");
gf_msg(this->name, GF_LOG_DEBUG, 0, GD_MSG_GET_VOL_REQ_RCVD,           "Received get vol req");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_SYNC_REQ_RCVD,           "Received volume sync req "           "for volume %s",           (flags & GF_CLI_SYNC_ALL) ? "all" : volname);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PROBE_RCVD,           "Received probe from uuid: %s", uuid_utoa(friend_req.uuid));
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_UNFRIEND_REQ_RCVD,           "Received unfriend from uuid: %s", uuid_utoa(friend_req.uuid));
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_FRIEND_UPDATE_RCVD,           "Received friend update from uuid: %s", uuid_utoa(friend_req.uuid));
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_UUID_RECEIVED,                   "Received my uuid as Friend");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PROBE_RCVD,           "Received probe from uuid: %s", uuid_utoa(probe_req.uuid));
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PEER_NOT_FOUND,               "Unable to find peerinfo"               " for host: %s (%d)",               remote_hostname, port);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Responded to %s, op_ret: %d, "           "op_errno: %d, ret: %d",           remote_hostname, rsp.op_ret, rsp.op_errno, ret);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_PROFILE_REQ_RCVD,           "Received volume profile req "           "for volume %s",           volname);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_GETWD_REQ_RCVD,           "Received getwd req");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_MOUNT_REQ_RCVD,           "Received mount req");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_UMOUNT_REQ_RCVD,           "Received umount req");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CONNECT_RETURNED,           "connect returned %d", ret);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CONNECT_RETURNED,           "connect returned %d", ret);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PEER_NOT_FOUND,               "Unable to find peerinfo"               " for host: %s (%d)",               hoststr, port);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PEER_NOT_FOUND,               "Unable to find peerinfo"               " for host: %s %d",               hoststr, port);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Responded to %s (%d), ret: %d", hostname, port, ret);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Responded to %s (%d), ret: %d, op_ret: %d", remote_hostname, port,           ret, op_ret);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_STATUS_VOL_REQ_RCVD,               "Received status volume req for volume %s", volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CLRCLK_VOL_REQ_RCVD,           "Received clear-locks volume req "           "for volume %s",           volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_BARRIER_VOL_REQ_RCVD,           "Received barrier volume request for "           "volume %s",           volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "Default output directory: %s", odir);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "Default filename: %s", filename);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DAEMON_STATE_REQ_RCVD,           "Received request to get state for glusterd");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SNAPSHOT_PENDING,                       "Snapshot is pending on %s:%s. "                       "Hence not starting the brick",                       brickinfo->hostname, brickinfo->path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_BRICK_DISCONNECTED,                       "Brick %s:%s has disconnected from glusterd.",                       brickinfo->hostname, brickinfo->path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_PEER_DISCONNECTED,                   "Peer <%s> (<%s>), in state <%s>, has disconnected "                   "from glusterd.",                   peerinfo->hostname, uuid_utoa(peerinfo->uuid),                   glusterd_friend_sm_state_name_get(peerinfo->state.state));
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_HEAL_VOL_REQ_RCVD,           "Received heal vol req "           "for volume %s",           volname);
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_STATEDUMP_VOL_REQ_RCVD,           "Received statedump request for "           "volume %s with options %s",           volname, options);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "Global dict not present.");
gf_msg(this->name, GF_LOG_DEBUG, 0, GD_MSG_VOLINFO_GET_FAIL,               "gfproxyd Volfile %s is not present", svc->proc.volfile);
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_GNFS_XLATOR_NOT_INSTALLED,               "nfs/server.so xlator is not installed");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_GNFS_XLATOR_NOT_INSTALLED,               "nfs/server.so xlator is not installed");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_ALREADY_STOPPED,               "%s already stopped", proc->name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SVC_STOP_SUCCESS,           "Stopping %s daemon running in pid: "           "%d",           proc->name, pid);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOLINFO_GET_FAIL,                   "failed to get option"                   " %s",                   quota_options[i]);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DIR_OP_FAILED,                   "Failed to find "                   "directory %s.",                   backend_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_PROBE_REQ_RESP_RCVD,           "Received probe resp from uuid: %s, host: %s", uuid_utoa(rsp.uuid),           rsp.hostname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_HOST_PRESENT_ALREADY,               "Host: %s  with uuid: %s "               "already present in cluster with alias hostname: %s",               rsp.hostname, uuid_utoa(rsp.uuid), peerinfo->hostname);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_PROBE_REQ_RESP_RCVD,           "Received resp to probe req");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Received %s from uuid: %s, host: %s, port: %d",           (op_ret) ? "RJT" : "ACC", uuid_utoa(rsp.uuid), rsp.hostname,           rsp.port);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Received %s from uuid: %s, host: %s, port: %d",           (op_ret) ? "RJT" : "ACC", uuid_utoa(rsp.uuid), rsp.hostname,           rsp.port);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_RESPONSE_INFO,           "Received %s from uuid: %s", (ret) ? "RJT" : "ACC",           uuid_utoa(rsp.uuid));
gf_msg(this->name, GF_LOG_DEBUG, 0, GD_MSG_VOLINFO_GET_FAIL,               "snapd Volfile %s is not present", svc->proc.volfile);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_NODE_DISCONNECTED,                       "%s has disconnected "                       "from glusterd.",                       svc->name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "primary not found, while handling " GEOREP " options");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "secondary not found, while handling " GEOREP " options");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DEFAULT_TEMP_CONFIG,               "Using default config template(%s).", temp_conf_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CONFIG_INFO,               "Using passed config template(%s).", conf_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DEFAULT_TEMP_CONFIG,               "Using default config template(%s).", temp_conf_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_PEER_DISCONNECTED,                   "Peer %s, which is a part of %s volume, is"                   " down. Force creating geo-rep session."                   " On bringing up the peer, re-run"                   " \"gluster system:: execute"                   " gsec_create\" and \"gluster volume"                   " geo-replication %s %s create push-pem"                   " force\"",                   down_peerstr, volinfo->volname, volinfo->volname, secondary);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_INVALID_SECONDARY,                           "%s is not a valid secondary "                           "volume. Error: %s. Force "                           "creating geo-rep"                           " session.",                           secondary, *op_errstr);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_FORCE_CREATE_SESSION,               "Session between %s and %s is already created. Force"               " creating again.",               volinfo->volname, secondary);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_FORCE_CREATE_SESSION,               "get_secondaryhost_from_voluuid failed %s %s!!", secondary_host,               secondary_vol);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CONFIG_INFO,               "Using passed config template(%s).", conf_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DEFAULT_TEMP_CONFIG,               "Using default config template(%s).", temp_conf_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SESSION_INACTIVE,               "geo-replication status %s %s : session is not "               "active",               volinfo->volname, secondary);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SECONDARY_URL_INVALID,                       "%s is not a valid secondary url.", secondary);
gf_msg(this->name, GF_LOG_INFO, 0,                       GD_MSG_GET_STATEFILE_NAME_FAILED,                       "Unable to get statefile's name");
gf_msg(this->name, GF_LOG_INFO, ENOENT, GD_MSG_FILE_OP_FAILED,                   "%s statefile not present.", statefile);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "No cmd_args_count");
gf_msg("glusterd", GF_LOG_INFO, ENOENT, GD_MSG_MODULE_NOT_INSTALLED,                   GEOREP                   " module "                   "not installed in the system");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_FORCE_CREATE_SESSION,                   "rename of old working dir %s to "                   "new working dir %s is done! ",                   old_working_dir, new_working_dir);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_FORCE_CREATE_SESSION,                       "rename of old working dir %s to "                       "new working dir %s failed! Error: %s!",                       old_working_dir, new_working_dir, strerror(errno));
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_STALE_VOL_DELETE_INFO,                   "Deleting stale volume %s", volinfo->volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_REBALANCE_DISCONNECTED,                   "Rebalance process for volume %s has disconnected"                   " and defrag refcnt is %d.",                   volinfo->volname, refcnt);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_GET_CONFIG_INFO_FAILED,               "couldn't get HA_CLUSTER_NODES from file %s", GANESHA_HA_CONF);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_NFS_GNS_HOST_FOUND,                   "ganesha host found "                   "Hostname is %s",                   hostname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SVC_STOP_SUCCESS,                   "Shd service is detached for volume %s from pid %d",                   volinfo->volname, glusterd_proc_get_pid(&svc->proc));
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEFAULT_OPT_INFO,               "The default transport type for tcp,rdma volume "               "is tcp if option is not defined by the user ");
gf_msg("pmap", GF_LOG_INFO, 0, GD_MSG_BRICK_ADD,           "adding brick %s on port %d", brickname, port);
gf_msg("pmap", GF_LOG_INFO, 0, GD_MSG_BRICK_REMOVE,           "removing brick %s on port %d", brickname, p);
gf_msg("glusterd", GF_LOG_INFO, ENOTSUP, GD_MSG_UNSUPPORTED_VERSION,               "Client %s (%d -> %d) doesn't support required "               "op-version (%d). Rejecting volfile request.",               peerinfo->identifier, peerinfo->min_op_version,               peerinfo->max_op_version, volinfo->client_op_version);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MOUNT_REQ_RCVD,           "Received mount request for volume %s", volume);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEFRAG_STATUS_UPDATED,                   "received defrag status updated");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VERS_INFO,           "using the op-version %d", peer_op_version);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_VERS_INFO,               "Using Program %s, Num (%d), Version (%d)",               peerinfo->mgmt->progname, peerinfo->mgmt->prognum,               peerinfo->mgmt->progver);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_VERS_INFO,               "Using Program %s, Num (%d), Version (%d)",               peerinfo->peer->progname, peerinfo->peer->prognum,               peerinfo->peer->progver);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_VERS_INFO,               "Using Program %s, Num (%d), Version (%d)",               peerinfo->mgmt_v3->progname, peerinfo->mgmt_v3->prognum,               peerinfo->mgmt_v3->progver);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_LOG_ROTATE_REQ_RECVD,           "Received log rotate req "           "for volume %s",           volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_ALREADY_STOPPED,               "%s already stopped", service);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SNAPSHOT_PENDING,               "Snapshot is pending on %s:%s. "               "Hence not starting the brick",               brickinfo->hostname, brickinfo->path);
gf_msg(this->name, GF_LOG_NOTICE, 0, GD_MSG_RETRY_WITH_NEW_PORT,                   "Retrying to start brick %s with new port %d",                   brickinfo->path, port);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_VERS_MISMATCH,               "Version of volume %s differ. local version = %d, "               "remote version = %d on peer %s",               volinfo->volname, volinfo->version, version, hostname);
gf_msg(this->name, GF_LOG_INFO, 0,                   GD_MSG_QUOTA_CONFIG_VERS_MISMATCH,                   "Quota configuration versions of volume %s "                   "differ. local version = %d, remote version = "                   "%d on peer %s",                   volinfo->volname, volinfo->quota_conf_version, quota_version,                   hostname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "peer is possibly old version");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered MOUNTV3 successfully");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered MOUNTV1 successfully");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered NFSV3 successfully");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered NLM v4 successfully");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered NLM v1 successfully");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_DEREGISTER_SUCCESS,               "De-registered ACL v3 successfully");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SERVER_QUORUM_NOT_MET,                   "Skipping brick "                   "restart for volume %s as quorum is not met",                   volinfo->volname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SERVER_QUORUM_NOT_MET,                       "Skipping"                       " brick restart for volume %s as "                       "quorum is not met",                       volinfo->volname);
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_SECONDARY_URL_INVALID,                   "%s is not a valid secondary url.", secondary);
gf_msg(this1->name, GF_LOG_INFO, 0,                   GD_MSG_GET_STATEFILE_NAME_FAILED,                   "Unable to get"                   " statefile's name");
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_NO_STATEFILE_ENTRY,               "state-file entry is missing in config file."               "Not Restarting");
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_GSYNC_VALIDATION_FAIL,               GEOREP " start option validation failed ");
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_PIDFILE_NOT_FOUND,               "pid-file entry is missing in config file."               "Not Restarting");
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_GEO_REP_START_FAILED,               "Geo-Rep Session was not started between "               "%s and %s::%s. Not Restarting",               volinfo->volname, secondary_url, secondary_vol);
gf_msg(this1->name, GF_LOG_INFO, 0, GD_MSG_RECOVERING_CORRUPT_CONF,               "Recovering from a corrupted config. "               "Not Restarting. Use start (force) to "               "start the session between %s and %s::%s.",               volinfo->volname, secondary_url, secondary_vol);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_STATEDUMP_OPTS_RCVD,           "Received following statedump options: %s", dup_options);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_STATEDUMP_INFO,           "sending signal %d to brick with pid %d", sig, pid);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_STATEDUMP_INFO,           "Performing statedump on nfs server with "           "pid %d",           pid);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_STATEDUMP_INFO,           "Performing statedump on quotad with "           "pid %d",           pid);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_STALE_VOL_DELETE_INFO,                   "Deleting stale volume %s", volinfo->volname);
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "Couldn't get node index");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                   "Couldn't get client name");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_SET_FAILED,                   "Couldn't set client name");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get fuse-count");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get gfapi-count");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get rebalance-count");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get glustershd-count");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get quotad-count");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                       "Couldn't get snapd-count");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_TASK_ID_INFO,           "Generated task-id %s for key %s", uuid_str, key);
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_BRK_PORT_NO_ADD_INDO,               "adding dst-brick port no %d", dst_port);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_BAD_BRKORDER,           "Bad brick order found");
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_FAILED,               "auth allow list is not set");
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_FAILED,               "old auth allow list is not set, no need to replace the list");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SVC_ATTACH_FAIL,               "svc %s of volume %s attached successfully to pid %d", svc->name,               volinfo->volname, glusterd_proc_get_pid(&svc->proc));
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CONNECT_RETURNED,               "not connected yet");
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_ATTACH_INFO,           "adding svc %s (volume=%s) to existing "           "process with pid %d",           svc->name, volinfo->volname, glusterd_proc_get_pid(&svc->proc));
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_SVC_ATTACH_FAIL,                   "Volume %s "                   " is marked as stale, not attempting further shd svc attach "                   "attempts",                   volinfo->volname);
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DETACH_INFO,           "removing svc %s (volume=%s) from existing "           "process with pid %d",           svc->name, volinfo->volname, glusterd_proc_get_pid(&svc->proc));
gf_msg("glusterd", GF_LOG_INFO, 0, GD_MSG_OP_VERS_INFO,               "retrieved op-version: %d", conf->op_version);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_OP_VERS_SET_INFO,               "Detected new install. Setting"               " op-version to maximum : %d",               GD_OP_VERSION_MAX);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_OP_VERS_SET_INFO,               "Upgrade detected. Setting"               " op-version to minimum : %d",               GD_OP_VERSION_MIN);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_NEW_NODE_STATE_CREATION,                   "Creating a new node_state "                   "for volume: %s.",                   entry->d_name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_ALREADY_MOUNTED,               "brick_mount_path (%s) already mounted.", brick_mount_path);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MISSED_SNAP_LIST_EMPTY,                   "No missed snaps list.");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_SVC_STOP_SUCCESS,           "%s service is stopped", svc->name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_NODE_DISCONNECTED,                       "%s has disconnected "                       "from glusterd.",                       svc->name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_NODE_DISCONNECTED,                       "glustershd has disconnected from glusterd.");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_RETRIEVED_UUID,               "retrieved UUID: %s", uuid_utoa(priv->uuid));
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_GENERATED_UUID,           "generated UUID: %s", uuid_utoa(priv->uuid));
gf_msg("glusterd", GF_LOG_INFO, errno, GD_MSG_MODULE_NOT_INSTALLED,                   GEOREP " module not installed in the system");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_FILE_DESC_LIMIT_SET,                   "Maximum allowed open file descriptors "                   "set to 65536");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CLUSTER_RC_ENABLE,               "cluster-test-mode is enabled logdir is %s", dir_data->data);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CURR_WORK_DIR_INFO,           "Using %s as working directory", workdir);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_CURR_WORK_DIR_INFO,           "Using %s as pid file working "           "directory",           rundir);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_SET_FAILED,               "base-port override: %d", conf->base_port);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_SET_FAILED,               "max-port override: %d", conf->max_port);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_SET_FAILED,               "lock-timer override: %d", conf->mgmt_v3_lock_timeout);
gf_msg(this->name, GF_LOG_INFO, 0,                       GD_MSG_LOCALTIME_LOGGING_ENABLE,                       "localtime logging enable");
gf_msg(this->name, GF_LOG_INFO, 0,                       GD_MSG_LOCALTIME_LOGGING_DISABLE,                       "localtime logging disable");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MISSED_SNAP_GET_FAIL,               "No missed snaps");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_VERS_MISMATCH,                   "Version of volume %s differ. "                   "local version = %d, remote version = %d "                   "on peer %s",                   snap_volinfo->volname, snap_volinfo->version, version,                   hostname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MISSED_SNAP_PRESENT,               "Snapshot %s from peer %s missing on localhost", peer_snap_name,               hostname);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MISSED_SNAP_DELETE,               "Peer %s has missed a delete "               "on snap %s",               peername, peer_snap_name);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_QUORUM_COUNT_IGNORED,                       "Ignoring small quorum-count "                       "(%d) on dispersed volume",                       tmp);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_REPLACE_BRK_REQ_RCVD,           "Received replace brick req");
gf_msg(this->name, GF_LOG_INFO, 0,           (op == GD_OP_REPLACE_BRICK)               ? GD_MSG_REPLACE_BRK_COMMIT_FORCE_REQ_RCVD               : GD_MSG_RESET_BRICK_COMMIT_FORCE_REQ_RCVD,           "Received %s request.", gd_rb_op_to_str(cli_op));
gf_msg(this->name, loglevel, 0, GD_MSG_SNAPSHOT_OP_FAILED, "%s",               err_str);
gf_msg(this->name, loglevel, 0, GD_MSG_SNAP_CLONE_PREVAL_FAILED, "%s",               err_str);
gf_msg(this->name, loglevel, 0, GD_MSG_SNAPSHOT_OP_FAILED, "%s",               err_str);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_SNAPSHOT_PENDING,                   "snapshot was pending. lvm not present "                   "for brick %s:%s of the snap %s.",                   brickinfo->hostname, brickinfo->path,                   snap_vol->snapshot->snapname);
gf_msg(this->name, loglevel, 0, GD_MSG_SNAPSHOT_OP_FAILED, "%s",               err_str);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_OP_SUCCESS,               "Successfully marked "               "snap %s for decommission.",               snap->snapname);
gf_msg(this->name, GF_LOG_INFO, EINVAL, GD_MSG_SNAP_NOT_FOUND,               "Snapshot (%s) does not exist", name);
gf_msg(this->name, GF_LOG_INFO, 0,                       GD_MSG_MISSED_SNAP_STATUS_DONE,                       "Updating missed snap status "                       "for %s:%s=%s:%d:%s:%d as DONE",                       missed_snapinfo->node_uuid, missed_snapinfo->snap_uuid,                       snap_opinfo->snap_vol_id, snap_opinfo->brick_num,                       snap_opinfo->brick_path, snap_opinfo->op);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_MISSED_SNAP_STATUS_DONE,                   "Updating missed snap status "                   "for %s:%s=%s:%d:%s:%d as DONE",                   missed_snapinfo->node_uuid, missed_snapinfo->snap_uuid,                   snap_opinfo->snap_vol_id, snap_opinfo->brick_num,                   snap_opinfo->brick_path, snap_opinfo->op);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DUP_ENTRY,               "Duplicate entry. Not updating");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_LOCALTIME_LOGGING_ENABLE,                   "localtime logging enable");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_LOCALTIME_LOGGING_DISABLE,                   "localtime logging disable");
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_VOL_TRANSPORT_TYPE_CHANGE,                   "changing transport-type for volume %s to %s", volname,                   value);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,                   "No Volume name present. "                   "Locks have not been held.");
gf_msg(THIS->name, GF_LOG_INFO, 0, GD_MSG_DICT_GET_FAILED,               "force flag is not set");
gf_msg(THIS->name, GF_LOG_INFO, 0,                       GD_MSG_VOL_TYPE_CHANGING_INFO,                       "Changing the type of volume %s from "                       "'distribute' to 'replica'",                       volinfo->volname);
gf_msg(THIS->name, GF_LOG_INFO, 0,                           GD_MSG_REPLICA_COUNT_CHANGE_INFO,                           "Changing the replica count of "                           "volume %s from %d to %d",                           volinfo->volname, volinfo->replica_count,                           replica_count);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_ADD_BRICK_REQ_RECVD,           "Received add brick req");
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_SUCCESS,               "replica-count is %d", replica_count);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_SUCCESS,               "arbiter-count is %d", arbiter_count);
gf_msg(this->name, GF_LOG_INFO, 0, GD_MSG_REM_BRICK_REQ_RECVD,           "Received rem brick req");
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_FAILED,               "request to change replica-count to %d", replica_count);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_SUCCESS,                   "replica-count is set %d", replica_count);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_SUCCESS,                   "arbiter-count is set %d", arbiter_count);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_SUCCESS,                   "type is set %d, need to change it", type);
gf_msg(this->name, GF_LOG_INFO, errno, GD_MSG_DICT_GET_FAILED,               "changing replica count %d to %d on volume %s",               volinfo->replica_count, replica_count, volinfo->volname);
gf_msg(THIS->name, GF_LOG_INFO, 0, AFR_MSG_SUBVOLS_DOWN,               "All subvolumes are not up");
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_LOCAL_CHILD,               "selecting local read_child %s",               priv->children[child_index]->name);
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SUBVOL_UP,               "Subvolume '%s' came back up;
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_QUORUM_MET,                   "Client-quorum is met");
gf_msg(THIS->name, GF_LOG_INFO, 0, AFR_MSG_SUBVOLS_DOWN,               "no subvolumes up");
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_INTERNAL_LKS_FAILED,               "Blocking entrylks failed.");
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SELF_HEAL_INFO,           "performing data selfheal on %s", uuid_utoa(fd->inode->gfid));
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_FD_CTX_GET_FAILED,                   "unable to get fd ctx for fd=%p", local->fd);
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_FD_CTX_GET_FAILED,                   "unable to get fd ctx for fd=%p", local->fd);
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_INFO_COMMON,               "fd not open on any subvolumes. aborting.");
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SELF_HEAL_INFO,           "performing entry selfheal on %s", uuid_utoa(fd->inode->gfid));
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SELF_HEAL_INFO,           "performing metadata selfheal on %s", uuid_utoa(inode->gfid));
gf_msg(this->name, GF_LOG_INFO, -ret, AFR_MSG_SELF_HEAL_INFO,                   "Failed to set pending metadata xattr on child %d for %s", i,                   uuid_utoa(inode->gfid));
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SPLIT_BRAIN,                   "clear time "                   "split brain on %s",                   uuid_utoa(replies[source].poststat.ia_gfid));
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_THIN_ARB,                           "I am "                           "not the good shd. Skipping. "                           "SHD = %d.",                           healer);
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SELF_HEAL_INFO,               "starting full sweep on subvol %s",               afr_subvol_name(this, healer->subvol));
gf_msg(this->name, GF_LOG_INFO, 0, AFR_MSG_SELF_HEAL_INFO,               "finished full sweep on subvol %s",               afr_subvol_name(this, healer->subvol));
gf_msg(this->name, loglevel, 0, AFR_MSG_SELF_HEAL_INFO,           "%s %s selfheal on %s. "           "sources=%s sinks=%s",           status, type, uuid_utoa(gfid), sources_str, sinks_str);
gf_msg(ec->xl->name, GF_LOG_INFO, 0, EC_MSG_HEAL_FAIL,               "%s/%s: Not able to heal", uuid_utoa(parent->gfid), name);
gf_msg(ec->xl->name, GF_LOG_INFO, 0, EC_MSG_HEAL_FAIL,                   "Index entry needs to be purged for: %s ",                   uuid_utoa(loc->gfid));
gf_msg(ec->xl->name, GF_LOG_DEBUG, 0, EC_MSG_HEAL_FAIL,                   "Heal is not required for : %s ", uuid_utoa(loc->gfid));
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of 'GF_FOP_FSYNC'");
gf_msg(fop->xl->name, GF_LOG_DEBUG, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of 'GF_FOP_LOOKUP'");
gf_msg(fop->xl->name, GF_LOG_DEBUG, 0, EC_MSG_DICT_MISMATCH,               "Mismatching dictionary in "               "answers of 'GF_FOP_XATTROP'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_FD_MISMATCH,               "Mismatching fd in answers "               "of 'GF_FOP_OPENDIR': %p <-> %p",               dst->fd, src->fd);
gf_msg(this->name, GF_LOG_INFO, 0, EC_MSG_EC_UP,           "Going UP : Child UP = %s Child Notify = %s",           ec_bin(str1, sizeof(str1), ec->xl_up, ec->nodes),           ec_bin(str2, sizeof(str2), ec->xl_notify, ec->nodes));
gf_msg(this->name, GF_LOG_INFO, 0, EC_MSG_EC_DOWN,           "Going DOWN : Child UP = %s Child Notify = %s",           ec_bin(str1, sizeof(str1), ec->xl_up, ec->nodes),           ec_bin(str2, sizeof(str2), ec->xl_notify, ec->nodes));
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_DICT_MISMATCH,               "Mismatching dictionary in "               "answers of 'GF_FOP_GETXATTR'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_FD_MISMATCH,               "Mismatching fd in answers "               "of 'GF_FOP_OPEN': %p <-> %p",               dst->fd, src->fd);
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of 'GF_FOP_READLINK'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_VECTOR_MISMATCH,               "Mismatching vector in "               "answers of 'GF_FOP_READ'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of 'GF_FOP_READ'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of 'GF_FOP_STAT'");
gf_msg(this->name, GF_LOG_DEBUG, op_errno, EC_MSG_HEAL_FAIL,               "Heal failed");
gf_msg(this->name, GF_LOG_DEBUG, 0, EC_MSG_HEAL_SUCCESS,                   "Heal succeeded on %d/%d "                   "subvolumes",                   gf_bits_count(mask & ~(good | bad)),                   gf_bits_count(mask & ~good));
gf_msg(ec->xl->name, loglevel, 0, EC_MSG_CHILDS_INSUFFICIENT,           "Insufficient available children for this request: "           "Have : %d, Need : %u : Child UP : %s "           "Mask: %s, Healing : %s : %s ",           have, need, ec_bin(str1, sizeof(str1), ec->xl_up, ec->nodes),           ec_bin(str2, sizeof(str2), fop->mask, ec->nodes),           ec_bin(str3, sizeof(str3), fop->healing, ec->nodes),           ec_msg_str(fop));
gf_msg(fop->xl->name, fop_log_level(fop->id, op_errno), op_errno,               EC_MSG_SIZE_VERS_UPDATE_FAIL,               "Failed to update version and size. %s", ec_msg_str(fop));
gf_msg(healer->this->name, GF_LOG_DEBUG, 0, EC_MSG_HEAL_FAIL,               "Purging index for gfid %s:", uuid_utoa(loc.gfid));
gf_msg(this->name, GF_LOG_INFO, 0, EC_MSG_FULL_SWEEP_START,                   "starting full sweep on subvol %s",                   ec_subvol_name(this, healer->subvol));
gf_msg(this->name, GF_LOG_INFO, 0, EC_MSG_FULL_SWEEP_STOP,               "finished full sweep on subvol %s",               ec_subvol_name(this, healer->subvol));
gf_msg(ec->xl->name, GF_LOG_DEBUG, ENOMEM, EC_MSG_FILE_DESC_REF_FAIL,               "Failed to create and add stripe in cache");
gf_msg(xl->name, GF_LOG_INFO, 0, EC_MSG_EXTENSION_NONE,               "Not using any cpu extensions");
gf_msg(xl->name, GF_LOG_INFO, 0, EC_MSG_EXTENSION_NONE,                   "Not using any cpu extensions");
gf_msg(xl->name, GF_LOG_INFO, 0, EC_MSG_EXTENSION,                   "Using '%s' CPU extensions", gen->name);
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_LOCK_MISMATCH,               "Mismatching lock in "               "answers of 'GF_FOP_LK'");
gf_msg(fop->xl->name, GF_LOG_NOTICE, 0, EC_MSG_IATT_MISMATCH,               "Mismatching iatt in "               "answers of '%s'",               gf_fop_list[fop->id]);
gf_msg(fop->xl->name, GF_LOG_DEBUG, 0, EC_MSG_XDATA_MISMATCH,               "Mismatching xdata in answers "               "of '%s'",               ec_fop_name(fop->id));
gf_msg(this->name, op_errno, 0, 0, "subvolume %s returned -1",               prev->name);
gf_msg(this->name, GF_LOG_DEBUG, 0,                   DHT_MSG_HASHED_SUBVOL_GET_FAILED,                   "Failed to get hashed subvol for path %s"                   "gfid is %s ",                   local->loc.path, gfid_local);
gf_msg(this->name, GF_LOG_INFO, op_errno,                       DHT_MSG_REVALIDATE_CBK_INFO,                       "Revalidate: subvolume %s for %s "                       "(gfid = %s) returned -1",                       prev->name, local->loc.path, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LAYOUT_MISMATCH,                       "Mismatching layouts for %s, gfid = %s", local->loc.path,                       gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_UNLINK_LOOKUP_INFO,           "lookup_unlink returned with "           "op_ret -> %d and op-errno -> %d for %s",           op_ret, op_errno, ((path == NULL) ? "null" : path));
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_UNLINK_LOOKUP_INFO,           "lookup_unlink returned with "           "op_ret -> %d and op-errno -> %d for %s",           op_ret, op_errno, ((path == NULL) ? "null" : path));
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_UNLINK_LOOKUP_INFO,           "Returned with op_ret %d and "           "op_errno %d for %s",           op_ret, op_errno, ((path == NULL) ? "null" : path));
gf_msg(this->name, GF_LOG_INFO, 0,                           DHT_MSG_LAYOUT_PRESET_FAILED,                           "Could not set pre-set layout "                           "for subvolume %s",                           cached_subvol->name);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,                   "%s: no pre-set layout for subvolume %s,"                   " gfid = %s",                   local->loc.path,                   (cached_subvol ? cached_subvol->name : "<nil>"), gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,                   "%s: failed to set layout for subvol %s, "                   "gfid = %s",                   local->loc.path,                   (cached_subvol ? cached_subvol->name : "<nil>"), gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LAYOUT_PRESET_FAILED,                   "Failed to set layout for subvol %s"                   ", gfid = %s",                   cached_subvol ? cached_subvol->name : "<nil>", gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,                       "attempting deletion of stale linkfile "                       "%s on %s (hashed subvol is %s)",                       loc->path, prev->name,                       (local->hashed_subvol ? local->hashed_subvol->name                                             : "<null>"));
gf_msg(this->name, GF_LOG_INFO, op_errno, DHT_MSG_LINK_FILE_LOOKUP_INFO,               "Lookup of %s on %s (following linkfile) failed "               ",gfid = %s",               local->loc.path, subvol->name, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LINK_FILE_LOOKUP_INFO,               "Lookup of %s on %s (following linkfile) reached dir,"               " gfid = %s",               local->loc.path, subvol->name, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LINK_FILE_LOOKUP_INFO,               "lookup of %s on %s (following linkfile) reached link,"               "gfid = %s",               local->loc.path, subvol->name, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LAYOUT_PRESET_FAILED,               "Failed to set layout for subvolume %s,"               "gfid = %s",               prev->name, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_LAYOUT_PRESET_FAILED,                   "%s: could not set pre-set layout for subvolume %s",                   loc->path, prev->name);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,               "%s: No link subvol for linkto", loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_HASHED_SUBVOL_GET_FAILED,                   "Cannot determine MDS, fetching xattr %s randomly"                   " from a subvol for path %s ",                   key, loc->path);
gf_msg(this->name, GF_LOG_INFO, 0,                               DHT_MSG_HASHED_SUBVOL_DOWN,                               "MDS %s is down for path"                               " path %s so fetching xattr "                               "%s randomly from a subvol ",                               local->mds_subvol->name, loc->path, key);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_FIX_LAYOUT_INFO,               "fixing the layout of %s", loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_PARENT_LAYOUT_CHANGED,                   "create (%s/%s) (path: %s): parent layout "                   "changed. Attempting a layout refresh and then a "                   "retry",                   pgfid, local->loc.name, local->loc.path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,               "creating %s on %s (got create on %s)", local->loc.path,               subvol->name, loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_PARENT_LAYOUT_CHANGED,                   "mkdir (%s/%s) (path: %s): parent layout "                   "changed. Attempting a refresh and then a "                   "retry",                   pgfid, local->loc.name, local->loc.path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_INVALID_LINKFILE,                   "Linkfile does not have link subvolume. "                   "path = %s, gfid = %s",                   lookup_local->loc.path, gfid);
gf_msg(this->name, GF_LOG_DEBUG, 0, DHT_MSG_LOG_FIXED_LAYOUT, "%s",           output_string);
gf_msg("dht", GF_LOG_DEBUG, EINVAL, DHT_MSG_DICT_SET_FAILED,               "dht layout dict set failed");
_gf_msg(const char *domain, const char *file, const char *function,        int32_t line, gf_loglevel_t level, int errnum, int trace,        uint64_t msgid, const char *fmt, ...){    return 0;
gf_msg(this->name, GF_LOG_INFO, 0,                       DHT_MSG_SUBVOL_DECOMMISSION_INFO,                       "decommissioning subvolume %s",                       conf->subvolumes[i]->name);
gf_msg(this->name, GF_LOG_INFO, 0, 0,                       "rebal thread count configured to %d",                       rebal_thread_count);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_COMMIT_HASH_INFO,               "%s using commit hash %u", __func__, commit_hash);
gf_msg("switch", GF_LOG_INFO, 0, DHT_MSG_SWITCH_PATTERN_INFO,                   "'*' pattern will be taken by default "                   "for all the unconfigured child nodes,"                   " hence neglecting current option");
gf_msg(this->name, loglevel, op_errno,                   DHT_MSG_MIGRATE_HARDLINK_FILE_FAILED,                   "link of %s -> %s"                   " failed on  subvol %s",                   loc->name, uuid_utoa(loc->gfid), hashed_subvol->name);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "new target found - %s"               " for file - %s",               (*new_subvol)->name, loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "locks will be migrated"               " for file: %s",               loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, 0,                   "destination for file "                   "- %s is changed to - %s",                   loc->path, hashed_subvol->name);
gf_msg(this->name, log_level, 0, DHT_MSG_MIGRATE_FILE_COMPLETE,           "completed migration of %s from subvolume %s to %s", loc->path,           cached_subvol->name, hashed_subvol->name);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_MIGRATE_FILE_SKIPPED,                       "File migration skipped for %s.", entry_loc.path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_MIGRATE_FILE_SKIPPED,                   "File migration skipped for %s.", entry_loc.path);
gf_msg(this->name, GF_LOG_INFO, -ret, DHT_MSG_DIR_LOOKUP_FAILED,                   "Dir:%s renamed or removed. "                   "Skipping",                   loc->path);
gf_msg(this->name, GF_LOG_INFO, -ret, DHT_MSG_LAYOUT_FIX_FAILED,                   "Setxattr failed. Dir %s "                   "renamed or removed",                   loc->path);
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "local subvol: "               "%s",               conf->local_subvols[i]->name);
gf_msg(this->name, GF_LOG_INFO, 0, 0, "node uuid : %s",                   uuid_utoa(*uuid_ptr));
gf_msg(this->name, GF_LOG_INFO, 0, 0,               "local subvol: %s,"               "cnt = %" PRIu64,               conf->local_subvols[i]->name, size_files);
gf_msg(this->name, GF_LOG_INFO, 0, 0, "Total size files = %" PRIu64,           total_size);
gf_msg(THIS->name, GF_LOG_INFO, 0, 0,               "Rebalance estimates will not be available for the "               "first %d seconds.",               ESTIMATE_START_INTERVAL);
gf_msg("DHT", GF_LOG_INFO, 0, DHT_MSG_REBALANCE_STATUS,               "Rebalance is %s. Time taken is %.2f secs "               "Files migrated: %" PRIu64 ", size: %" PRIu64               ", lookups: %" PRIu64 ", failures: %" PRIu64               ", skipped: "               "%" PRIu64,               status, elapsed, files, size, lookup, failures, skipped);
gf_msg("", GF_LOG_INFO, 0, DHT_MSG_REBALANCE_STOPPED,           "Received stop command on rebalance");
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,               "Using specified subvol %s", local_volname);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,               "Using the first local "               "subvol %s",               xl->name);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,                   "Found local subvol, "                   "%s",                   candidate->name);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_SUBVOL_INFO,               "Unable to find local subvolume, switching "               "to dht mode");
gf_msg(this->name, GF_LOG_INFO, op_errno, DHT_MSG_RENAME_FAILED,               "Rename %s -> %s on %s failed, (gfid = %s)", local->loc.path,               local->loc2.path, prev->name, gfid);
gf_msg(this->name, GF_LOG_INFO, op_errno, DHT_MSG_RENAME_FAILED,               "rename %s -> %s on %s failed, (gfid = %s) ", local->loc.path,               local->loc2.path, prev->name, gfid);
gf_msg(this->name, GF_LOG_INFO, op_errno, DHT_MSG_OPENDIR_FAILED,               "opendir on %s for %s failed,(gfid = %s) ", prev->name,               local->loc.path, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_RENAME_FAILED,                   "Rename dir failed: subvolume down (%s)",                   conf->subvolumes[i]->name);
gf_msg(this->name, GF_LOG_INFO, op_errno, DHT_MSG_RENAME_FAILED,                   "%s: Rename (linkto file) on %s failed, "                   "(gfid = %s) ",                   local->loc.path, prev->name,                   local->loc.inode ? uuid_utoa(local->loc.inode->gfid) : "");
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_RENAME_FAILED,               "No hashed subvolume in layout for path=%s,"               "(gfid = %s)",               oldloc->path, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_RENAME_FAILED,               "No cached subvolume for path = %s,"               "(gfid = %s)",               oldloc->path, gfid);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_RENAME_FAILED,               "No hashed subvolume in layout for path=%s", newloc->path);
gf_msg(this->name, GF_LOG_INFO, 0, DHT_MSG_RENAME_INFO,           "renaming %s (%s) (hash=%s/cache=%s) => %s (%s) "           "(hash=%s/cache=%s) ",           oldloc->path, gfid, src_hashed->name, src_cached->name, newloc->path,           newloc->inode ? newgfid : NULL, dst_hashed->name,           dst_cached ? dst_cached->name : "<nul>");
gf_msg("md-cache", GF_LOG_TRACE, 0,                           MD_CACHE_MSG_DISCARD_UPDATE,                           "prebuf doesn't match the value we have cached,"                           " invalidate the inode(%s)",                           uuid_utoa(inode->gfid));
gf_msg(this->name, GF_LOG_DEBUG, 0, 0,               "Skipping xattr update due to empty value");
gf_msg(this->name, GF_LOG_DEBUG, 0, 0,               "Skipping xattr update due to empty value");
gf_msg("md-cache", GF_LOG_INFO, 0, MD_CACHE_MSG_NO_XATTR_CACHE,               "Disabled cache for all xattrs, as registering for "               "xattr cache invalidation failed");
gf_msg(this->name, GF_LOG_INFO, 0, MD_CACHE_MSG_NO_XATTR_CACHE,               "Disabled cache for all xattrs, as registering for "               "xattr cache invalidation failed");
gf_msg("quick-read", GF_LOG_INFO, 0, QUICK_READ_MSG_LRU_NOT_EMPTY,                   "quick read inode table lru not empty");
gf_msg(this->name, GF_LOG_INFO, 0,               READ_AHEAD_MSG_UNDESTROYED_FILE_FOUND,               "undestroyed read ahead file structures found");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_CHILD_STATUS_FAILED,               "No xlator %s is found in child status list", name);
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_CLIENT_OPVERSION_GET_FAILED,               "Failed to get client opversion");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_CLIENT_VERSION_NOT_SET,               "client-version not set, may be of older version");
gf_msg(this->name, GF_LOG_INFO, 0, PS_MSG_CLIENT_ACCEPTED,               "accepted client from %s (version: %s) with subvol %s",               client->client_uid, (clnt_version) ? clnt_version : "old", name);
gf_msg("", GF_LOG_INFO, ENOMEM, PS_MSG_NO_MEMORY,               "server_ctx_get() failed");
gf_msg("", GF_LOG_INFO, EBADF, PS_MSG_FD_NOT_FOUND,                   "fd not "                   "found in context");
gf_msg("", GF_LOG_INFO, EBADF, PS_MSG_FD_NOT_FOUND,                   "fd not "                   "found in context");
gf_msg(this->name, fop_log_level(GF_FOP_LOOKUP, op_errno), op_errno,                   PS_MSG_LOOKUP_INFO,                   "%" PRId64                   ": LOOKUP %s (%s/%s), client: %s, "                   "error-xlator: %s",                   frame->root->unique, state->loc.path,                   uuid_utoa(state->resolve.pargfid), state->resolve.bname,                   STACK_CLIENT_NAME(frame->root),                   STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_LOOKUP, op_errno), op_errno,                   PS_MSG_LOOKUP_INFO,                   "%" PRId64                   ": LOOKUP %s (%s), client: %s, "                   "error-xlator: %s",                   frame->root->unique, state->loc.path,                   uuid_utoa(state->resolve.gfid),                   STACK_CLIENT_NAME(frame->root),                   STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_LEASE, op_errno), op_errno,               PS_MSG_LK_INFO,               "%" PRId64 ": LEASE %s (%s), client: %s, error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_LK, op_errno), op_errno,               PS_MSG_LK_INFO,               "%" PRId64 ": LK %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_INODELK, op_errno), op_errno,               PS_MSG_INODELK_INFO,               "%" PRId64               ": INODELK %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FINODELK, op_errno), op_errno,               PS_MSG_INODELK_INFO,               "%" PRId64 ": FINODELK %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_ENTRYLK, op_errno), op_errno,               PS_MSG_ENTRYLK_INFO,               "%" PRId64               ": ENTRYLK %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FENTRYLK, op_errno), op_errno,               PS_MSG_ENTRYLK_INFO,               "%" PRId64 ": FENTRYLK %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_ACCESS_INFO,               "%" PRId64               ": ACCESS %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_DIR_INFO,               "%" PRId64               ": RMDIR %s (%s/%s), client: %s, "               "error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_MKDIR, op_errno), op_errno,               PS_MSG_DIR_INFO,               "%" PRId64               ": MKDIR %s (%s/%s) client: %s, "               "error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_MKNOD, op_errno), op_errno,               PS_MSG_MKNOD_INFO,               "%" PRId64               ": MKNOD %s (%s/%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FSYNCDIR, op_errno), op_errno,               PS_MSG_DIR_INFO,               "%" PRId64 ": FSYNCDIR %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_READDIR, op_errno), op_errno,               PS_MSG_DIR_INFO,               "%" PRId64 ": READDIR %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_OPENDIR, op_errno), op_errno,               PS_MSG_DIR_INFO,               "%" PRId64               ": OPENDIR %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, loglevel, op_errno, PS_MSG_REMOVEXATTR_INFO,               "%" PRId64               ": REMOVEXATTR %s (%s) of key %s, client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), state->name,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FREMOVEXATTR, op_errno),               op_errno, PS_MSG_REMOVEXATTR_INFO,               "%" PRId64 ": FREMOVEXATTR %" PRId64               " (%s) (%s), "               "client: %s, error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), state->name,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_GETXATTR, op_errno), op_errno,               PS_MSG_GETXATTR_INFO,               "%" PRId64               ": GETXATTR %s (%s) (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), state->name,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FGETXATTR, op_errno), op_errno,               PS_MSG_GETXATTR_INFO,               "%" PRId64 ": FGETXATTR %" PRId64               " (%s) (%s), "               "client: %s, error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), state->name,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(THIS->name, GF_LOG_INFO, 0, PS_MSG_SETXATTR_INFO,           "%" PRId64           ": SETXATTR %s (%s) ==> %s, client: %s, "           "error-xlator: %s",           frame->root->unique, state->loc.path, uuid_utoa(state->resolve.gfid),           k, STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(THIS->name, GF_LOG_INFO, op_errno, PS_MSG_SETXATTR_INFO,                   "client: %s, "                   "error-xlator: %s",                   STACK_CLIENT_NAME(frame->root),                   STACK_ERR_XL_NAME(frame->root));
gf_msg(THIS->name, GF_LOG_INFO, 0, PS_MSG_SETXATTR_INFO,           "%" PRId64 ": FSETXATTR %" PRId64           " (%s) ==> %s, client: %s, "           "error-xlator: %s",           frame->root->unique, state->resolve.fd_no,           uuid_utoa(state->resolve.gfid), k, STACK_CLIENT_NAME(frame->root),           STACK_ERR_XL_NAME(frame->root));
gf_msg(THIS->name, GF_LOG_INFO, op_errno, PS_MSG_SETXATTR_INFO,                   "client: %s, "                   "error-xlator: %s",                   STACK_CLIENT_NAME(frame->root),                   STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_RENAME_INFO,               "%" PRId64               ": RENAME %s (%s/%s) -> %s (%s/%s), "               "client: %s, error-xlator: %s",               frame->root->unique, state->loc.path, oldpar_str,               state->resolve.bname, state->loc2.path, newpar_str,               state->resolve2.bname, STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_UNLINK, op_errno), op_errno,               PS_MSG_LINK_INFO,               "%" PRId64               ": UNLINK %s (%s/%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_LINK_INFO,               "%" PRId64               ": SYMLINK %s (%s/%s), client: %s, "               "error-xlator:%s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_LINK_INFO,               "%" PRId64               ": LINK %s (%s) -> %s/%s, client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path, gfid_str, newpar_str,               state->resolve2.bname, STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_TRUNCATE_INFO,               "%" PRId64               ": TRUNCATE %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FSTAT, op_errno), op_errno,               PS_MSG_STAT_INFO,               "%" PRId64 ": FSTAT %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FTRUNCATE, op_errno), op_errno,               PS_MSG_TRUNCATE_INFO,               "%" PRId64 ": FTRUNCATE %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FLUSH, op_errno), op_errno,               PS_MSG_FLUSH_INFO,               "%" PRId64 ": FLUSH %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FSYNC, op_errno), op_errno,               PS_MSG_SYNC_INFO,               "%" PRId64 ": FSYNC %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_WRITE, op_errno), op_errno,               PS_MSG_WRITE_INFO,               "%" PRId64 ": WRITEV %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_READ, op_errno), op_errno,               PS_MSG_READ_INFO,               "%" PRId64 ": READV %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_RCHECKSUM, op_errno), op_errno,               PS_MSG_CHKSUM_INFO,               "%" PRId64 ": RCHECKSUM %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_OPEN, op_errno), op_errno,               PS_MSG_OPEN_INFO,               "%" PRId64 ": OPEN %s (%s), client: %s, error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_CREATE_INFO,               "%" PRId64               ": CREATE %s (%s/%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.pargfid), state->resolve.bname,               STACK_CLIENT_NAME(frame->root), STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_LINK_INFO,               "%" PRId64               ": READLINK %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_STAT, op_errno), op_errno,               PS_MSG_STAT_INFO,               "%" PRId64 ": STAT %s (%s), client: %s, error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_SETATTR_INFO,               "%" PRId64               ": SETATTR %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, (state->loc.path) ? state->loc.path : "",               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FSETATTR, op_errno), op_errno,               PS_MSG_SETATTR_INFO,               "%" PRId64 ": FSETATTR %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_XATTROP, op_errno), op_errno,               PS_MSG_XATTROP_INFO,               "%" PRId64               ": XATTROP %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FXATTROP, op_errno), op_errno,               PS_MSG_XATTROP_INFO,               "%" PRId64 ": FXATTROP %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_READDIRP, op_errno), op_errno,               PS_MSG_DIR_INFO,               "%" PRId64 ": READDIRP %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_FALLOCATE, op_errno), op_errno,               PS_MSG_ALLOC_INFO,               "%" PRId64 ": FALLOCATE %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_DISCARD, op_errno), op_errno,               PS_MSG_DISCARD_INFO,               "%" PRId64 ": DISCARD %" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_ZEROFILL, op_errno), op_errno,               PS_MSG_ZEROFILL_INFO,               "%" PRId64 ": ZEROFILL%" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, PS_MSG_SERVER_IPC_INFO,               "%" PRId64 ": IPC%" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, fop_log_level(GF_FOP_SEEK, op_errno), op_errno,               PS_MSG_SEEK_INFO,               "%" PRId64 ": SEEK%" PRId64               " (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->resolve.fd_no,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, 0,               "%" PRId64               ": SETACTIVELK %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(this->name, GF_LOG_INFO, op_errno, 0,               "%" PRId64               ": GETACTIVELK %s (%s), client: %s, "               "error-xlator: %s",               frame->root->unique, state->loc.path,               uuid_utoa(state->resolve.gfid), STACK_CLIENT_NAME(frame->root),               STACK_ERR_XL_NAME(frame->root));
gf_msg(req->trans->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(req->trans->name, GF_LOG_INFO, 0, PS_MSG_SERVER_CTX_GET_FAILED,               "server_ctx_get() "               "failed");
gf_msg(trav->name, GF_LOG_TRACE, 0, LG_MSG_VOL_OPTION_ADD,                           "adding option '%s' for "                           "volume '%s' with value '%s'",                           cmd_option->key, trav->name, cmd_option->value);
gf_msg(xl->name, GF_LOG_DEBUG, 0, LG_MSG_XLATOR_OPTION_INVALID,               "option '%s' is not recognized", key);
gf_msg("glusterfs", GF_LOG_INFO, 0, LG_MSG_GRAPH_CLEANUP_FAILED,                   "cond wait failed ");
gf_msg("mgmt", GF_LOG_INFO, 0, LG_MSG_GRAPH_DETACH_STARTED,               "detaching child %s", volfile_obj->vol_id);
gf_msg("mgmt", GF_LOG_INFO, 0, LG_MSG_GRAPH_ATTACH_PID_FILE_UPDATED,               "Old pid=%d found in pidfile %s. Cleaning the old pid and "               "Updating new pid=%d",               old_pid, pid_file, pid);
gf_msg("mgmt", GF_LOG_INFO, 0, LG_MSG_GRAPH_ATTACH_PID_FILE_UPDATED,               "PID %d updated in pidfile=%s", getpid(), file);
gf_msg("libglusterfs", GF_LOG_INFO, errno,                   LG_MSG_READ_ATTRIBUTE_FAILED,                   "Couldn't read "                   "extended attribute for the file %d",                   fd);
gf_msg("libglusterfs", GF_LOG_INFO, errno,                   LG_MSG_READ_ATTRIBUTE_FAILED,                   "Couldn't read "                   "extended attribute for the file %s",                   path);
gf_msg("event-history", GF_LOG_INFO, 0, LG_MSG_INVALID_ARG,               "history for the xlator is NULL");
_gf_msg(const char *domain, const char *file, const char *function,        int32_t line, gf_loglevel_t level, int errnum, int trace,        uint64_t msgid, const char *fmt, ...){    int ret = 0;
ret = _gf_msg(domain, file, function, line, level, 0, trace, msgid, "%s",                  msg);
gf_msg(GF_PARSE, GF_LOG_INFO, 0, LG_MSG_REGEX_OP_FAILED,               "Failed to compile regex pattern.");
gf_msg(THIS->name, GF_LOG_INFO, 0, LG_MSG_DISCONNECT_CLIENT,               "Shutting down connection %s", client->client_uid);